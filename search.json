[{"title":"Best practices for writing Dockerfiles","url":"/docker/best-practices-for-writing-dockerfiles/","content":"\n\n\nGeneral guidelines and recommendations (一般准则和建议)\nCreate ephemeral containers (创建临时容器)\nUnderstand build context (理解构建上下文)\nPipe Dockerfile through stdin (通过 stdin 管道化 Dockerfile)\nBuild an image using a Dockerfile from stdin, without sending build context (使用来自 stdin 的 Dockerfile 构建镜像, 不发送构建上下文)\nBuild from a local build context, using a Dockerfile from stdin (从本地构建上下文进行构建, 使用来自 stdin 的 Dockerfile)\nBuild from a remote build context, using a Dockerfile from stdin (使用来自 stdin 的 Dockerfile, 从一个远程构建上下文进行构建)\n\n\nExclude with .dockerignore (使用 .dockerignore 进行排除)\nUse multi-stage builds (使用多阶段构建)\nDon’t install unnecessary packages (不要安装不必要的包)\nDecouple applications (解耦应用程序)\nMinimize the number of layers (最小化层的数量)\nSort multi-line arguments (排序多行参数)\nLeverage build cache (利用构建缓存)\n\n\nDockerfile instructions (Dockerfile 指令)\nFROM (FROM 指令)\nLABEL (LABEL 指令)\nRUN (RUN 指令)\napt-get\nUsing pipes (使用管道)\n\n\nCMD (CMD 指令)\nEXPOSE (EXPOSE 指令)\nENV (ENV 指令)\nADD or COPY (ADD 或 COPY 指令)\nENTRYPOINT (ENTRYPOINT 指令)\nVOLUME (VOLUME 指令)\nUSER (USER 指令)\nWORKDIR (WORKDIR 指令)\nONBUILD (ONBUILD 指令)\n\n\n参考\n\n\n\n当运行一个镜像并生成一个容器时, 添加了一个新的可写 (writable) 层 (容器层 (container layer)) 到下面的层的最上面\n所有对于运行中容器的修改, 例如写入新文件, 修改已存在的文件, 删除文件, 都是写入到这个容器层\nGeneral guidelines and recommendations (一般准则和建议)Create ephemeral containers (创建临时容器)尽量创建 “短暂的&#96; 容器\n“短暂的” 意味着无状态的, 可以随时停止, 启动和重启的容器\n尽量创建轻量级, 无依赖或最小依赖的容器\nUnderstand build context (理解构建上下文)默认情况下, 以执行 docker build 命令的当前工作目录作为构建上下文, 并使用当前工作目录中的 Dockerfile\n可以使用 -f 标志来指定 Dockerfile 的位置. 就算指定了 -f 标志, 默认情况下还是将当前工作目录中的文件目录及其递归文件目录发送给 Docker daemon 作为构建上下文\n./myproject├── context│   └── hello└── dockerfiles    └── Dockerfile\n\ndocker build --no-cache -t helloapp:v2 -f dockerfiles/Dockerfile context\n\n\n-f dockerfiles/Dockerfile - 指定了 Dockerfile 文件的位置\ncontext - 指定了构建上下文 (build context)\n\nPipe Dockerfile through stdin (通过 stdin 管道化 Dockerfile)可以通过 stdin 来传递 Dockerfile 给 docker build\necho -e &#x27;FROM busybox\\nRUN echo &quot;hello world&quot;&#x27; | docker build -\n\necho -e 启用反斜杠转义\ndocker build -&lt;&lt;EOFFROM busyboxRUN echo &quot;hello world&quot;EOF\n\nBuild an image using a Dockerfile from stdin, without sending build context (使用来自 stdin 的 Dockerfile 构建镜像, 不发送构建上下文)docker build [OPTIONS] -\n\n这个语法使用来自 stdin 的 Dockerfile 构建镜像, 不发送额外的文件作为构建上下文\n- 代替了 PATH 的位置, 并指示 Docker 从 stdin (只包含一个 Dockerfile) 而不是从一个目录中读取构建上下文\ndocker build -t myimage:latest -&lt;&lt;EOFFROM busyboxRUN echo &quot;hello world&quot;EOF\n\n上面的例子使用通过 stdin 传递的 Dockerfile 构建镜像. 没有文件作为构建上下文发送给 daemon\n在你的 Dockerfile 不需要复制文件到镜像中时去掉构建上下文非常有用, 这样可以提高构建速度, 因为没有文件需要发送给 daemon\n如果以 stdin 传递 Dockerfile 但又使用了 COPY&#x2F;ADD 指令, 构建将会报错\nBuild from a local build context, using a Dockerfile from stdin (从本地构建上下文进行构建, 使用来自 stdin 的 Dockerfile)docker build [OPTIONS] -f- PATH\n\n这个语法使用你本地文件系统上的文件来构建镜像, 当使用来自 stdin 的 Dockerfile\n这个语法使用 -f (或 --file) 选项来指定使用哪个 Dockerfile, 使用 - 作为文件名来指示 Docker 从 stdin 中读取 Dockerfile\nExample:\n# build an image using the current directory as context, and a Dockerfile passed through stdindocker build -t myimage:latest -f- . &lt;&lt;EOFFROM busyboxCOPY somefile.txt ./RUN cat /somefile.txtEOF\n\n使用当前目录作为上下文构建镜像, 并从 stdin 传递 Dockerfile\nBuild from a remote build context, using a Dockerfile from stdin (使用来自 stdin 的 Dockerfile, 从一个远程构建上下文进行构建)docker build [OPTIONS] -f- PATH\n\n这个语法使用远程 Git 仓库中的文件构建镜像, 读取来自 stdin 的 Dockerfile\n这个语法使用 -f (或 --file) 选项来指定使用哪个 Dockerfile, 使用 - 作为文件名来指示 Docker 从 stdin 中读取 Dockerfile\n这个语法在你从一个没有 Dockerfile 的仓库中进行构建时很有用, 或者你想要使用自定义的 Dockerfile 进行构建而不需要维护这个仓库的分支\nExample:\ndocker build -t myimage:latest -f- https://github.com/docker-library/hello-world.git &lt;&lt;EOFFROM busyboxCOPY hello.c ./EOF\n\n上述例子使用来自 stdin 的 Dockerfile, 添加来自 “hello-world”  Git 仓库中的 hello.c 文件到镜像中\n在背后: 当使用一个远程 Git 仓库作为上下文进行镜像构建时, Docker 在本地机器上执行这个仓库的 git clone 命令, 并将这些文件作为构建上下文发送给 daemon. 所以这个功能要求 git 要安装在你运行 docker build 命令的主机上\nExclude with .dockerignore (使用 .dockerignore 进行排除)使用 .dockerignore 文件来排除掉不是关联到构建中的文件\nUse multi-stage builds (使用多阶段构建)多阶段构建 剧烈地减少最终镜像的大小而不用挣扎于减少中间层和文件数量\n因为镜像在构建进程的最终阶段被构建, 所以可以通过利用构建缓存来最小化镜像层\n如果你的构建包含多层, 可以将它们以 最少修改(确保重用了缓存) 到 最常修改 的顺序进行排序:\n\n安装构建应用程序需要的工具\n安装或更新库依赖\n生成你的应用程序\n\nExample - 一个 Go 应用程序的 Dockerfile:\n# syntax=docker/dockerfile:1FROM golang:1.16-alpine AS build# 为项目安装需要的工具# 运行 `docker build --no-cache .` 来更新依赖RUN apk add --no-cache gitRUN go get github.com/golang/dep/cmd/dep# 使用 Gopkg.toml 和 Gopkg.lock 列出项目依赖# 这些层只有在 Gopkg 文件更新时才重新构建COPY Gopkg.lock Gopkg.toml /go/src/project/WORKDIR /go/src/project/# 安装依赖库RUN dep ensure -vendor-only# 复制整个项目并构建# 项目目录中的文件改变时会重新构建这个层COPY ./go/src/project/RUN go build -o /bin/project# 这会生成一个单层的镜像FROM scratchCOPY --from=build /bin/project /bin/projectENTRYPOINT [&quot;/bin/project&quot;]CMD [&quot;--help&quot;]\n\nDon’t install unnecessary packages (不要安装不必要的包)为了减小复杂度, 依赖, 文件大小和构建时间, 避免安装额外或不必要的包\nDecouple applications (解耦应用程序)每个应用程序应该只有一个关注点\n解耦应用程序为多个容器使得横向扩展与重用容器更加容易\n例如, 一个 web 应用程序栈可能包含三个分开的容器, 每个容器都有自己唯一的镜像, 以解耦的方式来管理 web 应用程序, 数据库和一个基于内存的缓存\n将每个容器限制为一个进程是一个很好的经验法则, 但这并不是硬性规定. 例如, 不止容器可以通过 init 进程来生成, 一些程序本身也会生成进程. 例如, Celery 可以产生多个工作进程, 而 Apache 可以为每个请求创建一个进程\n使用你最好的判断力来保持容器尽可能干净和模块化\n如果容器彼此依赖, 你可以使用 Docker 容器网络 来确保这些容器之间可以通信\nMinimize the number of layers (最小化层的数量)只有 RUN, COPY, ADD 指令会创建层. 其他指令创建临时中间镜像, 不会增加构建的大小\n当可能的时候, 使用 多阶段构建, 并且只复制你需要的构件到最终镜像中. 这使得你将工具和调试信息包含到中间构建阶段而不会增加最终镜像的大小\nSort multi-line arguments (排序多行参数)只要有可能, 通过按字母数字排序多行参数来简化以后的更改. 这有助于避免包的重复并不使列表更新更容易. 这也有助于 PR 进行阅读和审查. 在 \\ 添加一个空格也会有帮助\nExample:\nRUN apt-get update &amp;&amp; apt-get install -y \\  bzr \\  cvs \\  git \\  mercurial \\  subversion \\  &amp;&amp; rm -rf /var/lib/apt/lists/*\n\nLeverage build cache (利用构建缓存)在 docker build 命令上使用 --no-cache=true 选项来关闭缓存\n使用如下规则来判断是否使用缓存:\n\n从已经存在于缓存中的父镜像开始, 将下一条指令与从该基础镜像派生的所有子镜像进行比较, 以查看其中一个是否使用相同的指令构建的. 如果不是, 则缓存无效\n在大多数情况下, 只需将 Dockerfile 中的指令与其中一个子镜像进行比较就足够了. 但是, 某些指令需要更多的检查和解释\n对于 ADD 和 COPY 指令, 检查镜像中的文件的内容并为每个文件计算校验和. 这些校验和中不考虑文件的最后修改和最后范围时间. 在查找缓存期间, 将检验和与现有镜像中的校验和进行比较. 如果文件中有任何更改, 例如内容和元数据, 则缓存无效\n除了 ADD 和 COPY 指令之外, 缓存检查不会查看容器中的文件来确定缓存匹配. 例如, 在处理 RUN apt-get -y update 命令时, 不会检查容器中更新的文件以确定是否存在缓存命中. 在这种情况下, 只有命令字符串本身用于查找匹配项\n\n一旦缓存失效, 所有后续的 Dockerfile 命令都会生成新的镜像并且不会使用缓存\nDockerfile instructions (Dockerfile 指令)FROM (FROM 指令)尽量使用最新的官方镜像作为你的镜像的基础镜像\n推荐使用 Alpine 镜像, 因为它受到严格控制且体积非常小 (当前小于 6 MB), 同时仍然是一个完整的 Linux 发行版\nLABEL (LABEL 指令)可以为镜像添加标签来帮助通过项目组织镜像, 记录授权信息, 帮助自动化等等\n可以添加多个 LABEL\n在 Docker 1.10 前, 推荐只使用一个 LABEL, 这是为了防止每个 LABEL 生成一个额外的层\n# Set one or more individual labelsLABEL com.example.version=&quot;0.0.1-beta&quot;LABEL vendor1=&quot;ACME Incorporated&quot;LABEL vendor2=ZENITH\\ IncorporatedLABEL com.example.release-date=&quot;2015-02-12&quot;LABEL com.example.version.is-production=&quot;&quot;\n\n# Set multiple labels on one lineLABEL com.example.version=&quot;0.0.1-beta&quot; com.example.release-date=&quot;2015-02-12&quot;\n\n# Set multiple labels at once, using line-continuation characters to break long linesLABEL vendor=ACME\\ Incorporated \\      com.example.is-beta= \\      com.example.is-production=&quot;&quot; \\      com.example.version=&quot;0.0.1-beta&quot; \\      com.example.release-date=&quot;2015-02-12&quot;\n\nRUN (RUN 指令)将长或复杂的 RUN 语句拆分为用反斜杠 \\ 分隔的多行, 以使您的 Dockerfile 更具可读性, 可理解性和可维护性\napt-getRUN 最常见的用例可能是 apt-get 的应用程序. 因为用它来安装软件包，所以 RUN apt-get 命令有几个需要注意的问题\nExample - 总是在同一个 RUN 语句中将 RUN apt-get update 和 apt-get install 结合在一起:\nRUN apt-get upadte &amp;&amp; apt-get install -y \\    package-bar \\    package-baz \\    package-foo \\    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\nrm -rf /var/lib/apt/lists/* 命令用来清理 apt 缓存, 减少镜像大小, 因为 apt 的缓存没有保存在一个层里面了\nUsing pipes (使用管道)RUN wget -O - https://some.site | wc -l &gt; /number\n\nDocker 使用 /bin/sh -c 翻译器来执行这些命令, 这个翻译器只会评估管道中最后一个操作的退出码来判断是否成功\n例如上面的例子, 如果 wc 命令成功则认为构建阶段成功并生成一个新的镜像, 即使 wget 命令失败了\n如果你希望命令因为管道中的任意阶段的错误而失败, 前置 set -o pipefail &amp;&amp; 来确保意外错误不会导致构建无意中成功:\nRUN set -o pipefail &amp;&amp; wget -O - https://some.site | wc -l /number\n\n注意: 不是所有 shell 都支持 -o pipefail 选项\n考虑使用 RUN 的 exec 形式来明确指定一个支持 pipefial 选项的 shell:\nRUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;set -o pipefail &amp;&amp; wget -O - https://some.site | wc -l /number&quot;]\n\nCMD (CMD 指令)CMD 指令应该用于使用任何参数运行镜像中包含的软件\nCMD 应该总是使用 CMD [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;...] 的形式\n因此如果镜像是用作一个服务, 例如 Apache 和 Rails, 可以像这样 CMD [&quot;apache2&quot;, &quot;-DFOREGROUND&quot;]\n事实上，这种形式的指令推荐用于任何基于服务的镜像\n在大多情况下, CMD 应该给定一个交互式 shell, 例如 bash, python 或 perl\n例如, CMD [&quot;perl&quot;, &quot;-de0&quot;], CMD [&quot;python&quot;], CMD [&quot;php&quot;, &quot;-a&quot;]\n使用这种形式意味着当你执行 docker run -ti python 时, 你会进入到一个可使用的 shell 中\nCMD 应该极少地以 CMD [&quot;param&quot;, &quot;param&quot;] 的方式与 ENTRYPOINT 一起使用, 除非你和你的预期用户已经非常熟悉 ENTRYPOINT 的工作方式\nEXPOSE (EXPOSE 指令)EXPOST 指令指明容器在哪个端口上监听连接\n因此, 应该为你的应用程序使用通用的传统的端口\n例如, Apache web server 应该使用 EXPOSE 80, MongoDB 应该使用 EXPOSE 27017\n对于外部访问, 你的用户可以使用带有一个标志的 docker run 命令, 这个标志指示了怎样映射指定端口到他们选择的端口上\n对于容器链接, Docker 为 从 接收容器 到 源容器的路径 提供了环境变量 (例如, MYSQL_PORT_3306_TCP)\nENV (ENV 指令)为了让新的软件更易于使用, 你可以使用 ENV 来为你的容器中安装的软件更新 PATH 环境变量. 例如, ENV PATH=/usr/local/nginx/bin:$PATH 确保 CMD [&quot;nginx&quot;] 正常工作\nENV 指令还可用于提供 特定于你想要容器化的服务 所需的 环境变量, 例如 Postgres 的 PGDATA\n最后, ENV 还可以用来设置常用的版本号, 使版本变化更容易维护:\nENV PG_MAJOR=9.3ENV PG_VERSION=9.3.4RUN curl -SL https://example.com/postgres-$PG_VERSION.tar.xz | tar -xJC /usr/src/postgres &amp;&amp; ...ENV PATH=/usr/local/postgres-$PG_MAJOR/bin:$PATH\n\n类似于在程序中的常量 (与硬编码值相反), 这种方法允许你改变单个 ENV 指令来自动神奇地提升容器中软件的版本\n每个 ENV 行创建一个新的中间层, 就像 RUN 命令. 这意味着即使你在后面的的层中取消 (unset) 环境变量, 这个环境变量还会持久化在这个层中且它的值可以被转存 (dumped). 你可以通过创建一个 Dockerfile 并构建它来测试一下:\n# syntax=docker/dockerfile:1FRO alpineENV ADMIN_USER=&quot;mark&quot;RUN echo $ADMIN_USER &gt; ./markRUN unset ADMIN_USER\n\n$ docker run --rm test sh -c &#x27;echo $ADMIN_USER&#x27;mark\n\n为了避免这样并真正地 unset 环境变量, 使用带有 shell 命令的 RUN 命令来在单个层中 set, use, unset 这个变量\n可以使用 ; 或 &amp;&amp; 来分隔你的命令. 如果使用 &amp;&amp;, 且任何一个命令失败, docker build 也会跟着失败. 这通常是个好主意\n使用 \\ 作为行持续字符来为 Linux Dockerfiles 提高可读性\n你也可以将所有的命令保存到一个 shell 脚本中, 然后使用 RUN 命令来运行这个 shell 脚本:\n# syntax=docker/dockerfile:1FROM alpineRUN export ADMIN_USER=&quot;mark&quot; \\    &amp;&amp; echo $ADMIN_USER &gt; ./mark \\    &amp;&amp; unset ADMIN_USERCMD sh\n\nADD or COPY (ADD 或 COPY 指令)虽然 ADD 和 COPY 功能相似, 总的来说, 推荐使用 COPY\n这是因为 COPY 比 ADD 更加透明\nCOPY 只支持基础的将本地文件复制到容器中\n但是 ADD 还有一些不是很明显的额外的功能 (像是仅限本地的 tar 文件解压缩和远程 URL 获取)\n因此, ADD 的最佳用途是将本地 tar 文件自动提取到镜像中, 例如: ADD rootfs.tar.xz /\n如果你有多个 Dockerfile 步骤使用了来自你的上下文中的不同文件, 单独 COPY 它们, 而不是一次性全部 COPY. 这确保了每个步骤的构建缓存仅在特定的需要的文件发生改变时才失效 (强制重新运行该步骤)\nExample:\nCOPY Requirements.txt /tmp/RUN pip install --requirement /tmp/requirements.txtCOPY . /tmp/\n\n与将 COPY . /tmp/ 放在前面相比, RUN 步骤导致的缓存失效更少. 因为 COPY . /tmp/ 将更多的文件进行了复制\n因为镜像大小很重要, 所以强烈建议不要使用 ADD 从远程 URLs 获取包; 应该改成使用 curl 或 wget\n这样, 可以在提取文件之后删除不再需要的文件且不必在镜像中添加另外一层\nExample - 避免这样做:\nADD https://example.com/big.tar.xz /usr/src/things/RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/thingsRUN make -C /usr/src/things all\n\n相反地, 要这样做:\nRUN mkdir -p /usr/src/things \\    &amp;&amp; curl -SL https://example.com/big.tar.xz \\    | tar -xJC /usr/src/things \\    &amp;&amp; make -C /usr/src/things all\n\n对于其他的不需要使用 ADD 的自动抽取功能的项目 (文件, 目录), 应该总是使用 COPY\nENTRYPOINT (ENTRYPOINT 指令)ENTRYPOINT 的最佳用途是设置镜像的主命令, 使得镜像 像 该命令一样 运行 (然后使用 CMD 作为默认标志)\nExample - 使用 s3cmd 命令行工具:\nENTRYPOINT [&quot;s3cmd&quot;]CMD [&quot;--help&quot;]\n\n现在镜像可以像这样运行来展示命令帮助信息: $ docker run s3cmd\n或者使用正确的参数来执行命令: $ docker run s3cmd ls s3://mybucket\n如同上面的命令所示的, 这非常有用, 因为镜像的名称可以兼作对二进制文件的引用\nENTRYPOINT 指令也可以与帮助脚本结合使用, 允许它以与上述命令类似的方式运行, 即使在启动工具时可能需要多个步骤\n例如, Postgres 官方镜像 使用如下脚本作为它的 ENTRYPOINT:\n#!/bin/bashset -eif [ &quot;$1&quot; = &#x27;postgres&#x27; ]; then    chown -R postgres &quot;$PGDATA&quot;    if [ -z &quot;$(ls -A &quot;$PGDATA&quot;)&quot; ]; then        gosu postgres initdb    fi    exec gosu postgres &quot;$@&quot;fiexec &quot;$@&quot;\n\n这个帮助脚本被复制到容器中, 且在容器启动时通过 ENTRYPOINT 运行:\nCOPY ./docker-entrypoint.sh /ENTRYPOINT [&quot;/docker-entrypoint.sh&quot;]CMD [&quot;postgres&quot;]\n\n这个脚本允许用户以多种方式和 Postgres 进行交互\n简单地启动 Postgres: $ docker run postgres\n运行 Postgres 并传递参数给 server: $ docker run postgres postgres --help\n最后它还可以用来启动一个完全不同的工具, 例如: $ docker run --rm -it postgres bash\nVOLUME (VOLUME 指令)VOLUME 指令应该用来公开任何数据库存储区域, 配置存储或者由 docker 容器创建的文件&#x2F;文件夹\n强烈建议将 VOLUME 用于镜像的任何 可变的 和&#x2F;或 用户可维护的 部分\nUSER (USER 指令)如果一个服务可以不需要权限来运行, 使用 USER 改成一个非 root 用户\n通过在 Dockerfile 中创建用户和用户组来开始, 使用类似这样的指令: RUN groupadd -r postgres &amp;&amp; useradd --no-log-init -r -g postgres postgre\n注意, 考虑明确的 UID&#x2F;GID: 镜像中的用户和用户组被分配了一个不确定的 UID&#x2F;GID, 因为无论镜像如何重建, 都会分配 “下一个” UID&#x2F;GID. 所以, 如果它很关键, 应该分配一个显示的 UID&#x2F;GID\n由于 Go archive&#x2F;tar 包的处理稀疏文件的一个未解决的 bug, 尝试在 Docker 容器中创建具有非常大 UID 的用户可能会导致磁盘空间耗尽, 因为容器层中的 /var/log/faillog 已填充 NULL (\\0) 字符\n一种解决方法是将 --no-log-init 标志传递给 useradd\nDebian&#x2F;Ubuntu adduser 包装器不支持这个标志\n避免安装或使用 sudo, 因为它具有不可预测的 TTY 和可能导致问题的信号转发行为. 如果你真的需要类似于 sudo 的功能, 例如将守护进程初始化为 root 当以非 root 的身份运行, 请考虑使用 gosu\n最后, 为了减少层和复杂性, 避免频繁地来回切换用户\nWORKDIR (WORKDIR 指令)为了清晰性和可靠性, 你应该始终为你的 WORKDIR 使用绝对路径\n此外, 你应该使用 WORKDIR 而不是像 RUN cd ... &amp;&amp; do-something 之类的指令, 这些指令难以阅读, 故障排除和维护\nONBUILD (ONBUILD 指令)当前 Dockerfile 构建结束后, 将执行 ONBUILD 命令\nONBUILD 在 从当前镜像派生的 任何子镜像 中运行\n将 ONBUILD 命令看作 父Dockerfile 传递给 子Dockerfile 的指令\nDocker 构建在 子Dockerfile 中的所有命令之前执行 ONBUILD 命令\nONBUILD 对于镜像很有用, 这个镜像 FROM 一个给定镜像中构建. 例如, 你可以将 ONBUILD 用于一个语言栈镜像, 这个镜像在 Dockerfile 中构建以该语言编写的任意用户软件, 正如你在 Ruby 的 ONBUILD 变体 中看到的\n使用 ONBUILD 构建的镜像要有一个单独的标签, 例如: ruby:1.9-onbuild 或 ruby:2.0-onbuild\n将 ADD 或 COPY 添加到 ONBUILD 时要小心. 如果新构建的上下文缺少要添加的资源, 则 ONBUILD 镜像会灾难性地失败. 如上所述, 添加一个单独的标签有助于让 Dockerfile 作者做出选择来缓解这种情况\n参考Dockerfile best practices\n","categories":["Docker"],"tags":["Docker","Notes"]},{"title":"Dockerfile reference","url":"/docker/dockerfile-reference/","content":"\n\n\nUsage (使用)\nBuildKit\nFormat (格式)\nParser directives (解析器指令)\nsyntax\nescape\n\n\nEnvironment replacement (环境更换)\n.dockerignore file (.dockerignore 文件)\nFROM (FROM 指令)\nUnderstanding how ARG and FROM interact (理解 ARG 和 FROM 怎样交互)\n\n\nRUN (RUN 指令)\nKnow issues (RUN) (RUN 指令的已知问题)\n\n\nCMD (CMD 指令)\nLABEL (LABEL 指令)\nMAINTAINER (deprecated) (MAINTAINER 指令 已过时)\nEXPOSE (EXPOSE 指令)\nENV (ENV 指令)\n替代的语法\n\n\nADD (ADD 指令)\nCOPY (COPY 指令)\nENTRYPOINT (ENTRYPOINT 指令)\nExec form ENTRYPOINT example (Exec 形式 ENTRYPOINT 例子)\nShell form ENTRYPOINT example (Shell 形式 ENTRYPOINT 例子)\nUnderstand how CMD and ENTRYPOINT interact (理解 CMD 和 ENTRYPOINT 是怎样交互的)\n\n\nVOLUME (VOLUME 指令)\nNotes about specifying volumes (关于指定卷的注意事项)\n理解\n\n\nUSER (USER 指令)\nWORKDIR (WORKDIR 指令)\nARG (ARG 指令)\nDefault values (默认值)\nScope (作用域)\nUsing ARG variables (使用 ARG 变量)\nPredefined ARGs (预定义的 ARGs)\nAutomatic platform ARGs in the global scope (全局范围内的自动平台 ARGs)\nImpact on build caching (对构建缓存的影响)\n\n\nONBUILD (ONBUILD 指令)\nSTOPSIGNAL (STOPSIGNAL 指令)\nHEALTHCHECK (HEALTHCHECK 指令)\nSHELL (SHELL 指令)\n参考\n\n\n\n\nDocker can build images automatically by reading the instructions from a Dockerfile.\n\n通过从一个 Dockerfile 中读取指令, Docker 可以自动构建镜像\n\nA Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image.\n\nDockerfile 是一个文本文档, 包含了用户可以在命令行上调用的, 以组合镜像的所有命令\n\nUsing docker build users can create an automated build that executes several command-line instructions in succession.\n\n使用 docker build, 用户可以创建一个自动化构建, 这个构建连续执行多个命令行指令\n\nThis page describes the commands you can use in a Dockerfile.\n\n这个页面描述了你可以在 Dockerfile 中使用的命令\n\nWhen you are done reading this page, refer to the Dockerfile Best Practices for a tip-oriented guide.\n\n在你读完这个页面之后, 查看 Dockerfile Best Practices 以获取面向提示的指南\nUsage (使用)\nThe docker build command builds an image from a Dockerfile and a context.\n\ndocker build 命令从 Dockerfile 和 上下文 中构建镜像\n\nThe build’s context is the set of files at a specified location PATH or URL.\n\n构建的上下文是位于指定 PATH 或 URL 的位置中的一组文件\n\nThe PATH is a directory on your local filesystem. The URL is a Git repository location.\n\nPATH 是在你本地文件系统上的一个文件夹. URL 是一个 Git 仓库地址\n\nThe build context is processed recursively. So, a PATH includes any subdirectories and the URL includes the repository and its submodules.\n\n构建上下文是递归处理的. 所以, PATH 包括了所有的子目录, URL 包括了仓库和它的子模块\n\nThis example shows a build command that uses the current directory (.) as build context:\n\n这个例子展示了一个使用当前目录 (.) 作为构建上下文的构建命令:\n$ docker build .\n\n\nThe build is run by the Docker daemon, not by the CLI. The first thing a build process does is send the entire context (recursively) to the daemon. In most cases, it’s best to start with an empty directory as context and keep your Dockerfile in that directory. Add only the files needed for building the Dockerfile.\n\n这个构建是通过 Docker daemon 运行的, 不是通过 CLI. 构建过程做的第一件事是将整个上下文 (递归地) 发送到 daemon. 在大多数情况下, 最好使用一个空目录作为上下文来开始, 并将 Dockerfile 保存在这个目录中. 只添加构建 Dockerfile 所需要的文件\n\nWarningDo not use your root directory, /, as the PATH for your build context, as it causes the build to transfer the entire contents of your hard drive to the Docker daemon.\n\n警告, 不要将根目录 / 设置为你的构建上下文的 PATH, 因为这将会导致构建将你硬盘上的全部内容传输给 Docker daemon\n\nTo use a file in the build context, the Dockerfile refers to the file specified in an instruction, for example, a COPY instruction. To increase the build’s performance, exclude files and directories by adding a .dockerignore file to the context directory. For information about how to create a .dockerignore file see the documentation on this page.\n\n要在构建上下文中使用文件, Dockerfile 查看 (refer to) 在指令中指定的文件, 例如, 一个 COPY 指令. 为了提高构建的性能, 通过添加一个 .dockerignore 文件到上下文目录中来排除文件和目录. 查看这个页面上的 create a .dockerignore file 获取关于如何创建一个 .dockeringore 文件的信息\n\nTraditionally, the Dockerfile is called Dockerfile and located in the root of the context. You use the -f flag with docker build to point to a Dockerfile anywhere in your file system.\n\n习惯上, Dockerfile 被称为 Dockerfile, 位于上下文的根目录中. 你可以在 docker build 中使用 -f 标志来指向一个在你文件系统中任何位置上的 Dockerfile\n$ docker build -f /path/to/a/Dockerfile .\n\n\nYou can specify a repository and tag at which to save the new image if the build succeeds:\n\n你可以指定在构建成功保存新镜像时使用的仓库和标签:\n$ docker build -t shyke/myapp .\n\n\nTo tag the image into multiple repositories after the build, add multiple -t parameters when you run the build command:\n\n要在构建之后将镜像标记到多个仓库, 在运行 build 命令时添加多个 -t 参数:\n$ docker build -t shyke/myapp:1.0.2 -t shyke/myapp:latest .\n\n\nBefore the Docker daemon runs the instructions in the Dockerfile, it performs a preliminary validation of the Dockerfile and returns an error if the syntax is incorrect:\n\n在 Docker daemon 运行 Dockerfile 中的指令前, Docker daemon 对 Dockerfile 进行一个初步的校验, 如果语法不正确这返回错误:\n\nThe Docker daemon runs the instructions in the Dockerfile one-by-one, committing the result of each instruction to a new image if necessary, before finally outputting the ID of your new image. The Docker daemon will automatically clean up the context you sent.\n\nDocker daemon 一个一个地运行 Dockerfile 中的指令, 如果必要的话, 在最终输出你的新镜像的 ID 前, 提交每一个指令的结果到一个新的镜像中. Docker daemon 会自动清理你你发送的上下文\n\nNote that each instruction is run independently, and causes a new image to be created - so RUN cd /tmp will not have any effect on the next instructions.\n\n注意, 每个指令都是独立运行的, 导致一个新镜像被创建, 所以 RUN cd /tmp 将不会对下一个指令产生任何影响\n\nWhenever possible, Docker uses a build-cache to accelerate the docker build process significantly. This is indicated by the CACHED message in the console output. (For more information, see the Dockerfile best practices guide):\n\n只要有可能, Docker 就会使用构建缓存来显著加快 docker build 的处理. 这由控制台输出中的 CACHED 消息指示. (查看 Dockerfile best practices guide 获取更多信息):\n$ docker build -t svendowideit/ambassador .\n\n\nBy default, the build cache is based on results from previous builds on the machine on which you are building. The --cache-from option also allows you to use a build-cache that’s distributed through an image registry refer to the specifying external cache sources section in the docker build command reference.\n\n默认情况下, 构建缓存基于你正在构建的机器上的先前的构建结果. --cache-from 选项还允许你使用通过镜像注册处分发的构建缓存, 请参考 docker build 命令手册中的 specifying external cache sources section 部分\n\nWhen you’re done with your build, you’re ready to look into scanning your image with docker scan, and pushing your image to Docker Hub.\n\n当完成构建时, 你就可以开始使用 docker scan 来扫描你的镜像, 并推送你的镜像到 Docker Hub\nBuildKitBuildKit 后端提供了比旧的构建工具更多的功能\n设置 DOCKER_BUILDKIT=1 环境变量来开启使用 BuildKit\nFormat (格式)Dockerfile 中的格式:\n# 注释指令 参数\n\n指令不是大小写敏感的,约定使用大写形式\n一个 Dockerfile 必须以 FROM 指令为开始\n但是 FROM 指令可以出现在 解析器指令(parser directives), 注释, 全局范围的 ARGs 之后\nFROM 之前只能有一个或多个 ARG 指令，这些指令声明在 Dockerfile 的 FROM 行中使用的参数\nDocker 只会将以 # 开头的行看作是注释\n# CommentRUN echo &#x27;we are running some # of cool things&#x27;\n\n注释行在 Dockerfile 指令开始执行前将会被删除\nExample - 以下两个指令是等同的:\nRUN echo hello \\# commentworld\n\nRUN echo hello \\world\n\n在注释中不支持 行继续字符 (Line continuation)\n为了向后兼容, # 和 指令 前的空格将会被忽略\nExample - 以下两种写法是等同的:\n        # this is a comment-line    RUN echo helloRUN echo world\n\n# this is a comment-lineRUN echo helloRUN echo world\n\n但是, 在指令参数中的空格是会被保留的:\nRUN echo &quot;\\     hello\\     world&quot;\n\nParser directives (解析器指令)解析器指令是可选的, 并且会影响 Dockerfile 中后续行的处理方式\n解析器指令不会添加层 (layers) 到构建中, 也不会作为一个构建步骤出现\n解析器指令通过 # directive=value 的形式作为特殊的注释类型出现\n一个指令只能使用一次\n一旦一个注释, 空白行或者构建器指令 (builder instruction) 已经被处理了, 那么 Docker 将不会再寻找解析器指令. Docker 将所有的解析器指令看作是普通的注释, 不会去校验它是否为一个解析器指令\n因此, 所有的解析器指令必须在 Dockerfile 的最上面\n解析器指令不会大小写敏感的, 但是约定使用小写\n还约定在任何解析器指令后面包含一个空行\n在解析器指令中不支持换行符\n未知的解析器指令当做普通注释\n解析器指令中允许使用非换行空格\n支持如下两种解析器指令:\n\nsyntax\nescape\n\nsyntax# syntax=[remote image reference]\n\n例如:\n# syntax=docker/dockerfile:1# syntax=docker.io/docker/dockerfile:1# syntax=example.com/user/repo:tag@sha256:abcdef...\n\n这个功能只能在使用 BuildKit 后端时使用, 在使用传统构建器后端时将会被忽略\nsyntax 指令定义了用来构建 Dockerfile 的 Dockerfile 语法的位置\n这些 Dockerfile 语法实现作为一个 Docker 镜像进行发布\nBuildKit 使用外部的 Dockerfile 语法实现来在一个容器沙盒环境中执行构建\n官方的 Dockerfile 语法实现位于 Docker Hub 中的 docker/dockerfile 仓库中\n稳定版本的语法实现: docker/dockerfile:1\n实验版本的语法实现: docker/dockerfile:labs\nescape# escape=\\\n\n或者\n# escape=`\n\nescape 指令用来设置在 Dockerfile 中使用的转义符符号. 默认的转义符号是 \\\n在 Windows 平台中, 路径分隔符是 \\, 因此可以使用这个指令来设置转义符号为 `\n# escape=`FROM microsoft/nanoserverCOPY testfile.txt c:\\RUN dir c:\\\n\nEnvironment replacement (环境更换)环境变量（使用 ENV 语句声明）也可以在某些指令中用作要由 Dockerfile 解释的变量\n还会处理转义来将类似变量的语法包含在语句字面量中\n环境变量在 Dockerfile 中用 $variable_name 或 $&#123;variable_name&#125; 表示\n使用 \\ 对 $ 进行转义\nDockerfile 中的如下指令支持环境变量:\n\nADD\nCOPY\nENV\nEXPOSE\nFROM\nLABEL\nSTOPSIGNAL\nUSER\nVOLUME\nWORKDIR\nONBUILD (和上面的指令结合的时候)\n\nENV abc=helloENV abc=bye def=$abcENV ghi=$abc\n\ndef 的值为 hello; ghi 的值为 bye; 因为每一行的指令是基于上一个指令生成的镜像的\n.dockerignore file (.dockerignore 文件)在 Docker CLI 将上下文发送给 Docker Daemon 前, Docker CLI 在上下文的根目录中寻找一个名称为 .dockerignore 的文件\n如果这个文件存在, CLI 将会修改上下文来排除匹配这个文件中的模式的文件或目录\n这避免了将很大的文件或者敏感的文件发送到 Daemon 中\n并且避免了在使用 ADD 或 COPY 时潜在地添加大文件或敏感文件到镜像中\nCLI 解析 .dockerignore 文件\n.dockerignore 文件使用新行作为多个模式的分隔\n为了进行匹配, 上下文的根作为工作目录和根目录\n例如, 模式 /foo/bar 和 foo/bar 都会排除 PATH 下 foo 目录中的名称为 bar 的文件或目录, 或者是排除位于 URL 指向的 Git 仓库的根下的 foo 目录中的 bar 文件或目录\n.dockerignore 文件中第一列为 # 的行被认为是注释, 不会被 CLI 解析\n# comment*/temp**/*/temp*temp?\n\nTable - Build behavior:\n\n\n\nRule\nBehavior\n\n\n\n# comment\n忽略\n\n\n*/temp*\n排除根 (root) 下的一级子目录中名称以 temp 开头的文件或目录\n\n\n*/*/temp*\n排除根 (root) 下的二级子目录中名称以 temp 开头的文件或目录\n\n\ntemp?\n排除根 (root) 目录下所有的名字以 temp 开头然后接一个字符的文件或目录. 例如 /tempa, /tempb\n\n\n匹配使用 Go 语言的 filepath.Match 规则\n一个预处理步骤删除了头尾的空白字符, 并使用 Go 语言的 filepath.Clean 消除 . 和 .. 元素\n在预处理后, 空白行将会被忽略\nDocker 还支持使用 ** 来匹配任何数量的目录 (包括 0 个目录). 例如 **/*.go 将会排除所有目录中以 .go 结尾的所有文件, 根目录下的文件也会被排除\n以符号 ! 开头的行用来声明不要进行排除的文件或目录\nExample:\n*.md!README.md\n\n除了 README.md 文件之外的以 .md 结尾的文件都会被排除\n你还可以使用 .dockerignore 文件来排除 Dockerfile 文件和 .dockerignore 文件. 这两个文件仍然会被发送到 Daemon, 因为需要使用它们来进行构建. 但是 ADD 和 COPY 指令不会复制它们到镜像中\n因为历史原因, . 模式被忽略了\nFROM (FROM 指令)FROM [--platform=&lt;platform&gt;] &lt;image&gt; [AS &lt;name&gt;]\n\nFROM [--platform=&lt;platform&gt;] &lt;image&gt;[:&lt;tag&gt;] [AS &lt;name&gt;]\n\nFROM [--platform=&lt;platform&gt;] &lt;image&gt;[@&lt;digest&gt;] [AS &lt;name&gt;]\n\nFROM 指令初始化一个新的构建阶段, 为后续指令设置基础镜像\n因此, 有效的 Dockerfile 必须以一个 FROM 指令开始\niamge 可以是任何有效的镜像, 可以特别容易地从公开仓库 拉取一个镜像来开始\nARG 是 Dokcerfile 中唯一可以出现在 FROM 前面的指令\nFROM 可以在单个 Dockerfile 中出现多次来创建多个镜像, 或者使用一个构建阶段作为另一个构建阶段的依赖\n只需在每个新的 FROM 指令之前记录 提交的最后一个输出的 镜像ID\n每个 FROM 指令都会清除先前指令创建的任何状态\n通过添加 AS name 给 FROM 指令, 可以可选地为一个新的构建阶段指定名字. 这个名字可以在后面的 FROM 和 COPY --from=&lt;name&gt; 指令中用来指向这个阶段中构建的镜像\ntag 和 digest 值是可选的, 如果都没有指定这两个值, 构建器默认使用 latest 标签. 如果构建器找不到 tag 值将会返回返回一个错误\n如果 FROM 引用多平台镜像，可选的 --platform 标志可用于指定镜像的平台. 例如 linux/amd64, linux/arm64, windows/amd64\n默认情况下使用构建请求的目标平台\n全局构建参数可以用于 --platform 标志的值, 例如 自动的平台 ARGs 允许你强制阶段为当本地构建平台 (--platform=$BUILDPLATFORM), 并使用它交叉编译到阶段内的目标平台\nUnderstanding how ARG and FROM interact (理解 ARG 和 FROM 怎样交互)FROM 指令支持任何通过 ARG 指令声明的变量, ARG 指令出现在第一个 FROM 指令之前\nARG CODE_VERSION=latestFROM base:$&#123;CODE_VERSION&#125;CMD /code/run-appFROM extras:$&#123;CODE_VERSION&#125;CMD /code/run-extras\n\n在 FROM 指令之前声明的 ARG 指令在构建阶段之外, 所以它不能在 FROM 指令之后的任何指令中使用\n要使用在第一个 FROM 之前声明的 ARG 的默认值，请使用在构建阶段内没有值的 ARG 指令:\nARG VERSION=latestFROM busybos:$VERSIONARG VERSIONRUN echo $VERSION &gt; image_version\n\nRUN (RUN 指令)RUN 指令有两种形式:\n\nRUN &lt;command&gt; (shell形式, 命令是在一个 shell 中运行的, 在 Linux 上默认是 /bin/sh -c, 在 Windows 上默认是 cmd /S /C)\nRUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec形式)\n\nRUN 指令将会在当前镜像之上的新层中执行任何命令并提交结果. 提交的结果镜像将用于 Dockerfile 中的下一步\n将 RUN 指令分层并生成提交 符合 Docker 的核心概念, 其中提交非常廉价, 并且可以从镜像历史的任何点创建容器, 就像源代码控制一样\nexec 形式可以避免 shell 字符串处理, 并使用不包含指定 shell 执行文件的基础镜像 RUN 命令\n可以使用 SHELL 指令来为 shell 形式改变默认的 shell\n在 shell 形式中你可以使用 \\ 来将一个 RUN 指令换行到下一行:\nRUN /bin/bash -c &#x27;source $HOME/.bashrc; \\echo $HOME&#x27;\n\n要使用不同的 shell, 而不是 /bin/sh, 在 exec 形式中传入想要的 shell:\nRUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;]\n\nexec 形式被解析为一个 JSON 数组, 意味着你必须使用双引号 &quot; 来包围词语, 不要使用单引号\n不像 shell 形式, exec 形式不会调用一个命令 shell. 这意味着不会发生正常的 shell 处理. 例如, RUN [ &quot;echo&quot;, &quot;$HOME&quot; ] 将不会在 $HOME 上做变量替换. 如果你想要 shell 处理, 那么可以使用 shell 形式, 或者直接执行一个 shell 例如: RUN [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ]. 当使用 exec 形式并直接执行一个 shell 时, 和使用 shell 形式一样, 是 shell 来处理环境变量扩展, 而不是 Docker\n在 JSON 形式中有必要进行反斜线转义. 这在反斜杠是路径分隔符的 Windows 上尤为重要:\n错误: RUN [&quot;c:\\windows\\system32\\tasklist.exe&quot;]\n正确: RUN [&quot;c:\\\\windows\\\\system32\\\\tasklist.exe&quot;]\nRUN 指令的缓存不会在下一次构建期间自动失效\n像 RUN apt-get dist-upgrade -y 这样的指令的缓存在下次构建期间会被重新使用\nRUN 指令的缓存可以通过使用 --no-cache 标志来无效化, 例如 docker build --no-cache\n查看 Dockerfile 最佳实践 获取更多信息\n可以通过 ADD 和 COPY 指令来使 RUN 指令的缓存无效\nKnow issues (RUN) (RUN 指令的已知问题)问题 783 是关于文件权限的问题, 这个问题会在使用 AUFS 文件系统时出现. 尝试 rm 一个文件时可以注意到这个问题\nCMD (CMD 指令)CMD 指令有三种形式:\n\nCMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (exec 形式, 推荐使用这种形式)\nCMD [&quot;param1&quot;,&quot;param2&quot;] (作为 ENTRYPOINT 的默认参数)\nCMD command param1 param2 (shell 形式)\n\n在 Dockerfile 中只能有一个 CMD 指令. 如果你指定了超过 1 个 CMD 指令, 那么只有最后一个 CMD 指令生效\nCMD 指令的主要目的是为正在执行的容器提供默认值\n这些默认值可以包括可执行文件. 也可以省略可执行文件, 在这种情况下, 你必须指定 ENTRYPOINT 指令\n如果 CMD 指令用来为 ENTRYPOINT 指令提供默认参数, 那么 CMD 指令和 ENTRYPOINT 指令都要使用 JSON 数组格式来指定\nCMD 指令的 exec 形式作为 JSON 数组被解析, 这意味着你必须使用双引号来包裹内容\n不像 shell 形式, exec 形式不会调用一个命令 shell. 这意味着不会发生正常的 shell 处理\n例如 CMD [ &quot;echo&quot;, &quot;$HOME&quot; ] 将不会在 $HOME 上执行变量替换\n如果你想要 shell 处理, 要么使用 shell 形式, 要么直接执行 shell, 像这样: CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ]\n当使用 exec 形式且直接执行一个 shell, 正如在 shell 形式中那样, 将会是由 shell 而不是 Docker 来执行环境变量扩展\n当使用 shell 或 exec 格式时, CMD 指令设置了在运行镜像时执行的命令\n如果你使用 CMD 指令的 shell 形式, 那么 &lt;command&gt; 将会在 /bin/sh -c 中执行:\nFROM ubuntuCMD echo &quot;This is a test.&quot; | wc -\n\n如果你想要在没有 shell 情况下运行 &lt;command&gt;, 则必须将命令表示为 JSON 数组并提供可执行文件的完整路径\n这种数组形式是 CMD 指令的首选格式\n所有额外参数在数组中必须表达为字符串:\nFROM ubuntuCMD [ &quot;/usr/bin/wc&quot;, &quot;--help&quot; ]\n\n如果你想要你的容器每次都运行相同的可执行文件, 那么可以结合使用 CMD 指令和 ENTRYPOINT 指令\n如果用户在 docker run 中指定的参数, 那么这些参数将会覆盖 CMD 指令中指定的默认值\nNote: 不要混淆 RUN 和 CMD 指令. RUN 指令实际运行一个命令并提交结果; CMD 指令在构建时没有执行任何东西, 但是指定了镜像的预期 (intended) 命令\nLABEL (LABEL 指令)LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...\n\nLABEL 指令为镜像添加元数据\n一个 LABEL 是一个键值对\n要在 LABEL 值中包含空格, 请像在命令行解析中一样使用引号和反斜线\nExample:\nLABEL &quot;com.example.vendor&quot;=&quot;ACME Incorporated&quot;LABEL com.example.label-with-avlue=&quot;foo&quot;LABEL version=&quot;1.0&quot;LABEL describes=&quot;This is text illustrates \\that label-values can span multiple lines.&quot;\n\n一个镜像可以有多个 label\n可以在单独一行中指定多个 label. 在 Docker 1.10 版本之前, 这可以减少最终的镜像大小, 但是现在不是这样子了\n你也还可以选择在单独一行中知道指定多个 label, 使用如下两种方式:\nLABEL multi.label1=&quot;value1&quot; multi.label2=&quot;value2&quot; other=&quot;value3&quot;\n\nLABEL multi.label1=&quot;value1&quot; \\      multi.label2=&quot;value2&quot; \\      other=&quot;value3&quot;\n\n基础镜像或父镜像 (FROM 行中的镜像) 中包含的 labels 由你的镜像进行继承\n如果 label 已经存在但具有不同的值, 那么最近应用的值将覆盖任何之前设置的值\n要查看镜像的 labels, 使用 docker image inspect 命令. 可以使用 --format 选项来声明仅展示 labels:\n$ docker image inspect --format=&#x27;&#x27; myimage\n\nMAINTAINER (deprecated) (MAINTAINER 指令 已过时)MAINTAINER &lt;name&gt;\n\nMAINTAINER 指令用来设置创建镜像的作者字段\n使用 LABEL 指令来代替 MAINTAINER 指令: LABEL org.opencontainers.image.authors=&quot;SvenDowideit@home.org.au&quot;\nEXPOSE (EXPOSE 指令)EXPOSE &lt;port&gt; [&lt;port&gt;/&lt;protocol&gt;...]\n\nEXPOSE 指令通知 Docker, 容器要在运行时监听指定的网络端口\n你可以指定端口是监听在 TCP 还是 UDP 上, 如果没有指定协议那么默认是 TCP\nEXPOSE 指令实际上并没有发布 (publish) 端口\nEXPOSE 指令充当 构建镜像的人 和 运行容器的人 之间的一种文档, 关于打算发布 (publish) 哪些端口的文档\n要在运行容器时实际上发布端口, 在 docker run 命令上使用 -p 标志来发布并映射一到多个端口, 或者使用 -P 标志来发布所有暴露的 (exposed) 端口并将它们映射到高阶端口 (high-order ports)\n默认地, EXPOSE 指令假定使用 TCP. 你还可以指定 UDP:\nEXPOSE 80/udp\n\n要同时暴露 TCP 和 UDP, 那么包含两行:\nEXPOSE 80/tcpEXPOSE 80/udp\n\n在这种情况下, 如果你将 -P 和 docker run 一起使用, 这个端口将为 TCP 暴露一次, 为 UDP 暴露一次. 记住, -P 使用使用主机上的临时高阶主机端口 (high-ordered host port), 所以 TCP 和 UDP 的端口将会不同\n-P 标志将容器中所有暴露的端口映射到宿主机上的随机端口\n不管 EXPOSE 如何设置, 你可以在运行时使用 -p 标志来覆盖它们:\n$ docker run -p 80:80/tcp -p 80:80/udp\n\n要在主机系统上设置端口重定向, 查看使用 -P 标志\ndocker network 命令支持为容器之间的通信创建网络, 而无需暴露或发布特定端口, 因为连接到网络的容器可以通过任何端口互相通信. 更详细的信息请查看这个功能\nENV (ENV 指令)ENV &lt;key&gt;=&lt;value&gt; ...\n\nENV 指令设置环境变量 &lt;key&gt; 的值为 &lt;value&gt;\n该值将在构建阶段的所有后续指令的环境中, 也可以在许多指令中内联替换\n该值将会被解析为其他环境变量, 所以如果引号字符没有被转义, 那么引号字符将会被删除\n与命令行解析一样, 引号和反斜线可以用来在值中包含空格\nExample:\nENV MY_NAME=&quot;John Doe&quot;ENV MY_DOG=Rex\\ The\\ Dog # 使用反斜线来对空格转义ENV MY_CAT=fluffy\n\nENV 指令允许同时设置多个 &lt;key&gt;=&lt;value&gt; 变量, 下面的例子将会在最终镜像中产生相同的最终结果:\nENV MY_NAME=&quot;John Doe&quot; MY_DOG=Rex\\ The\\ Dog \\    MY_CAT=fluffy\n\n使用 ENV 设置的环境变量将持续到容器从结果镜像中运行的时候. 你可以使用 docker inspect 命令来查看这些环境变量值. 可以使用 docker run --env &lt;key&gt;=&lt;value&gt; 命令来修改这些环境变量值\n环境变量的持久化可能导致不可预料的副作用. 例如, 设置 ENV DEBIAN_FRONTEND=noninteractive 修改 apt-get 的行为, 可能会让你的镜像的用户感到迷惑\n如果一个环境变量仅仅在构建时需要而在最终镜像中不需要, 考虑为单独一个命令设置环境变量值:\nRUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y ...\n\n或者使用 ARG 指令, 这个指令的值不会持续到最终镜像中:\nARG DEBIAN_FRONTEND=noninteractiveRUN apt-get update &amp;&amp; apt-get install -y ...\n\n替代的语法ENV 指令还有一个替代的语法 ENV &lt;key&gt; &lt;value&gt;, 去掉了 =:\nENV MY_VAR my-value\n\n这个语法不允许*在单个 ENV 指令中设置多个环境变量\n这个替代的语法是为了向后的兼容性, 不建议继续使用\nADD (ADD 指令)ADD 指令有两种形式:\n\nADD [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;\nADD [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;]\n\n包含空格的路径需要第二种形式\n--chown 功能仅在用于构建 Linux 容器的 Dockfile 上受支持, 在 Windows 容器上不支持. 因为用户和用户组所有权概念不能在 Linux 和 Windows 之间转换, 因此使用 /etc/passwd 和 /etc/group 将用户名和组名转换为 ID 会限制此功能仅适用于基于 Linux 操作系统的容器\nADD 指令从 &lt;src&gt; 复制新的 文件,目录,远程文件URLs , 并将它们添加到镜像的文件系统中的 &lt;dest&gt; 路径上\n可以指定多个 &lt;src&gt; 资源, 但是如果它们是文件或者目录, 它们的路径被解析为相对于构建上下文的源\n每个 &lt;src&gt; 可以包含通配符, 并使用 Go 语言的 filepath.Match 来进行匹配:\nExample - 添加所有一个 “hom” 开头的文件:\nADD hom* /mydir/\n\nExample - ? 符号用来匹配任何单个字符:\nADD hom?.txt /mydir/\n\n&lt;dest&gt; 是一个绝对路径, 或者相对于 WORKDIR 的路径, &lt;src&gt; 将会被复制到目标容器内的这个路径中\nExample - 使用相对路径, 并添加 test.txt 到 &lt;WORKDIR&gt;/relativeDir/ 中:\nADD test.txt relativeDir /\n\nExample - 使用绝对路径, 添加 test.txt 到 /absoluteDir/ 中:\nADD test.txt /absoluteDir/\n\n当添加包含特殊字符 (例如 [ 和 ]) 的文件或目录时, 你需要使用 Golang 规则转义那些路径来避免将它们作为一个匹配模式来看待\nExample - 添加一个名称为 arr[0].txt 的文件:\nADD arr[[]0].txt /mydir/\n\n所有新文件和目录使用为零的 UID 和 GID 进行创建, 除非指定了可选的 --chown 标志, --chown 标志指定了给定的用户名, 组名, 或者 UID&#x2F;GID 的组合以请求添加内容的特定所有权\n--chown 标志的格式允许用户名和组名字符串或直接整数 UID 和 GID 的任意组合\n提供不带组名的用户名或不带 GID 的 UID 将使用与 GID 相同的数字作为 GID\n如果提供了用户名或组名, 则容器的根文件系统 /etc/passwd 和 /etc/group 文件将分别用于执行从名称到整数 UID 或 GID 的转换\nExample - 下面例子展示 --chown 标志的有效定义:\nADD --chown=55:mygroup files* /somedir/ADD --chown=bin files* /somedir/ADD --chown=1 files* /somedir/ADD --chown=10:11 files* /somedir/\n\n如果容器根文件系统不包含 /etc/passwd 或 /etc/group 文件, 并且在 --chown 标志中使用了用户名或组名, 则构建将在 ADD 操作时失败\n使用数字形 ID 不需要查找, 并且不依赖于容器根文件系统\n在 &lt;src&gt; 是一个远程文件 URL 的情况下, &lt;dest&gt; 将拥有 600 的权限\n如果正在获取的远程文件具有 HTTP Last-Modified 请求头, 则该请求头中的时间戳将用于设置目标文件的 mtime\n但是, 与在 ADD 期间处理的任何其他文件一样, 在确定文件是否已更改以及是否应该更新缓存时, 不会包含 mtime\n如果你通过 STDIN (docker build - &lt; somefile) 传递 Dockerfile 来进行构建, 那将会没有构建上下文, 所以 Dockerfile 只能包含一个基于 URL 的 ADD 指令\n你还可以通过 STDIN 传递压缩文件: (docker build - &lt; archive.tar.gz), 压缩文件根目录中的 Dockerfile 和压缩文件的其余部分将用作构建的上下文\n如果你的 URL 文件是使用认证保护的, 你需要使用 RUN wget, RUN curl 或容器中的其他工具, 因为 ADD 指令不支持认证\n如果 &lt;src&gt; 的内容已更改, 则第一个遇到的 ADD 指令将使 Dockerfile 中所有后续指令的缓存无效. 这包括使 RUN 指令的缓存无效化. 查看 Dockerfile Best Practices guide - Leverage build cache 获取信息\nADD 遵循以下规则:\n\n&lt;src&gt; 的路径必须在构建的上下文中; 不可以 ADD ../something/something, 因为 docker build 的第一步是发送上下文目录 (和子目录) 给 Docker Daemon\n如果 &lt;src&gt; 是一个 URL 且 &lt;dest&gt; 没有以一个斜线结尾, 那么文件从 URL 中下载并复制到 &lt;dest&gt;\n如果 &lt;src&gt; 是一个 URL 且 &lt;dest&gt; 以一个斜线结尾, 那么将从 URL 中推断文件名, 并将文件下载到 &lt;dest&gt;/&lt;filename&gt;. 例如, ADD http://example.com/foobar / 将会创建文件 /foobar. URL 必须有一个重要的路径, 以便在这种情况下可以找到适当的文件名 (http://example.com 无法工作)\n如果 &lt;src&gt; 是一个目录, 那么目录的全部内容被复制, 包括文件系统元数据; 目录本身不会被复制, 只有目录中的内容会被复制\n如果 &lt;src&gt; 是可识别的压缩格式 (identity, gzip, bzip2 或 xz) 的本地 tar 存档, 则将其解压缩为目录. 从远程 URLs 获取的资源不会解压缩. 当一个目录被复制或解压缩时, 它具有与 tar -x 相同的行为, 结果是如下的结合:\n目标路径上存在的任何东西\n源树 (source tree) 的内容, 用 “2” 的方式解决冲突. 以逐个文件为基础\n\n\n文件是否被鉴定为可识别的压缩格式仅取决于文件的内容, 而不是文件名. 例如, 如果一个空文件恰好以 .tar.gz 结尾, 这将不会被识别为压缩文件, 也不会生成任何类型的解压缩错误消息, 而是将文件简单地复制到目标位置\n如果 &lt;src&gt; 是任何其他类型的文件, 它会与元数据一起单独复制. 在这种情况下, 如果 &lt;dest&gt; 以 / 结尾, 则将其视为目录, 且 &lt;src&gt; 的内容将写入 &lt;dest&gt;/base(&lt;src&gt;\n如果指定了多个 &lt;src&gt; 源, 无论是直接指定还是使用了通配符指定, 那么 &lt;dest&gt; 必须是目录, 并且必须以 / 结尾\n如果 &lt;dest&gt; 不是以 / 结尾, 那么 &lt;dest&gt; 将被认为是一个普通文件且 &lt;src&gt; 的内容将会被写到 &lt;dest&gt;\n如果 &lt;dest&gt; 不存在, 它会连同其路径中所有缺失的目录一起创建\n\nCOPY (COPY 指令)COPY 指令有两种形式:\n\nCOPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;\nCOPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]\n\n包含空格的路径需要使用后一种形式\n--chown 功能仅在用于构建 Linux 容器的 Dockfile 上受支持, 在 Windows 容器上不支持. 因为用户和用户组所有权概念不能在 Linux 和 Windows 之间转换, 因此使用 /etc/passwd 和 /etc/group 将用户名和组名转换为 ID 会限制此功能仅适用于基于 Linux 操作系统的容器\nCOPY 指令从 &lt;src&gt; 中复制新文件或目录, 并将它们添加到容器文件系统的 &lt;dest&gt; 中\n可以指定多个 &lt;src&gt; 资源, 但文件和目录的路径被解释为相对于构建上下文的源 (source)\n每个 &lt;src&gt; 可能包含通配符且将会使用 Go 语言的 filepath.Match 规则进行匹配\nExample - 添加所有以 “hom” 开头的文件:\nCOPY hom* /mydir/\n\nExample - ? 用来代替任何单个字符. 例如 “home.txt”:\nCOPY hom?.txt /mydir/\n\n&lt;dest&gt; 是一个绝对路径, 或者一个相对于 WORKDIR 的路径, 源 (source) 将被复制到目标容器中\nExample - 使用一个相对路径, 添加 test.txt 到 &lt;WORKDIR&gt;/relativeDir/:\nCOPY test.txt relativeDir/\n\nExample - 使用绝对路径, 添加 test.txt 到 /absoluteDir/:\nCOPY test.txt /absoluteDir/\n\n当添加包含特殊字符 (例如 [ 和 ]) 的文件或目录时, 你需要使用 Golang 规则转义那些路径来避免将它们作为一个匹配模式来看待\nExample - 添加一个名称为 arr[0].txt 的文件:\nCOPY arr[[]0].txt /mydir/\n\n所有新文件和目录使用为零的 UID 和 GID 进行创建, 除非指定了可选的 --chown 标志, --chown 标志指定了给定的用户名, 组名, 或者 UID&#x2F;GID 的组合以请求添加内容的特定所有权\n--chown 标志的格式允许用户名和组名字符串或直接整数 UID 和 GID 的任意组合\n提供不带组名的用户名或不带 GID 的 UID 将使用与 GID 相同的数字作为 GID\n如果提供了用户名或组名, 则容器的根文件系统 /etc/passwd 和 /etc/group 文件将分别用于执行从名称到整数 UID 或 GID 的转换\nExample - 下面例子展示 --chown 标志的有效定义:\nCOPY --chown=55:mygroup files* /somedir/COPY --chown=bin files* /somedir/COPY --chown=1 files* /somedir/COPY --chown=10:11 files* /somedir/\n\n如果容器根文件系统不包含 /etc/passwd 或 /etc/group 文件, 并且在 --chown 标志中使用了用户名或组名, 则构建将在 COPY 操作时失败\n使用数字形 ID 不需要查找, 并且不依赖于容器根文件系统\n如果你通过 STDIN (docker build - &lt; somefile) 传递 Dockerfile 来进行构建, 那将会没有构建上下文, 所以不能使用 COPY\nCOPY 可选地接受一个 --from=&lt;name&gt; 标志, 这个标志可用于将源位置设置为先前的构建阶段 (使用 FROM .. AS &lt;name&gt; 创建), 该阶段将用于代替用户发送的构建上下文\n如果找不到具有指定名称的构建阶段, 则尝试使用具有相同名称的镜像\nCOPY 遵循如下规则:\n\n&lt;src&gt; 路径必须在构建的上下文中; 你不能 COPY ../something/something, 因为 docker build 的第一步是发送上下文件夹 (和子文件夹) 给 Docker Daemon\n如果 &lt;src&gt; 是一个文件夹, 那么这个文件夹中的全部内容都被复制, 包括文件系统元数据; 文件夹本身不会被复制, 只会复制它里面的内容\n如果 &lt;src&gt; 是任何其他类型的文件, 它会与它的元数据一起单独复制. 在这种情况下, 如果 &lt;dest&gt; 以 / 结尾, 则将其视为目录, 并且 &lt;src&gt; 的内容将写入 &lt;dest&gt;/base(&lt;src&gt;)\n如果指定了多个 &lt;src&gt; 资源, 无论是直接指定还是通过使用通配符指定, 那么 &lt;dest&gt; 必须是一个文件夹, 它必须以 \\ 作为结尾\n如果 &lt;dest&gt; 不是以 \\ 作为结尾, 它将被认为是一个普通文件, 且 &lt;src&gt; 的内容将被写到 &lt;dest&gt;\n如果 &lt;dest&gt; 不存在, 它会连同其路径中所有缺失的目录一起创建\n\n如果 &lt;src&gt; 的内容已更改, 则第一个遇到的 COPY 指令将使 Dockerfile 中所有后续指令的缓存无效. 这包括使 RUN 指令的缓存无效\n查看 Dockerfile best practices guide - Leverage build cache 获取更多信息\nENTRYPOINT (ENTRYPOINT 指令)ENTRYPOINT 有两种形式:\nexec 形式, 这是首选形式: ENTRYPOINT [ &quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot; ]\nshell 形式: ENTRYPOINT command param1 param2\nENTRYPOINT 允许你配置 容器 作为一个可执行文件来运行\nExample - 使用默认内容启动 Nginx, 监听 80 端口:\n$ docker run -i -t --rm -p 80:80 nginx\n\n传给 docker run &lt;image&gt; 的命令行参数将会附加到 exec 形式 ENTRYPOINT 指令中所有元素的后面, 并且会覆盖所有使用 CMD 指定的元素\n这允许传递参数给 ENTRYPOINT, 例如 docker run &lt;image&gt; -d 将会传递 -d 参数给 ENTRYPOINT\n可以使用 docker run --entrypoint 标志来覆盖 ENTRYPOINT 指令\nshell 形式阻止使用所有 CMD 指令或 run 命令行参数, 但缺点是你的 ENTRYPOINT 将作为 /bin/sh -c 的子命令启动, 这样不会传递信号 (signals)\n这意味着可执行文件不会是容器的 PID 1, 且不会接受到 Unix 信号 (signals), 所以你的可执行文件不会从 docker stop &lt;container&gt; 接受到一个 SIGTERM\n只有 Dockerfile 中的最后一个 ENTRYPOINT 指令会生效\nExec form ENTRYPOINT example (Exec 形式 ENTRYPOINT 例子)可以使用 ENTRYPOINT 的 exec 形式来设置非常稳定的默认命令和参数, 然后使用任一形式的 CMD 来设置额外的很有可能改变的默认值\n如果你需要为一个可执行文件编写一个启动脚本, 你可以通过使用 exec 和 gosu 命令来确保最后的可执行文件接受 Unix 信号 (signals):\n#!/usr/bin/env bashset -eif [ &quot;$1&quot; = &#x27;postgres&#x27; ]; then    chown -R postgres &quot;$PGDATA&quot;    if [ -z &quot;$(ls -A &quot;$PGDATA&quot;)&quot; ]; then        gosu postgres initdb    fi    exec gosu postgres &quot;$@&quot;fiexec &quot;$@&quot;\n\n最后, 如果你需要在关闭 (shutdown) 的时候做一些额外的清理工作 (或者和其他容器通信), 或者协调多个可执行文件, 你可能需要确保 ENTRYPOINT 脚本接收 Unix 信号 (signals), 传递它们, 然后做更多的工作:\n#!/bin/sh# Note: I&#x27;ve written this using sh so it works in the busybox container too# USE the trap if you need to also do manual cleanup after the service is stopped,#     or need to start multiple services in the one containertrap &quot;echo TRAPed signal&quot; HUP INT QUIT TERM# start service in background here/usr/sbin/apachectl startecho &quot;[hit enter key to exit] or run &#x27;docker stop &lt;container&gt;&#x27;&quot;read# stop service and clean up hereecho &quot;stopping apache&quot;/usr/sbin/apachectl stopecho &quot;exited $0&quot;\n\n如果你使用 docker run -it --rm -p 80:80 --name test apache 来运行这个镜像, 你可以使用 docker exec 或 docker top 检查容器的进程, 然后告诉 (ask) 脚本去停止 Apache:\n$ /usr/bin/time docker stop test\n\n你可以使用 --entrypoint 覆盖 ENTRYPOINT 设置, 但是这只能将二进制文件设置为 exec (不会使用 sh -c)\nexec 形式作为一个 JSON 数组来解析, 这意味着你必须使用双引号来包裹单词\n不像 shell 形式, exec 形式不会调用一个命令 shell. 这意味着正常的 shell 处理不会发生. 例如, ENTRYPOINT [&quot;echo&quot;, &quot;$HOME&quot;] 将不会在 $HOME 上执行变量替换. 如果你想要 shell 处理, 要么使用 shell 形式要么直接执行一个 shell, 例如: ENTRYPOINT [&quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot;]. 当使用 exec 形式并直接执行一个 shell, 与使用 shell 形式的情况一样, 进行环境变量扩展的是 shell 而不是 Docker\nShell form ENTRYPOINT example (Shell 形式 ENTRYPOINT 例子)可以为 ENTRYPOINT 指定一个纯字符串, 这个字符串将会在 /bin/sh -c 中执行\n这个形式将会使用 shell 来处理环境变量替换, 所有 CMD 或者 docker run 命令行参数都会被忽略\n为了确保 docker stop 会正确地通知长时间运行的 ENTRYPOINT 可执行文件, 记得使用 exec 来启动:\nFROM ubuntuENTRYPOINT exec top -b\n\n如果不使用 exec 执行命令, 则启动后的命令的进程 PID 将不是 1, 无法正常接收到 docker stop 发送的信号\nUnderstand how CMD and ENTRYPOINT interact (理解 CMD 和 ENTRYPOINT 是怎样交互的)CMD 和 ENTRYPOINT 指令都定义了运行容器时要执行的命令\n下面是描述它们合作的规则:\n\nDockerfile 必须指定至少一个 CMD 或 ENTRYPOINT 命令\n将容器作为可执行文件时应该定义 ENTRYPOINT\nCMD 应该用作 为ENTRYPOINT命令 或 在容器中执行临时命令 定义默认参数的一种方式\n运行容器时的替代参数会覆盖掉 CMD\n\nTable - 不同 ENTRYPOINT &#x2F; CMD 组合下会执行的命令:\n\n| No ENTRYPOINT | ENTRYPOINT ENTRY_exec ENTRY_p1 | ENTRYPOINT [“ENTRY_exec”, “ENTRY_p1”]:—|:—|:—|:—No CMD | error, not allowed | &#x2F;bin&#x2F;sh -c ENTRY_exec ENTRY_p1 | ENTRY_exec ENTRY_p1CMD [“CMD_exec”, “CMD_p1”] | CMD_exec CMD_p1 | &#x2F;bin&#x2F;sh -c ENTRY_exec ENTRY_p1 | ENTRY_exec ENTRY_p1 CMD_exec CMD_p1CMD [“CMD_p1”, “CMD_p2”] | CMD_p1 CMD_p2 | &#x2F;bin&#x2F;sh -c ENTRY_exec ENTRY_p1 | ENTRY_exec ENTRY_p1 CMD_p1 CMD_p2CMD CMD_exec CMD_p1 | &#x2F;bin&#x2F;sh -c CMD_exec CMD_p1 | &#x2F;bin&#x2F;sh -c ENTRY_exec ENTRY_p1 | ENTRY_exec ENTRY_p1 &#x2F;bin&#x2F;sh -c CMD_exec CMD_p1\n\n如果 CMD 是在基础镜像中定义的, 那么设置 ENTRYPOINT 将会重置 CMD 为空值. 在这种情况下, CMD 必须在当前镜像中定义来赋予一个值\nVOLUME (VOLUME 指令)VOLUME [&quot;/data&quot;]\n\n\nThe VOLUME instruction creates a mount point with the specified name and marks it as holding externally mounted volumes from native host or other containers.\n\nVOLUME 指令创建一个具有指定名称的挂载点, 并将其标记为 保存 来自本地主机或其他容器的 外部挂载卷\n值可以是一个 JSON 数组, VOLUME [&quot;/var/log/&quot;], 或者带有多个参数的纯字符串, 例如 VOLUME /var/log 或 VOLUME /var/log /var/db\n有关通过 Docker 客户端的更多信息&#x2F;例子和挂载说明, 请参考 Share Directories via Volumes 文档\ndocker run 命令使用基础镜像中 指定位置 存在的任何数据 初始化新创建的卷\nExample:\nFROM ubuntuRUN mkdir /myvolRUN echo &quot;hello world&quot; &gt; /myvol/greetingVOLUME /myvol\n\n这个 Dockerfile 生成一个镜像, 这个镜像导致 docker run 在 /myvol 创建一个新的挂载点, 并将 /greeting 文件复制到新创建的卷中\nNotes about specifying volumes (关于指定卷的注意事项)请记住以下 Dockerfile 中关于卷的事项\n\n基于 Windows 的容器 上的卷: 当使用基于 Windows 的容器时, 容器中卷的目的地必须是以下之一\n一个不存在的或空的目录\nC: 之外的驱动器\n\n\n从 Dockerfile 中更改卷: 如果任何构建步骤在卷声明之后修改了卷中的数据, 则这些修改将被丢弃\nJSON 格式: 这个列表作为一个 JSON 数组来解析. 你必须使用双引号来包裹词语\n主机目录是在容器运行时声明的: 主机目录 (挂载点) 本质上是依赖于主机的. 这是为了保持镜像的可移植性, 因为不能保证给定的主机目录在所有主机上都可用. 所以, 你不能从 Dockerfile 中挂载主机目录. VOLUME 指令不支持指定一个 host-dir 参数. 你必须在创建或运行容器时指定挂载点\n\n理解如果运行时用户忘记将保存文件的目录挂载为卷, 那么就会在容器存储层发生写操作\n可以在 Dockerfile 中事先指定某些目录挂载为匿名卷\n这样在运行时即使用户不指定挂载, 容器也可以正常运行, 也不会向容器存储层写入大量数据\n当容器运行时, 如果未使用 -v 指定挂载或未使用 --mount 指定数据卷, 那么 Docker 将会自动在 /var/lib/docker/volumes/ 创建一个数据卷 (可以使用 docker volume ls 查看到这个数据卷), 并将这个数据卷挂载到 VOLUME 设定的目录中\nUSER (USER 指令)USER &lt;user&gt;[:&lt;group&gt;]\n\n或者\nUSER &lt;UID&gt;[:&lt;GID&gt;]\n\nUSER 指令设置 在运行镜像时 与 Dockerfile中USER指令之后的任何RUN,CMD,ENTRYPOINT指令 使用的用户名称 (或者 UID) 和可选的用户组 (或者 GID)\n注意, 为用户指定用户组时, 用户将仅具有指定的组成员资格. 将忽略任何其他配置的组成员身份\n当用户没有一个主要组时, 镜像 (或下一条指令) 将会使用 root 组来运行\n在 Windows 上, 如果用户不是内置账户, 则必须先创建该用户. 可以通过将 net user 命令调用作为 Dockerfile 的一部分来完成\nFROM microsoft/windowsservercore# Create Windows user in the containerRUN net user /add patrick# Set it for subsequent commandsUSER patrick\n\nWORKDIR (WORKDIR 指令)WORKDIR /path/to/workdir\n\nWORKDIR 指令为 Dockerfile 中所有 RUN,CMD,ENTRYPOINT,COPY,ADD 指令设置工作目录\n如果 WORKDIR 不存在, 即使在随后的 Dockerfile 所有指令中都没有用上, 它还是会被创建\nWORKDIR 指令可以在 Dockerfile 中使用多次. 如果提供了一个相对路径, 这个路径将会相对于上一个 WORKDIR 指令的路径\nExample:\nWORKDIR /aWORKDIR bWORKDIR cRUN pwd\n\n这个 Dockerfile 中的 pwd 命令的最终输出是 /a/b/c\nWORKDIR 指令可以解析先前使用 ENV 设置的环境变量. 你只能使用在 Dockerfile 中明确设置的环境变量:\nExample:\nENV DIRPATH=/pathWORKDIR $DIRPATH/$DIRNAMERUN pwd\n\n在 Dockerfile 中最终的 pwd 命令的输出是 /path/$DIRNAME\n如果没有明确指定, 那么默认的工作目录是 /. 在实践中, 如果你不是从头开始 (FROM scratch) 构建 Dockerfile, 那么 WORKDIR 很有可能由你正在使用的基础镜像设置\n因此, 为了避免在未知目录下的进行意外操作, 最佳实践是明确设置你的 WORKDIR\nARG (ARG 指令)ARG &lt;name&gt;[=&lt;default value&gt;]\n\nARG 指令定义一个变量, 用户可以在构建时使用带有 --build-arg &lt;varname&gt;=&lt;value&gt; 标志的 docker build 命令将这个变量传递给构建器 (builder). 如果用户指定了一个没有在 Dockerfile 中定义的构建参数, 那么构建将会输出一个警告: [Warning] One or more build-args [foo] were not consumed.\n一个 Dockerfile 可以包含多个 ARG 指令\nExample:\nFROM busyboxARG user1ARG buildno\n\n警告: 不建议使用构建时变量传递机密, 例如 Github keys, 用户认证等. 通过 docker history 命令, 构建时变量对所有使用镜像的用户都是可见的. 查看 build images with BuildKit 部分, 了解构建镜像时使用机密的安全方法\nDefault values (默认值)ARG 指令可以选择包含默认值:\nFROM busyboxARG user1=someuserARG buildno=1\n\n如果 ARG 指令有一个默认值, 但是在构建时没有传递值进来, 那么构建器 (builder) 使用默认值\nScope (作用域)ARG 变量定义从在 Dockerfile 中定义它的行的位置开始生效, 而不是从命令行或者其他地方的参数使用开始\nExample:\n1 FROM busybox2 USER $&#123;user:-some_user&#125;3 ARG user4 USER $user\n\nExample - 用户通过这样调用来构建这个文件:\n$ docker build --build-arg user=what_user .\n\n第 2 行的 USER 计算结果为 some_user, 因为 user 变量在随后的第 3 行定义\n第 4 行的 USER 计算结果为 what_user, 因为 user 已经定义且值 what_user 已在命令行上传递\n在通过 ARG 指令定义之前, 对变量的任何使用都会导致空字符串\nARG 指令在定义它的构建阶段结束时超出了 (goes out of) 作用域. 要在多个阶段使用一个 arg, 每个阶段必须包含 ARG 指令\nExample:\nFROM busyboxARG SETTINGSRUN ./run/setup $SETTINGSFROM busyboxARG SETTINGSRUN ./run/other $SETTINGS\n\nUsing ARG variables (使用 ARG 变量)你可以使用 ARG 或 ENV 指令来指定可用于 RUN 指令的变量\n使用 ENV 指令定义的环境变量总是覆盖相同名字的 ARG 指令\nExample - 考虑这个有 ENV 和 ARG 指令的 Dockerfile:\nFROM ubuntuARG CONT_IMG_VERENV CONT_IMG_VER=v1.0.0RUN echo $CONT_IMG_VER\n\n然后, 假设使用如下命令构建这个镜像:\n$ docker build --build-arg CONT_IMG_VER=v2.0.1 .\n\n在这个情况下, RUN 指令使用 v1.0.0 而不是 通过用户传递给 ARG 的 v2.0.1\n这个行为类似于 shell 脚本, 其中局部范围的变量从它的定义点会覆盖作为参数传递或从环境继承的变量\n使用上面的示例但是使用不同的 ENV 规范, 你可以在 ARG 和 ENV 指令之间创建更有用的交互:\nFROM ubuntuARG CONT_IMG_VERENV CONT_IMG_VER=$&#123;CONT_IMG_VER:-v1.0.0&#125;RUN echo $CONT_IMG_VER\n\n不像 ARG 指令 ,ENV 值在构建的镜像中持续存在. 考虑一个不使用 --build-arg 标志的 docker 构建: $ docker build .\n使用上述例子的 Dockerfile, CONT_IMG_VER 还是持续存在于镜像中, 但是它的值将会是 v1.0.0, 因为它的默认值在第 3 行通过 ENV 指令设置\n这个例子中的变量扩展技术允许你从命令行传递参数, 并通过利用 ENV 指令将它们保存在最终镜像中\n仅有限的一组 Dockerfile 指令 支持变量扩展\nPredefined ARGs (预定义的 ARGs)Docker 有一组预定义的 ARG 变量, 你可以在 Dockerfile 中没有对应的 ARG 指令的情况下使用这些变量\n\nHTTP_PROXY\nhttp_proxy\nHTTPS_PROXY\nhttps_proxy\nFTP_PROXY\nftp_proxy\nNO_PROXY\nno_proxy\n\n要使用这些变量, 使用 --build-arg 标志在命令行上传递它们, 例如: $ docker build --build-arg HTTPS_PROXY=https://my-proxy.example.com\n默认情况下, 这些预定义变量从 docker history 的输出中排除. 排除它们可以降低在 HTTP_PROXY 变量中意外泄露敏感身份验证信息的风险\n例如, 考虑使用 --build-arg HTTP_PROXY=http://user:pass@proxy.lon.example.com 来构建下面的 Dockerfile:\nFROM ubuntuRUN echo &quot;Hello World&quot;\n\n在这种情况下, HTTP_PROXY 变量的值在 docker history 中是不可用的, 且不会被缓存. 如果你想要修改坐标 (location), 且你的代理服务器修改为 http://user:pass@proxy.sfo.example.com, 后续的构建不会导致缓存未命中\n如果你需要覆盖这个行为, 你可以像下面这样通过在 Dockerfile 中添加一个 ARG 指令:\nFROM ubuntuARG HTTP_PROXYRUN echo &quot;Hello World&quot;\n\n构建这个 Dockerfile 时, HTTP_PROXY 保留在 docker history 中, 更改其值会使构建缓存失效\nAutomatic platform ARGs in the global scope (全局范围内的自动平台 ARGs)这个功能只有在使用 BuildKit 时生效\nDocker 预定义了一组 ARG 变量, 其中包含有关执行构建的节点平台 (构建平台) 和生成镜像的平台 (目标平台) 的信息\n目标平台可以使用 docker build 上的 --platform 标志来指定\n自动设置如下 ARG 变量:\n\nTARGETPLATFORM - 构建结果的平台. 例如 linux/amd64,linux/arm/v7,windows/amd64\nTARGETOS - TARGETPLATFORM 的 OS 组件\nTARGETARCH - TARGETPLATFORM 的架构组件\nTARGETVARIANT - TARGETPLATFORM 的变体 (variant) 组件\nBUILDPLATFORM - 执行构建的节点平台\nBUILDOS - BUILDPLATFORM 的 OS 组件\nBUILDARCH - BUILDPLATFORM 的架构组件\nBUILDVARIANT - BUILDPLATFORM 的变体 (variant) 组件\n\n这些参数是在全局范围内定义的, 因此在构建阶段或你的 RUN 命令中不会自动使用. 要在构建阶段暴露这些参数中的一个, 不要声明值的方式来重新定义它:\nFROM alpineARG TARGETPLATFORMRUN echo &quot;I&#x27;m building for $TARGETPLATFORM&quot;\n\nImpact on build caching (对构建缓存的影响)ARG 变量不想 ENV 变量那样持续存在到构建的镜像中\n但是, ARG 变量以类似的方式影响构建缓存\n如果一个 Dockerfile 定义了一个 ARG 变量, 这个变量的值和之前的构建中不同, 然后会在第一次使用这个变量的时候发生 “缓存不命中”, 而不是在这个变量定义的时候\n特别是, 在 ARG 指令之后的所有 RUN 指令都隐式使用 ARG 变量 (作为环境变量), 因此可能导致缓存未命中\n所以预定义的 ARG 变量都免于缓存, 除非 Dockerfile 中有匹配的 ARG 语句\nExample - 考虑如下两个 Dockerfile:\nFROM ubuntuARG CONT_IMG_VERRUN echo $CONT_IMG_VER\n\nFROM ubuntuARG CONT_IMG_VERRUN echo hello\n\n如果你在命令行中指定了 --build-arg CONT_IMG_VER=&lt;value&gt;, 在两种情况下, 第 2 行的规范不会导致一个缓存未命中\n第 3 行导致缓存未命中\nARG CONT_IMG_VER 导致 RUN 那行被识别为与运行 CONT_IMG_VER=&lt;value&gt; echo hello 相同, 因此如果 &lt;value&gt; 发生变化, 我们会得到缓存未命中\n考虑同一命令行下的另一个示例:\nFROM ubuntuARG CONT_IMG_VERENV CONT_IMG_VER=$CONT_IMG_VERRUN echo $CONT_IMG_VER\n\n在这个例子中, 缓存未命中发生在第三行. 发生未命中是因为 ENV 中变量的值引用 ARG 变量且这个 ARG 变量通过命令行改变了. 在这个例子中, ENV 命令导致镜像包含了这个值\n如果 ENV 指令覆盖同名的 ARG 指令:\nFROM ubuntuARG CONT_IMG_VERENV CONT_IMG_VER=helloRUN echo $CONT_IMG_VER\n\n第 3 行不会导致一个缓存未命中, 因为 CONT_IMG_VER 的值是一个常量 (hello). 因此, 在 RUN (第 4 行) 中使用的环境变量和值在构建之间不会发生变化\nONBUILD (ONBUILD 指令)ONBUILD &lt;INSTRUCTION&gt;\n\nONBUILD 指令将 trigger 指令添加到镜像中, 以便稍后执行, 此时这个镜像用作另一个构建的基础\ntrigger 将在下游构建的上下文中执行 ,就好像它是在下游 Dockerfile 中的 FROM 指令之后立即插入的一样\n任何构建指令都可以注册为 trigger\n这在你构建一个 用作构建其他镜像的基础 的镜像时很有用, 例如一个应用程序构建环境或者一个可以使用用户特定配置自定义的守护进程\n例如, 如果你的镜像是一个可重复使用的 Python 应用程序构建器 ,它要求添加应用程序源代码到一个指定的目录, 然后可能需要在此之后调用的构建脚本\n现在你还不能就调用 ADD 和 RUN, 因为你还不能访问应用程序源代码, 并且每个应用程序构建都会不一样\n你可以简单地为应用程序开发人员提供模板 Dockerfile 以将其复制粘贴到他们的应用程序中, 但这样效率低下, 容易出错且难以更新, 因为它与特定应用程序代码混合在一起\n解决方法是使用 ONBUILD 注册预定义指令, 以便稍后在下一个构建阶段运行\n它是这样工作的:\n\n当遇到一个 ONBUILD 指令时, 构建器将一个 trigger 添加到正在构建的镜像的元数据中. ONBUILD 指令不会影响当前的构建\n在构建结束时, 所有触发器的列表存储到镜像清单 (manifest) 中, 在 ONBUILD 键下. 它们可以使用 docker inspect 命令来检查\n然后这个镜像可能用做一个新构建的基础镜像, 使用 FROM 指令. 作为处理 FROM 指令的一部分, 下游构建器查找 ONBUILD triggers, 并按它们注册的相同顺序执行它们. 如果任何触发器失败, FROM 指令将被中止, 这反过来导致构建失败. 如果所有 triggers 都执行成功, 则 FROM 指令完成并且构建照常继续进行\n触发器在执行后会从最终镜像中清除. 换句话说, 它们不会被下下个构建继承\n\nExample - 你可以添加这样的东西:\nONBUILD ADD . /app/srcONBUILD RUN /usr/local/bin/python-build --dir /app/src\n\n警告: 不允许使用 ONBUILD ONBUILD 的链式 ONBUILD 指令\n警告: ONBUILD 指令可能不会触发 FROM 或 MAINTAINER 指令\nSTOPSIGNAL (STOPSIGNAL 指令)STOPSIGNAL signal\n\nSTOPSIGNAL 指令设置系统调用信号, 这个信号将被发送到容器以退出\n这个信号可以是格式为 SIG&lt;NAME&gt; 的信号名称, 例如 SIGKILL, 也可以是匹配内核系统调用表中某个位置的无符号数值, 例如 9. 如果没有定义则默认值是 SIGTERM\n可以覆盖每个容器的镜像的默认停止信号, 在 docker run 和 docker create 上使用 --stop-signal 标志\nHEALTHCHECK (HEALTHCHECK 指令)HEALTHCHECK 指令有两种形式:\n\nHEALTHCHECK [OPTIONS] CMD command (通过在容器中运行一个命令来检查容器健康)\nHEALTHCHECK NONE (关闭所有从基础镜像继承的健康检查)\n\nHEALTHCHECK 指令告诉 Docker 怎样测试一个容器, 检查它是否还工作. 这可以检测诸如 Web 服务器陷入无限循环并且无法处理新连接的情况, 即使服务器进程仍在运行\n当容器指定了健康检查时, 除了正常状态外, 它还具有健康状态. 这个健康状态以 starting 为初始状态. 每当健康检查通过时, 它就会变成 healthy (无论它以前处于什么状态). 在连续失败一定次数后, 它变成 unhealthy 状态\n可以出现在 CMD 前的选项是:\n\n--interval=DURATION (默认: 30s)\n--timeout=DURATION (默认: 30s)\n--start-period=DURATION (默认: 0s)\n--retries=N (默认: 3)\n\n健康检查会在容器启动后间隔 interval 秒后第一次执行, 然后在每次检查结束后再间隔 interval 秒执行\n如果单个检查任务运行超过 timeout 秒, 则认为检查失败\n容器连续重试 retries 次健康检查失败则容器被认为是 unhealthy\nstart period 为需要时间启动的容器提供初始化时间. 在此期间的探测失败不会被计入最大重试次数\n但是, 如果健康检查在启动间隔期间成功了, 那么容器则被认为是已经启动的并且所有连续失败都计入最大重试次数\n在 Dockerfile 中只能有一个 HEALTHCHECK 指令. 如果你指定了多个 HEALTHCHECK 指令, 那么只有最后一个 HEALTHCHECK 指令生效\nCMD 关键字后面的命令可以是一个 shell 命令 (例如, HEALTHCHECK CMD /bin/check-running) 或者一个 exec 数组\n命令的退出状态指明了容器的健康状态. 可能的值:\n\n0: 成功 - 容器是健康的且可以使用了\n1: 不健康的 - 容器没有正确地工作\n2: 保留的 - 不要使用这个退出码\n\nExample - 每五分钟检查一次网络服务器是否能够在三秒内为网站主页提供服务:\nHEALTHCHECK --interval=5m --timeout=3s CMD curl -f http://localhost/ || exit 1\n\n为了帮助调试失败的探针, 命令写到 stdout&#x2F;stderr 的任何输出文本 (UTF-8 编码的)都会被存储到健康状态中, 并且可以使用 docker inspect 来查询. 这样的输出文本要保存短小 (当前只有头 4096 字节会被存储)\n当一个容器的健康状态改变了, 将会产生一个带有新状态的 health_status\nSHELL (SHELL 指令)SHELL [&quot;executable&quot;, &quot;parameters&quot;]\n\nSHELL 指令允许覆盖用于命令的 shell 形式的默认 shell\nLinux 上的默认 shell 是 [&quot;/bin/sh&quot;, &quot;-c&quot;], 在 Windows 上是 [&quot;cmd&quot;, &quot;/S&quot;, &quot;/C&quot;]\n在 Dockerfile 中 SHELL 指令必须使用 JSON 形式来编写\nSHELL 指令在 Windows 上特别有用, Windows 上有两个常用且非常不同的本地 shell: cmd 和 powershell, 以及包括 sh 在内的备用 shells\nSHELL 指令可以出现多次. 每个 SHELL 指令覆盖前面所有额 SHELL 指令, 并影响所有接下来的指令\nExample:\nFROM microsoft/windowsservercore# Executed as cmd /S /C echo defaultRUN echo default# Executed as cmd /S /C powershell -command Write-Host defaultRUN powershell -command Write-Host default# Executed as powershell -command Write-Host helloSHELL [&quot;powershell&quot;, &quot;-command&quot;]RUN Write-Host hello# Executed as cmd /S /C echo helloSHELL [&quot;CMD&quot;, &quot;/S&quot;, &quot;/C&quot;]RUN echo hello\n\n这些指令在 Dockerfile 中使用它们的 shell 形式时会受到 SHELL 指令的影响: RUN,CMD,ENTRYPOINT\n以下示例是在 Windows 上发现的常见模式, 可以使用 SHELL 指令进行简化:\nRUN powershell -command Execute-MyCmdlet -param1 &quot;c:\\foo.txt&quot;\n\n被 docker 执行的命令将会是: cmd /S /C powershell -command Execute-MyCmdlet -param1 &quot;c:\\foo.txt&quot;\n这样做有两个不高效的理由. 首先, 调用了一个没有必要的 cmd.ext 命令进程 (又名 shell). 其次, 每个使用 shell 形式的 RUN 指令要求一个额外的 powershell -command 作为命令的前缀\n为了让其更加高效, 可以采用两种机制之一. 一种是使用 JSON 形式 RUN 命令:\nRUN [&quot;powershell&quot;, &quot;-command&quot;, &quot;Execute-MyCmdlet&quot;, &quot;-param1 \\&quot;c:\\\\foo.txt\\&quot;&quot;]\n\n虽然 JSON 格式是明确的并且没有使用不必要的 cmd.exe，但它确实需要通过双引号和转义来增加详细信息\n另一种机制是使用 SHELL 指令和 shell 形式，为 Windows 用户提供更自然的语法，尤其是与 escape 解析器指令结合使用时:\n# escape=`FROM microsoft/nanoserverSHELL [&quot;powershell&quot;, &quot;-command&quot;]RUN New-Item -ItemType Directory C:\\ExampleADD Execute-MyCmdlet.ps1 c:\\example\\RUN c:\\example\\Execute-MyCmdlet -sample &#x27;hello world&#x27;\n\nSHELL 指令也可以用于修改 shell 的操作方式. 例如, 在 Windows 上使用 SHELL cmd /S /C /V:ON|OFF, 可以修改延迟的环境变量扩展语义\n如果需要其他 shell，例如 zsh, csh, tcsh 等，也可以在 Linux 上使用 SHELL 指令\n参考Dockerfile reference\n","categories":["Docker"],"tags":["Docker","Reference"]},{"title":"Gradle Authoring Tasks","url":"/gradle/gradle-authoring-tasks/","content":"\n\n\nGradle Authoring Tasks\nTask outcomes\nDefining tasks\nLocating tasks\nPassing arguments to a task constructor\nAdding dependencies to a task\nOrdering tasks\nAdding a description to a task\nSkipping tasks\nUsing a predicate\nUsing StopExecutionException\n\n\nEnabling and disabling tasks\nTask timeouts\nUp-to-date checks (AKA Incremental Build)\nTask inputs and outputs\nCustom task types\n\n\n\n\nTask rules\nFinalizer tasks\nLifecycle tasks\n\n\n\n\n\nGradle Authoring TasksTask outcomestask 执行完之后, 会产生执行结果:\n\n(no label) or EXECUTED : task 执行了它的行为\nUP-TO-DATE : task 的输出没有变化\nFROM-CACHE : task 的输出可以从之前的执行结果中找到\nSKIPPED : task 没有执行它的行为\nNO-SOURCE : task 不需要去执行它的行为\n\nDefining tasks在 tasks 集合上使用 register() 方法来添加 task\ntasks.register(&#x27;hello&#x27;) &#123;    doLast &#123;        println &#x27;hello&#x27;    &#125;&#125;def copy = tasks.register(&#x27;copy&#x27;, Copy) &#123;    from(file(&#x27;srcDir&#x27;))    into(buildDir)&#125;\n\nLocating tasks获取声明的 task\n总的来说, task 都可以从 tasks 集合中获取\n你应该使用返回一个 task provider 的方法: register() 和 named()\nbuild.register(&#x27;hello&#x27;)build.register(&#x27;copy&#x27;, Copy)println tasks.named(&#x27;hello&#x27;).get().nameprintln tasks.name(&#x27;copy&#x27;).get().destinationDir\n\n可以通过 tasks.withType() 方法来获取指定类型的 task:\ntasks.withType(Tar).configureEach &#123;    enabled = false&#125;tasks.register(&#x27;test&#x27;) &#123;    dependsOn tasks.withType(Copy)&#125;\n\n可以使用 tasks.getByPath() 方法通过 task 路径来获取 task; 不建议使用这个方法\n可以使用 task名称 或 一个相对路径 或 一个绝对路径 来调用 getByPath() 方法\ntasks.register(&#x27;hello&#x27;)println tasks.getByPath(&#x27;hello&#x27;).pathprintln tasks.getByPath(&#x27;:hello&#x27;).pathprintln tasks.getByPath(&#x27;project-a:hello&#x27;).pathprintln tasks.getByPath(&#x27;:project-a:hello&#x27;).path\n\nPassing arguments to a task constructor为了传递值给 Task 的构造方法, 必须使用 @javax.inject.Inject 注解来修饰相关的构造方法:\nabstract class CustomTask extends DefaultTask &#123;    final String message    final int number    @javax.inject.Inject    CustomTask(String message, int number) &#123;        this.message = message        this.number = number    &#125;&#125;\n\n使用:\ntasks.register(&#x27;myTask&#x27;, CustomTask, &#x27;hello&#x27;, 42)\n\n在构造器参数中传入 null 值将会导致空指针异常\nAdding dependencies to a taskExample - 使 task 依赖另一个项目的 task:\nproject(&#x27;project-a&#x27;) &#123;    tasks.register(&#x27;taskX&#x27;) &#123;        dependsOn &#x27;:project-b:taskY&#x27;        doLast &#123;            println &#x27;taskX&#x27;        &#125;    &#125;&#125;project(&#x27;project-b&#x27;) &#123;    tasks.register(&#x27;taskY&#x27;) &#123;        doLast &#123;            println &#x27;taskY&#x27;        &#125;    &#125;&#125;\n\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q taskX       taskYtaskX\n\n还可以使用 TaskProvider 实例:\ndef taskX = tasks.register(&#x27;taskX&#x27;) &#123; doLast &#123; println &#x27;taskX&#x27; &#125; &#125;def taskY = tasks.register(&#x27;taskY&#x27;) &#123; doLast &#123; println &#x27;taskY&#x27; &#125; &#125;taskX.configure &#123;    dependsOn taskY&#125;\n\n可以使用 lazy block 来定义 task 依赖\nlazy block 应该返回一个 Task 或 一个集合的 Task 对象:\ndef taskX = tasks.register(&#x27;taskX&#x27;) &#123;    doLast &#123;        println &#x27;taskX&#x27;    &#125;&#125;// Using a Gradle ProvidertaskX.configure &#123;    dependsOn(provider &#123;        tasks.findAll &#123; task -&gt; task.name.startsWith(&#x27;lib&#x27;) &#125;    &#125;)&#125;tasks.register(&#x27;lib1&#x27;) &#123;    doLast &#123;        println &#x27;lib1&#x27;    &#125;&#125;tasks.register(&#x27;lib2&#x27;) &#123;    doLast &#123;        println &#x27;lib2&#x27;    &#125;&#125;tasks.register(&#x27;notALib&#x27;) &#123;    doLast &#123;        println &#x27;notALib&#x27;    &#125;&#125;\n\nOrdering tasks有两个可用的顺序规则:\n\n必须在之后运行: must run after\n应该在之后运行: should run after\n\ntaskB.mustRunAfter(taskA) : taskB 必须在 taskA 执行完之后才能运行\ntaskB.shouldRunAfter(taskA) : 执行顺序不严格; 如果重现了循环顺序或并行构建时, 这个规则就不会生效\nExample - mustRunAfter:\ndef taskX = tasks.register(&#x27;taskX&#x27;) &#123; doLast &#123; println &#x27;taskX&#x27; &#125; &#125;def taskY = tasks.register(&#x27;taskY&#x27;) &#123; doLast &#123; println &#x27;taskY&#x27; &#125; &#125;taskY.configure &#123;    mustRunAfter taskX&#125;\n\n执行结果:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q taskY taskXtaskXtaskY\n\n同时声明了 taskY taskX 一起执行, 当由于 taskY mustRunAfter taskX, 所以先输出了 taskX 的结果\nExampel - shouldRunAfter:\ndef taskX = tasks.register(&#x27;taskX&#x27;) &#123; doLast &#123; println &#x27;taskX&#x27; &#125; &#125;def taskY = tasks.register(&#x27;taskY&#x27;) &#123; doLast &#123; println &#x27;taskY&#x27; &#125; &#125;taskY.configure &#123;    shouldRunAfter taskX&#125;\n\n执行结果:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q taskY taskXtaskXtaskY\n\n使用 Task.mustRunAfter(java.lang.Object) 和 Task.shouldRunAfter(java.lang.Object) 两个方法来指定顺序; 这两个方法可以接受一个 task实例, task名称, 或其他类型输入作为入参\nB.mustRunAfter(A) 或者 B.shouldRunAfter(A) 并没有指示任何 task 之间的依赖:\n\n分别独立执行 task A 和 task B 是可以的. 顺序规则只有在这两个 task 都被计划执行的时候生效: gradle -q taskB taskA\n当使用 --continue 参数运行时, 在 task A 运行失败后, task B 也可以开始执行\n\nAdding a description to a task可以添加描述到 task 中, 这些描述会在 gradle tasks 执行时显示\ntasks.register(&#x27;copy&#x27;, Copy) &#123;    description &#x27;Copies the resource directory to the target directory&#x27;    from &#x27;resources&#x27;    into &#x27;target&#x27;    include(&#x27;**/*.txt&#x27;, &#x27;**/*.xml&#x27;, &#x27;**/*.properties&#x27;)&#125;\n\nSkipping tasksUsing a predicatepredicate : 断言\n使用 onlyIf() 方法添加一个断言到 task 中\n只有当断言计算为 true 时, task 才会执行\n断言使用 Closure 实现\ndef hello = tasks.register(&#x27;hello&#x27;) &#123;    doLast &#123;        println &#x27;hello world&#x27;    &#125;&#125;hello.configure &#123;    onlyIf &#123; !project.hasProperty(&#x27;skipHello&#x27;) &#125;&#125;\n\n执行结果:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle hello               &gt; Task :hellohello worldBUILD SUCCESSFUL in 403ms1 actionable task: 1 executed╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle hello -PskipHelloBUILD SUCCESSFUL in 403ms\n\nUsing StopExecutionException使用 StopExecutionException\n如果这个异常在一个 action 中抛出, 那么这个 action 接下来的执行逻辑与这个 task 接下来的 action 都会跳过\n构建会继续执行下一个 task\nExampel - build.gradle:\ndef compile = tasks.register(&#x27;compile&#x27;) &#123;    doLast &#123;        println &#x27;We are doing the compile&#x27;    &#125;&#125;compile.configure &#123;    doFirst &#123;        if (true) &#123;            throw new StopExecutionException()        &#125;    &#125;&#125;tasks.register(&#x27;myTask&#x27;) &#123;    dependsOn(&#x27;compile&#x27;)    doLast &#123;        println &quot;I&#x27;m not affected&quot;    &#125;&#125;\n\n执行结果:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle myTask           &gt; Task :myTaskI&#x27;m not affectedBUILD SUCCESSFUL in 459ms2 actionable tasks: 2 executed\n\ntask compile 剩下的 action 没有执行; 依赖于 task compile 的 task myTask 正常执行\n这个特性在与 Gradle 提供的 task 一起使用时非常有用\n这个特性允许你添加 ++可选式执行++ 到 task 的内建 action 中\nEnabling and disabling tasks使用参数 enabled 来指明一个 task 是否可用\nenabled = false 的 task 会被标记为 SKIPPED, 这个 task 中的所有 action 都不会被执行\ndef disableMe = tasks.register(&#x27;disableMe&#x27;) &#123;    doLast &#123;        println &#x27;This should not be printed if the task is disabled&#x27;    &#125;&#125;disableMe.configure &#123;    enabled = false&#125;\n\nTask timeouts每个 task 有一个 timeout 属性, 用来限制 task 的执行时间\n但一个 task 到达它的过期时间, 这个 task 的执行线程会被置为中断, 这个 task 会被标记为执行失败\nfinalizer task 仍然会被运行\n如果使用了 --continue, 其他 task 可以在 timeouted task 后面继续执行\n不响应线程中断的 task 不可以被 timeout\ntasks.register(&quot;hangingTask&quot;) &#123;    doLast &#123;        Thread.sleep(10000)    &#125;    timeout = Duration.ofMillis(500)&#125;\n\nUp-to-date checks (AKA Incremental Build)Task inputs and outputsCustom task types通过两步来使自定义 task 类适配增量构建:\n\n为 task 类的输入和输入创建带有 getter 方法的属性\n添加适合的注解到每个属性上\n\nGradle 支持三种类型的输入和输出:\n\n简单类型\n文件系统类型\n内嵌类型\n\nTask rulestasks.addRule(&quot;Pattern: ping&lt;ID&gt;&quot;) &#123; String taskName -&gt;    if (taskName.startsWith(&quot;ping&quot;)) &#123;        task(taskName) &#123;            doLast &#123;                println &quot;Pinging: $&#123;taskName - &#x27;ping&#x27;&#125;&quot;            &#125;        &#125;    &#125;&#125;\n\n输出结果:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q pingFuck         Pinging: Fuck╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q ping2   Pinging: 2\n\nExample - Dependency on rule based tasks:\ntasks.addRule(&quot;Pattern: ping&lt;ID&gt;&quot;) &#123; String taskName -&gt;    if (taskName.startsWith(&quot;ping&quot;)) &#123;        task(taskName) &#123;            doLast &#123;                println &quot;Pinging: $&#123;taskName - &#x27;ping&#x27;&#125;&quot;            &#125;        &#125;    &#125;&#125;tasks.register(&#x27;groupPing&#x27;) &#123;    dependsOn &#x27;pingServer1&#x27;, &#x27;pingServer2&#x27;&#125;\n\n输出结果:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q groupPingPinging: Server1Pinging: Server2\n\nFinalizer tasksExample - Adding a task finalizer:\ndef taskX = tasks.register(&#x27;taskX&#x27;) &#123;    doFirst &#123;        throw new StopExecutionException()    &#125;    doLast &#123;        println &#x27;taskX&#x27;    &#125;&#125;def taskY = tasks.register(&#x27;taskY&#x27;) &#123;    doLast &#123;        println &#x27;taskY&#x27;    &#125;&#125;taskX.configure &#123; finalizedBy taskY &#125;\n\n运行结果:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q taskXtaskY\n\nfinalized task : taskX\nfinalizer task : taskY\n即使 finalized task 执行失败了, finalizer task 仍然会执行\n如果 finalized task 不做任何工作, 例如被标记为 UP-TO-DATE 或者它依赖的 task 失败了, 那么 finalizer task 不会执行\nfinalizer task 适合用来做无论什么情况都必须执行的 task, 例如做清理工作\nLifecycle tasksLifecycle tasks are tasks that do not work themselves\nLifecycle tasks 通常不会执行任何 action\nLifecycle tasks 可以用这些概念来表现:\n\n一个工作流步骤(check)\n一个可以构建的东西\n一个用来执行很多相同逻辑的便利的 task\n\n基础的插件定义了一些 standard lifecycle tasks, 例如 build, assemble, check\n所有的核心语言插件, 例如 Java Plugin, 使用并增强了这些基础插件之后拥有一些相同的基础 lifecycle task\n除非一个 lifecycle task 有 action，否则它的结果是由它的依赖关系决定的\n如果它的任何依赖被执行了, 那么 lifecycle task 会被认为是 EXECUTED 的\n如果它的所有依赖都是 UP-TO-DATE 的, SKIPPED的, 或者从缓存中换取的, 那么 lifecycle task 会被认为是 UP-TO-DATE 的\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Best practices for authoring maintainable builds","url":"/gradle/gradle-best-practices-for-authoring-maintainable-builds/","content":"\n\n\nBest practices for authoring maintainable builds\nAvoid using imperative logic in scripts\nAvoid using internal Gradle APIs\nAlternatives for oft-used internal APIs\n\n\nFollow conventions when declaring tasks\nImprove task discoverability\nMinimize logic executed during the configuration phase\nAvoid using the GradleBuild task type\nAvoid inter-project configuration\nExternalize and encrypt your passwords\n\n\n\n\n\nBest practices for authoring maintainable builds第三方的 Gradle lint plugin 插件可以帮助你保持构建脚本的代码风格\nAvoid using imperative logic in scripts避免在构建脚本中使用命令式代码, 尽量使用类似 Project.dependencies() 的声明式代码\n最终目的是在构建脚本中只包含声明式语言元素, 使得代码更加易于理解和维护\n命令式逻辑应该封装在二进制插件中, 然后 apply 到构建脚本中\nAvoid using internal Gradle APIs当 Gradle 或者 插件变更时, 在插件和构建脚本中使用 Gradle 内部 API 有破坏构建的可能性\nAlternatives for oft-used internal APIs如果要为你自定义的 task 提供一个内嵌的 DSL, 不要使用 org.gradle.internal.reflect.Instantiator, 使用 ObjectFactory\n不要使用 org.gradle.api.internal.ConventionMapping, 使用 Provider 或者 Property\n不要使用 org.gradle.internal.os.OperatingSystem, 使用其他方法来访问操作系统, 例如 Apache commons-lang SystemUtils 或者 System.getProperty(&quot;os.name&quot;)\n不要使用 org.gradle.util.CollectionUtils, org.gradle.util.internal.GFileUtils, 或者其他 org.gradle.util.* 中的类\nFollow conventions when declaring tasks\n在 task 名称后面的括号中只使用键值对来声明 task 类型\n其他配置应该在 task 的配置块中完成\n在声明一个 task 时只使用 Tasks.doFirst&#123;&#125; 或者 Tasks.doLast&#123;&#125; 来添加 task action\n声明一个专门的没有一个明确类型的 task 时, 当你只是声明单独一个 action 时应该使用 Task.doLast&#123;&#125;\n一个 task 应该声明一个 group 和 description\n\nExample - Definition of tasks following best practices:\n// build.gradleimport com.enterprise.DocsGeneratedef generateHtmlDocs = tasks.register(&#x27;generateHtmlDocs&#x27;, DocsGenerate) &#123;    group = JavaBasePlugin.DOCUMENTATION_GROUP    description = &#x27;Generates the HTML documentation for this project.&#x27;    title = &#x27;Project docs&#x27;    outputDir = layout.buildDirectory.dir(&#x27;docs&#x27;)&#125;tasks.register(&#x27;allDocs&#x27;) &#123;    group = JavaBasePlugin.DOCUMENTATION_GROUP    description = &#x27;Generates all documentation for this project.&#x27;    dependsOn generateHtmlDocs    doLast &#123;        logger.quiet(&#x27;Generating all documentation...&#x27;)    &#125;&#125;\n\nImprove task discoverability定义 task 的 group 和 description 属性来说明 task\nMinimize logic executed during the configuration phase最小化配置阶段中执行的逻辑\n注意任何不在 task action 中的代码都会在每次运行构建的时候被执行\nbuild scan 可以帮助你定位每个生命周期执行所花的时间\nAvoid using the GradleBuild task typeGradleBuild 类型的 task 允许一个构建脚本定义一个 task 来执行另一个 Gradle 构建\n非常不建议使用这个类\n使用多项目构建作为代替\n使用 composite builds 作为代替\nAvoid inter-project configuration以下操作应该避免:\n\n使用 Task.dependsOn(java.lang.Object) 明确依赖一个其他项目中的 task\n从另一个项目中设置属性值或者调用领域对象的方法\n使用 GradleBuild 执行其他部分的构建\n声明一个没有不要的项目依赖\n\nExternalize and encrypt your passwords外部化, 加密你的密码\nGradle 暴露了一个 API 来在 ProviderFactory 中提供凭证\n可以使用 Gradle Credentials Plugin 解决密码加密解密的问题\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Build Lifecycle","url":"/gradle/gradle-build-lifecycle/","content":"\n\n\nBuild Lifecycle\nBuild phases\nSettings file\nInitialization\nResponding to the lifecycle in the build script\nProject evaluation\nTask creation\nTask execution graph ready\nTask execution\n\n\n\n\n\n\n\nBuild LifecycleBuild phases\nInitialization : 为每个项目创建一个 Project 实例\nConfiguration : 配置 Project 实例对象; 所有项目的构建脚本会被执行\nExecution : 执行指定的 task\n\nSettings filesettings.gradle 文件在 Initialization 阶段被执行\n一个多项目构建在根项目目录中必须有一个 settings.gradle  文件, 因为 settings.gradle 文件中定义了哪些项目参与到多项目构建当中\n对于一个单项目构建来说, settings.gradle 是可选的\n可以在 settings.gradle 中为 build script classpath 添加依赖库\nExample - settings.gradle:\nrootProject.name = &#x27;basic&#x27;println &#x27;This is executed during the initialization phase&#x27;\n\nExample - build.gradle:\nprintln &#x27;This is executed during the configuration phase.&#x27;tasks.register(&#x27;configured&#x27;) &#123;    println &#x27;This is also executed during the configuration phase, because :configured is used in the build.&#x27;&#125;tasks.register(&#x27;test&#x27;) &#123;    doLast &#123;        println &#x27;This is executed during the execution phase.&#x27;    &#125;&#125;tasks.register(&#x27;testBoth&#x27;) &#123;    println &#x27;This is executed during the configuration phase as well, because :testBoth is used in the build.&#x27;&#125;\n\n运行结果:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle test testBoth[settings.gradle] This is executed during the initialization phase&gt; Configure project :[build.gradle] This is executed during the configuration phase.[tasks testBoth] This is executed during the configuration phase as well, because :testBoth is used in the build.&gt; Task :test[tasks test] This is executed during the execution phase.BUILD SUCCESSFUL in 668ms1 actionable task: 1 executed\n\nInitialization如果在子项目中执行多项目构建, 那么只有这个子项目和这个子项目的依赖项目会被构建, 但是 Gradle 需要为整个多项目构建创建 build configuration\nResponding to the lifecycle in the build script构建脚本可以在构建执行生命周期中接收到消息通知\n可以通过实现接口或者定义一个在通知发生时执行的 closure 来进行响应\nProject evaluationExample - Adding of test task to each project which has certain property set:\n// build.gradleallprojects &#123;    afterEvaluate &#123; project -&gt;        if (project.hasTests) &#123;            println &quot;Adding test task to $project&quot;            project.task(&#x27;test&#x27;) &#123;                doLast &#123;                    println &quot;Running tests for $project&quot;                &#125;            &#125;        &#125;    &#125;&#125;\n\n使用 Project.afterEvalute() 方法添加一个 closure 来在项目 evaluated 之后执行\nExample - Notifications:\n// build.gradlegradle.afterProject &#123; project -&gt;    if (project.state.failure) &#123;        println &quot;Evaluation of $project FAILED&quot;    &#125; else &#123;        println &quot;Evaluation of $project succeeded&quot;    &#125;&#125;\n\nafterProject 通知不管项目 evaluate 是否成功, 都会执行\nTask creation可以在 task 添加到项目中之后马上收到一个通知\nExample - Setting of certain property to all tasks:\n// build.gradletasks.whenTaskAdded &#123; task -&gt;    task.ext.srcDir = &#x27;src/main/java&#x27;&#125;\n\ntasks.register(‘a’)\nprintln “source dir is $a.srcDir”\nTask execution graph ready可以在 task 执行图创建完成之后马上接收到通知\nTask execution可以在任何 task 执行前后马上接受到通知\nExample - Logging of start and end of each task execution:\n// build.gradletasks.register(&#x27;ok&#x27;)tasks.register(&#x27;broken&#x27;) &#123;    dependsOn ok    doLast &#123;        throw new RuntimeException(&#x27;broken&#x27;)    &#125;&#125;gradle.taskGraph.beforeTask &#123; Task task -&gt;    println &quot;executing $task...&quot;&#125;gradle.taskGraph.afterTask &#123; Task task, TaskState state -&gt;    if (state.failure) &#123;        println &quot;FAILED&quot;    &#125;    else &#123;        println &quot;done&quot;    &#125;&#125;\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Command-Line Interface","url":"/gradle/gradle-command-line-interface/","content":"\n\n\nCommand-Line Interface\nExecuting tasks\nExecuting tasks in multi-project builds\nExecuting multiple tasks\nExcluding tasks from execution\nForcing tasks to execute\nContinuing the build when a failure occurs\nName abbreviation\n\n\nCommon tasks\nComputing all outputs\nRunning applications\nRunning all checks\nCleaning outputs\n\n\nProject reporting\nListing projects\nListing tasks\nShow task usage details\nReporting dependencies\nListing project dependencies\nListing project properties\n\n\nCommand-line completion\nDebugging options\nPerformance options\nGradle daemon options\nLogging options\nSetting log level\nCustomizing log format\nShowing or hiding warnings\n\n\nExecution options\nEnvironment options\nBootstrapping new projects\nCreating new Gradle builds\nStandardize and provision Gradle\n\n\nContinuous Build\nTerminating Continuous Build\nLimitations and quirks\nBuild cycles\nRestrictions with Java 9\nPerformance and stability\n\n\n\n\n\n\n\n\n\nCommand-Line InterfaceExecuting tasksgradle :myTask\n\nExecuting tasks in multi-project buildsgradle :my-subproject:taskNamegradle my-subproject:taskName\n\nExecuting multiple tasksgradle test deploy\n\n按声明的顺序依次执行 test task deploy task, 包括它们各自依赖的 task\nExcluding tasks from execution使用 -x 或 --exclude-task 命令行参数来排除要执行的 task\ngradle dist --exclude-task test\n\nForcing tasks to execute可以使用 --rerun-tasks 命令行参数强制 Gradle 忽略 up-to-date 检查来执行所有 task\ngradle test --rerun-tasks\n\nContinuing the build when a failure occurs默认情况下,  Gradle 会在遇到 task 执行失败时马上停止往下构建\n使用 --continue 命令行参数来告诉 Gradle 在遇到 task 失败时尽可能地继续执行其他 task, 以便在一个构建中获取更多的构建失败信息\ngradle test --continue\n\nName abbreviation名字缩写\n可以在命令行参数中使用 名字缩写 来代替 task 的全民, 只要这个 名字缩写 可以唯一标识这个 task\n例如, gradle che 足以让 Gradle 标识 check task\n同样的规则适用于 项目名字, 例如, gradle lib:che 相当于 gradle library:check\n还可以使用 foBa&#x2F;fB 来代替 fooBar 和 foo-bar\n可以使用 gradle mAL:cT 来代替 gradle my-awesome-library:compileTest\nCommon tasksComputing all outputs在 Gradle 的 build task 中, 指定 组装所有输出 和 运行所有检查是很常见的\ngradle build\n\nRunning applications应用程序通过 run task 来运行是很常见的, 这个任务组装应用程序并执行一些脚本或二进制文件\ngradle run\n\nRunning all checks使用 check task 执行所有验证任务(包括测试和检测)是很常见的\ngradle check\n\nCleaning outputs可以使用 clean task 来删除 build 目录的内容, 将会导致之前计算好的 outputs 丢失\ngradle clean\n\nProject reportingGradle 提供了一些内置的 task 来展示你的构建的具体细节\nListing projects显示所有的子项目\ngradle projects\n\nListing tasksgradle tasks\n\nExample - 展示所有的 task, 包括没有声明到 task group 的 task:\ngradle tasks --all\n\nExample - 展示指定组中的 task:\ngradle tasks --group=&quot;build setup&quot;\n\nShow task usage detailsgradle help --task someTask\n\nExample:\ngradle -q help --task libs\n\nReporting dependenciesgradle myTask --scan\n\nListing project dependenciesgradle dependencies\n\nExample - 显示构建脚本的依赖:\ngradle buildEnvironment\n\nExample - 了解 与指定输入匹配 的特定依赖项:\ngradle dependencyInsight [--configuration]\n\nListing project propertiesExample - 列出 api 项目的所有属性\ngradle -q api:properties\n\nCommand-line completionGradle 提供了 bash 和 zsh 的命令行补全\ngradle-completion\nDebugging options\n\n\n名称\n含义\n\n\n\n-S, --full-stacktrace\n打印异常所有的堆栈信息\n\n\n-s, --stacktrace\n打印用户的异常的堆栈信息\n\n\n--scan\n创建一个 build scan\n\n\n-Dorg.gradle.debug=true\n开启 Gradle 调试客户端进程, Gradle 默认会监听 localhost:5005 端口, 等待调试器的连接\n\n\n-Dorg.gradle-daemon.debug=true\n调试 Gradle 守护进程\n\n\nPerformance options使用这些选项过来优化构建性能\n大多数这些选项可能在 gradle.properties 文件中声明\n\n\n\n名称\n含义\n\n\n\n--build-cache, --no-build-cache\n默认为关闭; 是否开启 Gradle 的构建缓存, Gradle 会尝试重用之前的构建的 outputs\n\n\n--configure-on-demand, --no-configure-on-demand\n默认为关闭; 是否开启按需配置; 只有相关的项目会在这次构建中被配置\n\n\n--max-workers\n默认为处理器的数量; 设置 Gradle 可以使用的最大 worker 数量\n\n\n--parallel, --no-parallel\n默认为关闭; 是否并行地构建项目\n\n\n--priority\n默认为 normal; 指定 Gradle 守护进程及其启动的所有进程的调度优先级; 可选值为 normal 和 low\n\n\n--profile\n在 $buildDir/reports/profile 文件夹中生成更高级的性能报告. 推荐使用 --scan\n\n\n--scan\n生成一个详细的性能诊断构建扫描\n\n\n--watch-fs, --no-watch-fs\n在支持 Gradle 这个特性的平台上默认开启; 是否观察文件系统; 当开启时 Gradle 会在不同构建中重用它收集到的文件系统信息\n\n\nGradle daemon options\n\n\n名称\n含义\n\n\n\n--daemon, --no-daemon\n默认开启; 使用 Gradle 守护进程来运行构建\n\n\n--foreground\n在前台启动 Gradle 守护进程\n\n\n--status(Standalone command)\n运行 gradle --status 来列出正在运行的和最近停止的 Gradle 守护进程. 只显示同一个版本的 Gradle 的守护进程\n\n\n--stop(Standalone command)\n运行 gradle --stop 来停止同一个 Gradle 版本的所有守护进程\n\n\n-Dorg.gradle.daemon.idletimeout=(number of milliseconds)\n\n\n\nLogging optionsSetting log level\n\n\n名称\n含义\n\n\n\n-Dorg.gradle.logging.level=(quiet, warn, lifecycle, info, debug)\n通过 Gradle 属性设置日志级别\n\n\n-q, --quiet\n只打印异常日志\n\n\n-w, --warn\n设置日志级别为 warn\n\n\n-i, --info\n设置日志级别为 info\n\n\n-d, --debug\n设置日志级别为 debug(包含正常对账信息)\n\n\nlifecycle 是默认的日志级别\nCustomizing log format通过指定 console 模式来控制输出的颜色和字体\n\n\n\n名称\n含义\n\n\n\n-Dorg.gradle.console=(auto, plain, rich, verbose)\n通过 Gradle 属性指定 console 的模式\n\n\n--console=(auto, plain, rich, verbose)\n指定生成什么类型的 console\n\n\nplain\n只生成普通文本. 这个选项禁用所有颜色和其他富文本 console 输出. 在 Gradle 连接到一个终端时默认是这个模式\n\n\nrich\n开启颜色和其他富文本 console 输出\n\n\nverbose\n和 rich 一样, 但额外在 lifecycle 日志级别输出 task 名称. 在 Gradle 3.5 或更早之前的版本这个模式是默认的\n\n\nShowing or hiding warnings默认情况下, Gradle 不会显示所有的警告(例如, deprecation warnings)\n相反, Gradle 会收集它们并在构建的结尾渲染一个总结\n\n\n\n名称\n含义\n\n\n\n-Dorg.gradle.warning.mode=(all, fail, none, summary)\n通过 Gradle 属性配置不同的模式\n\n\n--warning-mode=(all, fail, none, summary)\n指定怎样打印警告日志. 默认是 summary\n\n\nall\n打印所有的警告日志\n\n\nfail\n打印所有警告日志, 并在出现任何警告时使构建失败\n\n\nsummary\n不打印警告日志, 在构建的结尾打印一个总结\n\n\nnone\n不打印所有警告日志, 在构建的结果也不打印总结\n\n\nExecution options\n\n\n名称\n含义\n\n\n\n--include-build\n以组合(composite)的形式运行构建, 包含指定的构建\n\n\n--offline\n指明构建要在不访问网络资源的情况下进行\n\n\n--refresh-dependencies\n刷新依赖的状态(state)\n\n\n--dry-run\n在停止执行所有 task 的 action 的情况下运行 Gradle; 主要用来显示哪个 task 会执行\n\n\n--wirte-locks\n指定所有可锁定的已解析的配置都应该保持其锁定状态\n\n\n--update-locks &lt;group:name&gt;[,&lt;group:name&gt;]*\n表示指定模块的版本必须在 lock file 文件中更新\n\n\n--no-rebuild\n不要重建项目依赖. 在调试和微调 buildSrc 时很有用, 但可能会导致错误结果, 谨慎使用\n\n\nEnvironment options\n\n\n名称\n含义\n\n\n\n-b, --build-file\n已过时; 指定构建文件, 默认是 build.gradle\n\n\n-c, --settings-file\n已过时; 执行 settings 文件, 默认是 settings.gradle\n\n\n-g, --gradle-user-home\n执行 Gradle 的用户家目录. 默认是用户家目录的 .gradle 目录\n\n\n-p, --project-dir\n指定 Gradle 的工作起始目录. 默认是当前目录\n\n\n--project-cache-dir\n指定特定项目的缓存目录. 默认是在根目录中的 .gradle 目录\n\n\n-D, --system-prop\n设置 JVM 的系统属性. 例如, -Dmyprop=myvalue\n\n\n-I, --init-script\n指定一个初始化脚本\n\n\n-P, --project-prop\n这是根目录的项目属性. 例如, -Pmyprop=myvalue\n\n\n-Dorg.gradle.jvmargs\n设置 JVM 参数\n\n\n-Dorg.gradle.java.home\n设置 JDK 家目录\n\n\nBootstrapping new projectsCreating new Gradle builds使用内置的 gradle init task 来创建一个新的 Gradle 构建, 在一个新的或已存在的项目上\n使用 init task 的时候可以指定一个项目类型, 查看 init plugin 获得更多细节:\ngradle init --type java-library\n\nStandardize and provision Gradle内置的 gradle wrapper task 生成一个脚本 gradlew, 这个脚本调用了一个指定版本的 Gradle, 会在使用这个指定版本的 Gradle 之前下载它\ngradle wrapper --gradle-version=4.4\n\n除了 --gradle-version, 还可以指定 --distribution-type=(bin|all), --gradle-distribution-url, --gradle-distribution-sha256-sum\nContinuous Build持续构建允许你自动重新执行要求的 task, 在 task 的 inputs 改变的时候\nExample - continuously run the test task and all dependent tasks by running:\ngradle test --continuous\n\nGradle 的行为就像你在修改源代码或者修改有助于测试的 task之后运行 gradle test一样\n这意味着不相关的变更(例如修改构建脚本)不会出发一个重新构建\n为了包含构建逻辑修改, 持续构建必须手动重新启动\nTerminating Continuous Build如果 Gradle 是附加(attached)到一个交互式的 input source, 例如一个中断, 那么持续构建可以通过 CTRL-D 来退出\n如果 Gradle 不是 attached 到一个交互式的 input source, 例如作为一个脚本的一部分来运行, 持续构建必须被中断, 使用类似 kill 的命令\n如果构建是通过 Tooling API 运行的, 那么通过 Tooling API 的取消机制来停止运行\nLimitations and quirksBuild cycles如果 Gradle 检测到一个 task 的 inputs 修改了的时候就会触发一个构建, 但是在触发一个构建的过程中, inputs 再次改变了, Gradle 就会再次触发一个构建\nRestrictions with Java 9因为 Java 9 中的类访问限制, Gradle 不能设置一些操作系统指定的选项:\n\n在 macOS, Gradle 将会每 10 秒轮询文件修改, 而不是每 2 秒\n在 Windows, Gradle 必须使用单独的文件观察, 将会导致持续构建在一个非常大的项目上不再工作\n\nPerformance and stability在各个平台上面都有各种问题, 建议不使用持续构建\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Configuration time and execution time","url":"/gradle/gradle-configuration-time-and-execution-time/","content":"Configuration time and execution timeParallel project execution通过命令行参数 --parallel 来使用并行模式\n或者在 Gradle properties 中进行配置\n如果没有指定并行的线程数, Gradle 将会根据可用的 CPU 核心数来选择合适的线程数量\n每个 parallel worker 在执行一个 task 的时候单独地拥有一个给定的 project\nDecoupled Projectdecoupled : 解耦\n如果两个 project 没有直接访问彼此的 project model, 那么就可以说着两个 project 是解耦的\n使用类似 allprojects 和 subprojects 关键字自动地导致你的项目是耦合的\n但是将 root project 和 subprojects 耦合在一起不会影响 configuration on-demand\n在任何 subprojects 的 build.gradle 中使用 allprojects 和 subprojects 将会导致耦合\n避免一个 subprojects 的构建脚本引用其他 subprojects 的构建脚本; 在 root project 中配置跨项目配置\n避免在执行阶段修改其他项目的配置\nConfiguration on demand按需配置尝试只配置请求的 task 关联的项目\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Declaring Dependencies between Subprojects","url":"/gradle/gradle-declaring-dependencies-between-subprojects/","content":"Declaring Dependencies between SubprojectsDepending on artifacts produced by another projectExample - Task generating a property file containing build information:\n// build.gradleplugins &#123;    id &#x27;java-library&#x27;&#125;version = &#x27;1.0&#x27;def buildInfo = tasks.register(&quot;buildInfo&quot;, BuildInfo) &#123;    version = project.version    outputFile = layout.buildDirectory.file(&#x27;generated-resources/build-info.properties&#x27;)&#125;sourceSets &#123;    main &#123;        output.dir(buildInfo.map &#123; it.outputFile.asFile.get().parentFile &#125;)    &#125;&#125;\n\nExample - buildSrc/src/main/java/BuildInfo.java:\npublic abstract class BuildInfo extends DefaultTask &#123;    @Input    public abstract Property&lt;String&gt; getVersion();    @OutputFile    public abstract RegularFileProperty getOutputFile();    @TaskAction    public void create() throws IOException &#123;        Properties prop = new Properties();        prop.setProperty(&quot;version&quot;, getVersion().get());        try (OutputStream out = new FileOutputStream(getOutputFile().getAsFile().get())) &#123;            prop.store(output, null);        &#125;    &#125;&#125;\n\nExample - Declaring a project dependency on the project producing the properties file:\n// build.gradledependencies &#123;    runtimeOnly project(&#x27;:producer&#x27;)&#125;\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Dependency Management","url":"/gradle/gradle-dependency-management/","content":"\n\n\nDependency Management\nLearning the Basics\nDeclaring repositories\nStrict limitation to declared repositories\nSupported repository types\nDifferent formats\nWith different connectivity\n\n\nFlat directory repository\nLocal repository\nMaven repositories\nSetting up composite Maven repositories\nLocal Maven repository\nThe case of mavenLocal()\n\n\nIvy repositories\nDefining an Ivy repositories with a standard layout\nDefining a named layout for an Ivy repository\nDefining custom pattern layout for an Ivy repository\nAccessing authenticated Ivy repositories\n\n\nRepository content filtering\nDeclaring content exclusively fonud in one repository\n\n\nMaven repository filtering\nSupported metadata sources\nPlugin repositories vs. build repositories\nPlugin repositories\n\n\nCentralizing repositories declaration\nSupported repository transport protocols\nHTTP(S) authentication schemes configuration\nusing preemptive authentication\nUsing HTTP header authentication\n\n\nHandling credentials\nDeclaring dependencies\nWhat are dependency configurations\nConfiguration inheritance and composition\n\n\nResolvable and consumable configurations\nDefining custom configurations\nDifferent kinds of dependencies\nModule dependencies\nFile dependencies\n\n\nVersioning of file dependencies\nProject dependencies\nType-safe dependencies\nGradle API dependency\nGradle TestKit dependency\nLocal Groovy dependency\nDocumenting dependencies\n\n\nUnderstanding the difference between libraries and applications\nProducers vs consumers\nStrong encapsulation\nBeing respectful of consumers\n\n\nViewing and debugging dependencies\nListing dependencies in a project\nIdentifying which dependency version was selected and why\n\n\nUnderstanding dependency resolution\nHow Gradle handles conflicts?\nVersion conflicts\nImplementation conflicts\nVersion conflicts resolution\nResolution strategy\n\n\nImplementation conflict resolution\nHow Gradle retrieves dependency metadata?\nThe Dependency Cache\nVerifying dependencies\nEnabling dependency verification\nThe verification metadata file\n\n\nBootstrapping dependency verification\n\n\n\n\nDeclaring Versions\nDeclaring a dependency without version\nDeclaring Rich Versions\nstrictly\nrequire\nprefer\nreject\nRich version declaration\n\n\nHandling versions which change over time\nDeclaring a dynamic version\nDeclaring a changing version\nControlling dependency cacheing programmatically\nControlling dependency caching from command line\nAvoiding network access with offline mode\nRefreshing dependencies\n\n\nUsing component selection rules\n\n\nLocking dependency versions\n\n\nControlling transitive Dependencies\nAdding constraints on transitive dependencies\nDowngrading versions and excluding dependencies\nOverriding transitive dependency versions\nExcluding transitive dependencies\n\n\nSharing dependency versions between projects\nCentral declaration of dependencies\nDeclaring a version catalog\nUsing a platform to control transitive versions\nImporting Maven BOMs\n\n\n\n\nExcluding a dependency from a configuration completely\nPublishing Libraries\nPublishing a project as module\nWhat to publish\nWhere to publish\nHow to publish\nSetting up basic publishing\nSuppressing validation errors\nUnderstanding Gradle Module Metadata\nGradle Module Metadata reproducibility\nDisabling Gradle Module Metadata publication\nSigning artifacts\n\n\n\n\n\n\n\nDependency ManagementLearning the BasicsGradle Build 会访问本地文件系统的仓库, 并将使用到的 artifact 保存到 Gradle Cache 中\n可以为不同 scope 声明不同的依赖, 例如, 为编译源代码的 scope, 为执行测试的 scope\n在 Gradle 中, 一个依赖的 scope 被称为配置(configuration)\nDeclaring repositoriesExample - Adding central Maven repository:\n// build.gradlerepositories &#123;    mavenCentral()&#125;\n\nExample - Adding Google Maven repository:\n// build.gradlerepositories &#123;    google()&#125;\n\n自定义 URLs 的仓库可以被定义为 Maven 或者 Ivy 仓库, 通过调用 RepositoryHandler API 中对应的方法来定义\nGradle 不仅支持 http 和 https 协议的 URLs, 还支持 file, sftp, s3 协议\n可以使用 ivy &#123;&#125; 来定义你自己的仓库布局\nExample - Declaring multiple repositories:\n// build.gradlerepositories &#123;    mavenCentral()    maven &#123;        url &quot;http://repo.spring.io/release&quot;    &#125;    maven &#123;        url &quot;https://repository.jboos.org/maven2&quot;    &#125;&#125;\n\n仓库声明的顺序决定了 Gradle 在运行时将会怎样检查依赖. 如果 Gradle 在一个仓库中发现了一个 module descriptor, Gradle 将会尝试在同一个仓库中下载这个 module 的所有 artifact\nStrict limitation to declared repositoriesMaven POM metadata 可以引用额外的仓库. 但是 Gradle 会忽略这些\nGradle 只会使用在构建中声明的仓库\nSupported repository typesDifferent formats一个兼容 Maven 构件的仓库\n一个兼容 Ivy 构建的仓库(包括自定义布局)\n本地(扁平)文件夹\nWith different connectivity一个认证的仓库\n一个多种远程协议的仓库, 例如 HTTPS, SFTP, AWS S3\nFlat directory repositoryExample - Flat repository resolver:\n// build.gradlerepositories &#123;    flatDir &#123;        dirs &#x27;lib&#x27;    &#125;    flatDir &#123;        dirs &#x27;lib1&#x27;, &#x27;lib2&#x27;    &#125;&#125;\n\nGradle 在这些目录中查找依赖\n这种类型的仓库不支持任何元数据格式, 例如 Ivy XML, Maven POM 文件\nGradle 会基于存在的构建动态地生成一个 module 描述器(没有任何依赖信息)\nGradle 更加倾向于使用有真正 module 描述器的 module, 而不是自动生成的\n如果两个 module 同时找到, flat directory 中的 module, 和其他仓库中的 module, 其他仓库中的这个 module 拥有 *.pom 文件来声明元数据, Gradle 将会使用有 *.pom 文件的仓库\nLocal repository本地仓库和 flat directory 的区别在于本地仓库遵循一个格式与包含元数据\n如果定义了本地仓库, Gradle 完全跳过它的依赖缓存, 因为不能保证在两次执行之间内容不会发生改变. 由于这个限制, 这会有很大的性能影响\n它们也使得构建的重现性更加难以实现，它们的使用应该限于修补或原型开发\nMaven repositoriesGradle 可以通过 URL 来声明 Maven 仓库\nExample - Adding custom Maven repository:\n// build.gradlerepositories &#123;    maven &#123;        url &quot;http://repo.mycompany.com/maven2&quot;    &#125;&#125;\n\nSetting up composite Maven repositories有时候一个仓库会将 POMs 发布到一个位置, 将 JARs 发布到一个位置, 将构建发布到另外一个位置\nExample - Adding additional Maven repositories for JAR files:\n// build.gradlerepositories &#123;    maven &#123;        // Look for POMs and artifacts, such as JARs, here        url &quot;http://repo2.mycompany.com/maven2&quot;        // Look for artifacts here if not found at the above location        artifactUrls &quot;http://repo.mycompany.com/jars&quot;        artifactUrls &quot;http://repo.mycompany.com/jars2&quot;    &#125;&#125;\n\nGradle 将会从 url 中搜索 POM 和 JAR. 如果 JAR 找不到, 将会从 artifactUrl 搜索\nLocal Maven repositoryGradle 可以从本地 Maven 仓库中获取依赖\nGradle 在自己的缓存中保存解析好的依赖. 一个构建不需要声明本地 Maven 仓库, 即使你从一个远程的 Maven 仓库解析依赖\n在添加一个 Maven 本地仓库之前, 你应该确认真的需要它\nExample - Adding the local Maven cache as a repository:\n// build.gradlerepositories &#123;    mavenLocal()&#125;\n\nGradle 默认从 USER_HOME/.m2 中读取 settings.xml 来定位本地 Maven 仓库, 否则 Gradle 将会使用默认的 USER_HOME/.m2/repository 位置\nThe case of mavenLocal()应该尽量避免添加 mavenLocal() 作为仓库. 存在的问题:\nMaven 使用它来作为一个缓存, 而不是一个仓库, 意味着它可能包含不完全的 module:\n\n例如. 如果 Maven 永远没有下载一个 module 的源码和文档文件, 那么 Gradle 也不会搜索它们, 因为 Gradle 一旦找到 module, 它就会在单个存储库中搜索文件\n\n作为一个本地仓库, Gradle 不相信它里面的内容, 因为:\n\n构件的源无法跟踪, 导致了正确性和安全性问题\n构件可以很容易地被覆盖, 导致了正确性, 安全性, 可重现性问题\n\n为了减轻元数据或者构件可以被修改的事实, Gradle 不会为本地仓库进行任何缓存:\n\n导致的结果是, 你的构建会更加慢\n声明本地 Maven 仓库的顺序是很重要的, 将 mavenLocal() 放在最前意味着你所有的构建都会更慢\n\n有一些情况你还是必须使用 mavenLocal():\n\n和 Maven 互相操作\n和 Gradle 自己互相操作\n\n如果还是要使用 mavenLocal(), 记得将其和仓库过滤器一起使用\nIvy repositoriesDefining an Ivy repositories with a standard layoutExample - Ivy repository:\n// build.gradlerepositories &#123;    ivy &#123;        url &quot;http://repo.mycompany.com/repo&quot;    &#125;&#125;\n\nDefining a named layout for an Ivy repositoryExample - Ivy repository with named layout:\n// build.gradlerepositories &#123;    ivy &#123;        url &quot;http://repo.mycompany.com/repo&quot;        layout &quot;maven&quot;    &#125;&#125;\n\n有效的 layout 是:\n\ngradle(默认)\nmaven\nivy\n\n在 IvyArtifactRepository.layout(java.lang.String) API 中查看更多 named layout 的细节\nDefining custom pattern layout for an Ivy repositoryExample - Ivy repository with pattern layout:\n// build.gradlerepositories &#123;    ivy &#123;        url &quot;http://repo.mycompany.com/repo&quot;        patternLayout &#123;            artifact &quot;[module]/[revision]/[type]/[artifact].[ext]&quot;        &#125;    &#125;&#125;\n\nAccessing authenticated Ivy repositoriesExample - Ivy repository with authentication:\n// build.gradlerepositories &#123;    ivy &#123;        url &quot;http://repo.mycompany.com&quot;        credentials &#123;            username &quot;user&quot;            password &quot;password&quot;        &#125;    &#125;&#125;\n\nRepository content filteringExample - Declaring repository contents:\n// build.gradlerepositories &#123;    maven &#123;        url &quot;http://repo.mycompany.com/maven2&quot;        content &#123;            // this repository *only* contains artifacts with group &quot;my.company&quot;            includeGroup &quot;my.company&quot;        &#125;    &#125;    mavenCentral &#123;        content &#123;            // this repository contains everything BUT artifacts with group starting with &quot;my.company&quot;            excludeGroupByRegex &quot;my\\\\.company.*&quot;        &#125;    &#125;&#125;\n\n默认情况下, 仓库包含所有东西, 什么东西都不排除\n如果你声明了 include, 将会 exclude 包含的东西以外的所有东西\n如果你声明了 exclude, 将会 include 排除的东西以外的所有东西\n如果你同时声明了 include 和 exclude, 只会 include 声明的东西和没有被 exclude 的东西\n可以使用指定 group, module, version, 或者精确的和正则的表达式来进行过滤\n可以使用 version 范围来过滤\n可以通过配置名或者配置值来进行过滤\n查看 RespositoryContentDescriptor 了解更多细节\nDeclaring content exclusively fonud in one repositoryexclusively : 独占地\nExample - Declaring exclusive repository contents:\n// build.gradlerepositories &#123;    // This repository will *not* be searched for artifacts in my.company    // despite being declared first    mavenCentral()    exclusiveContent &#123;        forRepository &#123;            maven &#123;                url &quot;http://repo.mycompany.com/maven2&quot;            &#125;        &#125;        filter &#123;            // this repository *only* contains artifacts with group &quot;my.company&quot;            includeGroup &quot;my.company&quot;        &#125;    &#125;&#125;\n\nMaven repository filteringExample - Splitting snapshots and releases:\n// build.gradlerepositories &#123;    maven &#123;        url &quot;https://repo.mycompany.com/releases&quot;        mavenContent &#123;            releaseOnly()        &#125;    &#125;    maven &#123;        url &quot;http://repo.mycompany.com/snapshots&quot;        mavenContent &#123;            snapshotsOnly()        &#125;    &#125;&#125;\n\nSupported metadata sources当在一个仓库中搜索一个 module 时, Gradle 默认地在仓库中检查 支持的元数据文件格式(supported metadata file formats)\n在一个 Maven 仓库中, Gradle 查找一个 .pom 文件\n在一个 Ivy 仓库中, Gradle 查找一个 Ivy.xml 文件\n在一个 flat directory 仓库中, Gradle 直接查找 .jar 文件, 因为没有元数据文件\n从 5.0 版本开始, Gradle 还会查找 .module 文件\n如果你定义了一个自定义仓库, 想要控制这些行为. 例如, 定义一个没有 .pom 文件的只有 jar 文件的 Maven 仓库, 可以这样进行配置:\nExample - Maven repository that supports artifacts without metadata:\n// build.gradlerepositories &#123;    maven &#123;        url &quot;http://repository.mycompany.com/repo&quot;        metadataSources &#123;            mavenPom()            artifact()        &#125;    &#125;&#125;\n\n可以声明多个 sources 来告诉 Gradle 来在一个文件查找不到时继续寻找, 通过 sources 的顺序来进行寻找\nTable - Supported metadata sources:\n\n\n\nMetadata\nDescription\nOrder\nMaven\nIvy&#x2F;flat dir\n\n\n\ngradleMetadata()\n寻找 .module 文件\n第一\nyes\nyes\n\n\nmavenPom()\n寻找 .pom 文件\n第二\nyes\nyes\n\n\nivyDescriptor()\n寻找 ivy.xml 文件\n第二\nno\nyes\n\n\nartifact()\n直接寻找构件文件\n第三\nyes\nyes\n\n\nIvy 和 Maven 仓库的默认行为从 Gradle 6.0 开始变化了\n在 6.0 之前, artifact() 是默认引入的, 导致了在 module 完全不存在时效率很差. 为了修正这个行为, 对于 Maven 仓库可以使用 mavenCentral &#123; metadataSources &#123; mavenPom(); artifact() &#125; &#125;\n在旧版本中, mavenCentral &#123; metadataSources &#123; mavenPom() &#125; &#125; 可以达到同样的行为\n从 Gradle 5.3 开始, 当解析一个 metadata 文件时, Ivy 的或者 Maven 的, Gradle 会寻找一个 marker 来表明一个匹配的 Gradle module metadata 文件是否存在. 如果存在, 将会使用这个 module 文件\n从 Gradle 5.6 开始, 可以通过添加 ignoreGradleMetadataRedirection() 来停止这个功能\nExample - Mavne repository that does not use gradle metadata redirection:\n// build.gradlerepositories &#123;    maven &#123;        url &quot;http://repo.mycompany.com/repo&quot;        metadataSources &#123;            mavenPom()            artifact()            ignoreGradleMetadataRedirection()        &#125;    &#125;&#125;\n\nPlugin repositories vs. build repositoriesGradle 将会在构建的两个不同阶段使用仓库\n第一个阶段是配置你的构建并加载插件时, Gradle 将会使用一组特别的仓库\n第二个阶段是在依赖解析的时候, 在这个时候 Gradle 将会使用你在项目中声明的仓库\nPlugin repositories默认情况下, Gradle 将会使用 Gradle plugin portal 来搜索插件\nExample - Using plugins from custom plugin repositories:\n// setting.gradlepluginManagement &#123;    repositories &#123;        maven &#123;            url &#x27;./maven-repo&#x27;        &#125;        gradlePluginPortal()        ivy &#123;            url &#x27;./ivy-repo&#x27;        &#125;    &#125;&#125;\n\nCentralizing repositories declaration除了在每个子项目的构建中, 或者在一个 allprojects &#123;&#125; 中声明仓库\nGradle 提供了一个集中的地方来为所有项目进行声明\n作为约定并应用于所有子项目的仓库可以被声明在 settings.gradle 文件中\nExample - Declaring a Maven repository in settings:\n// settings.gradledependencyResolutionManagement &#123;    repositories &#123;        mavenCentral()    &#125;&#125;\n\n默认情况下, 一个项目中的仓库声明将会覆盖 settings 中的声明, 可以通过修改这个行为来确保总是使用 settings 中的声明\nExample - Preferring settings repositories:\n// settings.gradledependencyResolutionManagement &#123;    repositoriesMode.set(RepositoriesMode.PREFER_SETTINS)&#125;\n\n因为一些原因, 一个项目或者一个声明了一个仓库, Gradle 会进行警告, 你可以让构建因为这样的行为而失败, 从而强制使用 settings 中的仓库\nExample - Enforcing settings repositories:\n// settings.gradledependencyResolutionManagement &#123;    repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS)&#125;\n\nExample - Preferring project repositories:\n// settings.gradledependencyResolutionManagement &#123;    repositoriesMode.set(RepositoriesMode.PREFER_PROJECT)&#125;\n\nSupported repository transport protocolsTable - Repository transport protocols:\n\n\n\nType\nCredential types\n\n\n\nfile\nnone\n\n\nhttp\nusername&#x2F;password\n\n\nhttps\nusername&#x2F;password\n\n\nsftp\nusername&#x2F;password\n\n\ns3\naccess key&#x2F;secret key&#x2F;session token or Environment variables\n\n\ngcs\ndefault application credentials sourced from well known files, Environment variables etc\n\n\n不要将密码明文保存在构建脚本中\n可以将证书存储在一个本地的 gradle.properties 文件中, 然后使用一个开源的 Gradle 插件来加解密证书, 例如 credentials plugin\nExample - Using the SFTP protocol for a repository:\n// build.gradlerepositories &#123;    maven &#123;        url &quot;sftp://repo.mycompany.com:22/maven2&quot;        credentials &#123;            username &quot;user&quot;            password &quot;password&quot;        &#125;    &#125;    ivy &#123;        url &quot;sftp://repo.mycompany.com:22/repo&quot;        credentials &#123;            username &quot;user&quot;            password &quot;password&quot;        &#125;    &#125;&#125;\n\nHTTP(S) authentication schemes configurationExampel - Accessing password-protected Maven repository:\n// build.gradlerepositories &#123;    maven &#123;        url &quot;http://repo.mycompany.com/maven2&quot;        credentials &#123;            username &quot;user&quot;            password &quot;password&quot;        &#125;    &#125;&#125;\n\nExample - Configure repository to use only digest authentication:\n// build.gradlerepositories &#123;    maven &#123;        url &quot;https://repo.mycompany.com/maven2&quot;        credentials &#123;            username &quot;user&quot;            password &quot;password&quot;        &#125;        authentication &#123;            digest(DigestAuthentication)        &#125;    &#125;&#125;\n\n当前支持的 authentication schemes 是:\n\nBasicAuthentication\nDigestAuthentication\nHttpHeaderAuthentication\n\nusing preemptive authenticationpreemptive : 抢占式\nGradle 的默认行为是仅仅在一个服务器响应 HTTP 401 时才提交认证\n在一些情况下, 服务器可能会响应不同的代码从而导致依赖解析失败\n为了解决这个问题, 认证可以抢占式地发送给服务器\n通过配置 BasicAuthentication scheme 来显式使用抢占式认证\nExample - Configure repository to use preemtive authentication:\n// build.gradlerepositories &#123;    maven &#123;        url &#x27;https://repo.mycompany.com/maven2&quot;        credentials &#123;            username &quot;user&quot;            password &quot;password&quot;        &#125;        authentication &#123;            basic(BasicAuthentication)        &#125;    &#125;&#125;\n\nUsing HTTP header authentication通过 HttpHeaderCredentials 使用 HttpHeaderAuthentication 来指定任何 HTTP header 类来使用要求 token, OAuth2, 或者其他基于 HTTP header 认证的保密 Maven 仓库\nExample - Accessing header-protected Maven repository:\n// build.gradlerepositories &#123;    maven &#123;        url &quot;http://repo.mycompany.com/maven2&quot;        credentials(HttpHeaderCredentials) &#123;            name = &quot;Private-Token&quot;            value = &quot;TOKEN&quot;        &#125;        authentication &#123;            header(HttpHeaderAuthentication)        &#125;    &#125;&#125;\n\nHandling credentials不要将用户名密码保存到构建脚本中, 将其保存到 Gradle Properties 中\nExample - Externalized repository credentials:\n// build.gradlerepositories &#123;    mavne &#123;        name = &quot;mySecureRepository&quot;        credentials(PasswordCredentials)    &#125;&#125;\n\n用户名和密码将会通过 mySecureRepositoryUsername 和 mySecureRepositoryPassword property 来进行查找\n认证信息可以通过 gradle.properties 文件, 命令行参数, 环境变量或者这些方式的组合来提供\n认证信息只有在构建真正使用到它的时候才会进行访问\n如果真的需要用到认证信息, Gradle 将会首先检查构建信息是否存在, 如果不存在则不会执行后面的 task\nTable - Credentials that support value lookup and their corresponding properties:\n\n\n\nType\nArgument\nBase property name\nRequired?\n\n\n\nPasswordCredentials\nusername\nUsername\nrequired\n\n\nPasswordCredentials\npassword\nPassword\nrequired\n\n\nAwsCredentials\naccesskey\nAccessKey\nrequired\n\n\nAwsCredentials\nsecretKey\nSecretKey\nrequired\n\n\nAwsCredentials\nsessionToken\nSessionToken\noptional\n\n\nHttpHeaderCredentials\nname\nAuthHeaderName\nrequired\n\n\nPasswordCredentials\nvalue\nAuthHeaderValue\nrequired\n\n\nDeclaring dependenciesWhat are dependency configurationsGradle 项目中声明的每个依赖都被应用到一个指定的作用域(scope)\nGradle 在配置的帮助下表示依赖的作用域\n每个配置都通过一个唯一的名字来进行标识\n许多 Gradle 插件添加了预定义的配置到你的项目中. 例如 Java 插件, 添加配置来表示不同的 classpath\nConfiguration inheritance and composition一个配置可以继承其他配置, 来形成一个继承层次结构\n子配置继承了父配置中声明的所有的依赖\n配置继承在 Gradle 核心插件中大量使用, 例如 Java 插件, testImplementation 配置继承了 implemention 配置\n可以通过使用 Configuration.extendsFrom(org.gradle.api.artifacts.Configuration[]) 方法来继承其他配置\n一个配置可以继承其他配置, 不管这个配置是定义在构建脚本中还是来自插件\n例如, 定义一个新的称为 smokeTest 的配置, 这个配置继承了 testImplementation 配置来重用已经存在的测试框架依赖\nExample - Extending a configuration from another configuration:\n// build.gradleconfigurations &#123;    smokeTest.extendsFrom testImplementation&#125;dependencies &#123;    testImplementation &#x27;junit:junit:4.13&#x27;    smokeTest &#x27;org.apache.httpcomponents:httpclient:4.5.5&#x27;&#125;\n\nResolvable and consumable configurations在 Gradle 中, 配置是依赖解析必不可少的一部分\n在依赖解析的上下文中, 区别一个 consumer 和 一个 producer 是很有用的\n配置至少有 3 中不同的规则:\n\n声明依赖\n作为一个 consumer, 将一组依赖解析到文件\n作为一个 producer, 暴露 artifact 和 它们的依赖, 供其他项目使用 (这种可消费的配置通常代表生产者提供给消费者的变体)\n\nExample - Configurations are used to declare dependencies:\n// build.gradleconfigurations &#123;    // declare a &quot;configuration&quot; named &quot;someConfiguration&quot;    someConfiguration&#125;dependencies &#123;    // add a project dependency to the &quot;someConfiguration&quot; configuration    someConfiguration project(&quot;:lib&quot;)&#125;\n\n上面的例子中没有告诉我们关于这个配置的预期使用者的任何信息, 特别是, 它没有告诉我们如何使用配置\nExample - Configurations representing concrete dependency graphs - 表示具体依赖关系图的配置:\n// build.gradleconfigurations &#123;    // declare a configuration that is going to resolve the compile classpath of the application    compileClasspath.extendsFrom(someConfiguration)    // declare a configuration that is going to resolve the runtime classpath of the application    runtimeClasspath.extendsFrom(someConfiguration)&#125;\n\n这时, 我们有 3 个不同的配置, 具有不同的角色\n\nsomeConfiguration 声明了我们项目的依赖. 它仅仅是一个包含了一系列依赖的桶\ncompileClasspath 和 runtimeClasspath 是要被解析的配置\n\n在 Configuration 类中这个区别通过 canBeResolved 标识来表示\n一个可以被解析的配置是一个我们可以计算出依赖关系图的配置, 因为它包含了所有需要解析的信息\n将 canBeResolved 设置为 false 的配置并不意味着要被解析. 这样的配置只用于声明依赖项\n尝试解析一个 canBeResolved 为 false 的配置是一个 error\n一个可以解析的配置至少继承一个不可解析的配置\n假如, lib 项目暴露一个 apiElements 配置, 这个配置是针对寻找 API 的消费者的. 这样一个配置是 可消费的(consumable) , 但是不意味着可解析的. 这是通过 Configuration 的 canBeConsumed 标识表示的:\nExample - Setting up configurations:\n// build.gradleconfigurations &#123;    // A configuration meant for consumers that need the API of this component    exposedApi &#123;        // This configuration is an &quot;outgoing&quot; configuration, it&#x27;s not meant to be resolved        canBeResolved = false        // As an outgoing configuration, explain that consumers may want to consume it        canBeConsumed = true    &#125;    // A configuration meant for consumers that need the implemention of this component    exposedRuntime &#123;        canBeResolved = false        canBeConsumed = true    &#125;&#125;\n\n总结, 一个配置的角色是通过 canBeResolved 和 canBeConsumed 标识的组合来表示的:\nTable - Configuration roles:\n\n\n\nConfiguration role\ncan be resolved\ncan be consumed\n\n\n\nBucket of dependencies\nfalse\nfalse\n\n\nResolve for certain usage\ntrue\nfalse\n\n\nExposed to consumers\nfalse\ntrue\n\n\nLegacy, dont’ use\ntrue\ngrue\n\n\nDefining custom configurationsExample - Declaring and using a custom configuration:\n// build.gradleconfigurations &#123;    jasper&#125;repositories &#123;    mavenCentral()&#125;dependencies &#123;    jasper &#x27;org.apache.tomcat.embed:tomcat-embed-jasper:9.0.2&#x27;&#125;tasks.register(&#x27;preCompileJsps&#x27;) &#123;    doLast &#123;        ant.taskdef(classname: &#x27;org.gradle.jasper.JspC&#x27;,                    name: &#x27;jasper&#x27;,                    classpath: configurations.jasper.asPath)        ant.jasper(validateXml: false,                    uriroot: file(&#x27;src/main/webapp&#x27;),                    outputDir: file(&quot;$buildDir/compiled-jsps&quot;))    &#125;&#125;\n\n一个项目的配置是通过 configurations 对象来管理的\nDifferent kinds of dependenciesModule dependenciesmodule 依赖是最普通的依赖. 它们引用依赖库中的 module\nExample - Module dependencies:\n// build.gradledependencies &#123;    runtimeOnly gourp: &#x27;org.springframework&#x27;, name: &#x27;spring-core&#x27;, version: &#x27;2.5&#x27;    runtimeOnly(group: &#x27;org.hibernate&#x27;, name: &#x27;hibernate&#x27;, version: &#x27;3.0.5&#x27;) &#123;        transitive = true    &#125;&#125;\n\n查看 DependencyHandler 的 API 获取更多的信息\n查看 ExternalModuleDependency 来获取更多对 module 依赖进行配置的信息\n在 Maven 中, 一个 module 只能有一个 artifact\n在 Ivy 和 Gradle 中, 一个 module 可以有多个 artifact. 每个 artifact 可以有一组不同的依赖\nFile dependencies没有任何 metadata 的依赖\nExample - Declaring multiple file dependencies:\n// build.gradleconfigurations &#123;    antContrib    externalLibs    deploymentTools&#125;dependencies &#123;    antContrib files(&#x27;ant/antcontrib.jar&#x27;)    externalLibs files(&#x27;libs/commons-lang.jar&#x27;, &#x27;libs/log4j.jar&#x27;)    deploymentTools(fileTree(&#x27;tools&#x27;) &#123; include &#x27;*.exe&#x27;&#125;)&#125;\n\n使用 Project.files(java.lang.Object...), ProjectLayout.files(java.lang.Object...), Project.fileTree(java.lang.Object) 来创建一个文件引用\n文件依赖允许你直接添加一组文件到配置中, 而不需要首先将这些文件添加到依赖仓库中\n为了添加一些文件作为配置的依赖, 可以简单地传入一个文件集合作为依赖:\nExample - File dependencies:\n// build.gradledependencies &#123;    runtimeOnly files(&#x27;libs/a.jar&#x27;, &#x27;libs/b.jar&#x27;)    runtimeOnly fileTree(&#x27;libs&#x27;) &#123; include &#x27;*.jar&#x27; &#125;&#125;\n\n文件依赖不包含在已发布的依赖描述符中\n文件依赖包含在同一构建中的可传递项目依赖中\n这意味着它们不能用在当前构建之外, 但它们可以用在同一个构建中\nExample - Generated file dependencies:\n// build.gradledependencies &#123;    implementation files(layout.buildDirectory.dir(&#x27;classes&#x27;)) &#123;        builtBy &#x27;compile&#x27;    &#125;&#125;tasks.register(&#x27;compile&#x27;) &#123;    doLast &#123;        println &#x27;compiling classes&#x27;    &#125;&#125;tasks.register(&#x27;list&#x27;) &#123;    dependsOn configurations.compileClasspath    doLast &#123;        println &quot;classpath = $&#123;configurations.compileClasspath.collect &#123; File file -&gt; file.name &#125;&#125;&quot;    &#125;&#125;\n\nVersioning of file dependencies建议明确表达文件依赖关系的意图和具体版本\n在文件名中定义版本来进行区分, 例如: commons-beanutils-1.3.jar\nProject dependenciesExample - Project dependencies:\n// build.gradledependencies &#123;    implementation project(&#x27;:shared&#x27;)&#125;\n\n在运行时, 构建自动确保以正确的顺序构建项目依赖项, 并将其添加到类路径中进行编译\nType-safe dependencies从 Gradle 7.0 开始的一个实验性 API\nExample - Declaring project dependencies using the type-safe API:\n// web-services/build.gradledependencies &#123;    implementation projects.utils    implementation projects.api&#125;\n\nproject(&quot;:some:path&quot;) 的一个问题是你必须记住你想依赖的每个项目的路径\nGradle API dependency你可以使用 DependencyHandler.gradleApi() 方法来将当前版本的 Gradle 的 API 声明为依赖\n在进行自定义 task 开发, 插件开发时很有用\nExample - Gradle API dependencies:\n// build.gradledependencies &#123;    implementation gradleApi()&#125;\n\nGradle TestKit dependency你可以使用 DependencyHandler.gradleTestKit() 方法来将当前版本的 Gradle 的 TestKit API 声明为依赖\n在为 Gradle 插件或者构建脚本进行编写和执行时很有用\nExample - Gradle TestKit dependencies:\n// build.gradledependencies &#123;    testImplementation gradleTestKit()&#125;\n\nLocal Groovy dependency通过 DependencyHandler.localGroovy() 来依赖跟着 Gradle 发布的 Groovy\n这在使用 Groovy 开发自定义 Gradle task 和插件中非常有用\nExample - Gradle’s Groovy dependencies:\n// build.gradledependencies &#123;    implementation localGroovy()&#125;\n\nDocumenting dependencies声明为什么要使用这个依赖\nExample - Giving a reason for choosing a certain module version in a dependency declaration:\n// build.gradleplugins &#123;    id &#x27;java-library&#x27;&#125;repositories &#123;    mavenCentral()&#125;dependencies &#123;    implementation(&#x27;org.ow2.asm:asm:7.1&#x27;) &#123;        because &#x27;we require a JDK 9 compatible bytecode generator&#x27;    &#125;&#125;\n\nExample - Using the dependency insight report with custom reasons:\ngradle -q dependencyInsight --dependency asm\n\nUnderstanding the difference between libraries and applicationsProducers vs consumers如果你构建一个类库, 那么你实际上是一个生产者\n一个消费者要从更大的角度来理解:\n\n一个依赖另一个项目的项目是一个消费者\n一个依赖一个 artifact 的 task 是一个细粒度的消费者\n\nStrong encapsulation为了让生产者编译一个库, 它需要它所有的 implementation 配置的依赖在编译类路径上\n一个类库中的一个赋值给 implementation 配置的依赖不会出现在消费者的编译类路径中\n一个类库中的一个赋值给 api 配置的依赖会出现在消费者的编译类路径中\n但是在运行时, 所有的依赖都是必须的\nBeing respectful of consumers无论什么时候, 作为一个开发者, 你决定包含一个依赖, 你必须明白这会给你的消费者带来后果\n例如, 如果你添加一个依赖到你的项目中, 这个依赖变成一个传递性依赖到你的消费者中, 将有可能导致依赖冲突\nViewing and debugging dependenciesListing dependencies in a projectdependencies task 只会执行在一个项目上, 如果执行在根项目上, 只会显示根项目的依赖, 而不会显示子项目的依赖. 所以要在正确的项目上运行这个 task\n通过 --configuration 来指定要显示的配置的依赖\nExample - 显示一个指定的配置的依赖报告\nrepositories &#123;    mavenCentral()&#125;configurations &#123;    scm&#125;dependencies &#123;    scm &#x27;org.eclipse.jgit:org.eclipse.jgit:4.9.2.201712150930-r&#x27;&#125;\n\n运行结果:\n╭─daisy at thinkpad in ~/Desktop╰─○ gradle dependencies --configuration scmStarting a Gradle Daemon (subsequent builds will be faster)&gt; Task :dependencies------------------------------------------------------------Root project &#x27;Desktop&#x27;------------------------------------------------------------scm\\--- org.eclipse.jgit:org.eclipse.jgit:4.9.2.201712150930-r     +--- com.jcraft:jsch:0.1.54     +--- com.googlecode.javaewah:JavaEWAH:1.1.6     +--- org.apache.httpcomponents:httpclient:4.3.6     |    +--- org.apache.httpcomponents:httpcore:4.3.3     |    +--- commons-logging:commons-logging:1.1.3     |    \\--- commons-codec:commons-codec:1.6     \\--- org.slf4j:slf4j-api:1.7.2A web-based, searchable dependency report is available by adding the --scan option.BUILD SUCCESSFUL in 9s1 actionable task: 1 executed\n\n不能被解析的依赖使用红色来标记\n在图中出现多次的同一个依赖会被省略并使用 * 号来标记\n解决了依赖冲突的依赖使用 -&gt; 来标记\nIdentifying which dependency version was selected and whyGradle 使用版本冲突解决(version conflict resolution) 来保证一个依赖只有一个版本存在于依赖图中\nGradle 提供了一个 dependencyInsight task 来生成依赖洞察报告\ndependencyInsight task 使用如下参数\n\n\n\n名称\n含义\n是否可选\n\n\n\n--dependency &lt;dependency&gt;\n指明要观察的依赖; 可以是完整的 group:name, 也可以是部分名称; 如果有多个依赖, 则全部依赖都会打印到报告中\n必填\n\n\n--configuration &lt;name&gt;\n指明要观察哪个配置中的依赖; 默认是 Java 插件中的 compileClasspath 配置\n有 Java 插件时是可选; 无 Java 插件时是必填\n\n\n--singlepath\nIndicates to render only a single path to the dependency\n可选\n\n\ndependencyInsight task 只能执行在一个项目上, 如果在根目录执行, 则只能显示根目录的情况, 不包括子目录的情况\nExample - Using the dependency insight report for a given dependency:\n╭─daisy at thinkpad in ~/Desktop╰─○ gradle dependencyInsight --dependency commons-codec --configuration scm&gt; Task :dependencyInsightcommons-codec:commons-codec:1.7   variant &quot;default&quot; [      org.gradle.status = release (not requested)   ]   Selection reasons:      - By conflict resolution : between versions 1.7 and 1.6commons-codec:commons-codec:1.7\\--- scmcommons-codec:commons-codec:1.6 -&gt; 1.7\\--- org.apache.httpcomponents:httpclient:4.3.6     \\--- org.eclipse.jgit:org.eclipse.jgit:4.9.2.201712150930-r          \\--- scmA web-based, searchable dependency report is available by adding the --scan option.BUILD SUCCESSFUL in 786ms1 actionable task: 1 executed\n\nUnderstanding dependency resolutionHow Gradle handles conflicts?在进行依赖解析时, Gradle 处理两种类型的冲突:\n\n版本冲突(version conflicts)\n实现冲突(implementation conflicts)\n\nVersion conflicts有两个或更多的依赖需要一个依赖的不同版本\nImplementation conflictsThat is when the dependency graph contains multiple modules that provide the same implementation, or capability in Gradle terminology\n也就是说, 依赖关系图包含多个提供相同实现的模块, 或者用 Gradle 术语来说就是相同的功能\nVersion conflicts resolutionResolution strategyGradle 将会考虑所有需要的版本, 无论它们出现在依赖图的什么地方\n在这些版本中, Gradle 将会选择版本号最高的一个\nGradle 支持 rich version declaration, 所以最高版本取决于版本的声明方式:\n\n如果没有涉及范围, 则将选择未被拒绝的最高版本\n如果声明为 strictly 的版本低于该版本, 则选择将会失败\n\n\n如果有涉及范围\n如果有非范围版本位于指定范围内或高于其上限, 则将选中该版本\n如果只有范围, 则将选择该范围现有的最高版本和最高上限\n如果声明为 strictly 的版本低于该版本, 则选择将失败\n\n\n\n注意, 在涉及范围的情况下, Gradle 需要元数据来确定所考虑的范围中存在哪些版本. 这将会导致马上查找元数据\nImplementation conflict resolution查看 Understanding variant selection 章节的说明\n查看 Selecting between candidates 章节的说明\nHow Gradle retrieves dependency metadata?Gradle 需要元数据来指明使用的 module 版本\nGradle 倾向于使用有元数据文件的 module\n一旦一个依赖仓库返回了一个元数据结果, 其余的依赖仓库将会被忽略\n如果 module 的元数据是一个 POM 文件并且定义了一个父 POM, Gradle 将会尝试递归解析每一个父 module 的 POM\nThe Dependency Cache如果所需的构件在构建指定的任何仓库中都不可用, 那么依赖解析将会失败, 即使本地缓存拥有从不同仓库检索到的此构件的副本\n依赖仓库的独立性允许构建以一种以前任何构建工具都没有做到的高级方式彼此隔离\n如果一个构件的 checksum 文件不能从远程服务器中下载, 那么即使已经存在一个构件, 远程的构建都会被下载\n如果本地的 Maven 仓库中拥有相同的构件, 且能够与远程服务中构件的 checksum 检验通过的话, 将会使用本地的 Maven 仓库\n通过基于构件的 SHA1 checksum 来缓存构件, Gradle 可以保持同一个构件的不同版本\nGradle 会跟踪缓存的依赖的使用情况, 缓存如果超过30没有被使用, 那么将会被删除\nVerifying dependencies依赖检查包含两个不同但又互补的操作:\n\nchecksum 检查, 检查一个依赖的完整性\nsignature 检查, 检查一个依赖的来源\n\nGradle 默认不进行依赖检查\nEnabling dependency verificationThe verification metadata file一旦找到配置文件, 将会自动开启依赖检验\n配置文件位于 $PROJECT_ROOT/gradle/verification-metadata.xml, 文件的最少内容为:\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;verification-metadata&gt;    &lt;configuration&gt;        &lt;verify-metadata&gt;true&lt;/verify-metadata&gt;        &lt;verify-signatures&gt;false&lt;/verify-signatures&gt;    &lt;/configuration&gt;&lt;/verification-metadata&gt;\n\n使用这个最小配置的文件, 一个项目使用任何额外依赖或插件都会马上失败, 因为它不包含任何 checksum 去检验\n在命令行中输出检验信息, 通过在 gradle.properties 文件中添加配置: org.gradle.dependency.verification.console=verbose\nBootstrapping dependency verification依赖检验文件可通过下面的命令行参数来生成: gradle --write-verification-metadata sha256 help\nDeclaring VersionsDeclaring a dependency without version使用依赖限制来进行依赖声明\n这样做的好处是依赖限制允许你在一个地方管理所有依赖的版本, 包括传递性依赖\nExample - Declaring a dependency without version:\n// build.gradledependencies &#123;    implementation &#x27;org.springframework:spring-web&#x27;&#125;dependencies &#123;    constraints &#123;        implementation &#x27;org.springframework:spring-web:5.0.2.RELEASE&#x27;    &#125;&#125;\n\nDeclaring Rich Versionsstrictly任何与此版本标记不符合的版本都会被排除\n这个是最强的版本声明\n在一个声明的依赖上, strictly 可以降低版本\n在一个传递性依赖上, 如果没有此子句可接受的版本可以被选择, 这将会导致依赖解析失败\n当定义了这个之后, 将会覆盖之前所有的 require 声明和清除之前的 reject\nrequire意味着选择的版本不能低于 require 可以接受的范围, 但是在冲突解决时可以高于 require 的范围, 即使更高的版本有一个排除型的边界值\n当定义了这个之后, 将会覆盖之前所有的 strictly 声明和清除之前的 reject\nprefer它只适用于对于 module 的版本没有更强的非动态声明的情况\n这个声明可以用来补充 strictly 和 require\nreject声明指定的版本不能适用于 module\n将有可能导致依赖解析失败\nRich version declaration// build.gradledependencies &#123;    implementation(&#x27;org.slf4j:slf4j-api&#x27;) &#123;        version &#123;            strictly &#x27;[1.7, 1.8[&#x27;            prefer &#x27;1.7.25&#x27;        &#125;    &#125;    constraints &#123;        implementation(&#x27;org.springframework:spring-core&#x27;) &#123;            version &#123;                require &#x27;4.2.9.RELEASE&#x27;                reject &#x27;4.3.16.RELEASE&#x27;            &#125;        &#125;    &#125;&#125;\n\nHandling versions which change over time一个动态版本可以使用版本范围 2.+ 或者使用一个占位符来代表最新的可用版本 latest.integration\n一个 module 可能不断地改变, 但是有相同的版本号\n例如 Maven 的 SNAPSHOT module, 它总是指向最新发布的构件\nDeclaring a dynamic version// build.gradleplugins &#123;    id &#x27;java-library&#x27;&#125;repositories &#123;    mavenCentral()&#125;dependencies &#123;    implementation &#x27;org.springframework:spring-web:5.+&#x27;&#125;\n\n默认情况下, Gradle 缓存依赖的动态版本 24 小时, 在这个时间窗口内 Gradle 不会从仓库中尝试去解析更新的版本\nDeclaring a changing version在 Maven 仓库中, 一个改变中的版本通常认为是一个 snapshot versions\nSnapshot versions 包含后缀 -SNAPSHOT\nExample - Declaring a dependency with a changing version:\n// build.gradleplugins &#123;    id &#x27;java-library&#x27;&#125;repositories &#123;    mavenCentral()    maven &#123;        url &#x27;https://repo.spring.io/snapshot/&#x27;    &#125;&#125;dependencies &#123;    implementation &#x27;org.springframework:spring-web:5.0.3.BUILD-SNAPSHOT&#x27;&#125;\n\n默认情况下,  Gradle 缓存 changing versions 依赖 24 个小时\n在这个时间内, Gradle 不会尝试去在指定仓库中解析更新版本的依赖\nControlling dependency cacheing programmatically在配置中使用 ResolutionStrategy\nExample - Dynamic version cache control:\n// build.gradleconfigurations.all &#123;    resolutionStrategy.cacheDynamicVersionsFor 10, &#x27;minutes&#x27;&#125;\n\nExample - Changing module cache control:\n// build.gradleconfigurations.all &#123;    resolutionStrategy.cacheChangingModulesFor 4, &#x27;hours&#x27;&#125;\n\nControlling dependency caching from command lineAvoiding network access with offline mode--offline 命令行参数用来告诉 Gradle 总是使用缓存中的 module, 不管它们是否需要再次检查\n离线运行时, Gradle 永远不会尝试访问网络来进行依赖解析, 如果需要的 module 不存在于依赖缓存时, 构建会失败\nRefreshing dependencies您可以通过命令行控制不同构建执行的依赖项缓存行为\n使用 --refresh-dependencies 选项来刷新所有的依赖缓存\n只有当你实际使用了 dynamic dependencies, 或者你有一些你没有意识到的 changing dependencies 时, refreshing dependencies 才会产生影响\n认为使用 --refresh-dependencies 会强制下载依赖是一个普遍的误解\nGradle 只会执行刷新 dynamic dependencies 的严格要求. 可能会执行下载新的一些文件或元文件, 或构件. 但是如果什么都没有变化的话, 这个参数的影响是很小的\nUsing component selection rulesExample - Component selection rule:\n// build.gradleconfigurations &#123;    rejectConfig &#123;        resolutionStrategy &#123;            componentSelection &#123;                all &#123; ComponentSelection selection -&gt;                    if (selection.candidate.group == &#x27;org.sample&#x27; &amp;&amp; selection.candidate.module == &#x27;api&#x27; &amp;&amp; selection.candidate.version == &#x27;1.5&#x27;) &#123;                        selection.reject(&quot;version 1.5 is broken for &#x27;org.sample:api&#x27;&quot;)                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;dependencies &#123;    rejectConfig &quot;org.sample:api:1.+&quot;&#125;\n\nExample &#x3D; Component selection rule with module target:\n// build.gradleconfigurations &#123;    targetConfig &#123;        resolutionStrategy &#123;            componentSelection &#123;                withModule(&quot;org.sample:api&quot;) &#123;                    ComponentSelection selection -&gt;                    if (selection.candidate.version == &quot;1.5&quot;) &#123;                        selection.reject(&quot;version 1.5 is broken for &#x27;org.sample:api&#x27;&quot;)                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;\n\nLocking dependency versions依赖锁定只有在 dynamic versions 中生效. 在 changing versions 中不生效\nExample - Locking a specific configuration:\n// build.gradleconfigurations &#123;    compileClasspath &#123;        resolutionStrategy.activeDependencyLocking()    &#125;&#125;\n\nControlling transitive DependenciesAdding constraints on transitive dependenciesconstraints : 限制; 约束\n依赖约束允许你为构建脚本中的依赖版本和传递性依赖的版本定义版本或者版本范围\n默认情况下, 满足所有情况的最高版本会被选择\nExample - Define dependency constraints:\n// build.gradledependencies &#123;    implementation &#x27;org.apache.httpcomponents:httpclient&#x27;    constraints &#123;        implementation(&#x27;org.apache.httpcomponents:httpclient:4.5.3&#x27;) &#123;            because &#x27;previouse versions have a bug impacting this application&#x27;        &#125;        implementation(&#x27;commons-codec:commons-codec:1.11&#x27;) &#123;            because &#x27;version 1.9 pulled from httpclient has bugs affecting this application&#x27;        &#125;    &#125;&#125;\n\n在这个例子中, 依赖声明中的所有版本都会被忽略. 相反, 将会使用定义在 constraints 块中的版本, 包括传递性依赖中的构件都会使用这个块中的声明的版本\n依赖约束只有在使用 Gradle Module Metadata 时才发布(published)\nDowngrading versions and excluding dependenciesOverriding transitive dependency versionsExample - Setting a strict version:\n// build.gradledependencies &#123;    implementation &#x27;org.apache.httpcomponents:httpclient:4.5.4&#x27;    implementation(&#x27;commons-codec:commons-codec&#x27;) &#123;        version &#123;            strictly &#x27;1.9&#x27;        &#125;    &#125;&#125;\n\n首先使用 strict versions 而不是 forced dependencies\nExample - Enforcing a dependency version:\n// build.gradledependencies &#123;    implementation &#x27;org.apache.httpcomponents:httpclient:4.5.4&#x27;    implementation(&#x27;commons-codec:commons-codec:1.9&#x27;) &#123;        force = true    &#125;&#125;\n\nExample - Enforcing a dependency version on the configuration-level:\n// build.gradleconfigurations &#123;    compileClasspath &#123;        resolutionStrategy.force &#x27;commons-codec:commons-codec:1.9&#x27;    &#125;&#125;dependencies &#123;    implementation &#x27;org.apache.httpcomponents:httpclient:4.5.4&#x27;&#125;\n\nExcluding transitive dependenciesExample - Excluding a transitive dependency for a particular dependency declaration:\n// build.gradledependencies &#123;    implementation(&#x27;commons-beanutils:commons-beanutils:1.9.4&#x27;) &#123;        exclude group: &#x27;commons-collections&#x27;, module: &#x27;commons-collections&#x27;    &#125;&#125;\n\nSharing dependency versions between projectsCentral declaration of dependencies这是一个孵化中的特性\nExample - Using a library declared in a version catalog:\n// build.gradledependencies &#123;    implementation(libs.groovy.core)&#125;\n\nDeclaring a version catalogExample - Declaring a version catalog:\n// settings.gradledependencyResolutionManagement &#123;    versionCatalogs &#123;        libs &#123;            alias(&#x27;groovy-core&#x27;).to(&#x27;org.codehaus.groovy:groovy:3.0.5&#x27;)            alias(&#x27;groovy-json&#x27;).to(&#x27;org.codehaus.groovy:groovy-json:3.0.5&#x27;)            alias(&#x27;groovy-nio&#x27;).to(&#x27;org.codehaus.groovy:groovy-nio:3.0.5&#x27;)            alias(&#x27;commons-lang3&#x27;).to(&#x27;org.apache.commons&#x27;, &#x27;commons-lang3&#x27;).version &#123;                strictly &#x27;[3.8, 4.0[&#x27;                prefer &#x27;3.9&#x27;            &#125;        &#125;    &#125;&#125;\n\nUsing a platform to control transitive versionsExample - Getting versions declared in a platform:\n// build.gradledependencies &#123;    // get recommended versions from the platform project    api platform(project(&#x27;:platform&#x27;))    // no version required    api &#x27;commons-httpclient:commons-httpclient&#x27;&#125;\n\nImporting Maven BOMsBOMs 是 .pom 文件中的 &lt;dependencyManagement&gt; 节点, 用来控制依赖的版本\nExample - Depending on a BOM to import its dependency comstraints:\n// build.gradledependencies &#123;    // import a BOM    implementation platform(&#x27;org.springframework.boot:spring-boot-dependencies:1.5.8.RELEASE&#x27;)    // define dependencies without versions    implementation &#x27;com.google.code.gson:gson&#x27;    implementation &#x27;dom4j:dom4j&#x27;&#125;\n\nExample - Importing a BOM, making sure the versions it defines override any other version found:\ndependencies &#123;    // import a BOM. The versions used in this file will override any other version found in the graph    implementation enforcedplatform(&#x27;org.springframework.boot:spring-boot-dependencies:1.5.8.RELEASE&#x27;)    // define dependencies without versions    implementation &#x27;com.google.code.gson:gson&#x27;    implementation &#x27;dom4j:dom4j&#x27;    // this version will be overridden by the one found in the BOM    implementation &#x27;org.codehaus.groovy:groovy:1.8.6&#x27;&#125;\n\nExcluding a dependency from a configuration completely使用 Configuration.exclude(java.util.Map), 这个方法将会自动排除配置中声明的所有依赖项的传递依赖\nExample - Excluding transitive dependency for a particular configuration:\n// build.gradleconfigurations &#123;    implementation &#123;        exclude group: &#x27;commons-collections&#x27;, module: &#x27;commons-collections&#x27;    &#125;&#125;dependencies &#123;    implementation &#x27;commons-beanutils:commons-beanutils:1.9.4&#x27;    implementation &#x27;com.opencsv:opencsv:4.6&#x27;&#125;\n\nPublishing LibrariesPublishing a project as modulePublishing 是将所构建的东西提供给消费者使用的过程\n在 Gradle 中, 这个过程是这样的:\n\n定义发布什么东西\n定义发布到哪里去\n执行发布\n\n最常见的两种类型的发布仓库: Maven-compatible 和 Ivy-compatible\n从 Gradle 6.0 开始, Gradle Module Metadata 将始终与 Ivy XML 或者 Maven POM 元数据文件一起发布\nGradle 内置 Maven Publish Plugin 和 Ivy Publish Plugin 来进行发布\nWhat to publishGradle 将 artifacts 和 metadata 结合在一起的东西称为一个 publication\n一个被发布到 Maven 仓库的 publication 包含:\n\n一个或多个 artifact\nGradle Module Metadata 文件\nMaven POM 文件; -sources 和 -javadoc JAR 文件\nchecksum\nsignature\n从 Gradle 6.0 开始, 还会包括 SHA256 和 SHA512 的 checksum\n\nWhere to publish使用 repositories 来告诉 Gradle 将 publication 发布到哪里\nHow to publishGradle 自动为所有可能的 publication 组合和仓库生成发布 task\n如果发布到 Maven 仓库, task 是 PublishToMavenRepository 类型的\nSetting up basic publishingExample - Applying the necessary plugins:\n// build.gradleplugins &#123;    id &#x27;java-library&#x27;    id &#x27;maven-publish&#x27;  // Maven 发布插件&#125;\n\n配置好插件之后, 就可以配置 publication 和 仓库了\n在这个例子中, 我们想要发布 jar task 生成的 JAR 文件到 Maven 仓库中\n只需要使用 PublishingExtension 提供的 publishing &#123;&#125; 块\nExample - Configuring a Java library for publishing:\n// build.gradlegroup = &#x27;org.example&#x27;version = &#x27;1.0&#x27;publishing &#123;    publications &#123;        // 定义了一个名称为 &quot;myLibrary&quot; , 类型为 &quot;MavenPublication&quot; 的 publication        // 这个 Publication 包含了 java component 提供的 JAR artifact 和 metadata        myLibrary(MavenPublication) &#123;                               from components.java        &#125;    &#125;    repositories &#123;        maven &#123;            // 一个基于文件的 Maven 仓库, 名称为 &quot;myRepo&quot;            name = &#x27;myRepo&#x27;            // 一个基于文件的 Maven 仓库            url = layout.buildDirectory.dir(&quot;repo&quot;)        &#125;    &#125;&#125;\n\ncomponents 是定义一个 publication 的标准方式\ncomponents 通过插件提供, 通常是开发语言或平台的类型. 例如: Java 插件定义了 SoftwareComponent 类型的 components.java; War 插件定义了 components.web\n通过结合项目的 group 和 version, publication 和 仓库定义提供了 Gradle 发布项目产品 JAR 包所需的一切\nGradle 将会创建一个专门的 publishMyLibraryPublicationToMyRepoRepository task 来执行; 这个 task 的名字基于 publish[PubName]PublicationTo[RepoName]Repository 模板\n可以直接单独执行上面的 publishMyLibraryPublicationToMyRepoRepository task\n或者可以执行 publish task, 这个 task 将会运行所有可用的发布 task, 例如执行 publishMyLibraryPublicationToMyRepoRepository task\nSuppressing validation errors在 GenerateModuleMetadata task 中指定要关闭的校验异常的名称\nExample - Disabling some validation errors:\n// build.gradletasks.withType(GenerateModuleMetadata).configureEach &#123;    // The value &#x27;enforced-platform&#x27; is provided in the validation    // error message you got    suppressedValidationErrors.add(&#x27;enforced-platform&#x27;)&#125;\n\nUnderstanding Gradle Module MetadataGradle Module Metadata 是一个用来序列化 Gradle 组件模型的格式\n类似于 Maven 的 POM 文件, Ivy 的 ivy.xml 文件\nmetadata 文件的目标是为消费者提供一个合理的发布到仓库中的模型\nGradle Module Metadata 是一个独一无二的格式, 通过使其跨平台和面向变体来增强依赖解析\n具体来说, Gradle Module Metadata 支持:\n\nrich version constraints\ndependency constraints\ncomponent capabilities\nvariant-aware resolution\n\n发布 Gradle Module Metadata 将会让你的构件消费者有更好的依赖管理\nGradle Module Metadata 通过 Maven Publish plugin 插件自动发布\nGradle Module Metadata reproducibility如果想在每次构建执行的时候生成一个独一无二的 module 文件\nExample - Configuring the build identifier of a publication:\n// build.gradlepublishing &#123;    publications &#123;        myLibrary(MavenPublication) &#123;            from components.java            withBuildIdentifier()        &#125;    &#125;&#125;\n\nDisabling Gradle Module Metadata publication有两种不发布 Gradle Module Metadata 的可能性:\n\n要发布的仓库不接受这种类型的 metadata 文件\n想要仅仅以 Maven 或 Ivy 的概念来发布项目\n\n通过停用生成 metadata 文件的 task 来达到这个目的\nExample - Disabling publication of Gradle Module Metadata:\n// build.gradletasks.withType(GenerateModuleMetadata) &#123;    enabled = false&#125;\n\nSigning artifactsSigning 插件可以用来签名所有的构件和元数据文件, 包括 Maven 的 POM 文件和 Ivy module descriptors\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Extending Gradle Developing Custom Gradle Plugins","url":"/gradle/gradle-extending-gradle-developing-custom-gradle-plugins/","content":"\n\n\nExtending Gradle Developing Custom Gradle Plugins\nPackaging a plugin\nBuild script\nbuildSrc project\nStandalone project\n\n\nWriting a simple plugin\nMaking the plugin configurable\nWorking with files in custom tasks and plugins\nA standalone project\nCreating a plugin id\nPublishing your plugin\nUsing your plugin in another project\nNote for plugins published without java-gradle-plugin\n\n\nPrecompiled script plugins\nWriting tests for your plugin\n\n\n\n\n\nExtending Gradle Developing Custom Gradle PluginsPackaging a plugin有多个地方可以用来放置你的 plugin 的源码\nBuild script可以直接在构建脚本中包含 plugin 源码\n这样做的好处是 plugin 被自动编译并包含到构建脚本的 classpath 中, 不需要你做任何东西\n但是, 这个 plugin 将不能在构建脚本以外的地方可见, 因此不能在构建脚本之外进行重用\nbuildSrc project可以将 plugin 源码放在 rootProjectDir/buildSrc/src/main/java[groovy|kotlin] 目录中\nGradle 将会编译和测试 plugin, 并使 plugin 在构建脚本上是可用的\nplugin 对于整个构建的构建脚本都是可见的. 但是, plugin 在构建之外是不可见的, 所以你不能在定义 plugin 之外的地方重用它\nStandalone project可以为 plugin 建立一个单独的项目\n这个项目生成并发布一个 JAR 文件来在多个构建中共享并使用\n这个 JAR 文件可能包含一些插件, 或绑定一些关联的 task 类到单独一个库中, 或者结合两者\nWriting a simple plugin为了创建一个 Gradle plugin, 需要编写一个实现了 Plugin 接口的类\n当 plugin 应用到项目中时, Gradle 会创建一个这个 plugin 类的实例, 然后调用这个实例的 Plugin.apply() 方法\n项目对象会作为一个参数传递到 plugin 实例中, 可以使用这个项目对象来做一些需要的配置\nExample - A custom plugin:\n// build.gradleclass GreetingPlugin implements Plugin&lt;Project&gt; &#123;    void apply(Project project) &#123;        project.task(&#x27;hello&#x27;) &#123;            doLast &#123;                println &#x27;Hello from the GreetingPlugin&#x27;            &#125;        &#125;    &#125;&#125;// Apply the pluginapply plugin: GreetingPlugin\n\nGradle 会为每个使用了 plugin 的项目都创建一个新的 plugin 实例\nPlugin 是一个泛型类, 除了可以接受 Project 类作为类型参数之外, 还可以接受 Settings 类, Gradle 类\nSettings 类用于 settings script\nGradle 类用于 initialization script\nMaking the plugin configurable大多数插件提供一些配置选项给构建脚本, 有一些插件使用配置选项来自定义插件的工作\n插件通过使用 extension objects 来完成这些\nGradle Project 对象有一个关联的 ExtensionContainer 对象, 这个对象包含了项目使用的插件的所有的配置和属性\n你可以通过添加一个 extension object 到这个 container 中来为你的插件提供配置选项\n一个 extension object 是一个简单的包含 Java Bean 属性来代表配置选项的对象\nExample - A custom plugin extension:\n// build.gradleabstract class GreetingPluginExtension &#123;    abstract Property&lt;String&gt; getMessage()    GreetingPluginExtension() &#123;        message.convention(&#x27;Hello from GreetingPlugin&#x27;)    &#125;&#125;class GreetingPlugin implements Plugin&lt;Project&gt; &#123;    void apply(Project project) &#123;        // Add the &#x27;greeting&#x27; extension object        def extension = project.extensions.create(&#x27;greeting&#x27;, GreetingPluginExtension)        // Add a task that uses configuration from the extension object        project.task(&#x27;hello&#x27;) &#123;            doLast &#123;                println extension.message.get()            &#125;        &#125;    &#125;&#125;apply plugin: GreetingPlugin// Configure the extensiongreeting.message = &#x27;Hi from Gradle&#x27;\n\n在这个例子中, GreetingPluginExtension 是一个拥有一个称为 message 属性的对象\n这个 extension 对象被添加到 project 中, 命名为 greeting. 然后这个对象变成一个可用的 project 属性, 使用这个 greeting 名字作为 extension object\nExample - A custom plugin with configuration block:\n// build.gradleinterface GreetingPluginExtension &#123;    Property&lt;String&gt; getMessage()    Property&lt;String&gt; getGreeter()&#125;class GreetingPlugin implements Plugin&lt;Project&gt; &#123;    void apply(Project project) &#123;        def extension = project.extensions.create(&#x27;greeting&#x27;, GreetingPluginExtension)        project.task(&#x27;hello&#x27;) &#123;            doLast &#123;                println &quot;$&#123;extension.message.get()&#125; from $&#123;extension.greeter.get()&#125;&quot;            &#125;        &#125;    &#125;&#125;apply plugin: GreetingPlugin// Configure the extension using a DSL blockgreeting &#123;    message = &#x27;Hi&#x27;    greeter = &#x27;Gradle&#x27;&#125;\n\n在这个例子中, 多个配置可以通过 greeting closure 组合在一起\nWorking with files in custom tasks and plugins在接受文件位置的输入配置时, 保持灵活是一个好主意\n你应该使用 Gradle 的 managed properties 和 project.layout 来选择文件或目录位置\n通过这个, 实际的位置将会在文件真的需要的时候被解析, 还可以在配置构建时的任何时候进行配置\nExample - Evaluating file properties lazily:\n// build.gradleabstract class GreetingToFileTask extends DefaultTask &#123;    @OutputFile    abstract RegularFileProperty getDestination()    @TaskAction    def greet() &#123;        def file = getDestination.get().asFile        file.parentFile.mkdirs()        file.write &#x27;Hello!&#x27;    &#125;&#125;def greetingFile = objects.fileProperty()tasks.register(&#x27;greet&#x27;, GreetingToFileTask) &#123;    destination = greetingFile&#125;tasks.register(&#x27;sayGreeting&#x27;) &#123;    dependsOn greet    doLast &#123;        def file = greetingFile.get().asFile        println &quot;$&#123;file.text&#125; (file: $&#123;file.name&#125;)&quot;    &#125;&#125;greetingFile.set(layout.buildDirectory.file(&#x27;hello.txt&#x27;))\n\ngradle -q sayGreeting\n\nA standalone project使用 Java Gradle Plugin Development Plugin\n这个插件将会自动使用 Java Plugin, 添加 gradleApi() 依赖到 api configuration, 生成必选的插件描述符(plugin descriptors)到结果 JAR 文件中, 配置发布时使用的 Plugin Marker Artifact\nExample - A build for a custom plugin\n// build.gradleplugins &#123;    id &#x27;java-gradle-plugin&#x27;&#125;gradlePlugin &#123;    plugins &#123;        simplePlugin &#123;            id = &#x27;org.example.greeting&#x27;            implementationClass = &#x27;org.example.GreetingPlugin&#x27;        &#125;    &#125;&#125;\n\nCreating a plugin idPlugin 的 id 和 Java 包的命名方法相似\nPlugin ids 要遵守如下规则:\n\n应该包含任意字母和数字, ., -\n必须包含至少一个 . 字符来分隔插件名称的命名空间\n按照惯例, 命名空间使用小写的反向域约定\n按照惯例, 在名称中只使用小写字符\norg.gradle 和 com.gradleware 命名空间不可以使用\n不可以以一个 . 字符作为开头或结尾\n不可以包含连续的 . 字符\n\nPublishing your plugin像发布普通的 artifact 一样发布到 Ivy 或者 Maven 仓库中\n也可以发布到 Gradle Plugin Portal 中\nUsing your plugin in another project为了在一个构建脚本中使用自定义插件, 你需要在 settings 文件的 pluginManagement &#123;&#125; 块中配置仓库\nExample - Using a custom plugin in another project:\n// settings.gradlepluginManagement &#123;    repositories &#123;        maven &#123;            url = uri(repoLocation)        &#125;    &#125;&#125;// build.gradleplugins &#123;    id &#x27;org.example.greeting&#x27; version &#x27;1.0-SNAPSHOT&#x27;&#125;\n\nNote for plugins published without java-gradle-plugin如果你的插件没有使用 Java Gradle Plugin Development Plugin 来发布, 那么发布的 JAR 就会缺少 Plugin Marker Artifact, 这个东西是 plugins DSL 用来定位插件的\n在这种情况下, 解析插件的建议的方式是在另外一个项目中添加 resolutionStrategy 到 pluginManagement &#123;&#125; 块中\nExample - Resolution strategy for plugins without Plugin Marker Artifact:\n// settings.gradleresolutionStrategy &#123;    eachPlugin &#123;        if (requested.id.namespace == &#x27;org.example&#x27;) &#123;            useModule(&quot;org.example:custom-plugin:$&#123;requested.version&#125;&quot;)        &#125;    &#125;&#125;\n\nPrecompiled script pluginsGradle 还允许你提供构建逻辑, 使用 Groovy 或 Kotlin DSLs 作为预编译脚本插件\n在 src/main/groovy 目录中编写 *.gradle\n预编译脚本插件被编译为 classes 文件, 然后打包到一个 JAR 中\nWriting tests for your pluginProjectBuilder 类创建的 Project 实例可以用来测试你的插件实现\nExample - Testing a custom plugin:\n// src/test/java/org/example/GreetingPluginTest.javapublic class GreetingPluginTest &#123;    @Test    public void greeterPluginAddsGreetingTaskToProject() &#123;        Project project = ProjectBuilder.builder().build();        project.getPluginManager().apply(&quot;org.example.greeting&quot;);        assertTrue(project.getTasks().getByName(&quot;hello&quot;) instanceof GreetingTask);    &#125;&#125;\n\nExample - Writing for a custom plugin:\n// src/main/resources/META-INF/gradle-plugins/org.example.greeting.propertiesimplementation-class=org.example.GreetingPlugin\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Extending Gradle Developing Custom Gradle Task Types","url":"/gradle/gradle-extending-gradle-developing-custom-gradle-task-types/","content":"\n\n\nExtending Gradle Developing Custom Gradle Task Types\nA standalone project\nUsing your task class in another project\n\n\nWriting tests for your task class\nDeclaring and Using Command Line Options\n\n\n\n\n\nExtending Gradle Developing Custom Gradle Task TypesA standalone projectExample - A build for a custom task\n// build.gradleplugins &#123;    id &#x27;groovy&#x27;&#125;dependencies &#123;    implementation gradleApi()&#125;\n\nExample - A custom task:\n// src/main/groovy/org/gradle/GreetingTask.groovypackage org.gradleimport org.gradle.api.DefaultTaskimport org.gradle.api.tasks.TaskActionimport org.gradle.api.tasks.Inputclass GreetingTask extends DefaultTask &#123;    @Input    String greeting = &#x27;hello from GreetingTask&#x27;    @TaskAction    def greet() &#123;        println greeting    &#125;&#125;\n\nUsing your task class in another project需要在构建脚本的 classpath 添加上自定义的 task 类\n使用 buildScript &#123;&#125; 块来为构建脚本添加外部依赖\nExample - Using a custom task in another project:\n// build.gradlebuildScript &#123;    repositories &#123;        maven &#123;            url = uri(repoLocation)        &#125;    &#125;    dependencies &#123;        classpath &#x27;org.gradle:task:1.0-SNAPSHOT&#x27;    &#125;&#125;tasks.register(&#x27;greeting&#x27;, org.gradle.GreetingTask) &#123;    greeting = &#x27;howdy!&#x27;&#125;\n\nWriting tests for your task class使用 ProjectBuilder 类创建 Project 实例来测试 task 类\nExample - Testing a custom task:\n// src/test/groovy/org/gradle/GreetingTaskTest.groovyclass GreetingTaskTest &#123;    @Test    void canAddTaskToProject() &#123;        Project project = ProjectBuilder.builder().build()        def task = project.task(&#x27;greeting&#x27;, type: GreetingTask)        assertTrue(task instanceof GreetingTask)    &#125;&#125;\n\nDeclaring and Using Command Line Options使用注解 @Option 修饰要作为命令行选项的属性的 setter 方法\nExample - Declaring a command line option:\nimport org.gradle.api.tasks.options.Option;public class UrlVerify extends DefaultTask &#123;    private String url;    @Option(Option = &quot;url&quot;, description = &quot;Configures the URL to be verified.&quot;)    public void setUrl(String url) &#123;        this.url = url;    &#125;    @Input    public String getUrl() &#123;        return url;    &#125;    @TaskAction    public void verify() &#123;        getLogger().quiet(&quot;Verifying URL &#x27;&#123;&#125;&#x27;&quot;, url);    &#125;&#125;\n\n只能使用双横杆来使用命令行参数: verifyUrl --url=http://www.google.com/\nSupported data types for options:\n\nboolean, Boolean, Property&lt;Boolean&gt;\nString, Property&lt;String&gt;\nenum, Property&lt;enum&gt;\nList&lt;String&gt;, List&lt;enum&gt;\n\nExample - Declaring available values for an option:\n@Option(option = &quot;output-type&quot;, description = &quot;Configures the output type.&quot;)public void setOutputType(OutputType outputType) &#123;    this.outputType = outputType;&#125;@OptionValues(&quot;output-type&quot;)public List&lt;OutputType&gt; getAvailableOutputTypes() &#123;    return new ArrayList&lt;OutputType&gt;(Arrays.asList(OutputType.values()));&#125;\n\nExample - Listing available values for option:\ngradle -q help --task processUrl\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Fine Tunning the Project Layout","url":"/gradle/gradle-fine-tunning-the-project-layout/","content":"Fine Tunning the Project LayoutProject locationsThe project tree is created in the settings.gradle\nThe location of the settings file is also the location of the root project\nBuilding the tree在 settings.gradle 中你可以使用 include 方法来创建项目树\nExample - Project layout:\n// settings.gradleinclude &#x27;project1&#x27;, &#x27;project2:child&#x27;, &#x27;project3:child1&#x27;\n\ninclude 方法使用项目路径作为参数\n项目路径是等同于其关联的物理文件系统路径\nservices:api 默认映射为文件夹 services/api (相对于项目根路径)\n你只需要定义树的叶子\nservices:hotels:api 创建 3 个项目:\n\nservices\nservices:hotels\nservices:hotels:api\n\nModifying elements of the project treesettings.gradle 文件中创建的多项目树被称为 project descriptors\n可以在 settings.gradle 文件中的任何时候修改这个 descriptors\nExample - Lookup of elements of the project tree:\n// settings.gradleinclude(&#x27;project-a&#x27;)println rootProject.nameprintln project(&#x27;:project-a&#x27;).name\n\n使用这个 descriptors 可以修改一个项目的名字, 项目目录, 构建文件\nExample - Modification of elements of the project tree:\n// settings.gradlerootProject.name = &#x27;main&#x27;include(&#x27;project-a&#x27;)project(&#x27;:project-a&#x27;).projectDir = file(&#x27;my-project-a&#x27;)project(&#x27;:project-a&#x27;).buildFileName = &#x27;project-a.gradle&#x27;\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Java & Other JVM Projects","url":"/gradle/gradle-java-other-jvm-projects/","content":"\n\n\nJava &amp; Other JVM Projects\nBuilding Java &amp; JVM projects\nDeclaring your source files via source sets\nThe main source set\nResources process\ntest source set\n\n\nManaging your dependencies\nCompiling your code\nCustomizing file and directory locations\nChanging compiler options\nTargeting a specific Java version\nCompiling and testing Java 6 and 7\nCompiling independent sources separately\n\n\nManaging resources\nJava properties files and reproducible builds\n\n\nRunning tasks\nPackaging and publishing\nModifying the JAR manifest\n\n\nGenerating API documentation\nCleaning the build\nBuilding JVM components\nBuilding Java libraries\nBuilding Java applications\nBuilding Java web applications\nBuilding Java EE applications\nBuilding Java Platforms\nEnabling Java preview features\nBuilding other JVM language projects\nCompilation dependency between languages\n\n\n\n\n\n\n\nJava &amp; Other JVM ProjectsBuilding Java &amp; JVM projectsJava 项目的最简单的构建脚本是使用 Java Library Plugin\n// build.gradleplugins &#123;    // 声明使用 Java Library Plugin    id &#x27;java-library&#x27;&#125;java &#123;    // 设置使用的 Java toolchain    toolchain &#123;        languageVersion = JavaLanguageVersion.of(17)    &#125;&#125;// 设置项目版本version = &#x27;1.2.1&#x27;\n\n通过使用 Java Library Plugin, 获得了如下的特性:\n\n一个 compileJava task, 用来编译所有位于 src/main/java 的 Java 源文件\n一个 compileTestJava task, 用来编译所有位于 src/test/java 的 Java 源文件\n一个 test task, 运行位于 src/test/java 的测试\n一个 jar task, 打包编译好的 main 类文件与 src/main/resources 中的资源文件到一个单独的 JAR 文件中, 名称为 &lt;project&gt;-&lt;version&gt;.jar\n一个 javadoc task, 为 main 类文件生成 Javadoc\n\ntoolchain 选项防止了使用不同的 Java 版本来进行构建\nJava Library Plugin 还将上面的 task 集成到了基础的 Base Plugin lifecycle tasks:\n\njar 关联到 assemble\ntest 关联到 check\n\nDeclaring your source files via source setssource sets 是一个强大的概念, 将编译的几个方面联系起来:\n\n源文件与源文件的位置\n编译类路径(compilation classpath), 包括任何需要的依赖\n编译后的文件的位置\n\nJava Library Plugin 自动为所有你创建的或者插件创建的 source set 创建了一个编译 task, 名字为 compileSourceSetJava task, 还创建了一些依赖配置(dependency configurations)\nThe main source set大多数语言插件, 包括 Java, 自动创建了一个 source set, 名称为 main\n用于项目的产品代码(production code)\n这个 main source set 特别的地方在于它的名字没有包含在 配置(configurations) 和 task 的名称中, 因此这就是为什么你拥有 compileJava task 和 compileOnly configurations 和 implementation configurations 而不是 compileMainJava task 和 mainCompileOnly configurations 和 mainImplementation configurations 的原因\nResources processJava 项目通常还包含源文件以外资源文件, 例如 properties 文件, 这些文件可能需要进行处理, 例如替换文件中的 tokens, 还需要将这些文件打包到最终的 JAR 包中\nJava Library Plugin 通过自动为每个定义好的 source set 创建一个指定的称为 processSourceSetResources 的 task 来处理这些文件. 如果是 main source set 的话, 这是创建名称为 processResources 的 task\ntest source setJava Library Plugin 还提供了一个 test source set 来代表项目的测试\ntest source set 被 test task 所使用\n项目通常使用这个 source set 来进行单元测试, 或集成测试, 或者验收测试\n还可以为你其他类型的测试创建一个新的 source set, 因为其他类型的测试要求不同的编译或运行时 classpath, 或者其他不同的设置\nManaging your dependencies为你的 Java 项目定义依赖只需要三种信息:\n\n你需要哪个依赖, 例如名字和版本\n这个依赖有什么用, 用于 compilation 还是 running\n在哪里寻找这个依赖\n\n前两个通过 dependencies &#123;&#125; 块来指定\n第三个通过 repositories &#123;&#125; 块来执行\n例如, 告诉 Gradle 你的项目需要版本为 3.6.7 的 Hibernate Core 来编译与运行你的代码, 同时从 Maven Central 仓库进行下载:\nExample - Declaring dependencies:\n// build.gradlerepositories &#123;    mavenCentral()&#125;dependencies &#123;    implementation &#x27;org.hibernate:hibernate-core:3.6.7.Final&#x27;&#125;\n\n\nRepository(ex: mavenCentral()) - 从哪里寻找你声明的依赖\nConfiguration(ex: implementation) - 一个命名的依赖集合, 为了一个特别的目标组合在一起, 例如编译或运行一个 module, 一个比 Maven scopes 更灵活的形式\nModule coordinate(ex: org.hibernate:hibernate-core-3.6.7.Final)\n\n就 configurations 而言, 主要感兴趣的是:\n\n\n\nName\nMeaning\n\n\n\ncompileOnly\n对于编译你的产品代码来说是必须, 但不是运行时 classpath 的一部分的依赖\n\n\nimplementation\n代替 compile; 用于编译时和运行时\n\n\nruntimeOnly\n代替 runtime; 只用于运行时, 不用于编译时\n\n\ntestCompileOnly\n和 compileOnly 一样, 但是是用于测试\n\n\ntestImplementation\nimplementation 的测试版本\n\n\ntestRuntimeOnly\nruntimeOnly 的测试版本\n\n\nJava Library Plugin 还提供了两个额外的 configurations: api 和 compileOnlyApi, 用来声明传递给 consumers 的依赖, 在编译时和运行时, 或只在编译时\n\nWhy no compile configuration?\n\n因为它不区分那些影响 Java library 项目的公共 API 的依赖和不影响的依赖\nCompiling your code运行 compileJava task 来编译产品代码\n运行 compileTestJava task 来编译测试代码\nCustomizing file and directory locations使用 source set 配置来声明源码位置\n每一个 source set 定义了它的源码存在的位置, 连同资源文件目录和类文件输出目录\n可以通过如下的语法来覆盖约定:\nExample - Declaring custom source directories:\n// build.gradlesourceSets &#123;    main &#123;        java &#123;            srcDirs = [&#x27;src&#x27;]        &#125;    &#125;    test &#123;        java &#123;            srcDirs = [&#x27;test&#x27;]        &#125;    &#125;&#125;\n\n通过上面的配置, Gradle 会直接从 src 和 test 目录分别查找源码\n如果你不想覆盖约定值, 只是想添加额外的源代码目录:\nExample - Declaring custom source directories additively:\n// build.gradlesourceSets &#123;    main &#123;        java &#123;            srcDir &#x27;thirdParty/src/main/java&#x27;        &#125;    &#125;&#125;\n\n关键的地方是, 使用 srcDir() 方法来添加一个目录路径, 使用 srcDirs 属性来替换任何已存在的值\n这在 Gradle 中是一个常用的约定: 通过设置属性值来覆盖, 通过调用对应的方法来添加值\n在 SourceSet 和 SourceDirectorySet DSL 文档中查看所有可用的属性和方法\nChanging compiler options通过对应的 task, 大部分的编译选项是可访问的, 例如 compileJava task 和 compileTestJava task. 这些 task 是 JavaCompile 类型的\n查看 JavaCompile 手册获取所有的选项\n例如, 你想使用为编译器使用单独的 JVM 进程, 与防止编译失败导致构建失败, 可以这样进行配置:\nExample - Setting Java compiler options:\n// build.gradlecompileJava &#123;    options.incremental = true    options.fork = true    options.failOnError = false&#125;\n\nTargeting a specific Java version默认情况下, Gradle 会使用运行 Gradle 的 JVM 的版本来编译 Java 代码\n通过使用 Java toolchain, 你可以确保使用一个指定 Java 版本, 在构建中定义, 可用于编译时, 运行时和文档\n还可以在 task 级别重写一些编译器和执行选项\n从 Java 9 开始, 可以将 Java 编译器配置为 为旧 Java 版本代码生成字节码, 同时确保代码不使用任何来自新版本的 API. Gradle 现在在编译 Java 时直接支持 CompileOptions 上的 release 标志. 这个选项的优先级比下面描述的属性要高\n\nDue to a bug in Java 9 that was fixed in Java 10, Gradle cannot leverage the release flag when compiling with Java 9.\n\nExample - Setting Java release flag:\n// build.gradlecompileJava &#123;    options.release = 7&#125;\n\nJava 编译器的历史选项仍然可用:\n\nsourceCompatibility : 声明 Java 源代码的版本\ntargetCompatibility : 声明代码可运行的最小的 JVM 版本\n\n这两个选项可以在每个 JavaCompile task 中设置, 或者在 java &#123;&#125; 扩展中为所有的编译 task 设置\n使用 toolchain 使得在 java &#123;&#125; 扩展级别上配置 sourceCompatibility 和 targetCompatibility 是不行的\nCompiling and testing Java 6 and 7Gradle 只能运行在 Java 8 或者更新的版本上\nGradle 还是支持为 Java 6&#x2F;7 编译, 测试, 生成 Javadoc, 执行代码\nJava 5和更旧的版本是不支持的\n使用 Java 6&#x2F;7, 配置如下的 task:\n\nJavaCompile task to fork and use the correct Java home\nJavadoc task to use the correct javadoc executable\nTest task and the JavaExec task to use the correct java executable\n\nCompiling independent sources separatelyJava 约定中已经将生产代码和测试代码分开进行编译了\n如果你有其他类型的源码, 例如集成测试之类的, 要进行分开独立编译\n可以使用 custom source set\n在什么时候需要定义一个 custom source set:\n\n需要使用一个独一无二的 classpath 来编译代码\n从不是被 main 和 test 目录保管的代码中生成 class\nForm a natural part of the project(形成项目的自然组成部分?)\n\n例如, 集成测试是项目的一部分, 因为集成测试要测试 main 中的代码, 除此之外, 集成测试通常有它们自己的独立于 test sources set 的依赖, 或者因为集成测试需要通过一个自定义的 Test task 来运行\nManaging resourcesJava Library Plugin 为每个处理其关联资源的 source set 添加一个特定的 Copy task\ntask 名称遵循 process[SourceSet]Resources 的约定\n如果是 main source set 的话, 就是 processResources 的 task 名称\ntask 将会自动拷贝任何在 src/[sourceSet]/resources 中的文件到一个目录中, 这个目录将会被包含在打包后的 JAR 文件中; 这个目标目录还会被包含到测试的运行时 classpath\nJava properties files and reproducible builds使用 WriteProperties task 来创建 Java properties 文件\nGradle 的 WriteProperties task 在 properties 没有改变时, 将生成字节级别的完全一样的输出\nRunning tasksJava Library Plugin 不仅提供了 src/test/java 中的单元测试自动编译, 还原生支持了使用 JUnit 3&#x2F;4&#x2F;5 和 TestNG 来运行测试\n\n一个自动化的 Test 类型的 test task, 使用 test source set\n一个 HTML 测试报告, 包含所有 Test task 的执行结果\n易于控制哪个 test 进行执行\n细粒度控制 test 怎样进行运行\n可以自定义执行测试与测试报告 test\n\n你没有可以用于所有 source set 的 Test task, 因为不是所有 source set 都是用来测试的. 所以这就是为什么你需要创建自定义的 Test task 来进行集成测试和验收测试, 如果这两个测试没有被包含在 test source set 中的话\nPackaging and publishing默认情况下, Java Library Plugin 提供了 jar task 来打包所有编译好的类和资源文件到一个单独的 JAR 文件中\n这个 JAR 文件也会被 assemble task 构建\n除此之外, Java Library Plugin 还可以通过配置来提供 javadocJar task 和 sourcesJar task 来打包 Javadoc 和 源码\n如果使用了发布插件, 那么可以通过 task 来进行发布\nExample - Configure a project to publish Javadoc and sources:\n// build.gradlejava &#123;    withJavadocJar()    withSourcesJar()&#125;\n\nExample - Creating a Java uber or fat JAR - 创建一个包含依赖的包:\n// build.gradleplugins &#123;    id &#x27;java&#x27;&#125;version = &#x27;1.0.0&#x27;repositories &#123;    mavenCentral()&#125;dependencies &#123;    implementation &#x27;commons-io:commons-io:2.6&#x27;&#125;tasks.register(&#x27;uberJar&#x27;, Jar) &#123;    archiveClassifier = &#x27;uber&#x27;    from sourceSets.main.output    dependsOn configurations.runtimeClasspath    from &#123;        configurations.runtimeClasspath.findAll &#123; it.name.endsWith(&#x27;jar&#x27;).collect &#123; zipTree(it) &#125; &#125;    &#125;&#125;\n\n查看 Jar 来获取更多配置选项信息\nModifying the JAR manifest每个 Jar task, War task, Ear task 的实例都有一个 manifest 属性来允许你自定义 archive 中的 MANIFEST.MF 文件\nExample - Customization of MANIFEST.MF:\n// build.gradlejar &#123;    manifest &#123;        attributes(&quot;Implementation-Title&quot;: &quot;Gradle&quot;,                    &quot;Implementation-Version&quot;: archiveVersion)    &#125;&#125;\n\nExample - Creating a manifest object:\n// build.gradleext.sharedManifest = manifest &#123;    attributes(&quot;Implementation-Title&quot;: &quot;Gradle&quot;,                &quot;Implementation-Version&quot;: version)&#125;tasks.register(&#x27;fooJar&#x27;, Jar) &#123;    manifest = project.manifest &#123;        from sharedManifest    &#125;&#125;\n\nExample - Separate MANIFEST.MF for a particular archive:\n// build.gradletasks.register(&#x27;barJar&#x27;, Jar) &#123;    manifest &#123;        attributes key1: &#x27;value1&#x27;        from sharedManifest, &#x27;src/config/basemanifest.txt&#x27;        from([&#x27;src/config/javabasemanifest.txt&#x27;, &#x27;src/config/libbasemanifest.txt&#x27;]) &#123;            eachEntry &#123; details -&gt;                if (details.baseValue != details.mergeValue) &#123;                    details.value = baseValue                &#125;                if (details.key == &#x27;foo&#x27;) &#123;                    details.exclude()                &#125;            &#125;        &#125;    &#125;&#125;\n\nExample - Saving a MANIFEST.MF to disk:\n// build.gradletasks.named(&#x27;jar&#x27;) &#123;    manifest.writeTo(layout.buildDirectory.file(&#x27;mymanifest.mf&#x27;))&#125;\n\nGenerating API documentationJava Library Plugin 提供了一个类型为 Javadoc 的 javadoc task, 用来为你的产品代码生成标准的 Javadocs, 例如, 无论任何在 main source set 中的源码\nExample - Using a custom doclet with Javadoc - 使用其他类型的 Javadoc:\n// build.gradleconfigurations &#123;    asciidoclet&#125;dependencies &#123;    asciidoclet &#x27;org.asciidoclet:asciidoclet:1.+&#x27;&#125;tasks.register(&#x27;configureJavadoc&#x27;) &#123;    doLast &#123;        javadoc &#123;            options.doclet = &#x27;org.asciidoclet.Asciidoclet&#x27;            options.docletpath = configurations.asciidoclet.files.toList()        &#125;    &#125;&#125;javadoc &#123;    dependsOn configureJavadoc&#125;\n\nExample - Defining a custom Javadoc task:\n// build.gradletasks.register(&#x27;testJavadoc&#x27;, Javadoc) &#123;    source = sourceSets.test.allJava&#125;\n\nCleaning the buildJava Library Plugin 通过使用 Base Plugin 添加了一个 clean task\n这个 clean task 删除所有在 $buildDir 目录中的东西\n这个 task 是一个 Delete 类型的实例, 可以通过修改 dir 属性来指定要删除的目录\nBuilding JVM components所有具体的 JVM 插件都是基于 Java Plugin\n上面的示例仅说明了这个基本插件提供的概念, 并与所有 JVM 插件共享这些\n建议使用具体的插件而不是直接使用 Java Plugin\nBuilding Java libraries通过 Java Library Plugin, 提供了一个 api 配置\n如果来自依赖的类出现在你的库的公共字段或方法中, 那么这个依赖将通过你的库的公共 API 公开出去, 因此这个依赖应该添加到 api 配置项中\n否则, 这个依赖是一个内部实现细节, 需要添加到 implementation 配置项中\nBuilding Java applications打包为 JAR 的 Java 应用程序并不能方便地从命令行或桌面环境启动\nApplication Plugin 通过创建一个发行版解决了命令行方面的问题, 这个发行版包含了 JAR 文件, 所有依赖, 启动脚本\n\nassemble task 创建包含应用运行需要的所有东西的 ZIP 和 TAR 发行版\n一个 run task 来从构建中启动程序\nShell 和 Windows 脚本来启动程序\n\nBuilding Java web applicationsGradle 核心仅仅直接支持打包成 WAR 文件的传统的 Servlet-based Web 应用程序\n通过 War Plugin 来支持, 这个插件自动使用 Java Plugin 和添加一个额外的打包步骤:\n\n从 src/main/webapp 复制静态文件到 WAR 文件中的根路径上\n复制编译好的类文件到 WAR 文件的 WEB-INF/classes 子目录中\n复制依赖的库到 WAR 文件的 WEB-INF/lib 子目录中\n\n这些都是通过 war task 来完成的, 这个 task 实际上替代了 jar task\nGradle 核心没有支持在构建中运行 Web 项目, 可以尝试使用 Gretty 插件提供的内嵌式 Servlet 容器来进行运行\nBuilding Java EE applications使用 Ear Plugin 来创建 EAR 文件\nBuilding Java Platforms一个 Java Platform 表示一组依赖声明和约束, 它们来自一个内聚单元, 将应用于消费者项目\nPlatform 没有源代码, 也没有自己的工件\nPlatform 就是 Maven 世界中的 BOM\n通过 Java Platform plugin 来实现, 这个常见配置了不同的配置和发布组件\n这个插件不使用 Java Plugin\nEnabling Java preview featuresExample - Enabling Java feature preview:\n// build.gradletasks.withType(JavaCompile) &#123;    options.compilerArgs += &quot;--enable-preview&quot;&#125;tasks.withType(Test) &#123;    jvmArgs += &quot;--enable-preview&quot;&#125;tasks.withType(JavaExec) &#123;    jvmArgs += &quot;--enable-preview&quot;&#125;\n\nBuilding other JVM language projectsGradle 本身提供了 Groovy 和 Scala 插件\n这些插件会自动应用对编译 Java 代码的支持, 并可以通过将它们与 java-library 插件结合来进一步增强\nCompilation dependency between languages这些插件创建了 Groovy&#x2F;Scala 编译和 Java 编译之间的依赖关系\n你可以改变这个默认行为, 通过调整所涉及的编译任务的类路径:\nExample - Changing the classpath of compile tasks:\n// build.gradletasks.named(&#x27;compileGroovy&#x27;) &#123;    // Groovy only needs the declared dependencies(and not longer the output of compileJava)    classpath = sourceSets.main.compileClasspath&#125;tasks.named(&#x27;compileJava&#x27;) &#123;    // Java also depends on the result of Groovy compilation(which automatically makes it depend of compileGroogy)    classpath += files(sourceSets.main.groovy.classesDirectory)&#125;\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Lazy Configuration","url":"/gradle/gradle-lazy-configuration/","content":"\n\n\nLazy Configuration\nLazy properties\nCreating a Property or Provider instance\nConnecting properties together\nWorking with files\nWorking with task inputs and outputs\nWorking with collections\nWorking with maps\nApplying a convention to a property\nMaking a property unmodifiable\n\n\n\n\n\nLazy ConfigurationLazy propertieslazy properties 会被延迟计算其值, 直到它被真的使用\n这有三个好处:\n\nBuild authors can wire together Gradle models without worrying when a particular property’s value will be known\nBuild authors can wire an output property of a task into an input property of some other task and Gradle automatically determines the task dependencies based on this connection\nBuild authors can avoid resource intensive work during the configuration phase, which can hava a large impact on build performance\n\nGradle 提供了两个接口来代表 lazy properties:\n\nProvider 接口代表一个只读的值\n值是只读的\nProvider.get() 返回当前值\n使用 Provider.map(Transformer) 从一个 Provider 创建一个 Provider\n在任何可以使用 Provider 的地方都可以使用继承了 Provider 的类\n\n\nProperty 接口代表一个可读写的值\n这个类型的 properties 都是可以配置的\nProperty 继承了 Provider 接口\nProperty.set(T) 方法用来设置值, 覆盖之前的值\nProperty.set(Provider) 从 Provider 中获取值来设置值, 覆盖之前的值\n可以使用工厂方法 ObjectFactory.property(Class) 来创建一个 Property\n\n\n\nlazy properties 是用来分配, 在需要的才查询, 通常情况下查询发生在执行阶段\nExample - Using a read-only and configurable property:\n// build.gradleabstract class Greeting extends DefaultTask &#123;    // A configurable greeting    @Input    abstract Property&lt;String&gt; getGreeting()    // Read-only property calculated from the greeting    @Internal    final Provider&lt;String&gt; message = greeting.map &#123; it + &#x27; from Gradle&#x27; &#125;    @TaskAction    void printMessage() &#123;        logger.quiet(message.get())    &#125;&#125;tasks.register(&quot;greeting&quot;, Greeting) &#123;    // Configure the greeting    greeting.set(&#x27;Hi&#x27;)    greeting = &#x27;Hi&#x27; // Alternative notation to calling Property.set() - only available in Groovy DSL&#125;\n\n运行结果:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_4╰─○ gradle -q greeting  Hi from Gradle\n\n使用 Property&lt;String&gt; 来代表一个可配置的属性\n使用 Provider&lt;String&gt; 来代表一个被计算的, 只读的的属性\nProvider 属性是从 Property 属性使用 map() 方法计算而来的, 所以可以在值修改时保持最新\n在一个 task 实现中, Gradle Groovy DSL 为每一个 Property 类型的属性生成了一个 setter 方法, 这个方法允许你使用 = 来为属性进行赋值\nCreating a Property or Provider instanceGradle 提供了工厂方法来创建 Provider 和 Property\nObjectFactory.property(Class) 创建一个新的 Property\nObjectFactory 实例可以从 Project.getObjects() 获取, 或者在构造方法和普通方法中注入 ObjectFactory\nProvider.map(Transformer) 从一个已存在的 Provider 或 Property 创建一个新的 Provider\n一个 Provider 可以使用 ProviderFactory.provider(Callable) 工厂方法来创建\nConnecting properties togetherlazy properties 的一个重要特性是它们可以连接在一起, 所以当修改一个 property 时, 可以自动反应到其他 property 中\nExample - Connecting properties together:\n// build.gradle// A project extensioninterface MessageExtension &#123;  // A configurable greeting  Property&lt;String&gt; getGreeting()&#125;// A task that displays a greetingabstract class Greeting extends DefaultTask &#123;  // Configurable by the user  @Input  abstract Property&lt;String&gt; getGreeting()  // Read-only property calculated from the greeting  @Internal  final Provider&lt;String&gt; message = greeting.map &#123; it + &#x27; from Gradle&#x27; &#125;  @TaskAction  void printMessage() &#123;    logger.quiet(message.get())  &#125;&#125;// Create the project extensionproject.extensions.create(&#x27;messages&#x27;, MessageExtension)// Create the greeting tasktasks.register(&quot;greeting&quot;, Greeting) &#123;  // Attach the greeting from the project extension  // Note that the values of the project extension have not been configured yet  greeting = messages.greeting&#125;messages &#123;  // Configure the greeting on the extension  // Note that there is no need to reconfigure the task&#x27;s `greeting` property. This is automatically updated as the extension property changes  greeting = &#x27;Hi&#x27;&#125;\n\nWorking with filesCollection of files recap:\n\n\n\nRead-only Type\nConfigurable Type\n\n\n\nFileCollection\nConfigurableFileCollection\n\n\nFileTree\nConfigurableFileTree\n\n\n所有这些类型都是 lazy 类型\nDirectory 和 RegularFile 分别代表一个目录和一个普通文件\nGradle 提供了两个特别的 Property 子类型来分别代表这两个类: RegularFileProperty 和 DirectoryProperty\nObjectFactory 提供了 ObjectFactory.fileProperty() 和 ObjectFactory.directoryProperty() 方法来创建这两个类实例\n一个 DirectoryProperty 也可以用来为 Directory 和 regularfile 创建一个延迟计算的 Provider, 分别使用 DirectoryProperty.dir(String) 和 DirectoryProperty.file(String)\nThese methods create providers whose values are calculated relative to the location for the DirectoryProperty they were created from\nThe values returned from these providers will reflect changes to the DirectoryProperty\nWorking with task inputs and outputsProperty API使得保持跟踪 task 的输出很容易\nWorking with collectionsGradle 提供了两个 lazy property 类型来帮助配置 Collection 属性\n对于 List 值, 使用 ListProperty 接口; 使用 ObjectFactory.listProperty(Class) 来创建一个新的 ListProperty\n对于 Set 值, 使用 SetProperty 接口; 使用 ObjectFactory.setProperty(Class) 来创建一个新的 SetProperty\n这些类型的 property 允许你通过 HasMultipleValues 和 HasMultipleValues.set(Provider) 重写整个集合的值, 或者通过 add 方法来添加新元素:\n\nHasMultipleValues.add(T) : 添加一个元素到集合中\nHasMultipleValues.add(Provider) : 添加一个延迟计算的元素到集合中\nHasMultopleValues.addAll(Provider) : 添加一个延迟计算的集合到集合中\n\n和所有 Provider 一样, 集合在 Provider.get() 方法被调用的使用进行计算\nWorking with mapsGradle 提供一个延迟 MapProperty 来允许 Map 值被配置\n使用 ObjectFactory.mapProperty(Class, Class) 来创建一个 MapProperty 实例\nApplying a convention to a property在一个 property 没有设置值的时候的使用 convention() 方法来添加一些约定, 或者默认值到一个 property 中\n这个方法接受一个值或者一个 Provider\nMaking a property unmodifiablelazy properties 提供了一些方法来静止值设置之后被修改\nfinalizeValue() 方法计算 property 的 final 值与防止以后对这个 property 的修改\n如果值是来自一个 Provider, 那么这个 Provider 就会被查询, 将它的结果作为 property 的最终值\n这个最终值代替了 Provider, 这个 property 不再最终这个 Provider 的值\n调用 finalizeValue() 方法会让一个 property 实例不可修改, 任何对这个 property 进一步的尝试修改都会失败\nGradle 在执行 task 的时候自动让一个 task 的 property 变成 final 的\nfinalizeValueOnRead() 方法只有值在被访问的时候才会被计算\nfinalizeValue() 方法是在调用的时候马上进行计算\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Logging","url":"/gradle/gradle-logging/","content":"\n\n\nLogging\nLog levels\nChoosing a log level\nStacktrace command-line options\n\n\nWriting your own log messages\nLogging from external tools and libraries\n\n\n\n\n\nLoggingLog levels\n\n\nNAME\nMESSAGE\n\n\n\nERROR\nError messages\n\n\nQUIET\nImportant information messages\n\n\nWARNING\nWarning messages\n\n\nLIFECYCLE\nProgress information messages\n\n\nINFO\nInformation messages\n\n\nDEBUG\nDebug messages\n\n\nChoosing a log level可以在命令行指定或者在 gradle.properties 文件中配置\nTable - Log level command-line options:\n\n\n\nOption\nOutputs Log Levels\n\n\n\nno logging options\nLIFECYCLE and higher\n\n\n-q or --quiet\nQUIET and higher\n\n\n-w or --warn\nWARN and higher\n\n\n-i or --info\nINFO and higher\n\n\n-d or --debug\nDEBUG and higher(that is, all log messages)\n\n\nDEBUG 日志级别会暴露敏感的安全信息到控制台中\nStacktrace command-line options\n-s or --stacktrace\n-S or --full-stacktrace\n\nWriting your own log messages在 QUIET 日志级别下, Gradle 重定向任何写到标准输出的内容到日志系统中\nExample - Using stdout to write log messages:\n// build.gradleprintln &quot;A message which is logged at QUIET level&quot;\n\nGradle 提供了一个 logger 属性到构建脚本中, logger 是 Logger 接口的实例; 这个接口继承了 SLF4J 的 Logger 接口, 还添加了一些 Gradle 的特别方法\nExample - Writing your own log messages:\n// build.gradlelogger.quiet(&#x27;An info log message which is always logged.&#x27;)logger.error(&#x27;An error log message.&#x27;)logger.warn(&#x27;A warning log message.&#x27;)logger.lifecycle(&#x27;A lifecycle info log message.&#x27;)logger.info(&#x27;An info log message.&#x27;)logger.debug(&#x27;An debug message.&#x27;)logger.trace(&#x27;A trace log message.&#x27;)\n\nExample - Writing a log message with placeholder:\n// build.gradlelogger.info(&#x27;A &#123;&#125; log message&#x27;, &#x27;info&#x27;)\n\nLogging from external tools and librariesProject 实例提供了一个 LoggingManager, 允许你进行一些配置\nExample - Configuring standard output capture:\n// build.gradlelogging.captureStandardOutput LogLevel.INFOprintln &#x27;A message which is logged at INFO level&#x27;\n\nExample - Configuring standard output capture for a task:\n// build.gradletasks.register(&#x27;logInfo&#x27;) &#123;    logging.captureStandardOutput LogLevel.INFO    doFirst &#123;        println &#x27;A task message which is logged at INFO level&#x27;    &#125;&#125;\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Managing Dependencies of JVM Projects","url":"/gradle/gradle-managing-dependencies-of-jvm-projects/","content":"\n\n\nManaging Dependencies of JVM Projects\nDissecting a typical build script\nUsing dependency configurations\nDeclaring dependencies\nResolving dependencies\nExposing artifacts for consumption\nJava Library Plugin 提供的基础 configurations\nimplementation\napi\ntestImplementation\n\n\n\n\n\n\n\n\n\nManaging Dependencies of JVM ProjectsDissecting a typical build scriptdissecting : 解剖\nExampel - Dependency declarations for a JVM-based project:\n// build.gradleplugins &#123;    id &#x27;java-library&#x27;&#125;repositories &#123;    mavenCentral()&#125;dependencies &#123;    implementation &#x27;org.hibernate:hibernate-core:3.6.7.Final&#x27;    api &#x27;com.google.guava:guava:23.0&#x27;    testImplementation &#x27;junit:junit:4.+&#x27;&#125;\n\nUsing dependency configurationsConfiguration 是一组 命名 的依赖和构件\nConfiguration 有三个主要的目的:\nDeclaring dependencies\nA plugin uses configurations to make it easy for build authors to declare what other subprojects or external artifacts are needed for various purpose during the execution of tasks defined by the plugin\n\n插件使用 Configuration 使得构建编写者在执行插件定义的 task 期间更加容易地声明为了各种目的而需要的其他子项目或外部构建\n例如, 一个插件可能需要 Spring web framework 依赖来编译源代码\nResolving dependencies插件使用 Configuration 来查找(或者下载)它定义的任务的输入\n例如, Gradle 可能需要从 Maven Central 下载 Spring web framework JAR 文件\nExposing artifacts for consumption插件使用 Configuration 来定义它生成的供其他项目使用构件\nJava Library Plugin 提供的基础 configurationsimplementation用来编译项目产品代码的依赖, 当不是项目暴露的 API 的一部分\n例如项目使用 Hibernate 作为项目内部的持久层实现\napi用来编译项目产品代码的依赖, 是项目暴露的 API 的一部分\n例如项目使用了 Guava 并在暴露的公共接口中使用了 Guava 的类作为方法签名的一部分\ntestImplementation用来编译和运行项目的测试源码的依赖\n例如项目决定使用 JUnit 测试框架来编写测试代码\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Organizing Gradle Projects","url":"/gradle/gradle-organizing-gradle-projects/","content":"\n\n\nOrganizing Gradle Projects\nSeparate language-specific source files\nSeparate source files per test type\nUse standard conventions as much as possible\nAlways define a settings file\nUse buildSrc to abstract imperative logic\nDeclare properties in gradle.properties file\nAvoid overlapping task outputs\nStandardizing builds with a custom Gradle distribution\n\n\n\n\n\nOrganizing Gradle ProjectsSeparate language-specific source filesJava: src/main/java\nGroovy: src/main/groovy\nKotlin: src/main/kotlin\nSeparate source files per test type将不同类型的测试的代码放到不同的目录中\n单元测试放到单元测试目录\n集成测试放到集成测试目录\n功能测试放到功能测试目录\n冒烟测试放到冒烟测试目录\nUse standard conventions as much as possible尽量使用约定大于配置的原则\nAlways define a settings fileGradle 总是会在目录结构中搜寻 settings.gradle 文件\n因此在根目录放置一个这个文件来避免初始化时搜寻文件的开销\n这个文件可以是空的或者声明了项目的名称\nUse buildSrc to abstract imperative logicbuildSrc 目录被当做是一个 included build\n在搜索目录之前, Gradle 会自动编译和测试 buildSrc 中的代码, 然后将其放在你的构建脚本的 classpath 上\n对于多项目构建, 只能有一个 buildSrc 目录在项目的根目录中\nbuildSrc 目录使用和 Java 或者 Groovy 项目一样的源代码路径约定, 例如 src/main/java\nbuildSrc 中可以直接访问 Gradle 的 API\n额外的依赖可以在 buildSrc 目录下的 build.gradle 文件中声明\nExample - Custom buildSrc build script:\n// buildSrc/build.gradlerepositories &#123;    mavenCentral()&#125;dependencies &#123;    testImplementation &#x27;junit:junit:4.13&#x27;&#125;\n\nbuildSrc 中的任何改动都会导致整个项目变为 OUT-TO-DATE, 因此如果进行了很小的增量修改, --no-rebuild 命令行参数可以帮助获得更快构建反馈, 但是要记得在最后进行一个完整的构建\nDeclare properties in gradle.properties file在 Gradle 中 properties 可以被定义在:\n\n构建脚本\ngradle.properties\n作为一个命令行参数\n\n在特定的场景中使用命令行参数定义 properties 是很常见的, 例如你只想控制本次的构建行为\n其他时候建议使用 gradle.properties 来定义 properties, 在这个文件中进行统一的配置管理, 将 properties 和构建逻辑分离开来\n一个 gradle.properties 文件放置在项目根目录中\n也可以将这个文件放置在 GRADLE_USER_HOME 目录中, 让这台机器上面的所有构建都能使用这个配置文件\nAvoid overlapping task outputs定义一个 task 的 outputs 时, 确保输出的目录在你的整个项目的所有 task 中是唯一的\n不要使多个 task 的 outputs 有重叠, 否则会影响 Gradle 的增量构建机制和构建缓存机制\nStandardizing builds with a custom Gradle distributioninitialzation scripts 使得在一台机器上面的所有项目中使用构建逻辑非常简单\n一个自定义的 Gradle distribution 结合了基础的 Gradle distribution 和一个到多个的自定义 initialzation scripts\n开发者只需要将它们的 Wrapper 文件指向 custom Gradle distribution 的 URL\ncustom Gradle distribution 还可以包含一个 gradle.properties 文件在 distribution 的顶层来提供跨整个组织的配置\n创建 custom Gradle distribution 的典型步骤:\n\n实现下载和重新打包一个 Gradle distribution 的逻辑\n为想要的逻辑定义一个或多个初始化脚本\n绑定初始化脚本到 Gradle distribution 中\n上传 Gradle distribution 包到一个 HTTP 服务器上\n修改所有项目的 Wrapper 文件为指向 custom Gradle distribution 的 URL\n\nExample - Building a custom Gradle distribution:\n// build.gradleplugins &#123;    id &#x27;base&#x27;&#125;// This is defined in buildSrcimport org.gradle.distribution.DownloadGradleversion = &#x27;0.1&#x27;tasks.register(&#x27;downloadGradle&#x27;, DownloadGrade) &#123;    description = &#x27;Downloads the Gradle distribution with a given version.&#x27;    gradleVersion = &#x27;4.6&#x27;&#125;tasks.register(&#x27;createCustomGradleDistribution&#x27;, Zip) &#123;    description = &#x27;Builds custom Gradle distribution and bundles initialzation scripts.&#x27;    dependsOn downloadGradle    def projectVersion = project.version    archiveFileName = downloadGradle.gradleVersion.map &#123; gradleVersion -&gt;         &quot;mycompany-gradle-$&#123;gradleVersion&#125;-$&#123;projectVersion&#125;-bin.zip&quot;    &#125;    from zipTree(downloadGradle.destinationFile)    from(&#x27;src/init.d&#x27;) &#123;        into &quot;$&#123;downloadGradle.distributionNameBase.get()&#125;/init.d&quot;    &#125;&#125;\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Gradle Plugin Development Plugin","url":"/gradle/gradle-plugin-development-plugin/","content":"Gradle Plugin Development PluginJava Gradle Plugin development plugin 可以用来协助开发 Gradle 插件\n这个插件自动使用了 Java Library 插件, 添加 gradleApi() 依赖到 api configuration 中, 并在 jar task 运行时执行插件元数据校验\n这个插件还集成了 TestKit, 这个库用来为插件代码编写和执行单元测试\n这个插件自动添加 gradleTestKit() 依赖到 testImplementation configuration 并生成一个插件 classpath manifest 文件来被 GradleRunner 实例来使用, 如果有这个实例的话\nUsageExample - Using the Java Gradle Plugin Development plugin:\n// build.gradleplugins &#123;    id &#x27;java-gradle-plugin&#x27;&#125;\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Gradle Plugin Reference","url":"/gradle/gradle-plugin-reference/","content":"\n\n\nGradle Plugin Reference\nJVM languages and frameworks\nNative languages\nPacking and distribution\nCode analysis\nIDE integration\nUtility\n\n\n\n\n\nGradle Plugin ReferenceJVM languages and frameworks\n\n\n名称\n描述\n\n\n\nJava\nProvides support for building any type of Java project\n\n\nJava Library\nProvides support for building a Java library\n\n\nJava Platform\nProvides support for building a Java platform\n\n\nGroovy\nProvides support for building any type of Groovy project\n\n\nScala\nProvides support for building any type of Scala project\n\n\nANTLR\nProvides support for generating parsers using ANTLR\n\n\nJVM Test Suite\nProvides support for modeling and configuring multiple test suite invocations\n\n\nNative languages\n\n\n名称\n描述\n\n\n\nC++ Application\nProvides support for building C++ applications on Windows, Linux, and macOS\n\n\nC++ Library\nProvides support for building C++ libraries on Windows, Linux, and macOS\n\n\nC++ Unit Test\nProvides support for building and running C++ executable-based tests on Windows, Linux, and macOS\n\n\nSwift Application\nProvides support for building Swift applications on Linux and macOS\n\n\nSwift Library\nProvides support for building Swift Library on Linux and macOS\n\n\nXCTest\nProvides support for building and running XCTest-based tests on Linux and macOS\n\n\nPacking and distribution\n\n\n名称\n描述\n\n\n\nApplication\nProvides support for building JVM-based, runnable applications\n\n\nWAR\nProvides support for building and packaging WAR-based Java web applications\n\n\nEAR\nProvides support for building and packaging Java EE applications\n\n\nMaven Publish\nProvides support for publishing artifacts to Maven-compatible repositories\n\n\nIvy Publish\nProvides support for building artifacts to Ivy-compatible repositories\n\n\nDistribution\nMakes it easy to create ZIP and tarball distributions of your project\n\n\nJava Library Distribution\nProvides support for creating ZIP distribution of a Java library project that includes its runtime dependencies\n\n\nCode analysis\n\n\n名称\n描述\n\n\n\nCheckstyle\nPerforms quality checks on your project’s Java source files using Checkstyle and generates associated reports\n\n\nPMD\nPerforms quality checks on your project’s Java source files using PMD and generates associated reports\n\n\nJaCoco\nProvides code coverage metrics for your Java project using JaCoco\n\n\nCodeNarc\nPerforms quality checks on your Groovy source files using CodeNarc and generates associated reports\n\n\nIDE integration\n\n\n名称\n描述\n\n\n\nEclipse\nGenerates Eclipse project files for the build that can be opened by the IDE. This set of plugins can also be used to fine tune Buildship’s import process for Gradle builds\n\n\nIntellij IDEA\nGenerates IDEA project files for the build that can be opened by the IDE. It can also be used to fine tune IDEA’s import process for Gradle builds\n\n\nVisual Studio\nGenerates Visual Studio solution and project files for build that can be opened by the IDE\n\n\nXcode\nGenerates Xcode workspace and project files for the build that can be opened by the IDE\n\n\nUtility\n\n\n名称\n描述\n\n\n\nBase\nProvides common lifecycle tasks, such as clean, and other features common to most builds\n\n\nBuild Init\nGenerates a new Gradle build of a specified type, such as a Java library. It can also generate a build script from a Maven POM\n\n\nSigning\nProvides support for digitally signing generated files and artifacts\n\n\nPlugin Development\nMakes it easier to develop and publish a Gradle plugin\n\n\nProject Report Plugin\nHelps to generate reports containing useful information about your build\n\n\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Plugins","url":"/gradle/gradle-plugins/","content":"\n\n\nPlugins\nThe Application Plugin\nBuilding JVM applicatoins\nBuilding applications using the Java Module System\nBuilding a distribution\nCustomizing start script generation\nTasks\nApplication extension\n\n\nThe Base Plugin\nUsage\nTask\nDependency management\ndefault\narchives\n\n\nContributed extensions\n\n\nBuild Init Plugin\nSupported Gradle build types\nTasks\nWhat to create\nBuild init types\npom build type (Maven conversion)\njava-application build type\njava-library build type\njava-gradle-plugin build type\ngroovy-library build type\ngroovy-application build type\ngroovy-gradle-plugin build type\nbasic build type\n\n\n\n\nThe Checkstyle Plugin\nTasks\ncheckstyleMain\ncheckstyleTest\ncheckstyleSourceSet\n\n\nDependencies added to other tasks\ncheck\n\n\nProject layout\nDependency management\n\n\nThe CodeNarc Plugin\nTasks\ncodenarcMain\ncodenarcTest\ncodenarcSourceSet\n\n\nDependencies added to other tasks\nProject layout\nDependency management\n\n\nThe Distribution Plugin\nTasks\ndistZip\ndistTar\nassembleDist\n\n\nDistribution contents\nPublishing\n\n\nThe Groovy Plugin\nTasks\ncompileGroovy\ncompileTestGroovy\ncompile&#123;SourceSet&#125;Groovy\ngroovydoc\n\n\nDependency management\nProject layout\nsrc/main/java\nsrc/main/resources\nsrc/main/groovy\nsrc/test/java\nsrc/test/resources\nsrc/test/groovy\nsrc/&#123;sourceSet&#125;/java\nsrc/&#123;sourceSet&#125;/resources\nsrc/&#123;sourceSet&#125;/groovy\n\n\nChanging the project layout\nDependency management\nAutomatic configuration of groovyClasspath\nConvention properties\nSource set properties\nsource set properties groovy\nsource set properties groovy.srcDirs\nsource set properties allGroovy\nmodified source set properties\n\n\nGroovyCompile\nCompiling and testing for Java 6 or Java 7\n\n\nThe IDEA Plugin\nUsage\nTasks\n\n\nThe JaCoco Plugin\nConfiguring the JaCoCo Plugin\nJaCoCo Report configuration\n\n\nThe Java Plugin\nTasks\nSourceSet Tasks\nLifecycle Tasks\nProject layout\nChanging the project layout\nSource sets\nSource set properties\nDependency management\nDependency configurations\nSourceSet dependency configurations\n\n\nContributed extension\n\n\nThe Java Library Plugin\nAPI and implementation separation\nRecognizing API and implementation dependencies\nThe Java Library Plugin configurations\nUsing classes instead of jar for compilation\nIncreased memory usage for consumers\nSignificant build performance drop on Windows for huge multi-projects\n\n\nDistribution a library\n\n\nThe Java Library Distribution Plugin\nTasks\nIncluding other resources in the distribution\n\n\nThe Java Platform Plugin\nUsage\nAPI and runtime separation\nLocal project constraints\nSourcing constraints from another platform\nPublishing platforms\nConsuming platforms\n\n\nMaven Publish Plugin\nTasks\nPublications\nIdentity values in the generated POM\nCustomizing the generated POM\nCustomizing dependencies versions\nDeclared versions(默认)\nResolved versions\n\n\n\n\nRepositories\nSnapshots and release repositories\nPublishing to Maven Local\n\n\nPublishing Maven relocation information\nComplete example\n\n\nThe PMD Plugin\nTasks\nDependency management\nConfiguration\n\n\n\n\n\n\n\nPluginsThe Application PluginApplication Plugin 帮助创建一个可执行的 JVM 程序\nApplication Plugin 使得开发期间启动应用程序变得容易, 同时将应用程序打包成一个 TAR&#x2F;ZIP, 包含了特定操作系统启动用的脚本\n应用 Application Plugin 同时隐含地应用了 Java Plugin. main source set 实际上是 application source set\n应用 Application Plugin 同时隐含地应用了 Distribution Plugin. A main distribution is created that packages up the application, including code dependencies and generated start scripts\nBuilding JVM applicatoinsExample - Using the application plugin:\n// build.gradleplugins &#123;    id &#x27;application&#x27;&#125;\n\n唯一需要为插件强制配置的是指定程序的入口(e.g 入口点(entry point))\nExample - Configure the application main class:\n// build.gradleapplication &#123;    mainClass = &#x27;org.gradle.sample.Main&#x27;&#125;\n\n你可以通过执行 run task(JavaExec) 来运行这个程序\n这个 task 将会编译 main source set, 然后用项目的编译好的类(和所有运行时依赖)作为 classpath 并使用指定的 main class 启动一个新的 JVM\n可以使用 gradle run --debug-jvm 在调试模式启动项目 (see JavaExec.setDebug(boolean))\n从 Gradle 4.9 版本开始, 命令行参数可以通过 --args 来传递. 例如, 如果现在启动应用程序的时候带上命令行参数 foo --bar, 你可以使用 gradle run --args=&quot;foo --bar&quot; (see JavaExec.setArgsString(java.lang.String))\n如果你的应用需要一组 JVM 配置或系统属性, 你可以配置 applicationDefaultJvmArgs 属性. 这些 JVM 参数会被应用到 run task 中, 也会包含到生成的启动脚本中\nExample - Configure default JVM settings:\n// build.gradleapplication &#123;    applicationDefaultJvmArgs = [&#x27;-Dgreeting.language=en&#x27;]&#125;\n\n如果你的应用的启动脚本要放到其他目录中, 而不是默认的 /bin 目录中, 你可以配置 executableDir 属性\nExample - Configure custom directory for start scripts:\n// build.gradleapplication &#123;    executableDir = &#x27;custom_bin_dir&#x27;&#125;\n\nBuilding applications using the Java Module SystemJava modules 也可以是可运行的, 你可以使用 Application Plugin 来运行和打包一个 modular 应用\n相对于 non-modular 应用来说, 你需要做两件事\n第一, 你需要添加一个 module-info.java 文件来描述你的应用程序 module\n第二, 除了 main class 之外, 你还需要告诉 Gradle 你想要运行的 module 的名字:\nExample - Configure the modular application’s main module:\n// build.gradleapplication &#123;    mainModule = &#x27;org.gradle.sample.app&#x27; // name defined in module-info.java    mainClass = &#x27;org.gradle.sample.Main&#x27;&#125;\n\n然后, 就可以通过 run task 或通过生成的启动脚本来项目作为 module 来运行, 并在运行时遵守 module 的边界\n配置的 main class 也会被放入应用程序的 module-info.class 文件中\n如果你直接使用 java 命令来运行 modular 应用程序, 提供模块名就可以了\nBuilding a distribution应用程序的发行版可以通过 Distribution Plugin 来创建(已经自动应用了这个插件)\n使用如下内容创建一个主要发行版:\nTable - Distribution content:\n\n\n\nLocation\nContent\n\n\n\n(root dir)\nsrc/dist\n\n\nlib\nAll runtime dependencies and main source set class files\n\n\nbin\nStart scripts(generated by startScripts task)\n\n\n添加到发行版的静态文件可以简单地添加到 src/dict 中\nExample - Include output from other tasks in the application distribution:\n// build.gradletasks.register(&#x27;createDocs&#x27;) &#123;    def docs = layout.buildDirectory.dir(&#x27;docs&#x27;)    outputs.dir docs    doLast &#123;        docs.get().asFile.mkdirs()        docs.get().file(&#x27;readme.txt&#x27;).asFile.write(&#x27;Read me!&#x27;)    &#125;&#125;distributions &#123;    main &#123;        contents &#123;            from(createDocs) &#123;                into &#x27;docs&#x27;            &#125;        &#125;    &#125;&#125;\n\nGradle 会知道在组合发行版之前要先执行提供这个文件的 task, Gradle 会帮助你执行\n运行 gradle installDist 来在 build/install/projectName 中创建一个应用程序的 image\n运行 gradle distZip 来创建一个包含发行版的 ZIP 文件\n运行 gradle distTar 来创建一个应用程序 TAR\n或者运行 gradle assemble 同时创建 ZIP 和 TAR\nCustomizing start script generationApplication Plugin 可以开箱即用地生成类 Unix 的和 Windows 的启动脚本\n启动脚本使用定义作为原始构建和运行时环境一部分的特定配置来启动 JVM\n默认的脚本模板是基于用来启动 Gradle 的启动脚本的\n启动脚本是可以自定义的 ,参考 CreateStartScripts 参看更多的细节和例子\nTasksApplication Plugin 添加了如下 task 到项目中:\n\n\n\n名称\n含义\n\n\n\nrun\nJavaExec 类型; 依赖于 classes; 启动应用程序\n\n\nstartScripts\nCreateStartScripts 类型; 依赖于 jar; 创建特定于操作系统的的脚本, 建项目作为 JVM 应用程序运行\n\n\ninstallDist\nSync 类型; 依赖于 jar, startScripts; 安装应用程序到指定的目录\n\n\ndistZip\nZip 类型; 依赖于 jar, startScripts; 创建一个完整的发行版 ZIP 文件, 包括了运行时库和特定的操作系统的脚本\n\n\ndistTar\nTar 类型; 依赖于 jar, startScripts; 创建一个完整的发行版 TAR 文件, 包括了运行时库和特定的操作系统的脚本\n\n\nApplication extensionApplication Plugin 添加一个扩展(extension) 到项目中, 可以用这个扩展来控制这个插件的行为\n查看 [JavaApplication](创建一个完整的发行版 ZIP 文件, 包括了运行时库和特定的操作系统的脚本) DSL 文档来获取更多扩展上可用的属性的信息\nThe Base PluginBase Plugin 提供了大多数构建中常见的一些 task 和 约定, 并向构建中添加了一个结构, 以促进其运行方式的一致性\nBase Plugin 最终要的贡献是一组生命周期 task, 这些 task 为更具体的其他插件提供的或脚本作者提供的 task 扮演了保护伞的角色\nUsageExample - Applying the Base Plugin:\n// build.gradleplugins &#123;    id &#x27;base&#x27;&#125;\n\nTask\n\n\n名称\n含义\n\n\n\nclean\nDelete 类型; 删除构建目录(默认为 build 目录)及其其中所有的东西; 通过 Project.getBuildDir() 项目属性指定的目录\n\n\ncheck\nlifecycle task; 插件或者脚本作者应该连接它们的验证 task, 例如一个测试 task, 到这个 lifecycle task, 使用 check.dependsOn(task)\n\n\nassemble\nlifecycle task; 插件或者脚本作者应该连接它们的创建发行版 task 或其他可消费的构建 task, 例如 jar, 到这个 lifecycle task, 使用 assemble.dependsOn(task)\n\n\nbuild\nlifecycle task;依赖于 check, assemble; 打算构建所有的东西, 包括运行所有测试, 生成产品构件, 生成文档; 应该比较少地直接连接 task 到 build 上, assemble 和 check 更推荐用来连接\n\n\nbuild&#123;Configuration&#125;\ntask rule; 组装那些附加到命名的配置的构件, 例如, buildArchives 将会执行创建连接到 archives configuration 的构件所需的任何 task\n\n\nclean&#123;Taks&#125;\ntask rule; 删除一个 task 定义好的 outputs, 例如, cleanJar 将会删除 Java Plugin 中 jar task 生成的 JAR 文件\n\n\nDependency managementBase Plugin 没有为依赖添加 configuration, 但是它添加了如下配置:\ndefault默认的配置\narchives一个项目生产构件的标准配置\nassemble task 生成所有的关联到 archives configuration 的构件\nContributed extensionsExample - Using the base extension:\n// build.gradlebase &#123;    archivesName = &quot;gradle&quot;    distsDirectory = layout.buildDirectory.dir(&#x27;custom-dist&#x27;)    libsDirectory = layout.buildDirectory.dir(&#x27;custom-libs&#x27;)&#125;\n\narchivesName\n\n默认为 $project.name\n为 archive task 提供默认的 AbstractArchiveTask.getArchiveBaseName()\n\n\n\ndistsDirectory\n\n默认为 $buildDir/distributions\n发行版 archives 所在的目录的默认名称\n\n\n\nlibsDirectory\n\n默认为 $buildDir/libs\n库 archives 所在目录的默认名称\n\n\n\n这个插件还为任何继承了 AbstractArchiveTask 的 task 提供了默认值:\ndestinationDirectory\n\n默认为 distsDirectory 或 libsDirectory\n\narchiveVersion\n\n默认为 $project.version , 如果项目没有版本就默认为 &#39;unspecified&#39;\n\narchiveBaseName\n\n默认为 $archivesBaseName\n\nBuild Init PluginBuild Init Plugin 用来创建一个新的 Gradle 构建\nBuild Init Plugin 支持创建不同类型的全新的 Gradle 构建, 或者将已存在的 Maven 构建转换为 Gradle 构建\nSupported Gradle build typesTable - Build init types:\n\n\n\nType\nDescription\n\n\n\npom\n将一个已存在的 Maven 构建转换为 Gradle 构建\n\n\nbasic\n一个基础的, 空的, Gradle 构建\n\n\njava-application\n一个 Java 实现的命令行应用程序\n\n\njava-gradle-plugin\n一个 Java 实现的 Gradle 插件\n\n\njava-library\n一个 Java 库\n\n\nkotlin-application\n一个 Kotlin&#x2F;JVM 实现的命令行应用程序\n\n\nkotlin-gradle-plugin\n一个 Kotlin&#x2F;JVM 实现的 Gradle 插件\n\n\nkotlin-library\n一个 Kotlin&#x2F;JVM 库\n\n\ngroovy-application\n一个 Groovy 实现的命令行应用程序\n\n\ngroovy-gradle-plugin\n一个 Groovy 实现的 Gradle 插件\n\n\ngroovy-library\n一个 Groovy 库\n\n\nscala-application\n一个 Scala 应用程序\n\n\nscala-library\n一个 Scala 库\n\n\ncpp-application\n一个 C++ 实现的命令行应用程序\n\n\ncpp-library\n一个 C++ 库\n\n\nTasksBuild Init Plugin 添加了如下 task 到项目中\n\n\n\nName\nDescription\n\n\n\ninit\nInitBuild 类型; 依赖于 wrapper; 创建一个 Gradle 构建\n\n\nwrapper\nWrapper 类型; 创建 Gradle wrapper 文件\n\n\nGradle 插件通常需要在使用之前被应用到一个项目中, 即先声明后使用\n但是, Build Init Plugin 对每一个构建来说是自动应用到根项目中的, 这意味你不需要在显式地应用它从而使用它\n你只需要在你想要创建 Gradle 构建的目录中简单地执行 init task\n不需要为了应用插件来创建一个 stub build.gradle\nBuild Init Plugin 还会使用 wrapper task 来为构建生成 Wrapper 文件\nWhat to create最简单最推荐的使用 init task 的方式是在交互式终端中运行 gradle init. Gradle 会列出可用的构建类型并告诉你去选择一个. 然后会询问一些额外的问题来让你微调结果\ninit task 有一些可用的命令行选项来让你控制生成什么东西. Gradle 不是运行在交互式终端时可以使用这些命令行选项\n构建类型通过命令行参数 --type 来指定. 例如, 创建一个 Java library 项目: gradle init --type java-library\n如果没有提供 --type 参数, Gradle 将会从运行环境中尝试进行推断. 例如, 如果查找到一个 pom.xml 文件将会推断 --type 为 pom 类型来将一个 Maven 项目转换为 Gradle 构建. 如果 --type 不能推断出来, 则使用 basic 类型\ninit task 还支持生成使用 Gradle Groovy DSL 或 Gradle Kotlin DSL 的构建脚本\n默认是 Groovy DSL\n可以使用 --dsl 命令行参数来选择 DSL. 例如, gradle init --type java-library --dsl kotlin\n可以使用 --project-name 来指定生成的项目的名称, 默认是 init task 运行的工作目录的名称\n可以使用 --package 来执行生成的源代码文件使用的包名, 默认是项目名称\n所有的构建类型也会设置 Gradle Wrapper\nBuild init typespom build type (Maven conversion)pom 类型可以用来转换一个 Maven 构建为 Gradle 构建\n这个通过将 POM 转换为一个或多个 Gradle 文件来实现的\njava-application build typejava-application 构建类型是不可推断的, 它必须显式声明\njava-application 构建类型有如下特性:\n\n使用 application 插件来生成 Java 实现的命令行应用程序\n使用 mavenCentral 依赖仓库\n使用 JUnit 4 来进行测试\n使用约定的目录位置来存放源代码\n如果没有任何存在的源代码和测试文件, 就包含一个简单的类和单元测试\n\n可以使用 --test-framework 参数来指定使用其他测试框架:\n\ngradle init --type java-application --test-framework junit-jupiter\ngradle init --type java-application --test-framework spock\ngradle init --type java-application --test-framework testng\n\njava-library build typejava-library 构建类型是不可推断的, 它必须显式声明\njava-library 有如下特性:\n\n使用 java 插件来生成一个 Java 实现的库\n使用 mavenCentral 依赖仓库\n使用 JUnit 4 作为测试框架\n使用约定的目录位置来存放源代码\n如果没有任何存在的源代码和测试文件, 就包含一个简单的类和单元测试\n\n使用 --test-framework 参数来使用其他测试框架:\ngradle init --type java-library --test-framework [junit-jupiter | spock | testng]\njava-gradle-plugin build typejava-gradle-plugin 构建类型是不可推断的, 它必须显式声明\njava-gradle-plugin 有如下特性:\n\n使用 java-gradle-plugin 插件来生成一个 Java 实现的 Gradle 插件\n使用 mavenCentral 依赖仓库\n使用 JUnit 4 和 TestKit 来进行测试\n使用约定的目录位置来存放源代码\n如果没有任何存在的源代码和测试文件, 就包含一个简单的类和单元测试\n\ngroovy-library build typegroovy-library 构建类型是不可推断的, 它必须显式声明\ngroovy-library 有如下特性:\n\n使用 groovy 插件来生成 Groovy 实现的库\n使用 mavenCentral 依赖仓库\n使用 Groovy 2.x\n使用 Spock testing framework 来进行测试\n使用约定的目录位置来存放源代码\n如果没有任何已存在的源代码和测试文件, 就包含一个简单的 Groovy 类和一个相关的 Spock specification\n\ngroovy-application build typegroovy-application 构建类型是不可推断的, 它必须显式声明\ngroovy-application 有如下特性:\n\n使用 application 和 groovy 插件来生成 Groovy 实现的命令行应用程序\n使用 mavenCentral 依赖仓库\n使用 Groovy 2.x\n使用 Spock testing framework 来进行测试\n使用约定的目录位置来存放源代码\n如果没有任何已存在的源代码和测试文件, 就包含一个简单的 Groovy 类和一个相关的 Spock specification\n\ngroovy-gradle-plugin build typegroovy-gradle-plugin 构建类型是不可推断的, 它必须显式声明\ngroovy-gradle-plugin 有如下特性:\n\n使用 java-gradle-plugin 和 groovy 插件来生成 Groovy 实现的 Gradle 插件\n使用 mavenCentral 依赖仓库\n使用 Groovy 2.x\n使用 Spock testing framework 和 TestKit 来进行测试\n使用约定的目录位置来存放源代码\n如果没有任何已存在的源代码和测试文件, 就包含一个简单的 Groovy 类和一个相关的 Spock specification\n\nbasic build typebasic 构建类型对于创建一个新的 Gradle 构建是很有用的. 它创建了简单的 settings 和 build 文件, 里面有注释和链接来帮助快速开始\n如果没有构建类型显式指定, 没有构建类型可以被推断出来, 则使用这个 basic 构建类型\nThe Checkstyle PluginExample - Using the Checkstyle plugin:\n// build.gradleplugins &#123;    id &#x27;checkstyle&#x27;&#125;\n\n这个插件添加了一些 task 到项目中来执行质量检查. 你可以通过运行 gradle check 来执行检查\nCheckstyle 将使用与运行 Gradle 相同的 Java 版本来运行\nTasksCheckstyle 插件添加如下 task 到项目中:\ncheckstyleMainCheckstyle 类型\n依赖于 classes\n在生产 Java 源代码文件上运行 Checkstyle\ncheckstyleTestCheckstyle 类型\n依赖于 testClasses\n在 Java 测试源代码文件上运行 Checkstyle\ncheckstyleSourceSetCheckstyle 类型\n依赖于 sourceSetClasses\n在给定的 source set 的 Java 源文件上运行 Checkstyle\nDependencies added to other tasksCheckstyle Plugin 添加如下依赖到 Java Plugin 的 task 中:\ncheck依赖于所有的 Checkstyle tasks, 包括 checkstyleMain 和 checkstyleTest\nProject layout默认情况下, Checkstyle Plugin 希望配置文件放到 root project 中, 但这是可以配置的\n&lt;root&gt;    config        checkstyle              // 1            checkstyle.xml      // 2            suppressions.xml\n\n1 : Checkstyle 配置文件放在这里\n2 : 主 Checkstyle 配置文件\nDependency managementCheckstyle Plugin 添加如下配置 configuration\ncheckstyle configuration : Checkstyle 使用的库\nThe CodeNarc PluginCodeNarc Plugin 在你项目的 Groovy 源代码上使用 CodeNarc 执行质量检查, 并生成检查报告\nExample - Using the CodeNarc plugin\n// build.gradleplugins &#123;    id &#x27;codenarc&#x27;&#125;\n\n这个插件添加了一些 task 到项目用, 来在使用 Groovy Plugin 时执行质量检查. 你可以通过运行 gradle check 来执行检查\nTasksCodeNarc Plugin 添加如下 task 到项目中\ncodenarcMainCodeNarc 类型\n在生产的 Groovy 源代码文件上运行 CodeNarc\ncodenarcTestCodeNarc 类型\n在 Groovy 测试源代码文件上运行 CodeNarc\ncodenarcSourceSetCodeNarc 类型\n在给定的 source set 的 Groovy 源代码文件上运行 CodeNarc\nDependencies added to other tasksCodeNarc Plugin 添加如下依赖到 Groovy Plugin 定义的 task 中\ncheck : 依赖于所有的 CodeNarc task, 包括 codenarcMain 和 codenarcTest\nProject layoutCodeNarc Plugin 希望如下的项目布局:\n&lt;root&gt;    config        codenarc            // 1            codenarc.xml    // 2\n\n1 : CodeNarc 配置文件放在这里\n2 : CodeNarc 的主要配置文件\nDependency managementCodeNarc Plugin 添加如下依赖配置\ncodenarc configuration : 配置 CodeNarc 使用的依赖\nThe Distribution PluginDistribution Plugin 帮助创建 archives, 这个 archives 作为项目的发行版(distribution)\nDistribution archives 通常包含可执行应用程序和其他辅助文件, 例如文档\nExample - Using the Distribution Plugin:\n// build.gradleplugins &#123;    id &#x27;distribution&#x27;&#125;\n\n使用 gradle distZip 来将主要的 distribution 打包成一个 ZIP 文件\n使用 gradle distTar 来将主要的 distribution 打包成一个 TAR 文件\n使用 gradle assembleDist 来将主要的 distribution 打包成一个 ZIP 文件 和 TAR 文件\n文件将会被创建到 $buildDir/distributions/$&#123;project.name&#125;-$&#123;project.version&#125;.&lt;&lt;ext&gt;&gt;\nTasksDistribution Plugin 添加了如下 tasks 到项目中\ndistZipZip 类型\n创建 distribution 内容的 ZIP\ndistTarTask 类型\n创建 distribution 内容的 TAR\nassembleDistTask 类型\n依赖于 distTar, distZIP\n创建 distribution 内容的 ZIP 和 TAR\nDistribution contents所有在 src/$distribution.name/dist 目录中的文件都会自动被包含到 distribution\n可以通过配置 Distribution object 来添加额外的文件作为 distribution 的一部分\nExample - Configuring the main distribution:\n// build.gradledistributions &#123;    main &#123;        distributionBaseName = &#x27;someName&#x27;        contents &#123;            from &#x27;src/readme&#x27;        &#125;    &#125;&#125;\n\nsrc/readme 目录将会被包含到 distribution 中, 同时默认还会包含 src/main/dist 目录\nbashName 属性被修改了, 所有生成的 distribution archives 的名字会有一个不同的名字\nPublishing一个 distribution 可以通过 Ivy Publish Plugin 或 Maven Publish Plugin 来进行发布\nExample - Adding distribution archives to an Ivy publication:\n// build.gradleplugins &#123;    id &#x27;ivy-publish&#x27;&#125;publishing &#123;    publications &#123;        myDistribution(IvyPublication) &#123;            artifact distZip            artifact customDistTar        &#125;    &#125;&#125;\n\nExample - Adding distribution archives to a Maven publication:\n// build.gradleplugins &#123;    id &#x27;maven-publish&#x27;&#125;publishing &#123;    publications &#123;        myDistribution(MavenPublication) &#123;            artifact distZip            artifact customDistTar        &#125;    &#125;&#125;\n\nThe Groovy PluginGroovy Plugin 扩展了 Java Plugin 来为 Groovy 项目添加支持\nGroovy Plugin 可以处理 Groovy 代码, Groovy 和 Java 混合的代码, 和单 Java 代码\nGroovy Plugin 支持联合编译(joint compilation), 允许你自由地混合和匹配 Groovy Java 代码, 通过在同一个方向上的依赖\n如果你想要从 java-library 插件的 API/implementation separation 中获益, 那么你还需要在你 Groovy 项目中使用 java-library\nExample - Using the Groovy Plugin:\n// build.gradleplugis &#123;    id &#x27;groovy&#x27;&#125;\n\nTasksGroovy Plugin 添加了如下 task 到项目中\ncompileGroovyGroovyCompile 类型\n依赖于 compileJava\n编译 Groovy 的产品源代码文件\ncompileTestGroovyGroovyCompile 类型\n依赖于 compileTestJava\n编译 Groovy 的测试文件\ncompile&#123;SourceSet&#125;GroovyGroovyCompile 类型\n依赖于 compile&#123;SourceSet&#125;Java\n编译给定的 source set 的 Groovy 源代码文件\ngroovydocGroovydoc 类型\n为 Groovy 生产源代码文件生成 API 文档\nDependency managementGroovy Plugin 添加如下 task 依赖到 Java Plugin 的 task 上\nTable - Groovy Plugin - additional task dependencies:\n\n\n\nTask name\nDepends on\n\n\n\nclasses\ncompileGroovy\n\n\ntestClasses\ncompileTestGroovy\n\n\n&#123;sourceSet&#125;Classes\ncompile&#123;SourceSet&#125;Groovy\n\n\nProject layout所有的 Groovy 源目录都可以包含 Groovy 和 Java 代码\nJava 源目录只能包含 Java 源代码\nsrc/main/javaJava 产品代码\nsrc/main/resources产品资源, 例如 XML 和 properties 文件\nsrc/main/groovyGroovy 产品代码. 可以包含 Java 源码文件来进行联合编译\nsrc/test/javaJava 测试代码\nsrc/test/resources测试资源\nsrc/test/groovyGroovy 测试代码. 可以包含 Java 源码文件来进行联合编译\nsrc/&#123;sourceSet&#125;/java命名为 {sourceSet} 的 source set 中的 Java 源码\nsrc/&#123;sourceSet&#125;/resources命名为 {sourceSet} 的 source set 中的资源\nsrc/&#123;sourceSet&#125;/groovy给定的 {sourceSet} 中的 Groovy 源码文件, 可以包含 Java 源码文件来进行联合编译\nChanging the project layoutGroovy Plugin 允许你为 Groovy 产品和测试源代码文件配置自定义的位置\nExample - Custom Groovy source layout:\n// build.gradlesourceSets &#123;    main &#123;        groovy &#123;            srcDirs = [&#x27;src/groovy&#x27;]        &#125;    &#125;    test &#123;        groovy &#123;            srcDirs = [&#x27;test/groovy&#x27;]        &#125;    &#125;&#125;\n\nDependency managementGradle 的安装包中已经包含一个 Groovy 库\n然而, Groovy 项目需要显式声明一个 Groovy 依赖. 这个依赖将会用在编译时和运行时 classpath 上. 它还将分别用于获得 Groovy 编译器和 Groovydoc 工具\n如果将 Groovy 用于产品代码, 那么 Groovy 依赖应该添加到 implementation configuration:\nExample - Configuration of Groovy dependency:\n// build.gradlerepositories &#123;    mavenCentral()&#125;dependencies &#123;    implementation &#x27;org.codehaus.groovy:groovy-all:2.4.15&#x27;&#125;\n\n如果 Groovy 仅仅用在测试代码, 那么 Groovy 依赖应该添加到 testImplementation configuration:\nExample - Configuration of Groovy test dependnecy:\n// build.gradledependencies &#123;    testImplementation &#x27;org.codehaus.groovy:groovy-all:2.4.15&#x27;&#125;\n\nGroovy 库不必是从一个远程仓库中获取, 也可以从一个本地 lib 目录中获取, 或者可能 checked in 到一个源码控制系统\nExample - Configuration of Groovy file dependnecy:\n// build.gradlerepositories &#123;    flatDir &#123; dirs &#x27;lib&#x27; &#125;&#125;dependencies &#123;    implementation module(&#x27;org.codehaus.groovy:groovy:2.4.15&#x27;) &#123;        dependency(&#x27;org.ow2.asm:asm-all:5.0.3&#x27;)        dependency(&#x27;antlr:antlr:2.7.7&#x27;)        dependency(&#x27;commons-cli:commons-cli:1.2&#x27;)        module(&#x27;org.apache.ant:ant:1.9.4&#x27;) &#123;            dependencies(&#x27;org.apache.ant:ant-junit:1.9.4@jar&#x27;,                         &#x27;org.apache.ant:ant-launcher:1.9.4&#x27;)        &#125;    &#125;&#125;\n\nAutomatic configuration of groovyClasspathGroovyCompile 和 Groovydoc task 以两种方式使用 Groovy 代码: 在 classpath 上和 在它们的 groovyClasspath 上\n前者用于定位源代码引用的类, 通常包含 Groovy 库和其他库\n后者用于加载和执行 Groovy 编译器和 Groovydoc 工具, 所以应该只包含 Groovy 库和它依赖\n除非一个 task 的 groovyClasspath 被显式配置, 否则 Groovy(base) Plugin 将会尝试从 task 的 classpath 来进行推断:\n\n如果在 classpath 上找到一个 groovy-all(-indy) Jar, 这个 Jar 将会被添加到 groovyClasspath\n如果在 classpath 上找到一个 groovy(-indy) Jar, 且项目声明了至少一个仓库, 那么一个相应的 groovy(-indy) 仓库依赖将会被添加到 groovyClasspath\n否则, task 的执行将会失败, 并在一个消息中表明 groovyClasspath 不能推断出来\n\n每个 jar 的 -indy 变体指的是具有调用动态支持的版本\nConvention propertiesGroovy Plugin 没有添加任何约定属性到项目中\nSource set propertiesGroovy Plugin 添加如下 extension 到项目中的每个 source set 中\n你可以在构建脚本中使用这些属性好像它们是 source set 对象的属性一样\nsource set properties groovyGroovySourceDirectorySet (read-only)\nDefault value: Not null\n这个 source set 的 Groovy 源文件\n包含所有在 Groovy 源目录中找到的 .groovy 和 .java 文件\n不包含所有其他的类型的文件\nsource set properties groovy.srcDirsSet&lt;File&gt;\nDefault value: [&#123;projectDir&#125;/src/&#123;name&#125;/groovy]\n\nThe source directories containing the Groovy source files of this source set\n\n包含该 source set 的 Groovy 源文件的源目录\n\nMay also contain Java source files for joint compilation\n\n还可能包含 Java 源文件来进行联合编译\nsource set properties allGroovyFileTree (read-only)\nDefault value: Not null\n\nAll Groovy source files of this source set. Contains only the .groovy files found in the Groovy source directories\n\n这个 source set 的所有 Groovy 源文件. 只包括 Groovy 源目录中的 .groovy 文件\n这些属性通过一个约定的类型为 GroovySourceSet 对象提供\nmodified source set propertiesGroovy Plugin 还会修改一些 source set 属性\n\n\n\nProperty name\nChange\n\n\n\nallJava\n添加所有在 Groovy 源目录中找到的 .java 文件\n\n\nallSource\n添加所有在 Groovy 源目录中找到的源文件\n\n\nGroovyCompileGroovy Plugin 为项目中的每一个 source set 添加了一个 GroovyCompile task\nGroovyCompile task 继承了 AbstractCompile, 和 JavaCompile task 类似\nGroovyCompile task 支持大多数官方 Groovy 编译器中的选项\nTable - Groovy Plugin - GroovyCompile properties:\n\n\n\nTask Property\nType\nDefault Value\n\n\n\nclasspath\nFileCollection\nsourceSet.compileClasspath\n\n\nsource\nFileTree\nsourceSet.groovy\n\n\ndestinationDirectory\nFile\nsourceSet.groovy.destinationDirectory\n\n\ngroovyClasspath\nFileCollection\ngroovy configuration if non-empty; Groovy library found on classpath otherwise\n\n\njavaLauncher\nProperty&lt;JavaLauncher&gt;\nNone but will be configured if a toolchain is defined on the java extension\n\n\nCompiling and testing for Java 6 or Java 7Example - Configure Java 7 build for Groovy:\n// build.gradlejava &#123;    toolchain &#123;        languageVersion = JavaLanguageVersion.of(7)    &#125;&#125;\n\nThe IDEA PluginIDEA Plugin 生成被 Intellij IDEA 使用的文件, 因此使得可以从 IDEA (File- Open Project) 中打开项目. 外部依赖(包括关联的源码和 Javadoc 文件)和项目依赖都会被考虑\nIDEA Plugin 会生成什么东西取决于你使用了其他什么插件\n总是会生成: 一个 IDEA module 文件. 如果项目是 root project, 生成一个 IDEA project 和 workspace 文件\n如果使用了 Java Plugin: 额外添加 Java 配置到 IDEA module 和 project 文件\nUsageExample - Using the IDEA plugin:\n// build.gradleplugins &#123;    id &#x27;idea&#x27;&#125;\n\nTasksidea :\n\n依赖于 ideaProject, ideaModule, ideaWorkspace\n生成所有 IDEA 配置文件\n\nopenIdea :\n\n依赖于 idea\n生成所有 IDEA 配置文件并在 IDEA 中打开项目\n\ncleanIdea :\n\nDelete 类型\n依赖于 cleanIdeaProject, cleanIdeaModule\n删除所有的 IDEA 配置文件\n\ncleanIdeaProject :\n\nDelete 类型\n删除所有 IDEA project 文件\n\ncleanIdeaModule :\n\nDelete 类型\n删除所有 IDEA module 文件\n\ncleanIdeaWorkspace :\n\nDelete 类型\n删除所有 IEDA workspace 文件\n\nideaProject :\n\nGenerateIdeaProject\n生成 .ipr 文件. 这个 task 仅用于 root project\n\nideaModule :\n\nGenerateIdeaProject 类型\n生成 .iml 文件\n\nideaWorkspace :\n\nGenerateIdeaWorkspace 类型\n生成 .iws 文件. 这个 task 仅用于 root project\n\nThe JaCoco PluginJaCoCo Plugin 为 Java 代码提供代码覆盖率, 通过集成 JaCoCo\nExample - Applying the JaCoCo Plugin:\n// build.gradleplugins &#123;    id &#x27;jacoco&#x27;&#125;\n\n如果 Java Plugin 已经应用到你的项目中, 一个新的 jacocoTestReport task 会被创建\n默认情况下, 一个 HTML 报告会在 $buildDir/reports/jacoco/test 目录中创建\n由于测试需要在生成报告之前执行, 所以 jacocoTestReport task 没有依赖 test task\nExample - Define dependencies between code coverage reports and test execution:\n// build.gradletest &#123;    // report is always generated after tests run    finalizedBy jacocoTestReport&#125;jacocoTestReport &#123;    // tests are required to run before generating the report    dependsOn test&#125;\n\nConfiguring the JaCoCo PluginExample - Configuring JaCoCo plugin settings:\n// build.gradlejacoco &#123;    toolVersion = &quot;0.8.7&quot;    reportsDirectory = layout.buildDirectory.dir(&#x27;customJacocoReportDir&#x27;)&#125;\n\nTable - Gradle defaults for JaCoCo properties:\n\n\n\nProperty\nGradle default\n\n\n\nreportsDirectory\n$buildDir/reports/jacoco\n\n\nJaCoCo Report configurationExample - Configuring test task:\n// build.gradlejacocoTestReport &#123;    reports &#123;        xml.required = false        csv.required = false        html.outputLocation = layout.buildDirectory.dir(&#x27;jacocoHtml&#x27;)    &#125;&#125;\n\nExample - Configuring violation rules:\n// build.gradlejacocoTestCoverageVerification &#123;    violationRules &#123;        rule &#123;            limit &#123;                minimum = 0.5            &#125;        &#125;        rule &#123;            enabled = false            element = &#x27;CLASS&#x27;            includes = [&#x27;org.gradle.*&#x27;]            limit &#123;                counter = &#x27;LINE&#x27;                value = &#x27;TOTALCOUNT&#x27;                maximum = 0.3            &#125;        &#125;    &#125;&#125;\n\n更多信息请查看文档\nThe Java PluginJava Plugin 将 Java 编译, 测试, 绑定的功能添加到项目中\nJava Plugin 作为其他的许多 JVM 语言 Gradle 插件的基础\nJava Plugin 添加基础构建 block 来和 JVM 项目一起工作. Java Plugin 的特性集已经被其他插件所覆盖, 可以根据项目类型提供更多的特性\n除了直接在项目中使用 Java Plugin, 你应该看看 java-library 或者 application 插件或者一种受支持的替代的 JVM 语言\nExample - Using the Java Plugin:\n// build.gradleplugins &#123;    id &#x27;java&#x27;&#125;\n\nTaskscompileJava:\n\nJavaCompile 类型\n\nDepends on: All tasks which contribute to the compilation classpath, including jar tasks from projects that are on the classpath via project dependencies\n\n\n依赖于提供编译 classpath 的所有任务, 包括通过项目依赖在类路径上的项目的 jar task\n使用 JDK 编译器编译 Java 产品源代码\n\nprocessResources:\n\nCopy 类型\n将产品资源(resources)复制到产品资源(resources)目录\n\nclasses:\n\n依赖于 compileJava, processResources\n这是一个聚合 task, 依赖于其他的 task; 其他插件可以附加额外的编译 task 到这个 task 上\n\ncompileTestJava:\n\nJavaCompile 类型\n依赖于 classes, 和所有用于测试编译 classpath 的 task\n使用 JDK 编译器编译 Java 测试代码\n\nprocessTestResources:\n\nCopy 类型\n将测试资源(resources)拷贝到测试资源(resources)目录\n\ntestClasses:\n\n依赖于 compileTestJava, processTestResources\n这是一个聚合 task, 仅依赖于其他 task; 其他插件可能附加额外的测试编译 task 到这个 task 上\n\njar:\n\nJar 类型\n依赖于 classes\n\nAssemble the production JAR file, based on the classes and resources attached to the main source set\n\n\n\njavadoc:\n\nJavadoc 类型\n依赖于 classes\n使用 Javadoc 为 Java 生产代码创建 API 文档\n\ntest:\n\nTest 类型\n依赖于 testClasses, 和所有的提供测试运行时 classpath 的 task\n使用 JUnit 和 TestNG 来运行单元测试\n\nclean:\n\nDelete 类型\n删除项目的 build 目录\n\nclean&#123;TaskName&#125;:\n\nDelete 类型\n删除指定 {TaskName} task 生成的文件. 例如 cleanJar, cleanTest\n\nSourceSet Tasks对于你添加到项目的每个 source set, Java Plugin 添加如下 task 给你:\ncompile&#123;SourceSet&#125;Java:\n\nJavaCompile 类型\n依赖于所有提供 source set 的编译类路径的 task\n使用 JDK 编译器编译指定的 source set 的 Java 源文件\n\nprocess&#123;SourceSet&#125;Resources:\n\nCopy 类型\n复制指定的 source set 的资源文件(resources) 到资源文件目录\n\n&#123;sourceSet&#125;Classes:\n\nTask 类型\n依赖于 compile&#123;SourceSet&#125;Java, process&#123;SourceSet&#125;Resources\n为打包和执行准备好指定的 source set 的 classes 和 resources. 一些插件可能会添加额外的编译 task 到 source set 上\n\nLifecycle TasksJava Plugin 将一些 task 附加到 Base Plugin 定义的生命周期 task 中\nJava Plugin 自动应用了 Base Plugin\nJava Plugin 还添加了一些其他的 task\nassemble:\n\n依赖于 jar, 和其他所有创建 artifacts 的关联到 archives configuration 的 task\n\nAggregate task that assembles all the archives in the project. This task is added by the Base Plugin\n\n\n\ncheck:\n\n依赖于 test\n\nAggregate task that performs verification tasks, such as running the tests\n\n\n\nSome plugins add their own verification tasks to check\n\n\n\nYou should also attach any custom Test tasks to this lifecycle task if you want them to execute for a full build\n\n\n\nThis task is added by the Base Plugin\n\n\n\nbuild:\n\n依赖于 check, assemble\n\nAggregate task that performs a full build of the project. This task is added by the Base Plugin\n\n\n\nbuildNeeded:\n\n\nDepends on: build, and buildNeeded tasks in all projects that are dependencies in the testRuntimeClasspath configuration\n\n\n\nPerforms a full build of the project and all projects it depends on\n\n\n\nbuildDependents:\n\n\nDepends on: build, and buildDependents tasks in all projects that have this project as a dependency in their testRuntimeClasspath configurations\n\n\n\nPerforms a full build of the project and all projects which depend upon it\n\n\n\nbuild&#123;ConfigName&#125;:\n\n\nDepends on: all tasks that generate the artifacts attached to the named - ConfigName - configuration\n\n\n\nAssembles the artifacts for the specified configuration. This rule is added by the Base Plugin\n\n\n\nupload&#123;ConfigName&#125;:\n\n\nDepends on: all tasks that generate the artifacts attached to the named - ConfigName - configuration\n\n\n\nAssembles and uploads the artifacts in the specified configuration. This rule is added by the Base Plugin\n\n\n\nProject layoutsrc/main/java : Java 产品代码\nsrc/main/resources : 产品资源, 例如 XML 和 properties 文件\nsrc/test/java : Java 测试代码\nsrc/test/resources : 测试资源\nsrc/&#123;sourceSet&#125;/java : 指定名字的 source set 的 Java 产品代码\nsrc/&#123;sourceSet&#125;/resources : 指定名字的 source set 的资源\nChanging the project layoutExample - Custom Java source layout:\n// build.gradlesourceSets &#123;    main &#123;        java &#123;            srcDirs = [&#x27;src/java&#x27;]        &#125;        resources &#123;            srcDirs = [&#x27;src/resources&#x27;]        &#125;    &#125;&#125;\n\nSource setsmain : 包含项目中的被编译和组合到 JAR 中的产品源代码\ntest : 包含用来编译与执行 JUnit 或 TestNG 的测试源代码. 这些是典型的单元测试, 但是你可以在这个 source set 中包含任何测试, 只要它们共享相同的编译时和运行时 classpaths\nSource set properties如下是 source set 中重要的属性, 可以在 API 文档中查看更多细节 SourceSet\n\nname\noutput\noutput.classesDirs\noutput.resourcesDir\ncompileClasspath\nannotationProcessorPath\nruntimeClasspath\njava\njava.srcDirs\njava.destinationDirectory\nresources\nresources.srcDirs\nallJava\nallSource\n\nDependency managementDependency configurations\nimplementation\ncompileOnly\ncompileClasspath extends compileOnly, implementation\nCompile classpath, used when compiling source. Used by task compileJava\n\n\nannotationProcessor\nAnnotation processors used during compilation\n\n\nruntimeOnly\nruntimeClasspath extends runtimeOnly, implementation\nRuntime classpath contains elements of the implementation, as well as runtime only elements\n\n\ntestCompileOnly\ntestCompileClasspath extends testCompileOnly, testImplementation\ntestRuntimeOnly extends runtimeOnly\ntestRuntimeClasspath extends testRuntimeOnly, testImplementation\narchives\ndefault extends runtimeElements\n\nSourceSet dependency configurations对于每个你添加到项目的 source set, Java Plugin 添加了如下 dependency configurations\nSourceSet dependency configurations\n\n{sourceSet}Implementation\n{sourceSet}CompileOnly\n{sourceSet}CompileClasspath extends {sourceSet}CompileOnly,{sourceSet}Implementation\n{sourceSet}AnnotationProcessor\n{sourceSet}RuntimeOnly\n{sourceSet}RuntimeClasspath extends {sourceSet}RuntimeOnly, {sourceSet}Implementation\n\nContributed extensionJava Plugin 添加了 java extension 到项目中\n这允许在一个专门的 DSL 块中配置大量的 Java 相关属性\nExample - Using the java extension:\n// build.gradlejava &#123;    toolchain &#123;        languageVersion = JavaLanguageVersion.of(11)    &#125;&#125;\n\nThe Java Library Plugin\nThe Java Library plugin expands the capabilities of Java Plugin by providing specific knowledge about Java libraries\n\nJava Library Plugin 通过提供关于 Java 库的特定知识来扩展 Java Plugin 的功能\n特别是, 一个 Java 库暴露了一个 API 给消费者\nJava Library Plugin 暴露的所有 source sets, tasks 和 configurations 在使用这个插件时都是显式可用的\nExample - Using the Java Library plugin:\n// build.gradleplugins &#123;    id &#x27;java-library&#x27;&#125;\n\nAPI and implementation separation标准 Java Plugin 和 Java Library Plugin 的关键区别是暴露 API 给消费者的概念\n一个 Library 意味着是一个暴露给其他组件用的 Java component\nJava Library Plugin 暴露了两个 configurations 来声明依赖: api 和 implementation\n\nThe api configuration should be used to declare dependencies which are exported by the library API\n\napi configuration 应该用来声明通过 library API 导出(exported)的依赖\n\nThe implementation configuration should be used to declare dependencies which are internal to the component\n\nimplementation configuration 应该用来声明在 component 内部的依赖\nExample - Declaring API and implementation dependencies:\n// build.gradledependencies &#123;    api &#x27;org.apache.httpcomponent:httpclient:4.5.7&#x27;    implementation &#x27;org.apache.commons:commons-lang3:3.5&#x27;&#125;\n\n\nDependencies appearing in the api configurations will be transitively exposed to consumers of the library, and as such will appear on the compile classpath of consumers\n\n出现在 api configuration 中的依赖将被传递给库的消费者, 因此依赖将出现在消费者的编译 classpath 上\n\nDependencies found in the implementation configuration will, on the other hand , not be exposed to consumers, and therefore not leak into the consumers’ compile classpath\n\n出现在 implementation configuration 中的依赖, 相反地, 不会暴露给消费者, 因此不会泄露到使用者的编译 classpath 上\n这带来了这些好处:\n\n依赖不再泄露到消费者的编译 classpath 上, 所以你永远不会再意外地依赖到一个传递性依赖\n由于减少的 classpath 大小, 所以更快的编译速度\n在 implementation 依赖改变的时候更少的重新编译. 消费者不再需要重新编译\n更干净的发布: 当与新的 maven-publish 插件一起使用时, Java 库会生成 POM 文件, 从而精确区分哪些需要编译, 哪些需要在运行时使用该库(换句话说, 就是不要混合什么需要用来编译库本身和什么需要根据库进行编译)\n\ncompile 和 runtime configurations 从 Gradle 7.0 开始已经被删除了, 迁移到使用 implementation 和 api configurations\n当你的构建消费了一个通过 POM metadata 发布的 module, Java Plugin 和 Java Library Plugin 都通过 POM 中的作用域来完成 api 和 implementation 的区分\n意味着编译时 classpath 只包含 Maven compile 作用域的依赖, 运行时 classpath 包含 Maven runtime 作用域的依赖\nMaven compile : 参与编译的过程的类库, 例如, 一些 API 接口\nMaven runtime : 不参与编译过程的类库, 只在运行的时候添加到 classpath 上, 例如, 一些 API 接口的实现\nRecognizing API and implementation dependenciesRecognizing : 识别\n\nPrefer the implementation configuration over api when possible\n\n尽可能地使用 implementation configuration, 而不是 api configuration. 这保持了依赖不在消费者的编译 classpath 上. 除此之外, 如果任何实现类型意外泄露到 public API 中, 消费者将立即编译失败\n所以什么时候使用 api configuration? 一个 API 依赖至少包含在库二进制接口中公开的一种类型, 通常称为 ABI(Application Binary Interface). 包括但不限于:\n\n在父类或接口中使用的类型\n在 public 的方法的参数中使用的类型, 包括泛型参数类型\npublic 字段中使用的类型\npublic 注解类型\n\n相反地, 以下类型和 ABI 是相反的, 因此应该声明为 implementation 依赖:\n\n在方法主体中专用的类型\n在 private 成员中专用的类型\n在内部类中专用的类型\n\nExample - Makingthe difference between API and implementation:\n// The following types can appear anywhere in the code// but say nothing about API or implementation usageimport org.apache.commons.lang3.exception.ExceptionUtils;import org.apache.http.HttpEntity;import org.apache.http.HttpResponse;import org.apache.http.HttpStatus;import org.apache.http.client.HttpClient;import org.apache.http.client.methods.HttpGet;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.io.UnsupportedEncodingException;public class HttpClientWraper &#123;    private final HttpClient client;// private member: implementation details    // HttpClient is used as a parameter of a public method    // so &quot;leaks&quot; into the public API of this component    public HttpClientWrapper(HttpClient client) &#123;        this.client = client;    &#125;    // public methods belongs to your API    public byte[] doRawGet(String url) &#123;        HttpGet request = new HttpGet(url);          try &#123;              HttpEntity entity = doGet(request);              ByteArrayOutputStream baos = new ByteArrayOutputStream();              entity.writeTo(baos);              return baos.toByteArray();          &#125; catch (Exception e) &#123;              ExceptionUtils.rethrow(e); // this dependency is internal only          &#125; finally &#123;              request.releaseConnection();          &#125;          return null;    &#125;    // HttpGet and HttpEntity are used in a private method, so they don&#x27;t belong to the API    private HttpEntity doGet(HttpGet get) throws Exception &#123;        HttpResponse response = client.execute(get);        if (response.getStatusList().getStatusCode() != HttpStatus.SC_OK) &#123;            System.err.println(&quot;Method failed: &quot; + response.getStatusLine());        &#125;        return response.getEntity()    &#125;&#125;\n\nHttpClientWrapper 的 public 构造方法使用了 HttpClient 作为参数, 所以 HttpClient 暴露给消费者, 因此它属于 API\nHttpGet 和 HttpEntity 在一个 private 的方法签名中使用, 因此它们不会把 HttpClient 算作 API 依赖\n来自 commons-lang 库的 ExceptionUtils 类型, 只在方法主体中使用(没有在方法的签名中), 所以它是一个 implementation 依赖\n所以, 我们可以推断出 httpclient 是一个 API 依赖, commons-lang 是一个 implementation 依赖. 这个结论翻译成构建脚本中如下的声明:\nExample - Declaring API and implementation dependencies:\n// build.gradledependencies &#123;    api &#x27;org.apache.httpcomponents:httpclient:4.5.7&#x27;    implementation &#x27;org.apache.commons:commons-lang3:3.5&#x27;&#125;\n\nThe Java Library Plugin configurations配置之间的依赖关系请查看文档的图\n用来声明依赖的 configurations:\n\ncompileOnlyApi\napi\ncompileOnly\nimplementation\nruntimeOnly\n\n编译一个组件时, 或运行这个库的 configurations:\n\napiElements(C)\nruntimeElements(C)\n\n组件内部使用的 configurations:\n\ncompileClasspath(R)\nruntimeClasspath(R)\n\nTable - Java Library Plugin - configurations used to declare dependencies:\n\n\n\nConfiguration name\nRole\nConsumable?\nResolvable?\nDescription\n\n\n\napi\n声明 API 依赖\nno\nno\n在这里声明可传递性地暴露给消费者的依赖, 用于编译时和运行时\n\n\nimplementation\n声明 implementation 依赖\nno\nno\n在这里声明仅内部使用, 不要暴露给消费者的依赖(这些依赖在运行时还是会暴露给消费者的)\n\n\ncompileOnly\n声明 compile only 依赖\nno\nno\n在这里声明编译时要求的,不是运行时要求的依赖. 这通常包括在运行时发现的隐藏的(shaded)依赖\n\n\ncompileOnlyApi\n声明 compile only API 依赖\nno\nno\n在这里声明你的 module 和你的消费者编译时要求的, 不是运行时的依赖. 这通常包括在运行时发现的隐藏的(shaded)依赖\n\n\nruntimeOnly\n声明 runtime 依赖\nno\nno\n在这里声明只要求在运行时的依赖\n\n\ntestImplementation\n测试依赖\nno\nno\n在这里声明用来编译测试的依赖\n\n\ntestCompileOnly\n声明 test compile only 依赖\nno\nno\n在这里声明只要测试编译时使用的, 不应该泄露到运行时的依赖. 这通常包括在运行时发现的隐藏的(shaded)依赖\n\n\ntestRuntimeOnly\n声明 test runtime 依赖\nno\nno\n在这里声明只在运行时使用的, 不在编译时使用的依赖\n\n\nTable - Java Library Plugin - configurations used by consumers:\n\n\n\nConfiguration name\nRole\nConsumable?\nResolvable?\nDescription\n\n\n\napiElements\nFor compiling against(针对) this library\nyes\nno\n这个 configuration 的目的是给消费者使用, 以检索针对此库编译所需的所有元素. 不像 default configuration, 这个 configuration 不会泄露 implementation 和 runtime 依赖\n\n\nruntimeElements\nFor executing this library\nyes\nno\n这个 configuration 的目的是给消费者使用, 以检索针对此库运行所需的所有元素\n\n\nTable - Java Library Plugin - configurations used by the library itself:\n\n\n\nConfiguration name\nRole\nConsumable?\nResolvable?\nDescription\n\n\n\ncompileClasspath\nFor compiling this library\nno\nyes\n这个 configuration 包含这个库的编译 classpath, 所以在调用 Java 编译器编译它时使用这个配置\n\n\nruntimeClasspath\nFor executing this library\nno\nyes\n这个 configuration 包含这个库的运行时 classpath\n\n\ntestCompileClasspath\nFor compiling the tests of this library\nno\nyes\n这个 configuration 包含这个库的测试编译时 classpath\n\n\ntestRuntimeClasspath\nFor executing tests of this library\nno\nyes\n这个 configuration 包含这个库的测试运行时 classpath\n\n\nUsing classes instead of jar for compilationJava Library Plugin 的一个特性是, 使用 library 的项目可以只消费类文件来编译, 而不是整个 JAR 包\n这可以减轻项目间的依赖关系, 因为当在开发过程中只需要执行 Java 代码编译时, 例如资源处理(processResources task)和 archive 打包(jar task)可以不用再执行\n是否使用 classes output 来代替 JAR 包是消费者来决定的\nIncreased memory usage for consumers一个间接的结果是, up-to-date 检查将需要更多的内存, 因为 Gradle 会快照单个类文件, 而不是单个 JAR 文件\n这可能导致大型项目的内存消耗增加, 在更多的情况下可以使 compileJava task 保持最新(e.g changing resources no longer changes the input for compileJava tasks of upstream projects)\nSignificant build performance drop on Windows for huge multi-projects对于单个类文件进行快照的另一个副作用是, 只影响 Windows 系统, 当在编译时 classpath 上处理大量的类文件时性能会显著下降\n唯一涉及的是非常大的 multi-projects 的大部分类似通过 api 依赖提供到 classpath 上\n你可以通过设置 org.gradle.java.compile-classpath-packaging 系统属性为 true 来减轻这个性能下降, 这个系统属性将 Java Library Plugin 的行为修改为在编译时 classpath 上使用 JAR 而不是使用类目录\n通过在编译时触发所有 jar tasks, 这个系统属性会有其他的性能影响和潜在的影响, 建议只有在 Windows 系统上面真的遇到性能问题是才使用\nDistribution a library使用 Java Library Distribution Plugin 来发布 library 和它的依赖\nThe Java Library Distribution PluginJava Library Distribution Plugin 添加构建一个 Java library 发行版 ZIP 的支持\n发行版(distribution)包含包含 library 和它的依赖的 JAR 文件\nExample - Using the Java Library Distribution Plugin:\n// build.gradleplugins &#123;    id &#x27;java-library-distribution&#x27;&#125;\n\nExample - Configure the distribution name:\n// build.gradledistributions &#123;    main &#123;        distributionBaseName = &#x27;my-name&#x27;    &#125;&#125;\n\ndistribution 会打包 library 的运行时依赖\n保存在 src/main/dist 中的所有文件会被添加到 archive distribution 的根目录\n运行 gradle distZip 来创建一个包含 distribution 的 ZIP 文件\nTasksdistZip\n\nZip 类型\n依赖于 jar\n创建一个完整的 distribution ZIP archive, 包括运行时库\n\nIncluding other resources in the distribution所有在 src/dist 目录中的文件都会被拷贝\n为了包含所有静态文件到 distribution 中, 简单地将它们整理到 src/dist 目录, 或者将它们添加到 distribution 的内容中\nExample - Include files in the distribution:\n// build.gradledistributions &#123;    main &#123;        distributionBaseName = &#x27;my-name&#x27;        contents &#123;            from &#x27;src/dist&#x27;        &#125;    &#125;&#125;\n\nThe Java Platform Plugin\nThe Java Platform Plugin brings the ability to declare platforms for the Java ecosystem\n\nJava Platform Plugin 带来了为 Java 生态系统声明平台的能力\n\nA platform can be used for different purpose:\n\n\na description of modules which are published together (and for example, share the same version)\na set of recommended versions for heterogeneous libraries. A typical example includes the Spring Boot BOM\nsharing a set of dependency versions between subprojects\n\n一个 Platform 可以用作不同的目的:\n\n一起发布的模块的描述(例如, 共享同一个版本号)\n一组为异构库(heterogeneous libraries)推荐的版本. 一个典型的例子是, 包含 Spring Boot BOM\n在不同子项目之间共享一组依赖版本\n\n\nA platform is a special kind of software component which doesn’t contain any sources: it is only used to reference other libraries, so that they play well together during dependency resolution\n\nPlatform 是一个特别的不包含任何源代码软件组件, 它只用来引用其他库, 以便它们可以在依赖解析的时候可以很好地合作\nPlatform 可以作为 Gradle Module Metadata 和 Maven BOMs 来进行发布\njava-platform 插件不能和 java, java-library 插件在一个给定项目中结合起来使用\n从概念上来说, 项目要么是没有二进制文件的 Platform, 要么是生成二进制文件的 Platform\nUsageExample - Using the Java Platform plugin:\n// build.gradleplugins &#123;    id &#x27;java-platform&#x27;&#125;\n\nAPI and runtime separation\nA major difference between a Maven BOM and a Java platform is that in Gradle dependencies and constraints are declared and scoped to a configuration and the ones extending it\n\nMaven BOM 和 Java Platform 之间的一个主要区别是, 在 Gradle, 依赖和约束被 声明和限定 在 configuration 和 configuration 的扩展上\n虽然许多用户只关心为编译时依赖声明约束, 从而让运行时和测试时依赖来继承, 但它允许声明仅适用于运行时或测试时的依赖和约束\n这个插件暴露了两个 configurations 来用来声明依赖: api 和 runtime\napi configuration 应该用来声明 用在 Platform 编译时的 约束(constraints)和依赖(dependencies)\nruntime configuration 应该用来声明 在运行时可见的 约束(constraints)和依赖(dependencies)\nExample - Declaring API and runtime constraints:\n// build.gradledependencies &#123;    constraints &#123;        api &#x27;commons-httpclient:commons-httpclient:3.1&#x27;        runtime &#x27;org.postgresql:postgresql:42.2.5&#x27;    &#125;&#125;\n\n这个例子使用了约束(constraints)而不是依赖(dependencies)\n一般而言, 这就是你想要做的: 约束(constraints)只在这样的组件被添加到依赖关系图(dependency graph)时才会生效, 无论是直接的还是传递的\n这意味着在 Platform 列出的所有约束(constraints)都不会添加依赖(dependency), 除非另一个组件(component)引入它, 约束(constraints)可以被看做是 推荐(recommendations)\n例如, 如果一个 Platform 声明了一个 org:foo:1.1 依赖, 如果没有其他东西引入 foo 依赖, foo 将不会出现在 graph. 但是, 如果 foo 出现在 graph 中, 那么冲突解析就会生效\n如果一个依赖引入了 org:foo:1.0, 那么我们就会选择使用 org:foo:1.1 来满足 Platform 的约束\n默认情况下, 为了避免在平台中添加依赖而不是约束的常见错误, 如果你尝试这样做, Gradle 将会 fail. 如果因为某些原因你还是想要添加依赖而不是约束, 你可以这样做:\nExample - Allowing declaration of dependencies:\n// build.gradlejavaPlatform &#123;    allowDependencies()&#125;\n\nLocal project constraints\nIf you have a multi-project build and want to publish a platform that links to subprojects, you can do it by declaring constraints on the subprojects which belong to the platform\n\n如果你有一个 multi-project 构建, 并想要发布一个链接到子项目的 Platform, 你可以通过声明属于该 Platform 的子项目的约束来实现:\nExample - Declaring constraints on subprojects:\n// build.gradledependencies &#123;    constraints &#123;        api project(&quot;:core&quot;)        api project(&quot;:lib&quot;)    &#125;&#125;\n\n\nThe project notation will become a classical group:name:version notation in the published metadata\n\n项目表示法将成为发布元数据中的经典 group:name:version 表示法\nSourcing constraints from another platform一个 Platform 继承另一个已经存在的 Platform\n为了让你的 Platform 引入第三方 Platform 的约束, 需要作为一个 platform dependency 来引入:\nExample - Importing a platform:\n// build.gradlejavaPlatform &#123;    allowDependencies()&#125;dependencies &#123;    api platform(&#x27;com.fasterxml.jackson:jackson-bom:2.9.8&#x27;)&#125;\n\nPublishing platforms使用 maven-plugin 插件来发布, 使用 javaPlatform component 来配置一个 Maven publication:\nExample - Publishing as a BOM:\n// build.gradlepublishing &#123;    publications &#123;        myPlatform(MavenPublication) &#123;            from components.javaPlatform        &#125;    &#125;&#125;\n\n这将会为 Platform 创建一个 BOM 文件, 使用 &lt;dependencyManagement&gt; 块，其中 &lt;dependencies&gt; 对应于平台模块中定义的约束\nConsuming platforms因为 Java Platform 是一种特殊类型的组件, Java Platform 上的依赖必须使用 platform 和 enforcedPlatform 关键字声明\n例如, 你想要在子项目之间共享依赖版本, 你可以定义一个声明了所有版本 platform module:\nExample - Recommend versions in a platform module:\n// build.gradledependencies &#123;    constraints &#123;        // Platform declares some versions of libraries used in subprojects        api &#x27;commons-httpclient:commons-httpclient:3.1&#x27;        api &#x27;org.apache.commons:commons-lang3:3.8.1&#x27;    &#125;&#125;\n\n然后让子项目依赖这个 Platform 来获取它的推荐:\nExample - Get recommendations from a platform:\n// build.gradledependencies &#123;    // get recommended versions from the platform project    api platform(project(&#x27;:platform&#x27;))    // no version required    api &#x27;commons-httpclient:commons-httpclient&#x27;&#125;\n\nMaven Publish PluginExample - Applying the Maven Publish Plugin:\n// build.gradleplugins &#123;    id &#x27;maven-publish&#x27;&#125;\n\nMaven Plublish Plugin 在项目上使用一个类型为 PublishingExtension 名称为 publishing 的 extension. 这个 extension 提供了命名的发布容器和命名的仓库容器\nMaven Plublish Plugin 和 MavenPublication publications , MavenArtifactRepository repositories 一起工作\nTasksgeneratePomFileFor&#123;PubName&#125;Publication\n\nGenerateMavenPom 类型\n为名称为 {PubName} 的 publication 生成一个 POM 文件, 在文件中填充已知的元数据例如项目名称, 版本和依赖. 这个 POM 文件默认的生成地址是 build/publications/$pubName/pom-default.xml\n\npublish&#123;PubName&#125;PublicationTo&#123;RepoName&#125;Repository\n\nPublishToMavenRepository 类型\n发布 {PubName} publication 到名字为 {RepoName} 的仓库. 如果没有指定仓库的名称, 则默认为 {RepoName} 为 Maven\n\npublish&#123;PubName&#125;PublicationToMavenLocal\n\nPublishToMavenLocal 类型\n拷贝 {PubName} publication 到本地 Maven 缓存. 一般是 $USER_HOME/.m2/repository, 拷贝 publication 的 POM 文件和其他元数据\n\npublish\n\n依赖于所有的 publish&#123;PubName&#125;PublicationTo&#123;RepoName&#125;Repository task\n一个聚合的 task, 这个 task 用来发布所有定义好的 publications 到所有定义好的仓库中. 这个 task 不包括拷贝 publications 到本地 Maven 缓存\n\npublishToMavenLocal\n\n依赖于所有的 publish&#123;PubName&#125;PublicationToMavenLocal task\n拷贝所有定义好的 publication 到本地 Maven 缓存, 包含它们的元数据(例如, POM 文件)\n\nPublications这个插件提供了类型为 MavenPublication 的 publications\n有四个主要的东西你可以在一个 Maven publication 中配置:\n\n一个 component. 通过 MavenPublication.from(org.gradle.api.component.SoftwareComponent)\n自定义的 artifacts. 通过 MavenPublication.artifact(java.lang.Object)\n基础元数据. 例如 artifactId, groupId, version\n其他 POM 文件中的内容. 通过 MavenPublication.pom(org.gradle.api.Action)\n\nIdentity values in the generated POM生成的 POM 文件的属性将包含从以下项目属性获得的标识值:\n\ngroupId - Project.getGroup()\nartifactId - Project.getName()\nversion - Project.getVersion()\n\nExample - Customizing the publication identity:\n// build.gradlepublishing &#123;    publications &#123;        maven(MavenPublication) &#123;            groupId = &#x27;org.gradle.sample&#x27;            artifactId = &#x27;library&#x27;            version = &#x27;1.1&#x27;            from components.java        &#125;    &#125;&#125;\n\nCustomizing the generated POM可以在发布之前自定义生成的 POM 文件\n查看 MavenPom 获取更多可用的属性和方法\nExample - Customizing the POM file:\n// build.gradlepublishing &#123;    publications &#123;        mavenJava(MavenPublication) &#123;            pom &#123;                name = &#x27;My Library&#x27;                description = &#x27;A concise description of my library&#x27;                url = &#x27;http://www.example.com/library&#x27;                properties = [                    myProp: &quot;value&quot;,                    &quot;prop.with.dots&quot;: &quot;anoterValue&quot;                ]                licenses &#123;                    license &#123;                        name = &#x27;The Apache License, Version 2.0&#x27;                        url = &#x27;http://www.apache.org/licenses/LICENSE-2.0.txt&#x27;                    &#125;                &#125;                developers &#123;                    developer &#123;                        id = &#x27;johnd&#x27;                        name = &#x27;John Doe&#x27;                        email = &#x27;john.doe@example.com&#x27;                    &#125;                &#125;                scm &#123;                    connection = &#x27;scm:git:git://example.com/my-library.git&#x27;                    developerConnection = &#x27;scm:git:ssh://example.com/my-library.git&#x27;                    url = &#x27;http://example.com/my-library/                &#125;            &#125;        &#125;    &#125;&#125;\n\nCustomizing dependencies versions支持两种策略来发布依赖\nDeclared versions(默认)使用构建脚本作者使用 dependencies &#123;&#125; 声明的依赖的版本\nResolved versions使用构建解析后的版本, 可能使用了解析规则和自动冲突解决\n这样做的好处是, 发布的版本对应于测试发布构建所针对的版本\n使用解析版本的例子:\n\n一个项目使用了依赖动态版本, 但更倾向于将给定发布的解析版本公开给其使用者\n结合 dependency locking, 你想要发布 locked versions\n一个项目利用了Gradle的富版本约束，它有一个到Maven的有损转换. 它发布已解析的版本，而不是依赖于转换\n\n使用 versionMapping DSL 方法来配置 VersionMappingStrategy:\nExample - Using resolved versions:\n// build.gradlepublishing &#123;    publications &#123;        mavenJava(MavenPublication) &#123;            versionMapping &#123;                usage(&#x27;java-api&#x27;) &#123;                    fromResolutionOf(&#x27;runtimeClasspath&#x27;)                &#125;                usage(&#x27;java-runtime&#x27;) &#123;                    fromResolutionResult()                &#125;            &#125;        &#125;    &#125;&#125;\n\n在上面的例子中, Gradle 将会使用在 runtimeClasspath 上解析的 api 中声明的依赖的版本, 这些依赖被映射到 Maven 的 compile scope\nGradle 还会使用在 runtimeClasspath 上解析的 implementation 中声明的依赖的版本, 这些依赖被映射到 Maven 的 runtime scope\nfromResolutionResult() 表示 Gradle 应该使用变量的默认类型\nruntimeClasspath 是 java-runtime 的默认 classpath\nRepositories这个插件提供了类型为 MavenArtifactRepository 的 repositories\nExample - Declaring repositories to publish to:\n// build.gradlepublishing &#123;    repositories &#123;        maven &#123;            // change to point to your repo, e.g. http://my.org/repo            url = layout.buildDirectory.dir(&#x27;repo&#x27;)        &#125;    &#125;&#125;\n\nSnapshots and release repositories发布 snapshot 和 release 版本到不同的仓库是一个很好的实践\nExample - Configuring repository URL based on project version:\n// build.gradlepublishing &#123;    repositories &#123;        maven &#123;            def releasesRepoUrl = layout.buildDirectory.dir(&#x27;repos/releases&#x27;)            def snapshotsRepoUrl = layout.buildDirectory.dir(&#x27;repos/snapshots&#x27;)            url = version.endsWith(&#x27;SNAPSHOT&#x27;) ? snapshotsRepoUrl : releasesRepoUrl        &#125;    &#125;&#125;\n\n你还可以使用一个项目属性或者系统属性来决定发布到哪个仓库\n例如, 使用系统属性 release 来发布到 release 仓库: gradle -Prelease publish\nExample - Configuring repository URL based on project property:\n// build.gradlepublishing &#123;    repositories &#123;        maven &#123;            def releasesRepoUrl = layout.buildDirectory.dir(&#x27;repos/releases&#x27;)            def snapshotsRepoUrl = layout.buildDirectory.dir(&#x27;repos/snapshots&#x27;)            url = project.hasProperty(&#x27;release&#x27;) ? releasesRepoUrl : releasesRepoUrl        &#125;    &#125;&#125;\n\nPublishing to Maven Local使用 PublishToMavenLocal task 来为每个 MavenPublication 进行发布\nPublishing Maven relocation information当一个项目发布它改变了 groupId 或者 artifactId (the coordinates) 的构件, 让所有使用这个项目的用户知道去哪儿寻找新的构件是很重要的\nMaven 可以通过 relocation 特性来帮助完成这个操作\n它的工作方式是, 项目在旧的坐标 (the coordinates) 下发布一个额外的构件, 这个坐标 (the coordinates) 仅由最小的 relocation POM 组成\n这个 POM 文件指定了在新的构件可以在哪儿寻找到\nMaven 仓库和构建工具可以提醒用户一个构件的 the coordinates 已经改变\n为了这个功能, 一个项目添加一个额外的 MavenPublication 来指定一个 MavenPomRelocation\nExample - Specifying a relocation POM:\n// build.gradlepublishing &#123;    publications &#123;        // ... artifact publications        // Specify relocation POM        relocation(MavenPublication) &#123;            pom &#123;                // Old artifact coordinates                groupId = &quot;com.example&quot;                artifactId = &quot;lib&quot;                version = &quot;2.0.0&quot;                distributionManagement &#123;                    relocation &#123;                        // New artifact coordinates                        groupId = &quot;com.new-example&quot;                        artifactId = &quot;lib&quot;                        version = &quot;2.0.0&quot;                        message = &quot;groupId has been changed&quot;                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;\n\n一个 relocation POM 只可以发布一次, 一旦发布过了, 就应该从构建脚本中删除\nrelocation POM 并不适用于所有场景, 如果一个构件分成了两个或多个构件, 那么一个 relocation POM 可能就派不上用处了\nComplete exampleExample - Publishing a Java library:\n// build.gradleplugins &#123;    id &#x27;java-library&#x27;    id &#x27;maven-publish&#x27;    id &#x27;signing&#x27;        // 创建签名信息&#125;group = &#x27;com.example&#x27;version = &#x27;1.0&#x27;java &#123;    withJavadocJar()    withSourcesJar()&#125;publishing &#123;    publications &#123;        mavenJava(MavenPublication) &#123;            artifactId = &#x27;my-library&#x27;            from components.java            versionMapping &#123;                usage(&#x27;java-api&#x27;) &#123;                    fromResolutionOf(&#x27;runtimeClasspath&#x27;)                &#125;                usage(&#x27;java-runtime&#x27;) &#123;                    fromResolutionResult()                &#125;            &#125;            pom &#123;                name = &#x27;My Library&#x27;                description = &#x27;A concise description of my library&#x27;                url = &#x27;http://www.example.com/library&#x27;                properties = [                    myProp: &quot;value&quot;,                    &quot;prop.with.dots&quot;: &quot;anotherValue&quot;                ]                licenses &#123;                    license &#123;                        name = &#x27;The Apache License, Version 2.0&#x27;                        url = &#x27;http://www.apache.com.org/licenses/LICENSE-2.0.txt&#x27;                    &#125;                &#125;                developers &#123;                    developer &#123;                        id = &#x27;john&#x27;                        name = &#x27;John Doe&#x27;                        email = &#x27;john.doe@example.com&#x27;                    &#125;                &#125;                scm &#123;                    connection = &#x27;scm:git:git://example.com/my-library.git&#x27;                    developerConnection = &#x27;scm:git:ssh://example-com/my-library.git&#x27;                    url = &#x27;http://example.com/my-library&#x27;                &#125;            &#125;        &#125;    &#125;    repositories &#123;        maven &#123;            // change URLs to point to your repos, e.g http://my.org/repo            def releasesRepoUrl = layout.buildDirectory.dir(&#x27;repos/releases&#x27;)            def snapshotsRepoUrl = layout.buildDirectory.dir(&#x27;repos/snapshots&#x27;)            url = version.endsWith(&#x27;SNAPSHOT&#x27;) ? snapshotsRepoUrl : releaseRepoUrl        &#125;    &#125;&#125;signing &#123;    sign publishing.publications.mavenJava&#125;javadoc &#123;    if (JavaVersion.current().isJava9Compatible()) &#123;        options.addBooleanOption(&#x27;html5&#x27;, true)    &#125;&#125;\n\n结果是如下的构件将会被发布:\n\nPOM 文件: my-library-1.0.pom\nJava component 的主要 JAR 构件文件: my-library-1.0.jar\n被显式配置的源文件 JAR 构件文件: my-library-1.0-sources.jar\n被显式配置的 Javadoc JAR 构件文件: my-library-1.0-javadoc.jar\n\nSigning Plugin 插件用来为每个构件生成一个签名文件, 除此之外, 还会为所有的构件文件和签名文件生成校验文件 (checksum files)\nThe PMD PluginPMD Plugin 在项目的 Java 源文件上使用 PMD 执行质量检查并从检查中生成报告\nExample - Using the PMD plugin:\n// build.gradleplugins &#123;    id &#x27;pmd&#x27;&#125;\n\nPMD Plugin 会添加一些 task 到项目中来执行质量检查, 可以通过运行 gradle check 来执行检查\nTaskspmdMain:\n\nPmd 类型\n在 Java 产品代码上运行 PMD\n\npmdTest:\n\nPmd 类型\n在 Java 测试代码上运行 PMD\n\npmd&#123;SourceSet&#125;:\n\nPmd 类型\n在指定 source set 上的 Java 源文件上运行 PMD\n\nPMD Plugin 添加如下依赖到 Java Plugin 定义的 task 中:\nTable - PMD Plugin - additional task dependencies:\n\n\n\nTask name\nDepends on\n\n\n\ncheck\nAll PMD tasks, including pmdMain and pmdTest\n\n\nDependency managementPMD Plugin 添加如下依赖配置:\nTable - PMD Plugin - dependency configurations:\n\n\n\nName\nMeaning\n\n\n\npmd\nThe PMD libraries to use\n\n\npmdAux\nThe additional libraries that are available for type resolution during analysis. This might be useful if PMD complains about missing classes\n\n\nConfiguration// build.gradlepmd &#123;    consoleOutput = true    toolVersion = &quot;6.21.0&quot;    rulesMinimumPriority = 5    ruleSets = [        &quot;category/java/errorprone.xml&quot;,        &quot;category/java/bestpractices.xml&quot;    ]&#125;\n\nPmdExtension\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Sharing Build Logic between Subprojects","url":"/gradle/gradle-sharing-build-logic-between-subprojects/","content":"Sharing Build Logic between SubprojectsConvention Plugins一个子项目的 type 告诉了我们这个项目有什么特性\nGradle 建议使用插件系统来组织构建逻辑\n一个插件应该定义一个子项目的 type, 例如 Java Plugin 配置了一个通用的 Java 项目\nCross project configuration建议使用插件或者给子项目其他特定类型的配置\n从子项目中抽取信息到特定类型\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Structuring and Building a Software Component with Gradle","url":"/gradle/gradle-structuring-and-building-a-software-component-with-gradle/","content":"\n\n\nStructuring and Building a Software Component with Gradle\nCreating a multi-project build\nAdding subprojects\nNaming recommendations\n\n\n\n\n\nStructuring and Building a Software Component with GradleCreating a multi-project buildExample - Basic multi-project build:\n.├── settings.gradle├── app│  ├── src│  │  └── main│  │     └── java│  │        └── com│  │           └── example│  │              └── Hello.java│  └── build.gradle\n\nsettings.gradle:\nrootProject.name = &#x27;basic-multiproject&#x27;include &#x27;app&#x27;\n\napp/build.gradle:\nplugins &#123;    id &#x27;application&#x27;&#125;application &#123;    mainClass = &#x27;com.example.Hello&#x27;&#125;\n\n// Hello.javapackage com.example;public class Hello &#123; public static void main(String[] args) &#123;  System.out.println(&quot;Hello world&quot;); &#125;&#125;\n\n运行结果:\n╭─daisy at thinkpad in ~/Desktop/basic-multiproject╰─○ gradle -q runHello world\n\nAdding subprojects首先在 settings.gradle 文件中使用 include 语句来添加新的子项目:\nrootProject.name = &#x27;basic-multiproject&#x27;include &#x27;app&#x27;include &#x27;lib&#x27;\n\nGradel 将会在子项目 lib/ 的目录中查找 build.gradle 构建文件\nNaming recommendations\n保持子项目的默认名称\n使用 - 来分隔项目名称中的单词; e.g kebab-case-formatting\n在 settings.gradle 文件中声明根项目的名称; 使用 rootProject.name; 如果不声明, 则默认是项目根目录的名称\n\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Testing Build Logic with TestKit","url":"/gradle/gradle-testing-build-logic-with-testkit/","content":"Testing Build Logic with TestKitGradle TestKit 是一个用来测试 Gradle 插件和构建逻辑的类库\nGradle TestKit 专注于功能测试\n通过将构建逻辑作为编程执行的构建的一部分来进行测试\nUsage通过如下步骤在你的插件构建中使用 TestKit\nExample - Declaring the TestKit dependency:\n// build.gradledependencies &#123;  testImplementation gradleTestKit()&#125;\n\ngradleTestKit() 包含了 TestKit 的类和 Gradle Tooling API client. 它没有包含 JUnit, TestNG, 或者其他任何的测试执行框架, 所以这些测试执行框架需要明确声明\nExample - Declaring the JUnit dependency:\n// build.gradledependencies &#123;  testImplementation(&quot;org.junit.jupiter:junit-jupiter:5.7.1&quot;)&#125;tasks.withType(Test).configureEach &#123;  useJUnitPlatform()&#125;\n\nTBC\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Testing in Java & JVM projects","url":"/gradle/gradle-testing-in-java-jvm-projects/","content":"\n\n\nTesting in Java &amp; JVM projects\nThe basics\nTest execution\nTest filtering\nSimple name pattern\nFull-qualified name pattern\n\n\nTest reporting\nCommunicating test results to CI servers and other tools via XML files\nConfiguration options\n\n\noutputPerTestCase\nmergeReruns\n\n\nTest detection\nTest grouping\nUsing JUnit 5\nCompiling and executing JUnit Jupiter tests\nExecuting legacy tests with JUnit Vintage\nFiltering test engine\n\n\nConfiguring integration tests\nSkipping the tests\nForcing tests to run\nDebugging when running tests\n\n\n\n\n\nTesting in Java &amp; JVM projects\n\n\nName\nMeaning\n\n\n\nTest execution\n控制测试怎样执行的方法\n\n\nTest filtering\n怎样选择特定的测试去执行, 如果影响这个过程\n\n\nTest detection\nGradle 怎样找到测试去执行\n\n\nTest grouping\n怎样使用框架的机制来将测试组合在一起\n\n\n一个新的用于建模测试执行阶段的配置 DSL 可以通过孵化中的 JVM Test Suite 插件来使用\nThe basics所有的 JVM 测试都围绕着一种任务类型: Test\nTest 使用任何支持的测试框架执行测试, 例如 JUnit, JUnit Platform, TestNG, 然后整理执行结果\n可以通过使用 TestReport 类型的 task 来将执行结果转换为一个报告\nTest 类型的 task 需要两个信息来开始执行:\n\n在哪里搜索编译好的测试类文件(属性: Test.getTestClassesDirs())\n执行的类路径, 类路径应该包含测试类文件和测试框架库文件(属性: Test.getClasspath())\n\n如果已经使用了 JVM 语言的插件, 例如 Java Plugin, 将会自动获得:\n\n一个专用于单元测试的 test source set\n一个用来运行单元测试的 Test 类型的 test task\n\nJVM 语言插件使用 source set 来配置 task, 使其有正确的执行类路径和包含编译好的类文件的目录, 另外, 还将 test task 关联到 check lifecycle task 上\ntest source set 自动创建了相关的依赖配置, 最常用的是 testImplementation 和 testRuntimeOnly 这两个配置, 插件会将这两个配置上的依赖绑定到 test task 的类路径中\n在大部分情况下, 你需要做的是配置好相关的编译时和运行时依赖, 添加任何必须的配置到 test task 中\nExample - A basic configuration for the ‘test’ task:\n// build.gradledependencies &#123;    testImplementation &#x27;junit:junit:4.13&#x27;&#125;test &#123;    useJUnit()    // 配置测试的 JVM 堆内存最大为 1G    maxHeapSize = &#x27;1G&#x27;&#125;\n\n查看更多的配置选项:\nJUnitOptions\nJUnitPlatformOptions\nTestNGOptions\nTest executionGradle 在 不同的(forked) JVM 中执行测试, 独立于主构建进程\n这样就避免了构建进程的 classpath 污染和内存消耗\n还可以使用不同于构建进程的 JVM 参数来执行测试\n通过多个 Test task 的属性来控制测试进程怎样启动:\n\n\n\nName\nDefault\nMeaning\n\n\n\nmaxParallelForks\n1\n执行测试的最大进程数; 要确保测试是互相隔离的; 使用 org.gradle.test.worker 属性来区别并行测试进程, 这个属性是每个进程唯一的\n\n\nforkEvery\n0(no maximum)\n这个属性执行了 Gradle 应该在一个测试进程中运行的测试类的最大数量, 在这个测试进程被丢弃或创建一个新的之前\n\n\nignoreFailures\nfalse\n是否在有测试失败的时候继续运行构建; 默认情况下, Test task 执行所有关联的测试, 不管这个配置\n\n\nfailFast\nfalse\n如果有一个测试失败就结束整个构建; 用于快速失败; 可以通过命令行参数 --fail-fast 来开启\n\n\ntestLogging\nnot set\n指明什么测试事件和事件级别要进行日志记录; 查看 TestLoggingContainer\n\n\n如果配置不正确, 测试进程会意外地退出\nTest filtering\nFiltering(建议使用此方式)\nTest inclusion&#x2F;exclusion\n\nGradle 的测试过滤基于以下规则:\n\n一个全限定类型名或一个方法全限定名, e.g: org.gradle.SomeTest, org.gradle.SomeTest.someMethod\n一个类的简单名称或一个方法名称, 以大写字母开头, e.g: SomeTest, SomeTest.someMethod\n* 通配符匹配\n\n可以在构建脚本上开启过滤, 或者使用 --tests 命令行参数来进行过滤\nExample - Filtering tests in the build script:\n// build.gradletest &#123;    filter &#123;        // include specific method in any of the tests        // 包含任何类中匹配的测试方法        includeTestsMatching &quot;*UiCheck&quot;        // include all tests from package        // 包含包中所有的测试        includeTestsMatching &quot;org.gradle.internal.*&quot;        // include all integration tests        // 包含匹配名称的类        includeTestsMatching &quot;*IntegTest&quot;    &#125;&#125;\n\n用命令行参数来执行单独一个测试方法是很有用的\n当你使用 --tests 时, 同时在构建脚本中包含声明也是同时生效的\n可以同时提供多个 --tests 选项来进行多个指定\nSimple name pattern从 4.7 版本开始, Gradle 将以大写字母开头的模板(pattern)看作是一个简单的类名, 或者类名加方法名\nExample - 执行 SomeTestClass 测试用例中的所有或执行一个测试, 不考虑这个类在哪个包中:\n# Executes all tests in SomeTestClassgradle test --tests SomeTestClass# Executes a single specified test in SomeTestClassgradle test --tests SomeTestClass.someSpecificMethodgradle test --tests SomeTestClass.*someMethod*\n\nFull-qualified name pattern# specific classgradle test --tests org.gradle.SomeTestClass# specific class and methodgradle test --tests org.gradle.SomeTestClass.someSpecificMethod# method name containing spacesgradle test --tests &quot;org.gradle.SomeTestClass.some method containing spaces&quot;# all classes at specific package(recursively)gradle test --tests &#x27;all.in.specific.package*&#x27;# specific method at specific package(recursively)gradle test --tests &#x27;all.in.specific.package*.someSpecificMethod&#x27;gradle test --tests &#x27;*IntegTest&#x27;gradle test --tests &#x27;*IntegTest*ui*&#x27;gradle test --tests &#x27;*ParameterizedTest.foo*&#x27;# the second iteration of a parametrized testgradle test --tests &#x27;*ParameterizedTest.*[2]&#x27;\n\n通配符 * 不会理会包分隔符 .\n通配符 * 是纯粹基于字符的, --tests *.SomeTestClass 将会匹配任何包, 忽略它的深度(depth)\n你还可以在命令行中将过滤器和 continuous build 相结合, 以便在产品或测试源文件的每次更改之后立即重新执行测试子集\nExample -当一个更改触发时, 执行 com.mypackage.foo 包中或其子包中的所有测试:\ngradle test --continuous --tests &quot;com.mypackage.foo.*&quot;\n\nTest reportingTest task 默认生成如下结果:\n\n一个 HTML 报告\n格式兼容 Ant JUnit report task 的 XML 测试报告, 这个格式可以被很多工具支持, 例如 CI 服务\n一个高效的二进制格式的结果, 被 Test task 用来生成其他格式的 results\n\nExample - Changing the default test report and results directories:\n// build.gradlereporting.baseDir = &quot;my-reports&quot;testResultsDirName = &quot;$buildDir/my-test-results&quot;tasks.register(&#x27;showDirs&#x27;) &#123;    doLast &#123;        logger.quiet(rootDir.toPath().relativize(project.reportsDir.toPath()).toString())        logger.quiet(rootDir.toPath().relativize(project.testResultsDir.toPath()).toString())    &#125;&#125;\n\nTestReport 类型的 task 可以用来生成自定义 HTML 测试报告. 只需要指定一个 destinationDir 和你想要包含在测试报告中的测试结果\nCommunicating test results to CI servers and other tools via XML files默认情况下, 每一个测试类一个测试结果文件, 保存到 $buildDir/test-results/$testTaskName 中\nExample - Changing JUnit XML results location for all test tasks:\n// build.gradletestResultsDirName = &quot;$buildDir/junit-xml&quot;\n\n经过这样的配置, XML 文件将会被写到 $buildDir/junit-xml/$testTaskName 中\nExample - Changing JUnit XML results location for a particular test task:\n// build.gradletest &#123;    reports &#123;        junitXml.outputLocation.set(layout.buildDirectory.dir(&quot;test-junit-xml&quot;))    &#125;&#125;\n\n经过这样的配置, test task 的 XML 文件将会被写到 $buildDir/test-junit-xml 中\nConfiguration optionsXML 文件的内容也可以配置, 用来传输不同的结果\n配置 JUnitXmlReport 选项\nExample - Configuring how the results are conveyed(传输,传递,表达):\n// build.gradletest &#123;    reports &#123;        junitXml &#123;            outputPerTestCase = true // defaults to false            mergeReruns = true // defaults to false        &#125;    &#125;&#125;\n\noutputPerTestCaseoutputPerTestCase 选项, 开启时, 将测试用例期间生成的任何输出日志与结果中的测试用例关联起来\n当关闭时(默认是关闭), 输出是与 整个测试用例 相关联, 而不是与 产生日志输出的单个测试用例 相关联\n大多数观察 JUnit XML 文件的现代工具都支持 “每个测试用例的输出” 的格式\nmergeReruns当 mergeReruns 开启时, 如果一个测试失败了但重试后成功了, 它的失败将会在 &lt;testcase&gt; 中被记录为 &lt;flakyFailure&gt; 而不是 &lt;failure&gt;\n这实际上是 surefire plugin of Apache Maven 在开启重试时提供的报告\n如果你的 CI 服务器可以识别这个格式, 它将会指明测试是脆弱的\n如果 mergeReruns 关闭时, 它将会忽略 &lt;flakyFailure&gt; 信息\n如果测试在重试之后还是失败了, 它将会指明测试失败了, 无论你的工具是否可以失败这个格式\n如果 mergeReruns 关闭了(默认), 每个测试的执行都会作为一个分开的测试用例列出\n开启 mergetReruns 选项不会添加任何重试&#x2F;重跑功能给测试执行\n重跑可以通过测试执行框架来启用, e.g: JUnit’s @RepeatedTest, 或者通过 Test Retry Gradle Plugin\nTest detection默认情况下, Gradle 将会运行它检测到的所有测试, 这是通过检查已编译的测试类来进行的\n这个检测根据不同的测试框架使用不同的条件\n对于 JUnit, Gradle 扫描 JUnit 3&#x2F;4 的测试类. 一个类被认为是一个 JUnit测试, 如果它是:\n\n最终继承自 TestCase 或 GroovyTestCase\n使用了 @Runwith 注解\n包含了使用 @Test 注解修饰的方法, 或者这个类的父类包含了这样的方法\n\n对于 TestNG, Gradle 扫描使用了 @Test 修饰的方法\n抽象类不会被执行\nGradle 会扫描测试 classpath 上 Jar 文件中的继承树. 如果这些 JAR 文件包含了测试类, 这些测试类也会被运行\n可以通过设置 Test 类上的 scanForTestClasses 属性为 false 来关闭测试类的检测. 当这样设置后, test task 只会使用 includes 和 excludes 属性来寻找测试类\n如果 scanForTestClasses 设置为 false 且没有包含和排除的选项指定, Gradle 默认运行任何匹配模式 **/*Tests.class 和 **/*Test.class 的类, 不包括匹配 **/Abstract*.class 的类\n对于 JUnit Platform, 只有 includes 和 excludes 可以用来过滤测试类, scanForTestClasses 没有效果\nTest groupingJUnit, JUnit Platform 和 TestNG 允许对测试方法进行复杂的分组\nJUnit 4.8 引入了 categories 的概念, 用于分组 JUnit 4 测试的类和方法\nTest.useJUnit(org.gradle.api.Action) 允许你指定你想要包含和排除的 JUnit categories\nExample - JUnit Categories - includes tests in CategoryA and excludes tests in CategoryB for the test task:\n// build.gradletest &#123;    useJUnit &#123;        includeCategories &#x27;org.gradle.junit.CategoryA&#x27;        excludeCategories &#x27;org.gradle.junit.CategoryB&#x27;    &#125;&#125;\n\nJUnit Platform 引入了 tagging 来代替 categories, 你可以通过使用 Test.useJUnitPlatform(org.gradle.api.Action) 来引入&#x2F;排除 tags:\nExample - JUnit Platform Tags:\n// build.gradletest &#123;    useJUnitPlatform &#123;        includeTags &#x27;fast&#x27;        excludeTags &#x27;slow&#x27;    &#125;&#125;\n\nTestNG 框架引入了类似的 test groups 的概念, 通过 Test.useTestNG(org.gradle.api.Action) 来为测试执行引入&#x2F;排除 test group:\nExample - Grouping TestNG tests:\n// build.gradletest &#123;    useTestNG &#123;        excludeGroups &#x27;integrationTests&#x27;        includeGroups &#x27;unitTests&#x27;    &#125;&#125;\n\nUsing JUnit 5JUnit 5 &#x3D; JUnit Platform + JUnit Jupiter + JUnit Vintage\nJUnit Platform : 提供一个在 JVM 上启动测试框架的基础\nJUnit Jupiter : The combination of the new programming model and extension model for writing tests and extensions in JUnit 5\nJunit Vintage : 提供一个 TestEngine 来在 JUnit Platform上运行基于 JUnit 3&#x2F;4 的测试\nExample - Enabling JUnit Platform to run your tests:\n// build.gradletest &#123;    useJUnitPlatform()&#125;\n\n查看 Test.useJUnitPlatform() 获取更多细节\nGradle 中的 JUnit 5 的使用还存在一些已知的缺陷\nCompiling and executing JUnit Jupiter tests只需要在依赖中添加 JUnit Jupiter 的依赖, 就可以开启 Gradle 中的 JUnit Jupiter 支持\nExample - JUnit Jupiter dependencies:\n// build.gradledependencies &#123;    testImplementation &#x27;org.junit.jupiter:junit-jupiter:5.7.1&#x27;&#125;\n\n将测试类放置到 src/test/java 中, 使用 gradle test 来执行测试\nExecuting legacy tests with JUnit Vintage在 JUnit Platform 上运行 JUnit 3&#x2F;4, 或者和 JUnit Jupiter 的测试混合在一起, 需要添加额外的 JUnit Vintage Engine 依赖\nExample - JUnit Vintage dependencies:\n// build.gradledependencies &#123;    testImplementation &#x27;org.junit.jupiter:junit-jupiter:5.7.1&#x27;    testCompileOnly &#x27;junit:junit:4.13&#x27;    testRuntimeOnly &#x27;org.junit.vintage:junit-vintage-engine&#x27;&#125;\n\n通过这个方法, 可以直接使用 gradle test 直接在 JUnit Platform 上运行 JUnit 3&#x2F;4 的测试, 而不需要重写它们\nFiltering test engineJUnit Platform 允许你使用不同的测试引擎, JUnit 现在只提供了两个实现了 TestEngine 的测试引擎: junit-jupiter-engine 和 junit-vintage-engine\n默认情况下, 在测试运行时 classpath 上的所有测试引擎都会被使用, 为了明确指定测试引擎, 在构建脚本中这样配置:\nExample - Filter specific engines:\n// build.gradletest &#123;    useJUnitPlatform &#123;        includeEngines &#x27;junit-vintage&#x27;        // excludeEngines &#x27;junit-jupiter&#x27;    &#125;&#125;\n\nConfiguring integration tests项目的一个常见需求是以一种或另一种形式合并集成测试\n集成测试的目的是验证项目的各个部分是否正确地一起工作\n这通常意味着相对于单元测试来说, 它们需要特殊的执行设置和依赖\n添加集成测试到构建中最简单的方法是利用孵化中的 JVM Test Suite Plugin\n如果孵化中的解决方案不是你想要的, 可以通过如下步骤来进行:\n\n为集成测试创建一个新的 source set\n将需要的依赖添加到该 source set 的适当 configurations 中\n为 source set 配置编译时和运行时 classpath\n创建一个 task 来运行集成测试\n\nExample - Setting up working integration tests:\n// build.gradlesourceSets &#123;    intTest &#123;        compileClasspath += sourceSets.main.output        runtimeClasspath += sourceSets.main.output    &#125;&#125;configurations &#123;    intTestImplementation.extendsFrom implementation    intTestRuntimeOnly.extendsFrom runtimeOnly&#125;dependencies &#123;    intTestImplementation &#x27;junit:junit:4.13&#x27;&#125;\n\n这将会配置一个新的称为 intTest 的 source set, 这个 source set 将会自动创建:\n\nintTestImplementation, intTestCompileOnly, intTestRuntimeOnly 配置(还包括其他不常用的配置)\n一个 compileIntTestJava task 来编译所有在 src/intTest/java 中的源文件\n\n这个例子还做了如下操作, 但不是所有的集成测试都需要的:\n\n为集成测试的编译时和运行时 classpath 添加 main source set 中的产品 classes, sourceSets.main.output 是包含已编译产品 classes 和资源的所有目录的文件集合\n让 intTestImplementation 配置继承 implementation 配置, 使得所有产品代码声明的依赖也变成集成测试的依赖\n\n在集成测试中一般需要将产品代码包括到编译时和运行时 classpath\n但有时候并不需要这样做, 例如你的产品代码打包成了可执行的包, 一个 WEB 应用程序, 这时候你的集成测试是通过 HTTP 和产品代码进行交互\n将单元测试的依赖添加到集成测试的依赖也是可选的, 通过 intTestImplementation.extendsFrom testImplementation\n这个例子中还有其他值得注意的地方:\n\n+= 允许你添加路径到 compileClasspath 和 runtimeClasspath 中, 而不是覆盖它们的值\n如果你使用基于约定的配置, 例如 intTestImplementation, 你必须在新的 source set 后面声明依赖\n\n创建和配置一个 source set 自动配置了编译阶段, 但是它在运行集成测试方面没有任何作用. 所以拼图的最后一块就是自定义 test task 来使用新的 source set 中的信息去配置 task 的运行时 classpath 和 测试类:\nExample - Defining a working integration test task:\n// build.gradletasks.register(&#x27;integrationTest&#x27;, Test) &#123;    description = &#x27;Runs integration tests.&#x27;    group = &#x27;verification&#x27;    testClassesDirs = sourceSets.intTest.output.classesDirs    classpath = sourceSets.intTest.runtimeClasspath        // 可以使用 mustRunAfter()    shouldRunAfter test&#125;check.dependsOn integrationTest\n\n编译好的测试类 - testClassesDirs 属性\n运行时需要的在 classpath 的类 - classpath 属性\nSkipping the tests在命令行中使用 -x 或 --exclude-task 选项来跳过测试:\ngradle build -x test\n\n将会排除 test task, 和其他独占地依赖 test task 的 task\n在构建脚本中跳过一个测试有多个方法\n一个普遍的做法是使用 Task.onlyIf(org.gradle.api.specs.Spec) 方法来让测试执行条件化:\nExample - Skipping the unit tests based on a project project:\n// build.gradletest.onlyIf &#123; !project.hasProperty(&#x27;mySkipTest&#x27;) &#125;\n\n在这个例子中, Gradle 将会标记跳过的测试为 SKIPPED, 而不是将它们从构建中排除\nForcing tests to run你可能遭遇这样一种情况, 测试依赖一个第三方服务和一些可能会改变的但又不能在构建中建模的东西\n你可以强制测试在这种情况下运行, 通过清除相关的 Test task 的 output, 然后重新运行它:\ngradle cleanTest test\n\ncleanTest 基于 Base Plugin 提供的 一个 task rule, 你可以将其用于任何 task\nDebugging when running tests通过设置 Test.getDebug() 属性为 true 或者使用 --debug-jvm 命令行参数来开启\n当测试的调试开启之后, Gradle 会将测试进程暂停, 然后监听 5005 端口\n你也可以在 DSL 中开启调试功能, 同时还能配置其他参数:\n// build.gradletest &#123;    debugOptions &#123;        enabled = true        port = 4455        server = true        suspend = true    &#125;&#125;\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"The Directories and Files Gradle Uses","url":"/gradle/gradle-the-directories-and-files-gradle-uses/","content":"\n\n\nThe Directories and Files Gradle Uses\nGradle user home directory\nCleanup of caches and distributions\n\n\nProject root directory\nProject cache cleanup\n\n\n\n\n\n\n\nThe Directories and Files Gradle UsesGradle 使用两个主要的目录来执行和管理它的工作: Gradle user home directory 和 Project root directory\nGradle user home directoryGradle 用户家目录, 默认是 $USER_HOME/.gradle, 是用来保存全局配置属性和初始化脚本和缓存和日志文件的\n$USER_HOME/.gradle/caches : 全局缓存目录(for everything that’s not project-specific)\n$USER_HOME/.gradle/caches/4.7 : 指定版本的缓存(例如用来支持增量式构建)\n$USER_HOME/.gradle/caches/jars-3 : 共享的缓存(for artifacts of dependencies)\n$USER_HOME/.gradle/caches/modules-2 : 共享的缓存(for artifacts of dependencies)\n$USER_HOME/.gradle/daemon : 守护进程的注册表和日志\n$USER_HOME/.gradle/init.d : 全局初始化脚本\n$USER_HOME/.gradle/jdks : toolchain support 下载的 JDK\n$USER_HOME/.gradle/wrapper/dists : Gradle Wrapper 下载的发行版\n$USER_HOME/.gradle/gradle.properties : 全局的 Gradle 配置属性\nCleanup of caches and distributions从 4.10 版本开始, Gradle 自动清理它的用户家目录\n当 Gradle 守护进程停止或关闭时, 清理工作将在后台运行\n如果使用了 --no-daemon, 它在构建会话结束之后在前台运行, 带有一个可视化的进度指示器\n定期应用一下清理策略(至少每 24 小时一次):\n\n检查 caches/&lt;gradle-version&gt;/ 中指定版本的缓存是否还在使用. 如果没有使用, 超过 30 天没使用过的发行版本文件夹就会被删除, 超过 7 天没使用的 SNAPSHOT 版本的文件夹将会被删除\ncaches/(e.g jars-*) 中的共享缓存会被检查是否有使用, 如果没有 Gradle 版本还在使用它们, 它们将会被删除\n检查被当前 Gradle 版本使用的 caches/(e.g jars-3 或者 modules-2) 中共享缓存的文件最后使用的时间. 取决于文件是否可以在本地重新创建或者从一个远程仓库重新下载, 将分别在 7 或 30 天后删除\n检查 wrapper/dists/ 中的 Gradle 发行版是否还在使用\n\nProject root directory$project_root_directory/.gradle : Gradle 生成的特定项目的缓存目录\n$project_root_directory/.gradle/4.8 : 特定版本的缓存(e.g 用来支持增量式构建)\n$project_root_directory/build : 这个项目的构建目录, Gradle 将在其中生成所有的构建 artifacts\n$project_root_directory/gradle/wrapper : 包含 Gradle Wrapper 的 JAR 文件和配置文件\n$project_root_directory/gradle.properties : 特性项目的 Gradle 配置属性\n$project_root_directory/gradlew(.bat) : 使用 Gradle Wrapper 来执行构建的脚本\n$project_root_directory/settings.gradle : 项目的配置文件, 定义一系列子项目的地方\n$project_root_directory/subproject-one : 子项目目录\n$project_root_directory/subproject-one/build.gradle : 每个子项目都有它自己的构建脚本\nProject cache cleanup从 4.10 版本开始, Gradle 自动清理特定项目的缓存目录\n在构建项目之后, 周期性(差不多每 24 小时)检查 .gradle/&lt;gradle-version&gt;/ 中特定版本的缓存目录是否还在使用中. 如果它们超过 7 天没被使用就会被删除\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"The Gradle Wrapper","url":"/gradle/gradle-the-gradle-wrapper/","content":"\n\n\nThe Gradle Wrapper\nAdding the Gradle Wrapper\nUpgrading the Gradle Wrapper\n\n\n\n\n\nThe Gradle WrapperWrapper 是一个脚本, 它调用一个指定版本的 Gradle, 如果需要它会提前下载 Gradle\n好处是不需要手动安装 Gradle 和配置环境, 可以直接通过 Wrapper 脚本来执行构建\n更重要的是让每个参与到项目开发人员都使用同一个版本的 Gradle 来构建这个项目\nAdding the Gradle Wrapper通过 Gradle 内置的 wrapper task 来生成 Wrapper 文件\nwrapper task 将会在项目目录中生成必要的 Wrapper 文件\nExample - Running the Wrapper task:\ngradle wrapper\n\n记得将 Wrapper 文件添加到版本控制系统中, 要添加所有的 Wrapper 文件, 包括 JAR 文件\n生成的 Wrapper 属性文件 gradle/wrapper/gradle-wrapper.properties 保存了关于 Gradle 发行版的信息\n可以通过这些命令行选项来进行配置:\n\n--gradle-version : 用来下载和执行 Wrapper 的 Gradle 版本\n--distribution-type : 用于 Wrapper 的 Gradle 发行版类型, bin 和 all 可选, 默认是 bin\n--gradle-distribution-url : 指向 Gradle 发行版 ZIP 文件的 URL\n--gradle-distribution-sha256-sum : 用来校验下载的 Gradle 发行版的校验码\n\n--distribution-type=all 可以让 IDE 开启代码补全并且可以导航到 Gradle 源代码\nExample - Providing options to Wrapper task:\ngradle wrapper --gradle-version 7.3.3 --distribution-type all\n\nExample - The generated distribution URL:\ndistributionUrl=https\\://services.gradle.org/distributions/gradle-7.3.0-all.zip\n\nWrapper 文件存放在项目根目录的 gradle 目录中, 这个目录中包含了如下文件:\n\ngradle-wrapper.jar : 包含用来下载 Gradle 发行版的代码\ngradle-wrapper.properties : 配置 Wrapper 运行时行为\ngradlew, gradlew.bat : 用来和 Wrapper 一起执行构建的脚本\n\nUpgrading the Gradle Wrapper使用 gradle wrapper --gradle-version 7.3.3 --distribution-type all 来更新到指定的版本\n运行这个 wrapper task 一次只会更新 gradle-wrapper.properties, 不会更新 gradle-wrapper.jar. 要更新这个问题件, 需要在运行一次 wrapper task\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"User Guide 小结","url":"/gradle/gradle-user-guide-conclusion/","content":"User Guide 小结初始化 Gradle 项目使用 init task, 查看 init plugin 获取更多信息\n为项目生成 wrapper 脚本并固化 Gradle 版本内置的 gradle wrapper task 生成一个脚本 gradlew, 这个脚本调用了一个指定版本的 Gradle, 会在使用这个指定版本的 Gradle 之前下载它\ngradle wrapper --gradle-version=4.4\n\n除了 --gradle-version, 还可以指定 --distribution-type=(bin|all), --gradle-distribution-url, --gradle-distribution-sha256-sum\n--distribution-type=all 可以让 IDE 开启代码补全并且可以导航到 Gradle 源代码\n命令行选项 dry run命令行选项 --dry-run\n在停止执行所有 task 的 action 的情况下运行 Gradle\n主要用来显示哪个 task 会执行, 查看 task 的执行顺序\n持续构建 Continuous Build在 task 的 inputs 改变的时候重新运行这个 task\ngradle test --continuous\n\n在各个平台上面都有各种问题, 建议不使用持续构建\n终端命令补全Gradle 提供了 bash 和 zsh 的命令行补全\ngradle-completion\n非 HTTPS 协议的仓库地址使用 --insecure-protocol 选项\n\nfail : 如果有不安全的仓库 URL 就马上中断构建\nallow : 自动为生成的 Gradle 构建脚本中的 Maven 仓库 URL 设置 allowInsecureProtocol 属性为 true\nwarn\nupgrade : 将 URLs 从 http 转换为 https\n\nSourceSet\nA SourceSet represents a logical group of Java source and resources files\n\n一个 SourceSet 代表着一个 Java 源码和资源文件的逻辑集合\nJava Plugin 的 annotationProcessor\nSince implementation details matter for annotation processors, they must be declared separately on the annotation process path\n\n由于实现细节对注释处理程序很重要，所以必须在注释处理路径上分别声明它们\n\nGradle ignores annotation processes on the compile classpath\n\nGradle 忽略了编译类路径上的注释过程\nExample - Declaring annotation processors:\n// build.gradledependenceis &#123;    // The dagger compiler and its transitive dependencies will only be found on annotation processing classpath    annotationProcessor &#x27;com.google.dagger:dagger-compiler:2.8&#x27;    // And we still need the Dagger library on the compile classpath itself    implementation &#x27;com.google.dagger:dagger:2.8&#x27;&#125;\n\nThe Distribution Plugin将额外的文件添加到生成的 distribution 中\ndistributions &#123;    main &#123;        contents &#123;            from &#x27;../README.md&#x27;            // 将上级目录中的文件拷贝到 docs/ 目录中            from(&#x27;../docs&#x27;) &#123;                into &#x27;docs&#x27;            &#125;        &#125;    &#125;&#125;\n\n有个规范的文件夹 src/main/dist 用来放置发行版需要打包的文件\n自定义 java-library\n声明所有的依赖\n在配置文件中配置依赖版本\n限制依赖版本\n\n自定义 gradle init task\n使用自定义 java-library\n生成自定义项目目录结构\n生成 IDEA 项目文件\n\n设置 JVM 版本使用 java extension\njava &#123;    toolchain &#123;        languageVersion = JavaLanguageVersion.of(11)    &#125;&#125;\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Gradle User Guide","url":"/gradle/gradle-user-guide/","content":"\n\n\nGradle User Guide\nExecuting Gradle builds\nAttaching a debugger to your build\nAdding and changing logging\nUnderstanding the build lifecycle\nThe Gradle Daemon\nWhy the Gradle Daemon is important for performance\nRunning Daemon Status\nDisabling the Daemon\nEnabling the Daemon\nStopping an existing Daemon\n\n\nInitialization Scripts\nUsing an init script\nWriting an init script\nConfiguring projects from an init script\n\n\nExternal dependencies for the init script\nInit script plugins\n\n\nExecuting Multi-Project Builds\nIdentifying project structure\nExecuting tasks by name\nExecuting tasks by fully qualified name\nMulti-Project Building and Testing\n\n\nBuild Cache\nEnable the Build Cache\nBuilt-in cacheable tasks\nConfigure the Build Cache\nBuilt-in local build cache\n\n\n\n\nBuild Script Basics\nTask dependencies\nManipulating existing tasks\n通过 API 访问 task\n为已存在的 task 添加行为\n\n\nDefault tasks\nExternal dependencies for the build script\n\n\n\n\n\nGradle User GuideExecuting Gradle builds\n优先使用 gradlew\ngradle projects\ngradle tasks\ngradle help --task &lt;taskName&gt;\ngradle &lt;taskName&gt;\n\nAttaching a debugger to your buildgradle help -Dorg.gradle.debug=true\n端口 5005\nAdding and changing logging--console=verbose\nUnderstanding the build lifecycle\n\n\nMaven phases\nGradle tasks\n\n\n\nclean\nclean; provided by the Base Plugin\n\n\ncompile\nclasses; provided by the Java Plugin and other JVM language plugins\n\n\ntest\ntest; provided by the Java Plugin and other JVM language plugins\n\n\npackage\nassemble; provided by Base Plugin\n\n\nverify\ncheck; provided by Base Plugin\n\n\ninstall\npublishToMavenLocal; provided by the Maven Publish Plugin\n\n\ndeploy\npublish; provided by the Maven Publish Plugin\n\n\nThe Gradle DaemonWhy the Gradle Daemon is important for performance不仅避免了每次构建时启动 JVM 的开销, 还在内存中缓存了项目结构, 文件, 任务等信息\n使用 --profile 来分析 Gradle Daemon 的影响\nGradle Daemon 从 Gradle 3.0 开始默认开启\nRunning Daemon Status使用 --status 命令来查看 Gradle Daemon 的状态\n╭─daisy at thinkpad in ~/IdeaProjects/RF/data-api on master✔╰─± ./gradlew --status   PID STATUS   INFO 14633 IDLE     6.1.1Only Daemons for the current Gradle version are displayed. See https://docs.gradle.org/6.1.1/userguide/gradle_daemon.html#sec:status\n\nDisabling the Daemon使用 --no-daemon 选项来停止启用 Gradle Daemon\n或者在 gradle.properties 文件中添加 org.gradle.daemon=false 配置\n在 CI 构建中可以不启用 Gradle Daemon, 来保证每次构建的独立\nEnabling the Daemon使用 --daemon 选项\nStopping an existing DaemonGradle Daemon 会监控内存使用, 在系统内存可用内存不足时停止自己\n使用 --stop 选项来手动停止 Gradle Daemon\n╭─daisy at thinkpad in ~/IdeaProjects/RF/data-api on master✔╰─± ./gradlew --stopStopping Daemon(s)1 Daemon stopped\n\n这个选项只会停止当前 Gradle 版本的 Daemon 的运行\nInitialization Scripts这些 init script 在构建开始之前执行\nUsing an init script\n在命令行使用 -I 或者 --init-script 选项; 在选项后附加脚本的路径; 可以多次使用选项来添加多个脚本\n在 USER_HOME/.gradle/ 目录中放置一个 init.gradle 文件\n在 USER_HOME/.gradle/init.d 目录中放置 .gradle 结尾的文件\n在 GRADLE_HOME/init.d/ 目录中放置 .gradle 结尾的文件\n\n如果有多个脚本文件需要执行, 根据上面的说明的顺序来执行\n同一文件夹中的脚本文件按照文件名字母顺序来执行\nWriting an init script一个 init script 是一个 Groovy 或者 Kotlin 脚本\n每个 init script 有一个 Gradle 实例关联\n任何 init script 中的属性引用或方法调用都会委托给这个 Gradle 实例\n每个 init script 都实现了 Script 接口\nConfiguring projects from an init script在构建中使用 init script 来配置项目\nExample - init.gradle:\nallprojects &#123;    repositories &#123;        mavenLocal()    &#125;&#125;\n\nExample - build.gradle:\nrepositories &#123;    mavenCentral()&#125;tasks.register(&#x27;showRepos&#x27;) &#123;    doLast &#123;        println &#x27;All repos:&#x27;        println repositories.collect &#123;it.name&#125;    &#125;&#125;\n\nExample - 使用 init script 来运行 showRepos task:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_2╰─○ gradle --init-script init.gradle -q showReposAll repos:[MavenLocal, MavenRepo]\n\nExternal dependencies for the init scriptinit script 也可以声明自己的依赖\n使用 initscript() 方法, 传递一个声明 init script 的 classpath 的 Closure\nExample - Declaring external dependencies for an init script - init.gradle:\nimport org.apache.commons.math.fraction.Fractioninitscript &#123;    repositories &#123;        maven &#123;            url &quot;https://maven.aliyun.com/nexus/content/groups/public/&quot;        &#125;    &#125;    dependencies &#123;        classpath &#x27;org.apache.commons:commons-math:2.0&#x27;    &#125;&#125;println Fraction.ONE_FIFTH.multiply(2)\n\n传递给 initscript() 方法的 Closure 配置了一个 ScriptHandler 实例\n使用了 classpath 配置来为 init script 的 classpath 添加了依赖\ninit script 不能使用项目的依赖\n配置了依赖之后, 就可以在 init script 中使用这些 classpath 中的类\nExample - build.gradle:\ntasks.register(&quot;doNothing&quot;)\n\nExample - 使用 init script 来运行 doNothing task:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_2╰─○ gradle --init-script init.gradle -q doNothing2 / 5\n\nInit script plugins可以在 init script 里面使用插件\nExample - init script:\napply plugin: EnterpriseRepositoryPluginclass EnterpriseRepositoryPlugin implements Plugin&lt;Gradle&gt; &#123;    void apply(Gradle gradle) &#123;        ....    &#125;&#125;\n\nGradle 会实例化 init script 中的插件, 然后调用插件的 Plugin.apply() 方法, 传入 Gradle 实例作为参数\nExecuting Multi-Project BuildsIdentifying project structuregradle projects\nExecuting tasks by namegradle test 会执行当前工作目录下所有的子项目的 test task\nGradle 总是会计算多项目构建中的每个项目与创建所有存在的 task 对象\n然后再根据 task 名称参数和当前工作目录, Gradle 过滤出那些需要被执行的 task\nExecuting tasks by fully qualified nameExample: gradle :services:webservice:build\n将会执行子项目 webservice 中的 build task\n一个 project path 以一个可选的 : 作为开始, 代表着根项目\n在一个 project path 中, 根项目是唯一一个不使用名字来标识的项目\n在 project path 后面是以 : 分隔的项目名序列\nMulti-Project Building and Testing构建所有依赖项目, 但只在修改了的项目上执行代码质量测试和单元测试: build task\n构建所有依赖项目, 同时在所有依赖项目上执行单元测试: buildNeeded task\n不仅测试修改了的项目, 还在依赖于++这个修改了的项目++的项目上执行测试: buildDependents task\n构建并测试所有项目, 在项目根目录执行: build task\nBuild Cache通过重用缓存起来的 task 的 outputs 来节省构建时间\n如果 task 的 inputs 没有改变则认为其 outputs 没有改变, 因此这个 outputs 可以缓存起来并重用\nGradle 不仅可以重用同一个工作空间中上一次的构建结果, 还可以重用本地机器上之前任何时间, 任何地方的构建结果\nEnable the Build Cache构建缓存默认不开启\n使用命令行选项 --build-cache 开启; Gradle 只会在这次的构建中使用构建缓存\n在 gradle.properties 中增加 org.gradle.caching=true 配置; Gradle 会在所有的构建中使用构建缓存, 除非明确指定了 --no-build-cache 参数\n当启用了构建缓存时, Gradle 会将构建 outputs 保存在 Gradle user home\nBuilt-in cacheable tasks\nJava toolchain: JavaCompile, Javadoc\nGroovy toolchain: GroovyCompile, Groovydoc\nScala toolchain: ScalaCompile, PlatformScalaCompile, ScalaDoc\nNative toolchain: CppCompile, CCompile, SwiftCompile\nTesting: Test\nCode quality tasks: Checkstyle, CodeNarc, Pmd\nJaCoco: JacocoMerge, JacocoReport\nOther tasks: AntlrTask, ValidatePlugins, WriteProperties\n\nConfigure the Build Cache在 settings.gradle 配置文件中使用 Settings.buildCache(org.gradle.api.Action) 块来配置构建缓存\nGradle 支持 本地缓存 和 远程缓存\nBuilt-in local build cache内置的本地构建缓存 DirectoryBuildCache 使用一个目录来保存构建缓存\n默认情况下, 这个目录位于 Gradle user home 目录下\nGradle 会定期清理本地缓存目录中最近未使用过的缓存\n通过 DirectoryBuildCache 中的配置选项来进行缓存配置\nExample - 配置本地缓存 - settings.gradle:\nbuildCache &#123;    local &#123;        directory = new File(rootDir, &#x27;build-cache&#x27;)        removeUnusedEntriesAfterDays = 30    &#125;&#125;\n\nBuild Script Basics自定义的 task 使用 tasks.register() 方法来进行声明:\ntasks.register(&#x27;hello&#x27;) &#123;    doLast &#123;        println &#x27;Hello world!&#x27;    &#125;&#125;\n\nTask dependenciesExample - build.gradle:\ntasks.register(&#x27;hello&#x27;) &#123;    doLast &#123;        println &quot;[task hello]&quot;    &#125;&#125;tasks.register(&#x27;intro&#x27;) &#123;    dependsOn tasks.hello    doLast &#123;        println &quot;[task intro]&quot;    &#125;&#125;tasks.register(&#x27;taskX&#x27;) &#123;    dependsOn &#x27;taskY&#x27;       // Lazy dependsOn, the other task does not exist(yet)    doLast &#123;        println &#x27;taskX&#x27;    &#125;&#125;tasks.register(&#x27;taskY&#x27;) &#123;    doLast &#123;        println &#x27;taskY&#x27;    &#125;&#125;\n\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q taskXtaskYtaskX╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q intro[task hello][task intro]\n\nManipulating existing tasks通过 API 访问 taskExmaple - 通过 API 访问 task 来添加依赖:\n4.times &#123;    tasks.register(&quot;task$it&quot;) &#123;        doLast &#123;            println &quot;I&#x27;m task number $it&quot;        &#125;    &#125;&#125;tasks.named(&#x27;task0&#x27;) &#123; dependsOn(&#x27;task2&#x27;, &#x27;task3&#x27;) &#125;\n\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q task0I&#x27;m task number task &#x27;:task2&#x27;I&#x27;m task number task &#x27;:task3&#x27;I&#x27;m task number task &#x27;:task0&#x27;\n\n为已存在的 task 添加行为可以多次调用 doFirst 或 doLast 方法来为 task 添加动作\nDefault tasks可以定义一个或多个 default tasks\ndefault tasks 在没有指定要运行的 task 时被运行\nExample - build.gradle:\ndefaultTasks &#x27;clean&#x27;, &#x27;run&#x27;tasks.register(&#x27;clean&#x27;) &#123;    doLast &#123;        println &#x27;Default Cleaning!&#x27;    &#125;&#125;tasks.register(&#x27;run&#x27;) &#123;    doLast &#123;        println &#x27;Default Running!&#x27;    &#125;&#125;tasks.register(&#x27;other&#x27;) &#123;    doLast &#123;        println &quot;I&#x27;m not a default task!&quot;    &#125;&#125;\n\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q      Default Cleaning!Default Running!\n\nExternal dependencies for the build script如果你的构建脚本需要使用外部类库, 你可以在构建脚本中将它们添加到脚本的 classpath 中\n使用 buildscript() 方法, 传入一个声明了构建脚本 classpath 的代码块\nExample - build.gradle:\nimport org.apache.commons.codec.binary.Base64buildscript &#123;    repositories &#123;        maven &#123;            url &quot;https://maven.aliyun.com/nexus/content/groups/public/&quot;        &#125;    &#125;    dependencies &#123;        classpath group: &#x27;commons-codec&#x27;, name: &#x27;commons-codec&#x27;, version: &#x27;1.2&#x27;    &#125;&#125;tasks.register(&#x27;encode&#x27;) &#123;    doLast &#123;        def byte[] encodedString = new Base64().encode(&#x27;hello world\\n&#x27;.getBytes())        println new String(encodedString)    &#125;&#125;\n\n传递给 buildscript() 方法的代码块配置了一个 ScriptHandler 实例\n在代码块中使用配置 dependencies 来添加依赖\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q encodeaGVsbG8gd29ybGQK\n\n对于多项目构建, 在一个项目的 buildscript() 方法中定义的依赖可用于所有子项目的构建脚本中\n每个项目自动集成一个 BuildEnvironmentReportTask 类型的 buildEnvironment task 报告构建脚本的依赖处理:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q buildEnvironment------------------------------------------------------------Root project &#x27;Gradle_test_3&#x27;------------------------------------------------------------classpath\\--- commons-codec:commons-codec:1.2A web-based, searchable dependency report is available by adding the --scan option.\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Using Gradle Plugins","url":"/gradle/gradle-using-gradle-plugins/","content":"\n\n\nUsing Gradle Plugins\nTypes of plugins\nUsing plugins\nBinary plugins\nLocations of binary plugins\nApplying plugins with the plugins DSL\nLimitations of the plugins DSL\n\n\nConstrained Syntax\nCan only be used in build scripts and settings file\nApplying external plugins with same version to subprojects\nApplying plugins from the buildSrc directory\nPlugin Management\n\n\nCustom Plugin Repositories\nPlugin Version Management\nPlugin Resolution Rules\n\n\nPlugin Marker Artifacts\nLegacy Plugin Application\nApplying plugins with the buildscript block\n\n\nScript plugins\n\n\n\n\n\nUsing Gradle PluginsGradle 核心提供了很少的自动化功能\n所有有用的特性都是由插件提供, 例如编译 Java 代码\n插件添加了新的 task(e.g JavaCompile), 领域对象(e.g SourceSet), 约定(e.g src/main/java) 和这个插件从其它插件集成的\nTypes of plugins\nbinary plugins\nscript plugins\n\nUsing plugins\nresolve 插件\napply 插件到 target 上, 通常是一个 Project\n\nresolve 一个插件意味着查找包含指定的插件的正确版本的 JAR 文件, 然后将其添加到脚本的 classpath\n一旦一个插件被 resolve 了, 它的 API 可以在构建脚本中使用\nscript plugin 是 self-resolving 的, 它们可以使用指定的文件路径或者 URL 来提供\nbinary plugin 作为 Gradle 发行版的一部分自动 resolve 了\napply 一个插件实际上是在你想要增强的项目上执行插件的 Plugin.apply(T) 方法\napply 插件是幂等的. 意味着你可以对一个插件执行多次 Plugin.apply(T) 方法\n使用插件最通常的做法是同时 resolve 和 apply 插件到当前项目中\n由于这是一个常用用法, 所以推荐构建作者使用 plugins DSL 在一个步骤中同时 resolve 和 apply 插件\nBinary plugins使用插件的全局唯一标识符 id 来 apply 插件, 或者使用插件的名字\nGradle 核心插件使用短名称来进行 apply, 例如 java 来代表核心 JavaPlugin\n其他所有插件必须使用全限定形式 id, 例如 com.github.foo.bar, 但是有一些遗留的插件仍然在使用短的, 非全限定形式的 id\n你在放置插件 id 取决于你是使用 plugins DSL 还是 buildscript block\nLocations of binary plugins插件就是任何实现了 Plugin 接口的类\nGradle 将核心插件作为发行版的一部分, 意味着核心插件已经自动 resolve 了\n非核心插件需要在 apply 之前进行 resolve, 通过如下方法:\n\n使用 plugins DSL 从插件入口或者自定义仓库中包含常见\n从一个外部 JAR 文件包含插件, 声明为 buildscript 的依赖\n在项目的 buildSrc 目录下定义插件源文件\n在构建脚本中声明插件类\n\nApplying plugins with the plugins DSLplugins DSL 和 Gradle plugin portal 一起提供了访问核心插件, 社区插件的简便方法\nplugins DSL 块配置了一个 PluginDependenciesSpec 实例\nExample - Applying a core plugin - 使用简短名称来使用核心插件:\nplugins &#123;    id &#x27;java&#x27;&#125;\n\nExample - Applying a community plugin - 使用全限定名称来使用社区插件:\nplugins &#123;    id &#x27;com.jfrog.bintray&#x27; version &#x27;1.8.5&#x27;&#125;\n\nLimitations of the plugins DSLplugins DSL 允许 Gradle :\n\n优化插件类的加载和重用\n允许不同插件使用功能不同版本的依赖\n\nConstrained Syntaxplugins &#123;    id &lt;&lt;plugin id&gt;&gt;                                                // 1    id &lt;&lt;plugin id&gt;&gt; version &lt;&lt;plugin version&gt;&gt; [apply &lt;&lt;false&gt;&gt;]   // 2&#125;\n\n1 : 用于 Gradle 核心插件或者在 build script 中可用的插件\n2 : for binary Gradle plugins that need to be resolved\n&lt;&lt;plugin id&gt;&gt; 和 &lt;&lt;plugin version&gt;&gt; 必须是常量字面量字符串\napply 语句可以用来禁用立即应用插件的默认行为\n除此之外, 没有其他语句可使用\nplugins &#123;&#125; 块必须是构建脚本中的顶层语句; 不能嵌套在其他构造中, 例如一个 if 语句中\nCan only be used in build scripts and settings fileplugins &#123;&#125; 块现在只能用在项目的构建脚本和 settings.gradle 中\nplugins &#123;&#125; 不能用在 script plugins 或者 init script 中; 将来的 Gradle 会移除这个限制\nApplying external plugins with same version to subprojects只在子项目中 apply 插件, 不在根项目中 apply 插件\nplugins &#123;&#125; 块的默认行为是立即 resolve 和 apply 插件\n使用 apply false 语法来告诉 Gradle 不要 apply 插件到当前项目, 然后在子项目的构建脚本中不带版本信息的方式来使用 plugins &#123;&#125; 块\nExample - Applying plugins only on certain subprojects:\n// settings.gradleinclude &#x27;hello-a&#x27;include &#x27;hello-b&#x27;include &#x27;goodbye-c&#x27;\n\n// build.gradleplugins &#123;    id &#x27;com.example.hello&#x27; version &#x27;1.0.0&#x27; apply false    id &#x27;com.example.goodbye&#x27; version &#x27;1.0.0&#x27; apply false&#125;\n\n// hello-a/build.gradleplugins &#123;    id &#x27;com.example.hello&#x27;&#125;\n\n// hello-b/build.gradleplugins &#123;    id &#x27;com.example.hello&#x27;&#125;\n\n// goodbye-c/build.gradleplugins &#123;    id &#x27;com.example.goodbye&#x27;&#125;\n\nApplying plugins from the buildSrc directory你可以 apply 一个在 buildSrc 目录中拥有定义好 id 的插件\nExample - Defining a buildSrc plugin with an ID:\n// buildSrc/build.gradleplugins &#123;    id &#x27;java-gradle-plugin&#x27;&#125;gradlePlugin &#123;    plugins &#123;        myPlugins &#123;            id = &#x27;my-plugin&#x27;            implementationClass = &#x27;my.MyPlugin&#x27;        &#125;    &#125;&#125;\n\nExample - Applying a plugin from buildSrc:\n// build.gradleplugins &#123;    id &#x27;my-plugin&#x27;&#125;\n\nPlugin ManagementpluginManagement &#123;&#125; 块只能使用在 setting.gradle 文件和 init script 中, 而且必须是文件的第一个块\nExample - Configuring pluginManagement per-project and globally:\n// settings.gradlepluginManagement &#123;    plugins &#123;&#125;    resolutionStrategy &#123;&#125;    repositories &#123;&#125;&#125;rootProject.name = &#x27;plugin-management&#x27;\n\n// init.gradlesettingsEvaluated &#123; settings -&gt;    settings.pluginManagement &#123;        plugins &#123;&#125;        resolutionStrategy &#123;&#125;        repositories &#123;&#125;    &#125;&#125;\n\nCustom Plugin Repositories默认情况下, plugins &#123;&#125; 从 Gradle Plugin Portal 获取插件\n在 pluginManagement &#123;&#125; 块中使用 repositories &#123;&#125; 来指定自定义的插件仓库\nExample - Using plugins from custom plugin repositories:\n// settings.gradlepluginManagement &#123;    repositories &#123;        maven &#123;            url &#x27;./maven-repo&#x27;        &#125;        gradlePluginPortal()        ivy &#123;            url &#x27;./ivy-repo&#x27;        &#125;    &#125;&#125;\n\nPlugin Version ManagementpluginManagement &#123;&#125; 中的 plugins &#123;&#125; 允许在一个地方为构建定义所有插件的版本; 然后插件可以在构建脚本的 plugins &#123;&#125; 中通过 id 来使用\npluginManagement.plugins &#123;&#125; 中管理插件版本的一个好处是没有构建脚本中 plugins &#123;&#125; 的语法限制\npluginManagement.plugins &#123;&#125; 可以从 gradle.properties 中获取版本值, 或者使用其他机制加载\nExample - Managing plugin versions via pluginManagement:\n// settings.gradlepluginManagement &#123;    plugins &#123;        id &#x27;com.example.hello&#x27; version &quot;$&#123;helloPluginVersion&#125;&quot;    &#125;&#125;\n\n// gradle.propertieshelloPluginVersion = 1.0.0\n\nPlugin Resolution Rules插件解析规则允许你修改 plugins &#123;&#125; 中的插件请求\n例如, 修改请求的版本\n在 pluginManagement &#123;&#125; 中使用 resolutionStrategy &#123;&#125; 来添加解析规则:\nExample - Plugin resolution strategy:\n// settings.gradlepluginManagement &#123;    resolutionStrategy &#123;        eachPlugin &#123;            if (requested.id.namespace == &#x27;com.example&#x27;) &#123;                useModule(&#x27;com.example:sample-plugins:1.0.0&#x27;)            &#125;        &#125;    &#125;    repositories &#123;        maven &#123;            url &#x27;./maven-repo&#x27;        &#125;        gradlePluginPortal()        ivy &#123;            url &#x27;/ivy-repo&#x27;        &#125;    &#125;&#125;\n\nPlugin Marker Artifacts下面的例子展示了发布一个 com.example.hello 插件和 com.example.goodbye 插件到 Ivy 和 Maven 仓库, 联合使用了 java-gradle-plugin, maven-publish, ivy-publish 插件\nExample - Complete Plugin Publishing Sample:\n// build.gradleplugins &#123;    id &#x27;java-gradle-plugin&#x27;    id &#x27;maven-publish&#x27;    id &#x27;ivy-publish&#x27;&#125;group &#x27;com.example&#x27;version &#x27;1.0.0&#x27;gradlePlugin &#123;    plugins &#123;        hello &#123;            id = &#x27;com.example.hello&#x27;            implementationClass = &#x27;com.example.hello.HelloPlugin&#x27;        &#125;        goodbye &#123;            id = &#x27;com.example.goodbye&#x27;            implementationClass = &#x27;com.example.goodbye.GoodbyePlugin&#x27;        &#125;    &#125;&#125;publishing &#123;    repositories &#123;        maven &#123;            url &#x27;../../consuming/maven-repo&#x27;        &#125;        ivy &#123;            url &#x27;../../consuming/ivy-repo&#x27;        &#125;    &#125;&#125;\n\n运行: gradle publish\nLegacy Plugin ApplicationExample - Applying a binary plugin:\n// build.gradleapply plugin: &#x27;java&#x27;\n\nExample - Applying a binary plugin by type:\n// build.gradleapply plugin: JavaPlugin\n\nApplying plugins with the buildscript block添加插件到构建脚本 classpath, 然后 apply 这个插件\n使用 buildscript &#123;&#125; 将外部 JAR 添加到构建脚本 classpath\nExample - Applying a plugin with the buildscript block:\n// build.gradlebuildscript &#123;    repositories &#123;        gradlePluginPortal()    &#125;    dependencies &#123;        classpath &#x27;com.jfrog.bintray.gradle:gradle-bintray-plugin:1.8.5&#x27;    &#125;&#125;\n\nScript pluginsExample - Applying a script plugin:\napply from: &#x27;other.gradle&#x27;\n\n可以从本地文件系统或者一个远程目录中获取\n本地文件目录关联项目目录\n远程脚本使用 HTTP URL 定义\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Working With Files","url":"/gradle/gradle-working-with-files/","content":"\n\n\nWorking With Files\nCopying a single file\nCopying multiple files\nCopying directory hierarchies\nCreating archives (zip, tar, etc)\nCreating “uber” or “fat” JARS\nCreating directories\nMoving files and directories\nRenaming files on copy\nDeleting files and directories\nFile paths in depth\nSingle files and directories\n\n\nFile collections\nFile trees\nUsing archives as file trees\nFile copying in depth\nFiltering files\nRenaming files\nFiltering file content(token substitution, templating, etc.)\nUsing the CopySpec class\nSharing copy specs\n\n\nMirroring directories and file collections with the Sync task\nDeploying single files into application servers\nInstalling executables\n\n\nArchive creation in depth\nArchving naming\nSharing content between multiple archives\nReproducible builds\n\n\n\n\n\n\n\nWorking With FilesAPI 有两个部分:\n\n指定哪个文件或目录去处理\n指定怎样处理文件或目录\n\nCopying a single file创建一个 Gradle 内建的 Copy task 的实例, 为其配置目标文件位置和输出位置, 来进行文件复制\nExample:\ntasks.register(&#x27;copyReport&#x27;, Copy) &#123;    from layout.buildDirectory.dir(&quot;reports/my-report.pdf&quot;)    into layout.buildDirectory.dir(&quot;toArchive&quot;)&#125;\n\nExample - Using implicit string paths:\ntasks.register(&#x27;copyReport2&#x27;, Copy) &#123;    from &quot;$buildDir/reports/my-report.pdf&quot;    into &quot;$buildDir/toArchive&quot;&#125;\n\nExample - Prefer task&#x2F;project properties over hard-coded paths:\ntasks.register(&#x27;copyReport3&#x27;, Copy) &#123;    from myReportTask.outputFile    into archiveReportsTask.dirToArchive&#125;\n\nCopying multiple filesExample - Using multiple arguments with from():\ntasks.register(&#x27;copyReportsForArchiving&#x27;, Copy) &#123;    from layout.buildDirectory.file(&quot;reports/my-report.pdf&quot;), layout.projectDirectory.file(&quot;src/docs/manual.pdf&quot;)    into layout.buildDirectory.dir(&quot;toArchive&quot;)&#125;\n\nExample - Using a flat filter:\ntasks.register(&#x27;copyPdfReportsForArchiving&#x27;, Copy) &#123;    from layout.buildDirectory.dir(&quot;reports&quot;)    include &quot;*.pdf&quot;     // 只包含 pdf 文件    into layout.buildDirectory.dir(&quot;toArchive&quot;)&#125;\n\nExample - Using a deep filter:\ntasks.register(&#x27;copyAllPdfReportsForArchiving&#x27;, Copy) &#123;    from layout.buildDirectory.dir(&quot;reports&quot;)    include &quot;**/*.pdf&quot;      // 将 reports/ 目录及其子目录的 pdf 进行移动    into layout.buildDirectory.dir(&quot;toArchive&quot;)&#125;\n\nCopying directory hierarchiesExample - Copying an entire directory, including all its subdirectories:\ntasks.register(&#x27;copyReportsDirForArchiving&#x27;, Copy) &#123;    from layout.buildDirectory.dir(&quot;reports&quot;)    into layout.buildDirectory.dir(&quot;toArchive&quot;)&#125;\n\nExample - Copying an entire directory, including itself:\ntasks.register(&#x27;copyReportsDirForArchiving2&#x27;, Copy) &#123;    from(layout.buildDirectory) &#123;        include &quot;reports/**&quot;    &#125;    into layout.buildDirectory.dir(&quot;toArchive&quot;)&#125;\n\nCreating archives (zip, tar, etc)Example - Archiving a directory as a ZIP:\ntasks.register(&#x27;packageDistribution&#x27;, Zip) &#123;    archiveFileName = &quot;my-distribution.zip&quot;    destinationDirectory = layout.buildDirectory.dir(&quot;dist&quot;)    from layout.buildDirectory.dir(&quot;toArchive&quot;)&#125;\n\nCreating “uber” or “fat” JARS使用 Project.zipTree(java.lang.Object) 方法和 Jar task\nExample - Creating a Java uber or fat JAR:\nplugins &#123;    id &#x27;java&#x27;&#125;version = &#x27;1.0.0&#x27;repositories &#123;    mavenCentral()&#125;dependencies &#123;    implementation &#x27;commons-io:commons-io:2.6&#x27;&#125;tasks.register(&#x27;uberJar&#x27;, Jar) &#123;    archiveClassifier = &#x27;uber&#x27;    from sourceSets.main.output    dependsOn configurations.runtimeClasspath    from &#123;        configurations.runtimeClasspath.findAll &#123;             it.name.endsWith(&#x27;jar&#x27;).collect &#123; zipTree(it) &#125;        &#125;    &#125;&#125;\n\nCreating directories在构建脚本或自定义 task 中使用 Project.mkdir(java.lang.Object) 方法来创建目录\nExample - Manually creating a directory:\ntasks.register(&#x27;ensureDirectory&#x27;) &#123;    doLast &#123;        mkdir &#x27;images&#x27;    &#125;&#125;\n\nMoving files and directoriesExample - Moving a directory using the Ant task:\ntasks.register(&#x27;moveReports&#x27;) &#123;    doLast &#123;        ant.move file: &quot;$&#123;buildDir&#125;/reports&quot;, todir: &quot;$&#123;buildDir&#125;/toArchive&quot;    &#125;&#125;\n\n建议使用 copy 代替 move\nRenaming files on copy使用 rename() 方法\nExample - Renaming files as they are copied:\ntasks.register(&#x27;copyFromStaging&#x27;, Copy) &#123;    from &quot;src/main/webapp&quot;    into layout.buildDirectory.dir(&#x27;explodedWar&#x27;)    rename &#x27;(.+)-staging(.+)&#x27;, &#x27;$1$2&#x27;&#125;\n\n上面的例子中使用了正则表达式\nExample - Truncating filenames as they are copied:\ntasks.register(&#x27;copyWithTruncate&#x27;, Copy) &#123;    from layout.buildDirectory.dir(&quot;reports&quot;)    rename &#123; String filename -&gt;        if (filename.size() &gt; 10) &#123;            return filename[0..7] + &quot;~&quot; + filename.size()        &#125;        else return filename    &#125;    into layout.buildDirectory.dir(&quot;toArchive&quot;)&#125;\n\nDeleting files and directories使用 Delete task 或者 Project.delete(org.gradle.api.Action) 方法来删除\n可以通过 Project.files(java.lang.Object...) 方法来指定要删除的文件或者文件夹\nExample - Deleting a directory:\ntasks.register(&#x27;myClean&#x27;, Delete) &#123;    delete buildDir&#125;\n\n使用 FileCollection 或 FileTree 机制来过滤要删除的文件\nExample - Deleting files matching a specific pattern:\ntasks.register(&#x27;cleanTempFiles&#x27;, Delete) &#123;    delete fileTree(&quot;src&quot;).matching &#123;        include &quot;**/*.tmp&quot;    &#125;&#125;\n\nFile paths in depthSingle files and directoriesGradle 提供了 Project.file(java.lang.Object) 方法来指定一个文件或目录的路径\n这个方法使用的相对路径是相对于项目路径的\n不要使用 new File(relative path) 来创建文件, 这个方法创建的路径是相对于当前工作路径的\nExample - Locating files:\n// Using a relative path; 相对于项目路径File configFile = file(&#x27;src/config.xml&#x27;)// Using an absolute pathconfigFile = file(configFile.absolutePath)// Using a File object with a relative pathconfigFile = file(new File(&#x27;src/config.xml&#x27;))// Using a java.nio.Path object with a relative pathconfigFile = file(Paths.get(&#x27;src&#x27;, &#x27;config.xml&#x27;))// Using an absolute java.nio.file.Path objectconfigFile = file(Paths.get(System.getProperty(&#x27;user.home&#x27;)).resolve(&#x27;global-config.xml&#x27;))\n\n在多项目构建中, file() 方法会使用当前项目的路径, 所以可能会是一个子项目的路径\n如果要相对于根项目的路径, 使用 Project.getRootDir() 属性来构建一个绝对路径\nExample - Creating a path relative to a parent project:\nFile configFile = file(&quot;$rootDir/shared/config.xml&quot;)\n\nFile collections一个 file collection 仅仅是一个文件路径的集合, 代表着 FileCollection 接口\nfile collection 是任何文件路径\n文件路径不是必须为关联的, 所以它们不需要是在同一个文件夹或者不是共享同一个父目录\n使用 ProjectLayout.files(java.lang.Object...) 方法来指定文件的集合, 该方法返回一个 FileCollection 实例\n这个方法甚至可以接受一个定义了 outputs 的 task 作为入参\nExample - Creating a file collection:\nFileCollection collection = layout.files(&#x27;src/file1.txt&#x27;,                                            new File(&#x27;src/file2.txt&#x27;),                                            [&#x27;src/file3.csv&#x27;, &#x27;src/file4.csv&#x27;],                                            Paths.get(&#x27;src&#x27;, &#x27;file5.txt&#x27;))\n\nfile collection 有这些总要的属性:\n\ncreated lazily : 延迟创建\niterated over : 可遍历\nfiltered : 可过滤\ncombined : 可组合\n\nExample - created lazily - Implementing a file collection:\ntasks.register(&#x27;list&#x27;) &#123;    doLast &#123;        File srcDir        // Create a file collection using a closure        // 这里的 srcDir 还未初始化, 但 files() 是 created lazily 的        collection = layout.files &#123; srcDir.listFiles() &#125;        srcDir = file(&#x27;src&#x27;)        println &quot;Contents of $srcDir.name&quot;        collection.collect &#123; relativePath(it).sort().each &#123;println it&#125; &#125;        srcDir = file(&#x27;src2&#x27;)        println &quot;Contents of $srcDir.name&quot;        collection.collect &#123; relativePath(it).sort().each &#123;println it&#125; &#125;    &#125;&#125;\n\ncreated lazily 的关键是传一个 closure 给 files() 方法, 这个 closure 需要返回一个可被 files() 方法接受的类型的值\nExample - Using a file collection:\n// Iterate over the files in the collectioncollection.each &#123; File file -&gt;    println file.name&#125;// Convert the collection to various typesSet set = collection.filesSet set2 = collection as SetList list = collection as ListString path = collection.asPathFile file = collection.singleFile// Add and subtract collectionsdef union = collection + layout.files(&#x27;src/file2.txt&#x27;)def difference = collection - layout.files(&#x27;src/file2.txt&#x27;)\n\nExample - Filtering a file collection:\nFileCollection textFiles = collection.filter &#123; File f -&gt; f.name.endsWith(&quot;.txt&quot;) &#125;\n\nFile trees一个 file collection 是一个扁平的文件集合\n一个 file tree 是一个文件和目录的层级结构\n使用 FileTree.getFiles() 方法将一个 file tree 转换为一个扁平的文件集合\n传递一个文件或目录给 Project.fileTree(java.lang.Object) 方法来创建一个 file tree\n这个方法将会使用这个基础目录的所有文件和目录来创建一个树, 但是不包括这个基础目录本身\nExample - Creating a file tree:\n// Create a file tree with a base directoryConfigurableFileTree tree = fileTree(dir: &#x27;src/main&#x27;)// Add include and exclude patterns to the treetree.include &#x27;**/*.java&#x27;tree.exclude &#x27;**/Abstract*&#x27;// Create a tree using closuretree = fileTree(&#x27;src&#x27;) &#123;    include &#x27;**/*.java&#x27;&#125;// Create a tree using a maptree = fileTree(dir: &#x27;src&#x27;, include: &#x27;**/*.java&#x27;)tree = fileTree(dir: &#x27;src&#x27;, includes: [&#x27;**/*.java&#x27;, &#x27;**/*.xml&#x27;])tree = fileTree(dir: &#x27;src&#x27;, include: &#x27;**/*.java&#x27;, exclude: &#x27;**/*test*/**&#x27;)\n\nExample - Changing default excludes in the settings script:\n// settings.gradleimport org.apache.tools.ant.DirectoryScannerDirectoryScanner.removeDefaultExclude(&#x27;**/.git&#x27;)DirectoryScanner.removeDefaultExclude(&#x27;**/.git/**&#x27;)\n\nExample - Using a file tree:\n// Iterate over the contents of a treetree.each &#123; File file -&gt;    println file&#125;// Filter a treeFileTree filtered = tree.matching &#123;    include &#x27;org/gradle/api/**&#x27;&#125;// Add trees togetherFileTree sum = tree + fileTree(dir: &#x27;src/test&#x27;)// Visit the elements of the treetree.visit &#123;    println &quot;$it.relativePath =&gt; $it.file&quot;&#125;\n\n许多 Gradle 插件提供了它们自己的 file tree 实例, 例如 Java 插件的 source sets\nUsing archives as file trees一个 archive 是将目录和文件层级结构打包到一起的文件\n换句话说, archive 是一个特殊的 file tree, Gradle 就是将 archive 当做 file tree 来看待的\nfileTree() 方法工作在普通文件系统上, 所以使用 Project.zipTree(java.lang.Object) 和 Project.tarTree(java.lang.Object) 方法来封装 archive 文件\n注: JAR, WAR 和 EAR 文件都是 ZIP 文件\nzipTree() 和 tarTree() 方法都会返回 FileTree 实例\n你可是使用这个实例来复制 archive 中的文件到文件系统中的某些目录中\n或者将一个 archive 和另一个 archive 合并到一起\nExample - Using an archive as a file tree:\n// Create a ZIP file tree using pathFileTree zip = zipTree(&#x27;someFile.zip&#x27;)// Create a TAR file tree using pathFileTree tar = tarTree(&#x27;someFile.tar&#x27;)// tar tree attempts to guess the compression based on the file extension// however if you must specify the compression explicitly you can:FileTree someTar = tarTree(resources.gzip(&#x27;someTar.ext&#x27;))\n\nFile copying in depthGradle 中复制文件步骤\n\n定义一个类型为 Copy 的 task\n指定要复制的文件或目录\n指定被复制的文件的目的地\n\nCopy task 实现了 CopySpec 接口, 这个接口提供了如下方法:\n\n一个 CopySpec.from(java.lang.Object...) 方法用来定义要复制什么\n一个 CopySpec.into(java.lang.Object) 方法用来定义目的地\n\n这两个方法是唯一不可选的\nfrom() 方法支持如下类型:\n\n一个 String 字符串\n一个 File\n一个 FileCollection 或 FileTree\n一个定义了 outputs 的 task\n\nfrom() 方法接受的文件路径可以是:\n\n一个文件\n一个目录; 这个目录被当做是文件树来处理, 这个目录中所有的东西都会被包含, 包括子目录; 但是这个目录本身不会被包含在复制当中\n一个不存在的文件; 这个路径将会被忽略\n\nExample - Specifying copy task source files and destination directory:\ntasks.register(&#x27;anotherCopyTask&#x27;, Copy) &#123;    // Copy everything under src/main/webapp    from &#x27;src/main/webapp&#x27;    // Copy a single file    from &#x27;src/staging/index.html&#x27;    // Copy the output of a task    from copyTask    // Copy the output of a task using Task outputs explicitly    from copyTaskWithPatterns.outputs    // Copy the contents of a Zip file    from zipTree(&#x27;src/main/assets.zip&#x27;)    // Determine the destination directory later    into &#123; getDestDir() &#125;&#125;\n\nFiltering files使用 CopySpec.include(java.lang.String...) 和 CopySpec.exclude(java.lang.String...) 方法\nExample - Selecting the files to copy:\ntasks.register(&#x27;copyTaskWithPatterns&#x27;, Copy) &#123;    from &#x27;src/main/webapp&#x27;    into layout.buildDirectory.dir(&quot;explodedWar&quot;)    include &#x27;**/*.html&#x27;    include &#x27;**/*.jsp&#x27;    exclude &#123; FileTreeElement details -&gt;        details.file.name.endsWith(&#x27;.html&#x27;) &amp;&amp; details.file.text.contains(&#x27;DRAFT&#x27;)    &#125;&#125;\n\n排除的部分和引入的部分重叠的话, 排除的规则胜出\nRenaming files使用两种方式来重命名:\n\n使用一个正则表达式\n使用一个 closure\n\nExample - Renaming files as they are copied:\ntasks.register(&#x27;rename&#x27;, Copy) &#123;    from &#x27;src/main/webapp&#x27;    into layout.buildDirectory.dir(&quot;explodedWar&quot;)    // Use a closure to convert all file names to upper case    rename &#123; String fileName -&gt;        fileName.toUpperCase()    &#125;    // Use a regular expression to map the file name    rename &#x27;(.+)-staging-(.+)&#x27;, &#x27;$1$2&#x27;    rename(/(.+)-staging-(.+)/, &#x27;$1$2&#x27;)&#125;\n\nFiltering file content(token substitution, templating, etc.)file content filtering 允许你在复制文件的时候转换它们的内容\nExample - Filtering files as they are copied:\nimport org.apache.tools.ant.filters.FixCrLfFilterimport org.apache.tools.ant.filters.ReplaceTokenstasks.register(&#x27;filter&#x27;, Copy) &#123;    from &#x27;src/main/webapp&#x27;    into layout.buildDirectory.dir(&quot;explodedWar&quot;)    // Substitution property tokens in files    expand(copyright: &#x27;2009&#x27;, version: &#x27;2.3.1&#x27;)    expand(project.properties)    // Use some of the filters provided by Ant    filter(FixCrLfFilter)    filter(ReplaceTokens, tokens: [copyright: &#x27;2009&#x27;, version: &#x27;2.3.1&#x27;])    // Use a closure to filter each line    filter &#123; String line -&gt;        &quot;[$line]&quot;    &#125;    // Use a closure to reomve lines    filter &#123; String line -&gt;        line.startsWith(&#x27;-&#x27;) ? null : line    &#125;    filteringCharset = &#x27;UTF-8&#x27;&#125;\n\nexpand() 方法将源文件当做 Groovy templates, 使用 $&#123;expression&#125; 格式的表达式\nUsing the CopySpec classcopy specs 有两个属性:\n\n它们可以独立于 task : 允许你在一个构建当中共享 copy specs\n它们是有层级结构的 : 在整个复制定义中提供细粒度控制\n\nSharing copy specs使用 Project.copySpec(org.gradle.api.Action) 方法, 在 task 之外创建 copy spec, 然后使用 CopySpec.with(org.gradle.api.file.CopySpec) 方法将这个 copy spec 关联到一个适合的 task 中\nExample - Sharing copy specifications:\nCopySpec webAssetsSpec = copySpec &#123;    from &#x27;src/main/webapp&#x27;    include &#x27;**/*.html&#x27;, &#x27;**/*.png&#x27;, &#x27;**/*.jpg&#x27;    rename &#x27;(.+)-staging(.+)&#x27;, &#x27;$1$2&#x27;&#125;tasks.register(&#x27;copyAssets&#x27;, Copy) &#123;    into layout.buildDirectory.dir(&quot;inPlaceApp&quot;)    with webAssetsSpec&#125;tasks.register(&#x27;distApp&#x27;, Zip) &#123;    archiveFileName = &#x27;my-app-dist.zip&#x27;    destinationDirectory = layout.buildDirectory.dir(&quot;dists&quot;)    from appClasses    with webAssetsSpec&#125;\n\nExample - Sharing copy patterns only:\ndef webAssetPatterns = &#123;    include &#x27;**/*.html&#x27;, &#x27;**/*.png&#x27;, &#x27;**/*.jpg&#x27;&#125;tasks.register(&#x27;copyAppAssets&#x27;, Copy) &#123;    into layout.buildDirectory.dir(&quot;inPlaceApp&quot;)    from &#x27;src/main/webapp&#x27;, webAssetPatterns&#125;tasks.register(&#x27;archiveDistAssets&#x27;, Zip) &#123;    archiveFileName = &#x27;distribution-assets.zip&#x27;    destinationDirectory = layout.buildDirectory.dir(&quot;dists&quot;)    from &#x27;distResources&#x27;, webAssetPatterns&#125;\n\nMirroring directories and file collections with the Sync taskSync task 继承了 Copy task, 复制源文件到目标文件夹, 然后删除目标文件夹中不是被复制而来的文件\n这个 task 同步了目标文件夹的内容\nExample - Using the Sync task to copy dependencies:\ntasks.register(&#x27;libs&#x27;, Sync) &#123;    from configurations.runtime    into layout.buildDirectory.dir(&quot;libs&quot;)&#125;\n\n还可以在 task 中使用 Project.sync(org.gradle.api.Action) 方法来完成同样的功能\nDeploying single files into application servers目标文件夹可能包含不可读的文件, 导致 Gradle 在做 UP-TO-DATE 检查时出问题, 因此使用 Task.doNotTrackState() 方法来避免这个问题\nExample - Using Copy to deploy a WAR file:\nplugins &#123;    id &#x27;war&#x27;&#125;tasks.register(&#x27;deployToTomcat&#x27;, Copy) &#123;    from war    into layout.buildDirectory.dir(&quot;tomcat/webapps&quot;)    doNotTrackState(&quot;Deployment directory contains unreadable files&quot;)&#125;\n\nInstalling executables目标文件夹作为安装目录有很多其他的可执行文件, 这些文件不能被 Gradle 识别, 使用 Task.doNotTrackState() 方法来避免 Gradle 花时间在这个目标文件夹下进行 UP-TO-DATE 检查\nExample - Using Copy to install an executable:\ntasks.register(&#x27;installExecutable&#x27;, Copy) &#123;    from &#x27;build/my-binary&#x27;    into &#x27;usr/local/bin&#x27;    doNotTrackState(&quot;Installation directory contains unrelated files&quot;)&#125;\n\nArchive creation in deptharchive 是自包含的文件系统, Gradle 将其看待为文件系统\n处理 archive 就像处理普通文件和目录一样\nGradle 支持创建 ZIP 和 TAR archive, 都是基于复制\nExample - Archiving a directory as a ZIP:\ntasks.register(&#x27;packageDistribution&#x27;, Zip) &#123;    archiveFileName = &#x27;my-distribution.zip&#x27;    destinationDirectory = layout.buildDirectory.dir(&quot;dist&quot;)    from layout.buildDirectory.dir(&quot;toArchive&quot;)&#125;\n\n可以使用所有的复制能力, 例如内容过滤, 文件重命名\n许多约定优先的插件提供了自己的 archive task, 例如 Java 插件提供了 jar task 来打包编译文件和资源文件到 JAR 文件中\nArchving namingBase plugin 提供了主要的命名约定, 这个插件默认在 $buildDir/distributions 目录中创建 archive, 使用 [projectName]-[version].[type] 作为默认的命名方式\nExample - Creating of ZIP archive:\nplugins &#123;    id &#x27;base&#x27;&#125;version = 1.0tasks.register(&#x27;myZip&#x27;, Zip) &#123;    from &#x27;somedir&#x27;    doLast &#123;        println archiveFileName.get()        println relativePath(destinationDirectory)        println relativePath(archiveFile)    &#125;&#125;\n\n运行结果:\n&gt; gradle -q myZiparchive-naming-1.0.zipbuild/distributionsbuild/distributions/archive-naming-1.0.zip\n\n提供 archiveFileName 和 destinationDirectory 属性来修改生成的文件名与目标目录\nAbstractArchiveTask.getArchiveFileName() 提供了默认的 archive 名称模式: [archiveBaseName]-[archiveAppendix]-[archiveVersion]-[archiveClassifier].[archiveExtension]\n可以在 task 中分别设置这些属性来进行定制\nExample - Configuration of archive task - custom archive name:\ntasks.register(&#x27;myCustomZip&#x27;, Zip) &#123;    archiveBaseName = &#x27;customName&#x27;    from &#x27;somedir&#x27;    doLast &#123;        println archiveFileName.get()    &#125;&#125;\n\nExample - Configuration of archive task - appendix &amp; classifier:\nplugins &#123;    id &#x27;base&#x27;&#125;version = 1.0// tag::base-plugin-config[]base &#123;    archivesName = &quot;gradle&quot;    distsDirectory = layout.buildDirectory.dir(&quot;custom-dist&quot;)    libsDirectory = layout.buildDirectory.dir(&quot;custom-libs&quot;)&#125;// end::base-plugin-config[]tasks.register(&#x27;myZip&#x27;, Zip) &#123;    from &#x27;somedir&#x27;&#125;tasks.register(&#x27;myOtherZip&#x27;, Zip) &#123;    archiveAppendix = &#x27;wrapper&#x27;    archiveClassifier = &#x27;src&#x27;    from &#x27;somedir&#x27;&#125;tasks.register(&#x27;echoNames&#x27;) &#123;    doLast &#123;        println &quot;Project name: $&#123;project.name&#125;&quot;        println myZip.archiveFileName.get()        println myOtherZip.archiveFileName.get()    &#125;&#125;\n\n可以在 AbstractArchiveTask API 中看到所有可用的 archive task 属性\nSharing content between multiple archives使用 Project.copySpec(org.gradle.api.Action) 方法来在 archives 之间共享内容\nReproducible builds重新创建完全一样的 archives\n所有东西都一模一样, 包括字节到字节, 文件的时间戳, 文件的顺序\nExample - Activating reproducible archives:\ntasks.withType(AbstractArchiveTask).configureEach &#123;    preserveFileTimestamps = false    reproducibleFileOrder = true&#125;\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"Gradle Writing Build Scripts","url":"/gradle/gradle-writing-build-scripts/","content":"\n\n\nGradle Writing Build Scripts\nThe Project API\nStandard project properties\n\n\nThe script API\nDeclaring variables\nExtra properties\n\n\nConfiguring arbitrary objects\nConfiguring arbitrary objects using an external script\nSome Groovy basics\nClosure delegate\n\n\n\n\n\n\n\nGradle Writing Build ScriptsThe Project API在构建脚本中几乎所有的顶层属性和代码块都是 Project API 的一部分\nExample - build.gradle:\nprintln nameprintln project.name\n\n运行结果:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q helpGradle_test_3Gradle_test_3\n\nStandard project properties\n\n\nName\nType\nDefault Value\n\n\n\nproject\nProject\nThe Project instance\n\n\nname\nString\nThe name of the project directory\n\n\npath\nString\nThe absolute path of the project\n\n\ndescription\nString\nA description of the project\n\n\nprojectDir\nFile\nThe directory containing the build script\n\n\nbuildDir\nFile\nprojectDir&#x2F;build\n\n\ngroup\nObject\nunspecified\n\n\nversion\nObject\nunspecified\n\n\nant\nAntBuilder\nAn AntBuilder instance\n\n\nExample - build.gradle:\nprintln &quot;path: [$&#123;path&#125;]&quot;println &quot;projectDir: [$projectDir]&quot;println &quot;buildDir: [$buildDir]&quot;println &quot;group: [$group]&quot;println &quot;version: [$version]&quot;\n\n运行结果:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q helppath: [:]projectDir: [/Users/daisy/Desktop/Gradle_test_3]buildDir: [/Users/daisy/Desktop/Gradle_test_3/build]group: []version: [unspecified]\n\nThe script API当 Gradle 执行一个 Groovy 构建脚本时, Gradle 将构建脚本编译成一个实现了 Script 的类; 所有在 Script 中声明的属性和方法都可以在你的构建脚本中使用\nDeclaring variables在一个构建脚本中可以定义两种类型的变量:\n\n本地变量\n额外属性(extra properties)\n\nGroovy 中使用 def 关键字定义本地变量\nKotlin 中使用 val 关键字定义本地变量\nExtra properties所有增强的 Gradle 领域模型对象都可以持有额外的用户定义的属性. 包括但不限于 project, tasks, source set\n通过对象的 ext 属性, 可以增加, 读取和设置 extra properties;或者, 使用 ext 代码块来同时增加多个属性\nplugins &#123;    id &#x27;java-library&#x27;&#125;// 使用 ext 代码块添加两个额外属性给 project 对象ext &#123;    springVersion = &quot;3.1.0.RELEASE&quot;    emailNotification = &quot;build@master.org&quot;&#125;// 使用 ext 属性添加一个 purpose 额外属性给每个 source set// 一旦额外属性被添加, 它们可以像预定义的属性一样被读取或者设置sourceSets.all &#123; ext.purpose = null&#125;sourceSets &#123;    main &#123;        purpose = &quot;production&quot;    &#125;    test &#123;        purpose = &quot;test&quot;    &#125;    plugin &#123;        purpose = &quot;production&quot;    &#125;&#125;tasks.register(&#x27;printProperties&#x27;) &#123;    doLast &#123;        println &quot;springVersion: [$&#123;springVersion&#125;]&quot;        println &quot;emailNotification: [$&#123;emailNotification&#125;]&quot;        sourceSets.matching &#123; it.purpose == &quot;production&quot; &#125;.each &#123; println it.name &#125;    &#125;&#125;\n\n运行结果:\n╭─daisy at thinkpad in ~/Desktop/Gradle_test_3╰─○ gradle -q printPropertiesspringVersion: [3.1.0.RELEASE]emailNotification: [build@master.org]mainplugin\n\nextra properties 的访问范围等于拥有它们的对象的访问范围, 这使得它们有比本地变量更大的作用范围\n一个 project 上的 extra properties 可以在 project 的子项目中可见\nConfiguring arbitrary objectsExample - Configuring arbitrary objects:\nimport java.text.FieldPositiontasks.register(&#x27;configure&#x27;) &#123;    doLast &#123;        def pos = configure(new FieldPosition(10)) &#123;            beginIndex = 1            endIndex = 5        &#125;        println pos.beginIndex        println pos.endIndex    &#125;&#125;\n\nConfiguring arbitrary objects using an external scriptExample - build.gradle:\ntasks.register(&#x27;configure&#x27;) &#123;    doLast &#123;        def pos = new java.text.FieldPosition(10)        apply from: &#x27;other.gradle&#x27;, to: pos        println pos.beginIndex        println pos.endIndex    &#125;&#125;\n\nExample - other.gradle:\n// Set propertiesbeginIndex = 1endIndex = 5\n\nSome Groovy basicsClosure delegateEach closure has a delegate object, which Groovy uses to look up variable and method references which are not local variables or parameters of the closure\nGradle uses this for configuration closures, where the delegate object is set to the object to be configured\nExample:\ndependencies &#123;    assert delegate == project.dependencies    testImplementation(&#x27;junit:junit:4.13&#x27;)    delegate.testImplementation(&#x27;junit:junit:4.13&#x27;)&#125;\n","categories":["Gradle - User Guides"],"tags":["Gradle","User Guides"]},{"title":"常用的 kubectl 命令","url":"/k8s/common-kubectl-command/","content":"命名空间每个命名空间包含了一组对象\n默认情况下, kubectl 交互的命名空间是 default\n使用 --namespace 标志指定命名空间: kubectl --namespace=mystuff 操作 mystuff 命名空间中的对象\n操作所有命名空间, 指定 --all-namespaces 标志\n上下文使用上下文永久改变默认命名空间\n创建一个拥有不同默认命名空间的上下文:\n$ kubectl config set-context &lt;上下文名称&gt; --namespace=&lt;命名空间名称&gt;\n\n使用新创建的上下文:\n$ kubectl config use-context &lt;上下文名称&gt;\n\n在 set-context 命令中使用 --users 或 --clusters 指定用户或集群\n查看 Kubernetes API 对象获取当前命名空间中的所有资源的清单: $ kubectl get &lt;资源名称&gt;\n获取特定资源: $ kubectl get &lt;资源名称&gt; &lt;对象名称&gt;\n获取更多信息, 使用 -o wide 标志\n输出 JSON 或 YAML 格式的对象, 使用 -o json,-o yaml 标志\n删除输出中的表头, 使用 --no-headers 标志\n使用 JSONPath 查询返回对象特定字段: $ kubectl get pods my-pod -o jsonpath --template=&#123;.status.podIP&#125;\n查看特定对象的详细信息: $ kubectl describe &lt;资源名称&gt; &lt;对象名称&gt;\n创建, 更新和销毁 Kubernetes 对象创建对象: $ kubectl apply -f obj.yaml\n再次运行 apply 命令更新对象: $ kubectl apply -f obj.yaml\napply 只会在集群对象与当前对象有差异时才进行操作与更新, 如无差异时则不会更改任何对象\n如果你想确保集群状态与文件系统状态相匹配, 可以反复使用 apply 来协调状态\n只查看 apply 命令会执行哪些操作, 使用 --dry-run 标志将对象输出到终端\n使用 edit 命令交互式在线修改保存对象: $ kubectl edit &lt;资源名称&gt; &lt;对象名称&gt;\n使用 edit-last-applied,set-last-applied,view-last-applied 来处理 apply 命令以前的配置历史记录: $ kubectl apply -f myobj.yaml view-last-applied\n删除对象: $ kubectl delete -f obj.yaml\n使用资源类型和名称删除对象: $ kubectl delete &lt;资源名称&gt; &lt;对象名称&gt;\n给对象添加标签和注释使用 annotate 和 label 命令来更新 Kubernetes 对象上的标签和注释: $ kubectl label pods bar color=red\n使用 --overwrite 标志来覆盖已有的标签或注释\n使用 &lt;标签名称&gt;- 的语法来移除标签: $ kubectl label pods bar color-\n调试命令查看正在运行的容器的日志: $ kubectl logs &lt;Pod 名称&gt;\n使用 -c 标志选择要查看的容器\n使用 -f 查看日志持续输出\n使用 exec 命令, 在运行的容器中执行命令: $ kubectl exec -it &lt;Pod 名称&gt; -- bash\n使用 attach 命令, 将终端附着到正在运行的进程上: $ kubectl attach -it &lt;Pod 名称&gt;. 这个命令允许你将输入发送到正在运行的进程, 前提是该进程能够读取标准输入\n使用 cp 命令将文件复制到容器, 或从容器复制文件: $ kubectl cp &lt;Pod 名称&gt;:&lt;/path/to/remote/file&gt; &lt;/path/to/local/file&gt;\n使用 port-forward 命令将网络流量从本地计算机转发到 Pod: $ kubectl port-forward &lt;Pod 名称&gt; 8080:80\n使用 top 命令查看节点或 Pod 正在使用的资源列表: $ kubectl top nodes, $ kubectl top pods\n使用 --all-namespaces 标志查看集群中所有节点或 Pod 的资源使用情况\n自动补齐命令要先安装 bash-completion 软件包才能启用命令自动补齐功能\n在终端中临时启动该功能: source &lt;(kubectl completion bash)\n要自动启用该功能, 将它添加到 $&#123;HOME&#125;/.bashrc 文件中: echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; $&#123;HOME&#125;/.bashrc\n如果使用 zsh, 查看 link 获取帮助\n查看集群的其他方法在 VSCode, Intellij 安装插件\n小结查看命令帮助文档: $ kubectl help or $ kubectl help &lt;命令名称&gt;\n","tags":["Notes"]},{"title":"Micronaut 中文文档 Appendices","url":"/micronaut/micronaut-appendices/","content":"\n\n\nAppendices\nMicronaut Architecture (Micronaut 架构)\nCompiler (编译器)\nAnnotation Metadata (注解元数据)\nBean Introspections (Bean 内省)\nBean Definitions (Bean 定义)\nConfiguration Properties Handling (配置属性处理)\n\n\nAOP Proxies (AOP 代理)\nSecurity Considerations (安全注意事项)\n\n\nApplication Context (应用程序上下文)\nHTTP Server (HTTP 服务器)\nServer Configuration (服务器配置)\nServer Configuration Security Considerations (服务器配置安全注意事项)\nNetty Server Initialization (Netty 服务器初始化)\nChannelPipeline Security Considerations (ChannelPipeline 安全注意事项)\nNetty Server Routing (Netty 服务器路由)\nNetty Server Routing Security Considerations (Netty 服务器路由安全注意事项)\n\n\n\n\nFrequently Asked Questions (FAQ) (最常问的问题)\nDoes Micronaut modify my bytecode? (Micronaut 修改了我的字节码吗?)\nWhy Doesn’t Micronaut use Spring? (为什么 Micronaut 不使用 Spring?)\nDoes Micronaut support Scala? (Micronaut 支持 Scala 吗?)\nCan Micronaut be used for purposes other than Microservices? (Micronaut 可以用在其他用途而不是作为微服务吗?)\nWhat are the advantages of Micronaut’s Dependency Injection and AOP implementation? (Micronaut 的依赖注入和 AOP 实现有什么优点?)\nWhy does Micronaut have its own Consul and Eureka client implementations? (为什么 Micronaut 有自己的 Consul 和 Eureka 客户端实现?)\nWhy am I encountering a NoSuchMethodError occurs loading my beans (Groovy)? (为什么我在加载我的 beans 时遇到了 NoSuchMethodError 问题?)\nWhy is it taking much longer than it should to start the application? (为什么启动应用程序花费的时间比应有的时间长得多?)\n\n\nUsing Snapshots (使用快照版本)\nCommon Problems (常见问题)\nDependency injection is not working (依赖注入不生效)\nA NoSuchMethodError occurs loading beans (Groovy) (加载 beans 时出现 NoSuchMethodError)\nIt is taking much longer to start my application than it should (*nix OS) (启动应用程序花费的时间比应有的时间长得多)\n\n\nBreaking Changes\n\n\n\n\n\nAppendices声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\nMicronaut Architecture (Micronaut 架构)\nThe following documentation describes Micronaut’s architecture and is designed for those who are looking for information on the internal workings of Micronaut and how it is architected.\n\n接下来的文档描述了 Micronaut 的架构, 并且是为那些正在寻找有关 Micronaut 内部工作原理和架构方式的信息的人设计的\n\nThis is not intended as end-user developer documentation, but for those interested in the inner workings of Micronaut.\n\n这不是作为终端开发人员的文档, 而是针对那些对 Micronaut 内部感兴趣的人的文档\n这个文档被分开为不同的章节来描述编译器, 内省, 应用程序容器, 依赖注入等等\n因为这个文档覆盖了 Micronaut 的内部工作, 许多 APIs 引用与描述都被认为是内部的, 非公开 API, 并且使用 @Internal 注解进行修饰\n内部 APIs 可以在 Micronaut 的补丁版本之间发生变化, 并且不会包含在 Micronaut 的语义化版本发布策略中\nCompiler (编译器)Micronaut 编译器是对现有语言编译器的一组扩展:\n\nJava : Java Annotation Processing (APT) API 是用于 Java 和 Kotlin 代码的 (将来的版本将会为 Kotlin 支持 KSP)\nGroovy : Groovy AST Transformations 用来参与 Groovy 代码编译\n\n为了使本文档保持简单, 其余部分将描述与 Java 编译器的交互\n\nThe Micronaut Compiler visits end user code and generates additional bytecode that sits alongside the user code in the same package structure.\n\nMicronaut 编译器访问最终用户代码, 在用户代码相同的包结构中生成与用户代码并列的额外字节码\n\nThe AST of user source is visited using implementations of TypeElementVisitor which are loaded via the standard Java service loader mechanism.\n\n用户源代码的 AST 使用 TypeElementVisitor 实现来访问, 这个实现通过 standard Java service loader mechanism 加载\n\nEach TypeElementVisitor implementation can override one or more of the visit* methods which receive an instance of Element.\n\n每个 TypeElementVisitor 实现可以重载一个或多个 visit* 方法, 这个方法接受一个 Element 实例\n\nThe Element API provides a language-neutral abstraction over the AST and computation of the AnnotationMetadata for a given element (class, method, field etc.).\n\nElement API 为 AST 和给定元素 (例如: 类,方法,字段等)的 AnnotationMetadata 的计算提供了一个语言中立的抽象\nAnnotation Metadata (注解元数据)\nMicronaut is an implementation of an annotation-based programming model. That is to say annotations form a fundamental part of the API design of the framework.\n\nMicronaut 是一个基于注解的编程模型的实现. 也就是说, 注解构成了框架 API 设计的基础部分\n\nGiven this design decision, a compilation-time model was formulated to address the challenges of evaluating annotations at runtime.\n\n考虑到这个设计决定, 制定了一个编译时模型来解决在运行时评估注解的挑战\n\nThe AnnotationMetadata API is a construct that is used both a compilation time and at runtime by framework components.\n\nAnnotationMetadata API 是一个在编译时和运行时都由框架组件使用的构造\n\nAnnotationMetadata represents the computed fusion of annotation information for a particular type, field, constructor, method or bean property and may include both annotations declared in the source code, but also synthetic meta-annotations that can be used at runtime to implement framework logic.\n\nAnnotationMetadata 表示特定类型, 字段, 构造方法, 方法或 bean 属性的注解信息的计算融合, 可能既包括源代码中声明的注解, 也可能包括可以在运行时用于实现框架逻辑的合成元注解\n\nWhen visiting source code within the Micronaut Compiler using the Element API for each ClassElement, FieldElement, MethodElement, ConstructorElement and PropertyElement an instance of AnnotationMetadata is computed.\n\n当使用 Element API 访问 Micronaut Compiler 中的源代码时, 会计算 AnnotationMetadata 的一个实例, 用于每个 ClassElement, FieldElement, MethodElement, ConstructorElement 和 PropertyElement\n\nThe AnnotationMetadata API tries to address the following challenges:\n\nAnnotationMetadata API 尝试解决如下挑战:\n\n\nAnnotations can be inherited from types and interfaces into implementations. To avoid the need to traverse the class&#x2F;interface hierarchy at runtime Micronaut will at build time compute inherited annotations and deal with member overriding rules\n\n\n可以从类或接口中继承注解. 为了避免在运行时遍历类&#x2F;接口层次结构, Micronaut 会在构建时计算继承的注解并处理成员覆盖规则\n\nAnnotations can be annotated with other annotations. These annotations are often referred to as meta-annotations or stereotypes. The AnnotationMetadata API provides methods to understand whether a particular annotation is declared as meta-annotation and to find out what annotations are meta-annotated with other annotations\n\n\n注解可以使用其他注解来注释. 这些注解通常被称为元注解或原型. AnnotationMetadata API 提供了方法来理解某个特定注解是否被声明为元注解, 以及找出哪些注解是使用其他注解进行元注释的\n\nIt is often necessary to fuse annotation metadata together from different sources. For example, for JavaBean properties you want to combine the metadata from the private field, public getter and public setters into a single view otherwise you have to run logic to runtime to somehow combine this metadata from 3 distinct sources.\n\n\n通常有必要将来自不同来源的注解元数据融合在一起. 例如, 对于 JavaBean 属性, 你希望将来自 private field, public setter&#x2F;getter 的元数据组合到一个视图中, 否则你必须在在运行时执行逻辑来以某种方式组合来自 3 个不同来源的元数据\n\nRepeatable annotations are combined and normalized. If inherited the annotations are combined from parent interfaces or classes providing a single API to evaluate repeatable annotations instead of requiring runtime logic to perform normalization.\n\n\n可重复的注解被合并且规范化. 如果继承, 注解将从父接口或类组合而来, 提供单个 API 来评估可重复的注解, 而不需要运行时逻辑来执行规范化\n\n\nWhen the source for a type is visited an instance of ClassElement is constructed via the ElementFactory API.\n\n当访问类型的源时, 通过 ElementFactory API 构造 ClassElement 的实例\n\nThe ElementFactory uses an instance of AbstractAnnotationMetadataBuilder which contains language specific implementations to construct AnnotationMedata for the underlying native type in the AST. In the case of Java this would be a javax.model.element.TypeElement.\n\nElementFactory 使用 AbstractAnnotationMetadataBuilder 的实例, 该实例包含特定于语言的实现, 用于为 AST 中的底层原生类型构造 AnnotationMetadata. 在 Java 情况下, 这将是一个 javax.model.element.TypeElement\n基本流程如下所示:\n\n\nAdditionally, the AbstractAnnotationMetadataBuilder will load via the standard Java service loader mechanism one or more instances of the following types that allow manipulating how an annotation is represented in the AnnotationMetadata:\n\n此外, AbstractAnnotationMetadataBuilder 通过 standard Java service loader mechanism 加载如下类型的一个或多个实例, 这些实例允许操作注解在 AnnotationMetadata 中的表示方式:\n\nAnnotationMapper : 一个可以将一个注解的值映射到另一个注解并在 AnnotationMetadata 中保留原始注解的类型\nAnnotationTransformer : 可以将一个注解的值转换为另一个注解的类型, 从而在 AnnotationMetadata 中删除原始注解\nAnnotationRemapper : 一个可以转换给定包中所有注解的值从而在 AnnotationMetadata 中删除原始注解的类型\n\n\nNote that at compilation time the AnnotationMetadata is mutable and can be further altered by implementations of TypeElementVisitor by invoking the annotate(..) method of the Element API.\n\n注意, AnnotationMetadata 在编译时是可变的, 可以被 TypeElementVisitor 的实现通过调用 Element API 的 annotate(..) 方法进行更一步的修改\n\nHowever, at runtime the AnnotationMetadata is immutable and fixed\n\n但是, AnnotationMetadata 在运行时是不可变且固定的\n\nThe purpose of this design to allow the compiler to be extended and for Micronaut to be able to interpret different source-level annotation-based programming models.\n\n这种设计的目的是允许编译器进行扩展, 并使 Micronaut 能够解释不同源代码级别的基于注解的编程模型\n\nIn practice this effectively allows decoupling the source code level annotation model from what is used at runtime such that different annotations can be used to represent the same annotation.\n\n在实践中, 这有效地允许将源代码级别的注解模型与运行时使用的注解模型分离, 以便可以使用不同的注解来表示相同的注解\n\nFor example jakarata.inject.Inject or Spring’s @Autowired are supported as synonyms for javax.inject.Inject by transforming the source level annotation to javax.inject.Inject which is the only annotation represented at runtime.\n\n比如 jakarta.inject.Inject 或者 Spring 的 @Autowired 作为 javax.inject.Inject 的同义词作为支持, 通过将源代码级别注解转换 javax.inject.Inject, 因为 javax.inject.Inject 是运行时唯一表示的注解\n\nFinally, annotations in Java also allow the definition of default values.\n\n最后, Java 中的注解还允许定义默认值\n\nThese defaults are not retained in individual instances of AnnotationMetadata but instead stored in a shared, static application-wide map for later retrieval for annotations known to be used by the application.\n\n这些默认值不会保留在 AnnotationMetadata 的各个实例中, 而是存储在一个共享的, 静态的应用程序范围的 map 中, 以便稍后进行注解检索, 这些注解已知被应用程序所使用\nBean Introspections (Bean 内省)\nThe goal of Bean Introspections is to provide an alternative to reflection and the JDK’s Introspector API that is coupled to the java.desktop module in recent versions of Java.\n\nBean Introspections 的目标是提供一种 反射 和 耦合到最近 Java 版本中 java.desktop 模块的 JDK 的 内省 API 的替代\n\nMany libraries in Java need to programmatically discover what methods represent properties of a class in some way and whilst the JavaBeans specification tried to establish a standard convention, the language itself has evolved to include other constructs like Records that represent properties as components.\n\nJava 中的许多库需要以编程的方式发现一个类的什么方法以某种方式代表属性, 虽然 JavaBeans 规范试图建立一个标准约定, 但是语言本身已经发展到包含其他构造 (例如 Records), Records 将属性表示为组件\n\nIn addition, other languages like Kotlin and Groovy have native support for class properties that need to be supported at the framework level.\n\n除此之外, 其他语言像 Kotlin 和 Groovy 已经原生支持 本来需要在框架级别支持的 类属性\n\nThe IntrospectedTypeElementVisitor visits declarations of the @Introspected annotation on types and generates at compilation time implementations of BeanIntrospection that are associated with each annotated type:\n\nIntrospectedTypeElementVisitor 扫描 @Introspected 在类型上的声明, 在编译时生成 BeanIntrospection 实现, 这个实现和每个注解类型关联:\n\n\nThis generation happens via the BeanIntrospectionWriter class which uses the ASM bytecode generation library to generate two additional classes.\n\n此生成通过 BeanIntrospectionWriter 类进行, 这个类使用 ASM 字节码生成库来生成另外两个类\n比如, 给定一个称为 example.Person 的类, 那么生成的类是:\n\n\nexample.$Person$IntrospectionRef - an implementation of BeanIntrospectionReference that allows the application to soft load the introspection without loading all of the metadata or the class itself (in the case where the introspected class is itself not on the classpath). Since references are loaded via ServiceLoader an entry in a generated META-INF&#x2F;services&#x2F;io.micronaut.core.beans.BeanIntrospectionReference referring to this type is also generated at compilation time.\n\n\nexample.$Person$IntrospectionRef - 一个 BeanIntrospectionReference 实现, 允许应用程序在不加载所有元数据或类本身的情况下软加载内省 (在内省类本身不在类路径上的情况下). 因为引用是通过 ServiceLoader 加载的, 在生成的 META-INFO/services/io.micronaut.core.beans.BeanIntrospectionReference 中引用此类型的 entry 也会在编译时生成\n\nexample.$Person$Introspection - an implementation of BeanIntrospection which contains the actual runtime introspection information.\n\n\nexample.$Person$Introspection - 一个 BeanIntrospection 的实现, 包含了实际的运行时内省信息\n\n下面的例子展示了 BeanIntrospection API 的使用:\ndef introspection = BeanIntrospection.getIntrospection(Person)                              // 1Person person = introspection.instantiate(&#x27;John&#x27;)                                           // 2println &quot;Hello $person.name&quot;BeanProperty&lt;Person, String&gt; property = introspection.getRequiredProperty(&#x27;name&#x27;, String)   // 3property.set(person, &#x27;Fred&#x27;)                                                                // 4String name = property.get(person)                                                          // 5println &quot;Hello $person.name&quot;\n\n1 : 通过类型查找一个 BeanIntrospection. 发生这种情况时, 将在 ServiceLoader 加载的 BeanTranspectionReference 实例中搜索 BeanIntrospection\n2 : instantiate 方法允许创建实例\n3 : 可以通过其中一个可用方法来加载 bean 的属性, 在这个情况下是 getRequiredProperty 方法\n4 : BeanProperty 引用可以用来写入可修改属性\n5 : 读取可读属性\nPerson 类只有在 getBeanType() 方法调用的时候才初始化. 如果类没有出现在 classpath 上那么会发生一个 NoClassDefFoundError, 要避免这个错误开发者可以先使用 BeanIntrospectionReference 上的 isPresent() 方法来尝试获取类型\n一个 BeanIntrospection 实现执行两个主要功能:\n\n\nThe introspection holds Bean metadata about the properties and constructor arguments for a particular type that is abstracted away from the actual implementation (JavaBean property, Java 17+ Record, Kotlin data classes, Groovy properties etc.) and which also provide access to AnnotationMetadata without needing to use reflection to load the annotations themselves.\n\n\n内省保存关于特定类型的属性和构造方法参数的 Bean 元数据, 该类型是从实际实现抽象出来的 (JavaBean 属性, Java 17+ Record, Kotlin 数据类, Groovy 属性等), 还提供对 AnnotationMetadata 的访问, 而无需使用反射来加载注解本身\n\nThe introspection enables the ability to instantiate and read&#x2F;write bean properties without the use of Java reflection, based purely on the subset of build-time generated information.\n\n\nintrospection 允许在不使用 Java 反射的情况下进行实例化和读&#x2F;写 bean 属性, 这完全基于构建时生成的信息子集\n\n\nOptimized reflection-free method dispatch is generated by overriding the dispatchOne method of AbstractInitializableBeanIntrospection, for example:\n\n优化的无反射方法调度是通过重写 AbstractInitializableBeanIntrospection 的 dispatchOne() 方法生成的, 例如:\nprotected final Object dispatchOne(int propertyIndex, Object bean, Object value) &#123;    switch(propertyIndex) &#123; // 1        case 0:            return ((Person) bean).getName();   // 2        case 1:            ((Person) bean).setName((String) value);    //3            return null;        default:            throw this.unknownDispatchAtIndexException(propertyIndex);  // 4    &#125;&#125;\n\n1 : 每个读或写方法都分配了一个索引\n2 : 在读取方法中使用索引直接获取值, 而不依赖反射\n3 : 索引用于写方法, 不使用反射来设置属性\n4 : 如果索引中不存在属性, 则会引发异常 ,尽管这是实现细节, 但是代码路径永远不会到达这里\n\nThe approach to use a dispatch method with an index was used to avoid the need to generate a class per method (which would consume more memory) or introduce the overhead of lambdas.\n\n使用带有索引的分派方法的方式是为了避免需要为每个方法生成一个类 (这将消耗更多内存) 或引入 Lambda 的开销\n\nIn order to enable type instantiation the BeanIntrospectionWriter will also generate an implementation of the instantiateInternal method which contains the reflection-free code to instantiate a given type based on known valid argument types:\n\n为了启用类型实例化, BeanProspectionWriter 还将生成 instantiateInternal 方法的实现, 该方法包含无反射代码, 用于根据已知的有效参数类型实例化给定类型:\npublic Object instantiateInternal(Object[] args) &#123;    return new Person(        (String) args[0],        (Integer) args[1]    );&#125;\n\nBean Definitions (Bean 定义)Micronaut 是 JSR-330 依赖注入规范的一个实现\n依赖注入 (或控制反转) 是 Java 中广泛采用的一种常见模式, 它允许松散地解耦组件, 从而使应用程序易于扩展和测试\n\nThe way in which objects are wired together is decoupled from the objects themselves in this model by a separate programming model.\n\n在这个模型中, 对象连接在一起的方式通过一个单独的编程模型与对象本身分离\n\nIn the case of Micronaut this model is based on annotations defined within the JSR-330 specification plus an extended set of annotations located within the io.micronaut.context.annotation\n\n在 Micronaut 的情况下, 该模型基于 JSR-330 规范中定义的注解, 以及位于 io.micronaut.context.annotation 包中的一组扩展注解\n\nThese annotations are visited by the Micronaut Compiler which traverses the source code language AST and builds a model used to wire objects together at runtime.\n\nMicronaut 编译器将访问这些注解, 该编译器将遍历源代码语言 AST, 并构建一个用于在运行时将对象连接在一起的模型\n\nIt is important to note that the actual object wiring is deferred until runtime.\n\n需要注意的是, 实际的对象连接推迟到运行时\n\nFor Java code BeanDefinitionInjectProcessor (which is a Java Annotation Processor) is invoked from the Java compiler for each class annotated with a bean definition annotation.\n\n对于 Java 代码, BeanDefinitionInjectProcessor (它是一个 Java 注解处理器) 从 Java 编译器中为每个用 bean 定义注解注释的类调用\n\nWhat constitutes a bean defining annotation is complex as it takes into account meta-annotations, but in general it is any annotation annotated with a JSR-330 bean @Scope\n\nbean 定义注解的构成很复杂, 因为它考虑了元注解, 但一般来说它是用 JSR-330 bean @Scope 注解注释的任意注解\n\nThe BeanDefinitionInjectProcessor will visit each bean in the user code source and generate additional byte code using the ASM byte code generation library that sits along side the annotated class in the same package.\n\nBeanDefinitionInjectProcessor 将会访问用户代码源中的每个 bean, 并使用位于同一个包中, 在被注解注释的类, 旁边的 ASM 字节码生成库生成额外的字节码\n\nFor historic reasons the dependency injection processor does not use the TypeElementVisitor API but will likely do so in the future\n\n由于历史原因, 依赖注入处理器不会使用 TypeElementVisitor API 但是会在将来使用\n\nByte code generation is implemented in the BeanDefinitionWriter which contains methods to “visit” different aspects of the way is bean is defined (the BeanDefinition).\n\n字节码生成是在 BeanDefinitionWriter 中实现的, 它包含一些方法, 可以 “访问” 不同方面的方法来定义 bean 的方式 (BeanDefinition)\n下图展示了这个流程:\n\n例如给定如下类:\n@Singletonclass Vehicle &#123;    final Engine engine    Vehicle(Engine engine) &#123; this.engine = engine&#125;    String start() &#123; engine.start() &#125;&#125;\n\n生成了如下的东西:\n\n\nA example.$Vehicle$Definition$Reference class that implements the BeanDefinitionReference interface that allows the application to soft load the bean definition without loading all of the metadata or the class itself (in the case where the introspected class is itself not on the classpath). Since references are loaded via ServiceLoader an entry in a generated META-INF/services/io.micronaut.inject.BeanDefinitionReference referring to this type is also generated at compilation time.\n\n\n一个 example.$Vehicle$Definition$Reference 类, 这个类实现了 BeanDefinitionReference 接口, 这个接口允许应用程序软加载 bean 定义而不需要加载完整的元数据或者类本身 (在内省类本身不存在于 classpath 的情况). 因为引用是通过 ServiceLoader 加载的, 因此生成的 META-INF/services/io.micronaut.inject.BeanDefinitionReference 中引用此类型的 entry 也会在编译时生成\n\nA example.$Vehicle$Definition which contains the actual BeanDefinition information.\n\n\n一个包含实际 BeanDefinition 信息的 example.$Vehicle$Definition\n\nBeanDefinition 是一种保存特定类型元数据的类型, 包括:\n\n类级别 [AnnotationMetadata](Class level AnnotationMetadata)\n计算出的 JSR-330 @Scope 和 @Qualifier\n可用 InjectPoint 实例的了解 (Knowledge of the available InjectionPoint instances)\n对任何已定义的 ExecutableMethod 的引用\n\n\nIn addition the BeanDefinition contains logic which knows how the bean is wired together, including how the type is constructed and fields and&#x2F;or methods injected.\n\n此外, BeanDefinition 包含知道 bean 如何连接在一起的逻辑, 包括如何构造类型以及如何注入字段和(或)方法\n\nDuring compilation the ASM byte code library is used to fill out the details of the BeanDefinition, including a build method that, for the previous example, looks like:\n\n在编译期间, ASM 字节码库用于填写 BeanDefinition 的详细信息, 包括一个 build 方法, 在上一例子中, 该方法如下所示:\npublic Vehicle build(    BeanResolutionContext resolution,   // 1    BeanContext context,    BeanDefinition definition) &#123;    Vehicle bean = new Vehicle(        (Engine) super.getBeanForConstructorArgument(   // 2            resolution,            context,            0,  // 3            (Qualifier) null        )    );    return bean;&#125;\n\n1 : BeanResolutionContext 用于跟踪循环 bean 引用并改进错误报告\n2 : 该类被实例化, 并且通过调用 AbstractInitializableBeanDefinition 的方法来查找每个构造方法参数\n3 : 在这个例子中, 将个跟踪构造方法参数的索引\n\nSpecial handling is required when a Java field or method has private access. In this case Micronaut has no option but to fallback to using Java reflection to perform dependency injection.\n\n当 Java 的 字段或方法是私有访问权限时需要特殊的处理. 在这种情况下, Micronaut 没有选择, 只能使用 Java 反射来执行依赖注入\nConfiguration Properties Handling (配置属性处理)\nThe Micronaut Compiler handles beans declared with the meta-annotation @ConfigurationReader such as @ConfigurationProperties and @EachProperty distinctly to other beans.\n\nMicronaut 编译器处理使用元注解 @ConfigurationReader 声明的 bean, 例如 @ConfigurationProperties 和 @EachProperty, 这与其他 bean 不同\n\nIn order to support binding Application Configuration to types annotated with one of the aforementioned annotations each discovered mutable bean property is dynamically annotated with the @Property annotation with the computed and normalized property name.\n\n为了支持将应用程序配置绑定到使用上述注解之一注释的类, 每个发现的可变 bean 属性都用 @Property 注解动态注释, 并带有计算的和规范化的属性名称\n例如有如下给定的类:\nExample - @ConfiguratinoProperties:\nimport io.micronaut.context.annotation.ConfigurationPropertiesimport javax.validation.constraints.Minimport javax.validation.constraints.NotBlank@ConfigurationProperties(&#x27;my.engine&#x27;)class EngineConfig &#123;    @NotBlank    String manufacturer = &#x27;Ford&#x27;    @Min(1L)    int cylinders    CrankShaft crankShaft = new CrankShaft()    @ConfigurationProperties(&#x27;crank-shaft&#x27;)    static class CrankShaft &#123;        Optional&lt;Double&gt; rofLength = Optional.empty()    &#125;&#125;\n\n\nThe setManufacturer(String) method will be annotated with @Property(name&#x3D;”my.engine.manufacturer”) the value of which will be resolved from the configured Environment.\n\nsetManufacturer(String) 方法将会被 @Property(name = &#39;my.engine.manufacturer&#39;) 注释, 值将会从配置的 Environment 中解析\n\nThe injectBean method of AbstractInitializableBeanDefinition is subsequently overridden with logic to handle looking up the normalized property name my.engine.manufacturer from the current BeanContext and inject the value if it is present in a reflection-free manner.\n\n随后使用逻辑覆盖 AbstractInitializableBeanDefinition 的 injectBean 方法, 以处理从当前 BeanContext 中查找规范化属性名 my.engine.manufacturer 的操作, 并在该值存在时以无反射方式注入该值\n\nProperty names are normalized into kebab case (lower case hyphen separated) which is the format used to store their values.\n\n属性名称被规范化为 kebab case (小写连字符分隔), 这是用于存储其值的格式\nExample - Configuration Properties Injection:\n@Generatedprotected Object injectBean(    BeanResolutionContext resolution,    BeanContext context,    Object bean) &#123;    if (this.containsProperties(resolution, context)) &#123; // 1        EngineConfig engineConfig = (EngineConfig) bean;        if (this.containsPropertyValue(resolution, context, &#x27;my.engine.manufacturer&#x27;)) &#123;    // 2            String value = (String) super.getPropertyValueForSetter(    // 3                resolution,                context,                &#x27;setManufacturer&#x27;,                Argument.of(String.class, &#x27;manufacturer&#x27;),  // 4                &#x27;my.engine.manufacturer&#x27;,   // 5                (String) null   // 6            );            engineConfig.setManufacturer(value);        &#125;    &#125;&#125;\n\n1 : 添加了一个顶层检查, 以查看是否存在带有 @ConfigurationProperties 注解中定义的前缀的属性\n2 : 执行检查以查看该属性是否实际存在\n3 : 如果确实如此, 则通过调用 AbstractInitializableBeanDefinition 的 getPropertyValueForSetter 方法来查找该值\n4 : 将创建一个 Argument 实例, 用于转换为目标类型 (在本例中为字符串). Argument 还可能包含泛型信息\n5 : 属性的计算和规范化的路径\n6 : 如果 Bindable 注解用于指定默认值, 则为默认值\nAOP Proxies (AOP 代理)\nMicronaut supports annotation-based Aspect Oriented Programming (AOP) which allows decorating or introducing type behaviour through the use of interceptors defined in user code.\n\nMicronaut 支持基于注解的 Aspect Oriented Programming (AOP), 允许通过使用用户代码中定义的拦截器来修饰或引入类型行为\n\nThe use of the AOP terminogy originates from AspectJ and historical use in Spring.\n\nAOP 术语的使用源于 AspectJ 和 Spring 中的历史用法\n\nAny annotation defined by the framework can be meta-annotated with the @InterceptorBinding annotation which supports different kinds of interception including:\n\n框架定义的任何注解都可以使用 @InterceptorBinding 注解进行元注释, 该注解支持不同类型的拦截, 包括:\n\nAROUND - 一个可用于修饰现有方法调用的注解\nAROUND_CONSTRUCT - 一个可用于拦截任何类型的构造的注解\nINTRODUCTION - 一个可用于”引入”新行为到抽象类型或接口的注解\nPOST_CONSTRUCT - 一个可用于拦截 在对象实例化之后执行的@PostConstruct的 调用的注解\nPRE_DESTROY - 一个可用于拦截 在对象即将被处理之后执行的@PreDestroy的 调用的注解\n\n\nOne or many instances of Interceptor can be associated with an @InterceptorBinding allowing the user to implement behaviour that applies cross cutting concerns.\n\n一个或多个 Interceptor 实例可以与 @InterceptorBinding 关联, 允许用户实现应用横切关注点的行为\n\nAt an implementation level, the Micronaut Compiler will visit types that are meta-annotated with @InterceptorBinding and construct a new instance of AopProxyWriter which uses the ASM bytecode generation library to generate a subclass (or an implementation in the case of interfaces) of the annotated type.\n\n在实现级别, Micronaut 编译器将返回被 @InterceptorBinding 注解注释的类型, 并构造一个新的 AopProxyWriter 实例, 该实例使用 ASM 字节码生成库来生成一个被注释的类的子类 (或接口的实现)\n\nMicronaut at no point modifies existing user byte code, the use of build-time generated proxies allows Micronaut to generate additional code that sits along side user code and enhances behaviour. This approach does have limitations however, for example it is required that annotated types are non-final and AOP advice cannot be applied to final or effectively final types such as Java 17 Records.\n\nMicronaut 任何时候都不会修改已存在的用户字节码, 使用构建时生成的代理可以让 Micronaut 生成附加的代码, 这些代码位于用户代码旁边, 并增强行为. 然而, 这种方法确实有局限性, 例如, 需要注释的类型要求是 non-final 的, 并且 AOP advice 不能应用到 final 或 最终为final 的类型 (例如 Java 17 的 Records)\n例如有如下给定的注解\nExample - Around Advice Annotation:\nimport io.microuant.aop.Aroundimport java.lang.annotation.*import static java.lang.annotation.ElementType.*import static java.lang.annotation.RetentionPolicy.RUNTIME@Documented@Retention(RUNTIME)         // 1@Target([TYPE, METHOD])     // 2@Around                     // 3@interface NotNull &#123;&#125;\n\n1 : 注解的保留策略必须是 RUNTIME\n2 : 通常, 你希望能够在类或方法级别应用 advice, 因此目标类型是 TYPE 和 METHOD\n3 : 这里使用 @Around 注解, 它本身使用 @InterceptorBinding(kind=AROUND) 进行注释, 可以被认为是为 AROUND advice 定义 @InterceptorBinding 的简单快捷方式\n当这个注解使用在类或方法上时, 例如:\nExample - Around Advice Usage:\nimport jakarta.inject.Singleton@Singletonclass NotNullExample &#123;    @NotNull    void doWork(String taskName) &#123;        println &quot;Doing job: $taskName&quot;    &#125;&#125;\n\n\nThe compiler will visit the type and the AopProxyWriter will generate additional bytecode using the ASM bytecode generation library.\n\n编译器会扫描这个类, AopProxyWriter 将使用 ASM 字节码生成库生成附加字节码\n\nDuring compilation the AopProxyWriter instance essentially proxies the BeanDefinitionWriter (see Bean Definitions), decorating the existing bytecode generation with additional behaviour.\n\n在编译期间, AopProxyWriter 实例实际上代理了 BeanDefinitionWriter, 用附加行为装饰现有的字节码生成\n\nBeanDefinitionWriter 将为每个 bean 生成常规类, 包括:\n\n$NotNullExample$Definition.class - 原始的没有被装饰的 bean 定义\n$NotNullExample$Definition$Exec.class - 一个包含允许不使用反射分派(dispatching)到每个被拦截方法的逻辑 ExecutableMethodsDefinition 的实现\n\nAopProxyWriter 将会装饰这个行为并生成 3 个附加类:\n\n$NotNullExample$Definition$Intercepted.class - 修饰类的一个子类, 包含对应用的 MethodInterceptor 实例的引用, 并覆盖所有被拦截的方法, 构造 MethodInterceptorChain 实例并调用应用的拦截器\n$NotNullExample$Definition$Intercepted$Definition.class - 对原始未装饰的 bean 定义进行子类化的 BeanDefinition\n$NotNullExample$Definition$Intercepted$Definition$Reference.class - 一个BeanDefinitionReference, 能够软加载被拦截的 BeanDefinition\n\n\nThe majority of the classes generated are metadata for loading and resolving the BeanDefinition.\n\n生成的大多数类都是用于加载和解析 BeanDefinition 的元数据\n实际构建时代理 是一个 $Intercepted 结尾的类\n\nThis class implements the Intercepted interface and subclasses the proxied type, overriding any non-final and non-private methods to invoke the MethodInterceptorChain.\n\n这个类实现了 Intercepted 接口, 并将代理类子类化, 重写所有 non-final 和 non-private 方法来调用 MethodInterceptorChain\n\nAn implementation will create a constructor which is used to wire in the dependencies on the intercepted type that looks like:\n\n实现将会创建一个构造方法, 该构造方法用于连接被拦截类上的依赖项, 如下所示:\nExample - An intercepted type constructor:\n@Generatedclass $NotNullExample$Definition$Intercepted extends NotNullExample implements Intercepted &#123;    // 1    private final Interceptor[][] $interceptors = new Interceptor[1][];    private final ExecutableMethod[] $proxyMethods = new ExecutableMethod[1];    public $NotNullExample$Definition$Intercepted(        BeanResolutionContext resolution,        BeanContext context,        Qualifier qualifier,        List&lt;Interceptor&gt; interceptors    ) &#123;        Exec executableMethods = new Exec(true);    // 2        this.$proxyMethods[0] = executableMethods.getExecutableMethodByIndex(0);    // 3        this.$interceptors[0] = InterceptorChain.resolveAroundInterceptors(            context,            this.$proxyMethods[0],            interceptors        );  // 4    &#125;&#125;\n\n1 : @Generated 子类继承了被装饰类并实现了 Intercepted 接口\n2 : 构造一个 ExecutableMethodsDefinition 实例, 将无反射分派器解析为原始方法\n3 : 名为 $proxyMethods 的内部数组包含对用于代理调用的每个 ExecutableMethod 实例的引用\n4 : 名为 $interceptors 的内部数据包含对于每个方法应用的 拦截器 实例的引用, 因为 @InterceptorBinding 可以是类级别或者方法级别, 对于每个方法, 它们可能不同\n\nEach non-final and non-private method of the proxied type that has an @InterceptorBinding associated with it (either type level or method level) is overridden with logic that proxies the original method, for example:\n\n代理类型的每个 non-final 和 non-private 都有一个与之关联的 @InterceptorBinding (类级别或方法级别), 使用代理原始方法的逻辑来覆盖这些方法, 例如:\n@Overridepublic void doWork(String taskName) &#123;    ExecutableMethod method = this.$proxyMethods[0];    Interceptor[] interceptors = this.$interceptrors[0];            // 1    MethodInterceptorChain chain = new MethodInterceptorChain(      // 2        interceptors,        this,        method,        new Object[]&#123;taskName&#125;    );    chain.proceed();                                                // 3&#125;\n\n1 : 找到该方法的 ExecutableMethod 实例和 Interceptor 实例数组\n2 : 使用拦截器数组, 一个被拦截的实例, 方法和参数来构造一个新的 MethodInterceptorChain\n3 : 调用 MethodInterceptorChain 上的 proceed() 方法\n\nNote that the default behaviour of the @Around annotation is to invoke the original overridden method of the target type by calling the super implementation via a generated synthetic bridge method that allows access to the super implementation (in the above case NotNullExample).\n\n注意, @Around 注解的默认行为是 通过生成合成桥方法 调用父类实现 来调用目标类型的原始被覆盖方法, 该合成桥方法允许访问父类实现\n\nIn this arrangement the proxy and the proxy target are the same object, with interceptors being invoked and the call to proceed() invoke the original implementation via a call to super.doWork() in the case above.\n\n在这种安排中, 代理和代理目标是同一个对象, 拦截器被调用, 在上述情况下, 调用 proceed() 是通过调用 super.doWork() 来执行原始的实现\n\nHowever, this behaviour can be customized using the @Around annotation.\n\n但是, 使用 @Around 可以自定义这个行为\n\nBy setting @Around(proxyTarget&#x3D;true) the generated code will also implement the InterceptedProxy interface which defines a single method called interceptedTarget() that resolves the target object the proxy should delegate method calls to.\n\n通过设置 @Around(proxyTarget=true), 生成的代码还将实现 InterceptedProxy 接口, 该接口定义了一个名为 interceptedTarget() 的方法, 该方法解析 代理应该将方法调用委托给的 目标对象\n\nThe default behaviour (proxyTarget&#x3D;false) is more efficient memory wise as only a single BeanDefinition is required and a single instance of the proxied type.\n\n默认行为 (proxyTarget=false) 在内存方面效率更高, 因为只需要一个 BeanDefinition 和一个代理类的实例\n\nThe evaluation of the proxy target is eager and done when the proxy is first created, however it can be made lazy by setting @Around(lazy&#x3D;true, proxyTarget&#x3D;true) in which case the proxy will only be retrieved when a proxied method is invoked.\n\n代理目标的评估是饥饿的, 且在第一次创建代理时进行 ,但是可以通过设置 @Around(lazy=true, proxyTarget=true) 使其变成惰性, 在这种情况下, 只有在调用代理方法时才会检索代理\n\nThe difference in behaviour between proxying the target with proxyTarget&#x3D;true is illustrated in the following diagram:\n\n下图显示了 proxyTarget=true 代理目标的行为差异:\n\n图片左边的序列 (proxyTarget=true) 通过调用 super 来调用代理方法\n图片右边的序列从 BeanContext 中查找代理目标并调用目标上的方法\n\nOne final customization option is @Around(hotswap&#x3D;true) which triggers the compiler to produce a compile-time proxy that implements HotSwappableInterceptedProxy which defines a single method called swap(..) that allows swapping out the target of the proxy with a new instance (to allow this to be thread safe the generated code uses a ReentrantReadWriteLock).\n\n最后一个定制选项是 @Around(hotswap = true), 它触发编译器生成一个编译时代理, 该代理实现了 HotSwappableInterceptedProxy, 该代理定义了一个名为 swap(..) 的方法, 这个方法允许用一个新实例交换代理的目标 (为了使线程安全, 生成的代码使用 ReentrantReadWriteLock)\nSecurity Considerations (安全注意事项)\nMethod interception via AROUND advice is typically used to define logic that addresses cross cutting concerns, one of which is security.\n\n通过 AROUND advice 进行的方法拦截通常用于定义解决交叉关注点的逻辑, 其中之一就是安全\n\nWhen multiple Interceptor instances apply to a single method it may be important from a security perspective that these interceptors execute in a specific order.\n\n当多个拦截器实例应用于单个方法时, 从安全角度来看, 这些拦截器按特定顺序执行可能很重要\n\nThe Interceptor interface extends the Ordered interface to enable the developer to control interceptor ordering by overriding the getOrder() method.\n\nInterceptor 接口继承了 Ordered 接口, 使开发者能够通过重写 getOrder() 方法来控制拦截器的顺序\n\nWhen the MethodInterceptorChain is constructed and multiple interceptors are present they are ordered with HIGHEST priority interceptors executed first.\n\n当 MethodInterceptorChain 被构造并且存在多个拦截器时, 它们被排序, 最高优先级的拦截器首先被执行\n\nTo aid the developer who defines their own Around Advice the InterceptPhase enumeration defines various constants that can be used to correctly declare the value of getOrder() (for example security typically falls within the VALIDATE phase).\n\n为了帮助开发者定义自己的 Around Advice, InterceptPhase 枚举定义了各种常量, 这些常量可用于正确声明 getOrder() 的值 (例如, 安全性通常属于 VALIDATE 阶段)\n\nTrace level logging can be enabled for the io.micronaut.aop.chain package to debug resolved interceptor order.\n\n可以为 io.micronaut.aop.chain 包开启跟踪日志级别来调试解析后的拦截器顺序\nApplication Context (应用程序上下文)\nOnce the job of the Micronaut Compiler is complete and the required classes generated, it is up to the BeanContext to load the classes for runtime execution.\n\n一旦 Micronaut 编译器 的工作完成并生成了所需的类, BeanContext 就可以加载这些类以供运行时执行\n\nWhilst the standard Java service loader mechanism is used to define instances of BeanDefinitionReference, the instances themselves are instead loaded with SoftServiceLoader which is a more lenient implementation that allows checking if the service is actually present before loading and also allows parallel loading of services.\n\n虽然 标准 Java 服务加载器机制 用于定义 BeanDefinitionReference 的是实例, 当实例本身使用 SoftServiceLoader 加载, 这是一种更宽松的实现, 允许在加载之前检查服务是否实际存在, 还允许并行加载服务\nBeanContext 执行如下步骤:\n\n并行地软加载所有 [BeanDefinitionReference](Soft load all BeanDefinitionReference instances in parallel)\n实例化所有使用 @Context 注解注释的 beans (beans 的作用域是整个上下文)\n为发现的每个已处理的 ExecutableMethod 运行每个 ExecutableMethodProcessor. 如果使用 @Executable(processOnStartup = true) 对方法进行元注释, 则该方法被视为 “已处理”\n在启动上下文时, 在类型 StartupEvent 上发布事件\n\n基本流程如下图所示:\n\n\nThe ApplicationContext is a specialized version of the BeanContext that adds the notion of one or more active environments (encapsulated by Environment) and conditional bean loading based on this environment.\n\nApplicationContext 是 BeanContext 的特别版本, 它添加了一个或多个活动环境 (封装为 Environment) 和基于该环境的 条件化 bean 加载\n\nThe Environment is loaded from one or more defined PropertySource instances that are discovered via the standard Java service loader mechanism by loading instances of PropertySourceLoader.\n\n环境是从一个或多个定义的 PropertySource 实例加载的, 这些实例是通过 标准 Java 服务加载器机制 通过加载 PropertySourceLoader 实例发现的\n\nA developer can extend Micronaut to load a PropertySource through an entirely custom mechanism by adding an additional implementation and the associated META-INF&#x2F;services&#x2F;io.micronaut.context.env.PropertySourceLoader file referencing this class.\n\n开发者可以通过一个完全定制的机制扩展 Micronaut 来加载 PropertySource, 方法是添加一个附加的实现和引用该类的相关 META-INF/services/io.micronaut.context.env.PropertySourceLoader 文件\n\nA high level different between a BeanContext and an ApplicationContext is illustrated below:\n\nBeanContext 和 ApplicationContext 之间的高级区别如下所示:\n\n\nAs seen above the ApplicationContext loads the Environment which is used for multiple purposes including:\n\n如上所示, ApplicationContext 加载用于多种目的的环境, 包括:\n\n通过 Bean Requirements 启用和禁用 beans\n允许通过 @Value 或 @Property 注入配置依赖项\n允许 Configuration Properties 绑定\n\nHTTP Server (HTTP 服务器)\nThe Micronaut HTTP server can be considered a Micronaut Module - that is a component of Micronaut that builds on the fundamental building blocks including Dependency Injection and the lifecycle of the ApplicationContext.\n\nMicronaut HTTP server 可以被认为是 Micronaut 的一个模块 - 这是一个建立于包含依赖注入和应用程序上下文生命周期的基础构建块的 Micronaut 组件\n\nThe HTTP server includes a set of abstract interfaces and common code contained with the micronaut-http and micronaut-http-server modules respectively (the former includes HTTP primitives shared across the client and the server).\n\nHTTP server 包含一组抽象接口和公共代码, 分别包含在 micronaut-http 和 micronaut-http-server 模块中 (前者包括在客户端和服务器之间共享的 HTTP 原语)\n\nA default implementation of these interfaces is provided based on the Netty I&#x2F;O toolkit the architecture of which is described in the image below:\n\n这些接口的默认实现是基于 Netty I&#x2F;O 工具包提供的, 其架构如下图所示:\n\n\nThe Netty API is in general a very low-level I&#x2F;O networking API designed for integrators to use to build clients and servers that present a higher abstraction layer. The Micronaut HTTP server is one such abstraction layer.\n\nNetty API 通常是一个非常低级别的 I&#x2F;O 网络 API, 专为集成商设计, 用于构建呈现更高抽象层的客户端和服务器. Micronaut HTTP 服务器就是这样一种抽象层\n\nAn architecture diagram of the Micronaut HTTP server and the components used in its implementation is described below:\n\nMicronaut HTTP server 的架构图及其实现中使用的组件描述如下:\n\n\nThe main entry point for running the server is the Micronaut class which implements ApplicationContextBuilder. Typically the developer places the following call into the main entry point of their application:\n\n运行服务器的主要入口点是实现了 ApplicationContextBuilder 的 Micronaut 类. 通常, 开发者将以下调用放入其应用程序的主入口:\nExample - Defining a main entry point:\npublic static void main(String[] args) &#123;    Micronaut.run(Application.class, args);&#125;\n\n\nThe passed arguments a transformed into a CommandLinePropertySource and available for dependency injection via @Value.\n\n传递的参数 args 转换为 CommandLinePropertySource 并可通过 @Value 进行依赖注入\n\nExecuting run will start the Micronaut ApplicationContext with the default settings and then search for a bean of type EmbeddedServer which is an interface that exposes information about a runnable server including host and port information.\n\n执行 run 将会使用默认设置启动 Micronaut ApplicationContext, 然后搜索 EmbeddedServer 类型的 bean, 该 bean 是公开有关可运行服务器的信息的接口, 包括主机和端口信息\n\nThis design decouples Micronaut from the actual server implementation and whilst the default server is Netty (described above), other servers can be implemented by third-parties simply by providing an implementation of EmbeddedServer.\n\n这种设计将 Micronaut 与实际的服务器实现解耦, 而默认服务器是 Netty (如上所述), 其他服务器可以由第三方简单地通过提供 EmbeddedServer 的实现来实现\nServer 如何启动的时序图如下所示:\n\n在使用 Netty 实现的情况下, EmbeddedServer 接口由 NettyHttpServer 实现\nServer Configuration (服务器配置)NettyHttpServer 读取 server 配置, 包括:\n\nNettyHttpServerConfiguration - HttpServerConfiguration 的扩展版本, 它定义了除 host, port 等之外的特定于 Netty 的配置选项\nEventLoopGroupConfiguration - 可以配置一个或多个 Netty EventLoopGroup, 可以将其配置为服务器独有的 或 与一个或多个 HTTP clients 共享的\nServerSslConfiguration - 为 ServerSslBuilder 提供配置, 用于配置 Netty SslContext 以用于 HTTPS\n\nServer Configuration Security Considerations (服务器配置安全注意事项)\nNetty’s SslContext provides an abstraction which allows using either the JDK-provided javax.net.ssl.SSLContext or an OpenSslEngine that requires the developer to additionally add netty-tcnative as a dependency (netty-tcnative is a fork of Tomcat’s OpenSSL binding).\n\nNetty 的 SslContext 提供了一个抽象, 这个抽象允许使用 JDK 提供的 javax.net.ssl.SSLContext 或者一个需要开发者添加附加的 netty-tcnative 作为依赖 (netty-tcnative 是 Tomcat’s OpenSSL binding 的分支) 的 OpenSslEngine\n\nThe ServerSslConfiguration allows configuring the application to a secure, readable location on disk where valid certificates exist to correctly configure the javax.net.ssl.TrustManagerFactory and javax.net.ssl.KeyManagerFactory by loading the configurtion from disk.\n\nServerSslConfiguration 允许将应用程序配置到磁盘上存在有效证书的安全, 可读位置, 以通过从磁盘加载配置来正确配置 javax.net.ssl.TrustManagerFactory 和 javax.net.ssl.KeyManagerFactory\nNetty Server Initialization (Netty 服务器初始化)当 NettyHttpServer 执行 start() 序列时, 它将执行如下步骤:\n\n读取 EventLoopGroupConfiguration 并创建启动 Netty server 所需的 parent 和 worker EventLoopGroup 实例\n计算要使用的特定于平台的 ServerSocketChannel (取决于操作系统, 这可能是 Epoll 或者 KQueue, 如果无法进行原生绑定, 则回退到 Java NIO)\n创建 ServerBoostrap 实例来初始化 SocketChannel (客户端和服务端之间的链接)\nSocketChannel 由 Netty ChannelInitializer 初始化, 它创建自定义的 Netty ChannelPipeline, 用于 Micronaut 以根据配置为 HTTP&#x2F;1.1 或 HTTP&#x2F;2 请求提供服务\nNetty ServerBootstrap 绑定到一个或多个配置端口, 有效地使服务器可用于接收请求\n触发两个 Bean 事件, 第一个 ServerStartupEvent 表示服务器已经启动, 最后一旦所有这些事件都处理完毕, 只有在设置了属性 micronaut.application.name 时才会触发 ServiceReadyEvent\n\n启动序列如下所示:\n\n\nA NettyHttpServerInitializer class is used to initialize the ChannelPipeline that handles incoming HTTP&#x2F;1.1 or HTTP&#x2F;2 requests.\n\n一个 NettyHttpServerInitializer 类被用来初始化处理传入的 HTTP&#x2F;1.1 或 HTTP&#x2F;2 请求的 ChannelPipeline\nChannelPipeline Security Considerations (ChannelPipeline 安全注意事项)\nThe ChannelPipeline can be customized by the user by implementing a bean that implements the ChannelPipelineCustomizer interface and adding a new Netty ChannelHandler to the pipeline.\n\nChannelPipeline 可以被用户自定义, 通过实现一个 bean, 这个 bean 实现 ChannelPipelineCustomizer 接口并添加一个新的 Netty ChannelHandler 到 pipeline 中\n\nAdding a ChannelHandler allows performing tasks such as wire-level logging of incoming and outgoing data packets and may be used when wire-level security requirements are required such as validating the bytes of the incoming request body or outgoing response body.\n\n添加 ChannelHandler 允许执行诸如传入和传出数据包的 wire-level 日志级别之类的任务, 并且可以在需要 wire-level 安全要求时使用, 例如验证传入请求正文或传出响应正文的字节\nNetty Server Routing (Netty 服务器路由)\nMicronaut defines a set of HTTP annotations that allow binding user code to incoming HttpRequest instances and customizing the resulting HttpResponse.\n\nMicronaut 定义了一组 HTTP 注解, 允许将该用户代码绑定到传入的 HttpRequest 实例并自定义生成的 HttpResponse\n\nOne or many configured RouteBuilder implementations construct instances of UriRoute which is used by the Router components to route incoming requests methods of annotated classes such as:\n\n一个或多个配置的 RouteBuilder 实现构造 UriRoute 实例, Router 组件使用 UriRoute 来路由被注解注释的类的传入请求方法, 例如:\nimport io.micronaut.http.MediaTypeimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Get@Controller(&#x27;/hello&#x27;)class HelloController &#123;    @Get(produces = MediaType.TEXT_PLAIN)    String index() &#123; &#x27;Hello World&#x27; &#125;&#125;\n\n请求绑定注解 可以用来绑定方法参数到 HTTP body, headers, parameters 等. 并且框架会在数据传输给接收方法之前自动处理正确的转义数据\n\nAn incoming request is received by Netty and a ChannelPipeline initialized by NettyHttpServerInitializer.\n\nNetty 接收传入的请求, 有 NettyHttpServerInitializer 初始化 ChannelPipeline\n\nThe incoming raw packets are transformed into a Netty HttpRequest which is subsequently wrapped in a Micronaut NettyHttpRequest which abstracts over the underlying Netty request.\n\n传入的原始数据包被转换为 Netty HttpRequest, 随后被包装在 Micronaut NettyHttpRequest 中, NettyHttpRequest 对底层 Netty 请求进行抽象\n\nThe NettyHttpRequest is passed through the chain of Netty ChannelHandler instances until it arrives at RoutingInBoundHandler which uses the aforementioned Router to match the request a method of an annotated @Controller type.\n\nNettyHttpRequest 通过 Netty ChannelHandler 实例链传递, 直到它到达 RoutingInBoundHandler, 它使用前面提到的 Router 将请求与带注解的 @Controller 类的方法相匹配\n\nThe RoutingInBoundHandler delegates to RouteExecutor for actual execution of the route, which deals with all the logic to dispatch to a method of an annotated @Controller type.\n\nRoutingInBoundHandler 委托给 RouteExecutor 以实际执行路由, 它处理所有逻辑以分派到带注解的 @Controller 类的方法\n\nOnce executed, if the return value is not null an appropriate MediaTypeCodec is looked up from the MediaTypeCodecRegistry for the response Content-Type (defaulting to application&#x2F;json).\n\n执行后, 如果返回值不为 null, 则从 MediaTypeCodecRegistry 中为响应 Content-Type 查找适当的 MediaTypeCodec (默认为 application/json)\n\nThe MediaTypeCodec is used to encode the return value into a byte[] and include it as the body of the resulting HttpResponse.\n\nMediaTypeCodec 用于将返回值编码为 byte[] 并将其作为结果 HttpResponse 的主体包含在内\n下图说明了传入请求的流程:\n\n\nThe RouteExecutor will construct a FilterChain to execute one or many HttpServerFilter prior executing the target method of an annotated @Controller type.\n\nRouteExecutor 将构造一个 FilterChain 来执行一个或多个 HttpServerFilter, 然后再执行带注解的 @Controller 类的目标方法\n\nOnce all of the HttpServerFilter instances have been executed the RouteExecutor will attempt to satisfy the requirements of the target method’s parameters, including any Request binding annotations.\n\n一旦所有 HttpServerFilter 实例都已执行, RouteExecutor 将尝试满足目标方法参数的要求, 包括任何请求绑定注解\n\nIf the parameters cannot be satisfied then a HTTP 400 - Bad Request HttpStatus response is returned to the calling client.\n\n如果无法满足参数, 则向调用客户端返回 HTTP 400 - Bad Request HttpStatus 响应\nNetty Server Routing Security Considerations (Netty 服务器路由安全注意事项)\nA HttpServerFilter instance can be used by the developer to control access to server resources. By not proceeding with the FilterChain an alternative response (such as a 403 - Forbidden) can be returned to the client barring access to sensitive resources.\n\n开发人员可以使用 HttpServerFilter 实例来控制对服务器资源的访问. 通过不继续使用 FilterChain, 可以将替代响应 (例如 403-Forbidden) 返回给客户端, 禁止访问敏感资源\n\nNote that the HttpServerFilter interface extends from the Ordered interface since it is frequently the case that multiple filters exist within a FilterChain.\n\n请注意, HttpServerFilter 接口从 Ordered 接口继承而来, 因为在 FilterChbain 中经常存在多个过滤器\n\nBy implementing the getOrder() method the developer can return an appropriate priority to control ordering.\n\n通过实现 getOrder() 方法, 开发者可以返回适当的优先级来控制排序\n\nIn addition, the ServerFilterPhase enum provides a set of constants developers can use to correctly position a filter, including a SECURITY phase where security rules are commonly placed.\n\n此外, ServerFilterPhabse 枚举提供了一组常量, 开发者可以使用它们来正确定位过滤器, 包括通常放置安全规则的 SECURITY 阶段\nFrequently Asked Questions (FAQ) (最常问的问题)\nThe following section covers frequently asked questions that you may find yourself asking while considering to use or using Micronaut.\n\n以下部分介绍了你在考虑使用或使用 Micronaut 时可能会发现的常见问题\nDoes Micronaut modify my bytecode? (Micronaut 修改了我的字节码吗?)\nNo. Your classes are your classes. Micronaut does not transform classes or modify the bytecode generated from the code you write. Micronaut produces additional classes at compile time in the same package as your original unmodified classes.\n\n没有. 你的类还是你的类. Micronaut 不会转换类或修改由你编写的代码生成的字节码. Micronaut 在编译时与原始未修改类的相同包中生成附加类\nWhy Doesn’t Micronaut use Spring? (为什么 Micronaut 不使用 Spring?)当问到为什么 Micronaut 不使用 Spring 时, 通常是指 Spring 依赖注入容器\nSpring 生态系统非常广泛, 你可以在 Micronaut 直接使用许多 Spring 库, 而无需 Spring 容器\nMicronaut 提供自己的原生的兼容 JSR-330 规范的依赖注入的原因是这些特性在 Spring (以及任何基于反射的 DI&#x2F;AOP 容器) 中的内存消耗和启动时间成本方面太大了\n为了支持运行时依赖注入, Spring:\n\n读取它在运行时找到的每个 bean 的字节码\n为每个 bean 方法, 构造方法, 字段等 上面的每个注解[合成新注解](Synthesizes new annotations for each annotation on each bean method, constructor, field etc. to support Annotation metadata.), 以支持注解元数据\n为每个 bean 的所有方法, 构造器, 字段等构建反射元数据\n\n结果是随着你的应用程序包含更多功能, 启动时间和内存消耗逐步恶化\n对于微服务和无服务函数来说, 保持启动时间和内存消耗保持在较低水平至关重要, 使用 Spring 容器的上述行为是不希望看到的, 因此 Micronaut 的设计者选择不使用 Spring\nDoes Micronaut support Scala? (Micronaut 支持 Scala 吗?)Micronaut 支持任何 支持注解处理器API 的 JVM 语言\nScala 目前不支持这个 API\n但是 Groovy 也不支持这个 API\n但是已经构建了处理 Groovy AST 的特殊支持\n如果构建类似于 inject-groovy 的模块, 将来技术上是可能支持 Scala 的, 但在撰写本文时不支持 Scala\nCan Micronaut be used for purposes other than Microservices? (Micronaut 可以用在其他用途而不是作为微服务吗?)可以\nMicronaut 非常模块化, 你可以选择仅使用依赖注入和 AOP 实现, 通过包含 micronaut-inject-java (或者为了使用 Groovy micronaut-inject-groovy) 依赖到你的应用程序中\n事实上, Micronaut 对无服务计算的支持正是使用了这种方法\nWhat are the advantages of Micronaut’s Dependency Injection and AOP implementation? (Micronaut 的依赖注入和 AOP 实现有什么优点?)Micronaut 处理你的类并在编译时生成所有元数据. 这消除了反射, 缓存反射元数据以及在运行时分析类的需要, 所有这些都会导致启动性能变慢和增加内存消耗\n除此之外, Micronaut 在编译时构建无反射 AOP 代理, 从而提高性能, 减少堆栈跟踪大小并减少内存消耗\nWhy does Micronaut have its own Consul and Eureka client implementations? (为什么 Micronaut 有自己的 Consul 和 Eureka 客户端实现?)现有的大多数 Consul 和 Eureka 客户端都是阻塞的, 并且包含许多使 JAR 文件膨胀的外部依赖项\nMicronaut 的 DiscoveryClient 使用 Microuant 的原生 HTTP 客户端, 大大减少了对外部依赖的需求, 并为两个发现服务器提供了响应式 API\nWhy am I encountering a NoSuchMethodError occurs loading my beans (Groovy)? (为什么我在加载我的 beans 时遇到了 NoSuchMethodError 问题?)\nGroovy by default imports classes in the groovy.lang package, including one named @Singleton, an AST transformation class that makes your class a singleton by adding a private constructor and static retrieval method.\n\nGroovy 默认导入 groovy.lang 包中的类, 包含了一个名称为 @Singleton 的注解, 一个 AST transformation 类来让你的类变成一个单例类, 通过添加一个 private 构造器和静态获取方法.\n\nThis annotation is easily confused with the javax.inject.Singleton annotation used to define singleton beans in Micronaut. Make sure you use the correct annotation in your Groovy classes.\n\n这个注解很容易与用在 Micronaut 中定义单例 bean 的 javax.inject.Singleton 注解混淆. 确保你在你的 Groovy 类中使用了正确的注解\nWhy is it taking much longer than it should to start the application? (为什么启动应用程序花费的时间比应有的时间长得多?)Micronaut 的启动时间通常非常快. 但是在应用程序级别, 可能会影响启动事件\n如果你遇到启动缓慢, 请查看所有减慢启动速度的应用程序启动监听器和 @Context 注释的 beans\n一些网络问题也可能导致启动缓慢. 例如, 在 Mac 上, /etc/hosts 文件的错误配置可能会导致问题出现. 请参阅一下 stackoverflow 答案\nUsing Snapshots (使用快照版本)Micronaut 里程碑版和稳定版本分发到 Maven Central\n一下代码片段展示了如何在 Gradle 中使用 Micronaut SNAPSHOT 版本. 最新的快照版本将始终是下一个补丁版本加 1 并附加 -SNAPSHOT\n例如, 如果最新版本是 “1.0.1”, 则当前快照将会是 “1.0.2-SNAPSHOT”:\next &#123;    micronautVersion = &#x27;2.4.0-SNAPSHOT&#x27;&#125;repositories &#123;    mavenCentral()  // 1    maven &#123; url &#x27;https://s01.oss.sonatype.org/content/repositories/snapshots/&#x27; &#125;    // 2&#125;\n\n1 : Micronaut releases are available on Maven Central\n2 : Micronaut snapshots are available on Sonatype OSS Snapshots\n使用 Maven 时, 编辑 pom.xml:\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;  ...  &lt;parent&gt;    &lt;groupId&gt;io.micronaut&lt;/groupId&gt;    &lt;artifactId&gt;micronaut-parent&lt;/artifactId&gt;    &lt;version&gt;2.4.0-SNAPSHOT&lt;/version&gt;  &lt;/parent&gt;  &lt;properties&gt;    &lt;micronaut.version&gt;2.4.0-SNAPSHOT&lt;/micronaut.version&gt;     ...  &lt;/properties&gt;  &lt;repositories&gt;    &lt;repository&gt;      &lt;id&gt;sonatype-snapshots&lt;/id&gt;      &lt;url&gt;https://s01.oss.sonatype.org/content/repositories/snapshots/&lt;/url&gt;     &lt;/repository&gt;  &lt;/repositories&gt;  ...&lt;/project&gt;\n\nCommon Problems (常见问题)以下部分介绍了开发者在使用 Micronaut 时遇到的常见问题\nDependency injection is not working (依赖注入不生效)依赖注入不生效的最常见原因是没有配置适当的注解处理器, 或者 IDE 没有正确配置\n有关如何使用你的语言进行配置, 请查阅语言支持的部分\nA NoSuchMethodError occurs loading beans (Groovy) (加载 beans 时出现 NoSuchMethodError)Groovy 默认导入 groovy.lang 包中的类, 包含了一个名称为 @Singleton 的注解, 一个 AST transformation 类来让你的类变成一个单例类, 通过添加一个 private 构造器和静态获取方法.\n这个注解很容易与用在 Micronaut 中定义单例 bean 的 javax.inject.Singleton 注解混淆. 确保你在你的 Groovy 类中使用了正确的注解\nIt is taking much longer to start my application than it should (*nix OS) (启动应用程序花费的时间比应有的时间长得多)\nThis is likely due to a bug related to java.net.InetAddress.getLocalHost() calls causing a long delay.\n\n这可能是由于一个bug, 这个 bug 是关于 java.net.InetAddress.getLocalHost() 调用导致的长时间延迟\n解决方案是修改你的 /etc/hosts 文件, 添加一个包含你的主机名的 entry\n要找到你的主机名, 在终端中运行 hostname\n然后编辑 /etc/hosts 文件来添加或改变如下面这样的 entries, 将 &lt;hostname&gt; 替换为你的主机名\n127.0.0.1       localhost &lt;hostname&gt;::1             localhost &lt;hostname&gt;\n\n要知道更多关于这个问题的信息, 查看这个 stackoverflow answer\nBreaking Changes略\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Application Configuration","url":"/micronaut/micronaut-application-configuration/","content":"\n\n\nApplication Configuration\nThe Environment (环境)\nEnvironment Priority (环境优先级)\nDisabling Environment Detection (关闭环境检测)\nDefault Environment (默认环境)\nMicronaut Banner (Micronaut Banner)\n\n\nExternalized Configuration with PropertySources (使用 PropertySource 的外部化配置)\nIncluded PropertySource Loaders (已经包含的 PropertySource 加载器)\nSupplying Configuration via Command Line (从命令行进行配置)\nSecrets and Sensitive Configuration (安全与敏感配置)\nProperty Value Placeholders (属性值占位符)\nProperty Value Binding (属性值绑定)\nUsing Random Properties (使用随机属性值)\nFail Fast Property Injection (快速失败的属性注入)\n\n\nConfiguration Injection (配置注入)\nUsing the @Value Annotation (使用 @Value 注解)\nUsing the @Property Annotation (使用 @Property 注解)\n\n\nConfiguration Properties (配置属性)\nIncludes Excludes (包含与排除)\nChange accessors style (改变访问风格)\nProperty Type Conversion (属性类型转换)\nDuration Conversion (持续时间转换)\nList or Array Conversion (列表和数组的转换)\nReadable Bytes (可读的字节)\nFormatting Dates (格式化的日期)\n\n\nConfiguration Builder (配置构建器)\nMapFormat (Map 格式)\n\n\nCustom Type Converters (自定义类型转换器)\nUsing @EachProperty to Drive Configuration (使用 @EachProperty 来驱动配置)\nList-Based Binding (基于列表的绑定)\n\n\nUsing @EachBean to Drive Configuration (使用 @EachBean 来驱动配置)\nImmutable Configuration (不可变配置)\nCustomizing accessors (自定义访问器)\n\n\nBootstrap Configuration (启动配置)\nBootstrap Context Beans (Bootstrap 上下文中的 Bean)\n\n\n\n\n\n\n\nApplication Configuration声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\n默认情况下, 可以在 Java properties, YAML, JSON 或者 Groovy files 中提供配置\n约定是搜索名称为 application.yml, application.properties, application.json 或者 application.groovy 的文件\n还可以通过系统属性或环境变量来覆盖任何配置属性\n每个配置源都使用 PropertySource 接口来建模, 并且这个机制是可以扩展的, 允许实现额外的 PropertySourceLoader 实现\nThe Environment (环境)应用程序环境被建模为 Environment 接口, 这个接口允许在创建一个 ApplicationContext 时定义一个或多个唯一环境名称\nExample - Initialing the Environment:\nwhen:ApplicationContext applicationContext = ApplicationContext.run(&quot;test&quot;, &quot;android&quot;)Environment environment = applicationContext.getEnvironment()then:environment.activeNames.contains(&quot;test&quot;)        // 定义了多个环境名称environment.activeNames.contains(&quot;android&quot;)     // 定义了多个环境名称\n\n激活的环境名允许根据环境加载不同的配置文件, 还可以使用 @Requires 注解来条件化加载 Beans 或 Bean @Configuration 包\n除此之外, Micronaut 还会尝试检测当前的环境, 例如在 Spock 和 JUnit 测试中, io.micronaut.context.env.Environment.TEST 是自动激活的环境\nio.micronaut.context.env.Environment 接口定义了一些预定义好的环境名称\n可以通过 micronaut.environments 系统属性或者 MICRONAUT_ENVIRONMENTS 环境变量来指定激活的环境, 多个环境名称使用逗号进行分隔:\njava -Dmicronaut.environments=foo,bar -jar myapp.jar\n\nEnvironment Priority (环境优先级)Micronaut 基于指定的环境来加载属性源, 不同环境的属性源可能多个相同的属性名称, 使用环境的顺序来指明使用哪个属性值\nMicronaut 使用如下优先级来处理(越下面优先级越高):\n\n推断的环境\n系统属性 micronaut.environments 设置的环境\n环境变量 MICRONAUT_ENVIRONMENTS 设置的环境\n通过应用程序上下文 Builder 明确指定的环境\n\nDisabling Environment Detection (关闭环境检测)可以通过将 系统属性micronaut.env.deduction 和 环境变量MICRONAUT_ENV_DEDUCTION 设置为 false 来关闭环境自动检测\n关闭了环境自动检测, 但是还是会使用手动指定的环境\nExample - 通过系统属性来关闭环境自动检测:\njava -Dmicronaut.env.deduction=false -jar myapp.jar\n\n还可以通过使用 ApplicationContextBuilder.#deduceEnvironment 方法来设置你的应用程序:\nvoid &#x27;test disable environment deduction via builder&#x27;() &#123;    when:    ApplicationContext ctx = ApplicationContext.builder().deduceEnvironment(false).start()    then:    !ctx.environment.activeNames.contains(Environment.TEST)    cleanup:    ctx.close()&#125;\n\nDefault Environment (默认环境)Micronaut 支持一个或多个默认环境\npublic static void main(String[] args) &#123;    Micronaut.build(args)             .mainClass(Application.class)             .defaultEnvironments(&quot;dev&quot;)             .start()&#125;\n\nMicronaut Banner (Micronaut Banner)如果要使用自定义的 Manner, 将自定义的 ASCII Art 放置到 src/main/resources/micronaut-banner.txt 文件中\n关闭 Banner:\npublic class Application &#123;    public static void main(String[] args) &#123;        Micronaut.build(args)                 .banner(false)                 .start();    &#125;&#125;\n\nExternalized Configuration with PropertySources (使用 PropertySource 的外部化配置)额外的 PropertySource 实例可以在初始化 ApplicationContext 之前被添加到环境中\nwhen:ApplicationContext applicationContext = ApplicationContext.run(                                            PropertySource.of(                                                &quot;test&quot;,                                                [                                                    &quot;micronaut.server.host&quot;: &quot;foo&quot;,                                                    &quot;micronaut.server.port&quot;: 8080                                                ]                                            ),                                            &quot;test&quot;,                                            &quot;android&quot;                                        )Environment environment = applicationContext.getEnvironment()then:&quot;foo&quot; == environment.getProperty(&quot;micronaut.server.host&quot;, String.class).orElse(&quot;localhost&quot;)\n\n\nAlternatively one can register a PropertySourceLoader by creating a META-INF&#x2F;services&#x2F;io.micronaut.context.env.PropertySourceLoader file containing a reference to the class name of the PropertySourceLoader.\n\nIncluded PropertySource Loaders (已经包含的 PropertySource 加载器)Micronaut 默认已经包含了一些从给定的位置和优先级加载属性的 PropertySourceLoader 实现\n\n命令行参数\n来自 SPRING_APPLICATION_JSON 的属性\n来自 MICRONAUT_APPLICATION_JSON 的属性\nJava 系统属性\n操作系统环境变量\n按顺序从系统属性 micronaut.config.files 或者 环境变量 MICRONAUT_CONFIG_FILES 指定的配置文件中加载. 文件路径可以使用逗号来分隔多个, 按文件声明的先后顺序明确优先级. 文件可以从文件系统中获取, 也可以使用 classpath: 前缀从类路径中获取\n从 application-&#123;environment&#125;.&#123;extension&#125; 中获取环境指定属性\n从 application.&#123;extension&#125; 获取应用程序指定属性\n\n默认支持 .properties,.json,yml, 还支持 .groovy\nSupplying Configuration via Command Line (从命令行进行配置)使用 Gradle&#x2F;Maven 时可以在命令行中进行配置\nGradle: ./gradlew run --args=&quot;-endpoints.health.enabled=true -config.property=test&quot;\nMaven: ./mvnw mn:run -Dmn.appArgs=&quot;-endpoints.health.enabled=true -config.property=test&quot;\n必须要在 main 方法将这些参数传递到 Context Builder 中, 才能使得这些配置生效:\nimport io.micronaut.runtime.Micronaut;public class Application &#123;    public static void main(String[] args) &#123;        Micronaut.run(Application.class, args);// passing args    &#125;&#125;\n\nSecrets and Sensitive Configuration (安全与敏感配置)不要将敏感信息例如密码直接存放到配置文件中\n要将敏感信息外部化到密码管理系统中(there are many options here, many provided by Cloud providers)\n可以使用属性占位符, 来自定义一个环境变量的名称并提供默认值:\nExample - Using Property Value Placeholders to Define Secure Configuration:\ndatasource:    default:        url: $&#123;JDBC_URL:`jdbc:mysql://localhost:3306/db`&#125;        username: $&#123;JDBC_USER:root&#125;        password: $&#123;JDBC_PASSWORD:&#125;        dailetc: MYSQL        driverClassName: $&#123;JDBC_DRIVER:com.mysql.cj.jdbc.Driver&#125;\n\n为了安全外部化配置，可以考虑使用microaut支持的安全管理系统:\n\nHashiCorp Vault\nKubernetes Secrets\n\nProperty Value Placeholders (属性值占位符)可以在 配置值(configuration values) 和 任何Micronaut注解 中使用 属性占位符语法 来引用 配置属性(configuration properties)\n可以使用 PropertyPlaceholderResolver 接口来编码式地获取配置属性\n基础语法是: $&#123;...&#125;:\nExample - Defining Property Placeholders:\nmyapp:    endpoint: http://$&#123;micronaut.server.host&#125;:$&#123;micronaut.server.port&#125;/foo\n\nExample - 在 : 字符后面定义默认值:\nmyapp:    endpoint: http://$&#123;micronaut.server.host:localhost&#125;:$&#123;micronaut.server.port:8080&#125;/foo\n\n在寻找不到指定的配置属性时, 将会会用 : 字符后面的默认值, 而不是抛出一个异常\n如果 : 字符后面的属性值包含了 : 字符, 那么需要进行转义:\nmyapp:    endpoint: $&#123;server.address:`http://localhost:8080`&#125;/foo\n\nProperty Value Binding (属性值绑定)在代码中放置引用或在占位符值中应该使用 kebab case(lowercase and hyphen-separated) 小写加横线来指明属性引用\n例如, 使用 micronaut.server.default-charset 而不是 micronaut.server.defaultCharset\nMicronaut 仍然允许在配置中指定 micronaut.server.defaultCharset, 因为 Micronaut 会自动将这样的配置进行转换来优化内存使用和减少解析配置的复杂度:\nTable - Property Value Normalization:\n\n\n\nConfiguration Value\nResulting Properties\nProperty Source\n\n\n\nmyApp.myStuff\nmy-app.my-stuff\nProperties, YAML etc.\n\n\nmy-app.myStuff\nmy-app.my-stuff\nProperties, YAML etc.\n\n\nmyApp.my-stuff\nmy-app.my-stuff\nProperties, YAML etc.\n\n\nMYAPP_MYSTUFF\nmyapp.mystuff, my-app.my-stuff\nEnvironment Variable\n\n\nMY_APP_MY_STUFF\nmy.app.my.stuff, my.app.my-stuff, my.app-my.stuff, my.app-my-stuff, my-app.my.stuff, my-app.my-stuff, my-app-my.stuff, my-app-my-stuff\nEnvironment Variable\n\n\n不可以通过驼峰命名来引用一个环境变量\n可以在 Micronaut Builder 中调用方法来控制环境属性怎么样参与到配置中:\nimport io.micronaut.runtime.Micronautclass Application &#123;    static void main(String[] args) &#123;        Micronaut.build()                 .mainClass(Application)                 .environmentPropertySource(false)                 //or                 .environmentVariableIncludes(&quot;THIS_ENV_ONLY&quot;)                 //or                 .environmentVariableExcludes(&quot;EXCLUDED_ENV&quot;)                 .start()    &#125;&#125;\n\n上面的配置对于属性占位符没有任何影响, 所以还是可以通过属性占位符来获取一个环境变量\nUsing Random Properties (使用随机属性值)Example:\nmicronaut:    application:        name: myapplication        instance:            id: $&#123;random.shortuuid&#125;\n\nTable - Random Values:\n\n\n\nProperty\nValue\n\n\n\nrandom.port\nAn available random port number\n\n\nrandom.int\nRandom int\n\n\nrandom.integer\nRandom int\n\n\nrandom.long\nRandom long\n\n\nrandom.float\nRandom float\n\n\nrandom.shortuuid\nRandom UUID of only 10 chars in length(Note: As this isn’t full UUID, collision COULD occur)\n\n\nrandom.uuid\nRandom UUID with dashes\n\n\nrandom.uuid2\nRandom UUID without dashes\n\n\n数值随机还支持范围和最大值\ninstance:    id: $&#123;random.int[-5, 10]&#125;    count: $&#123;random.int(5)&#125;\n\n$&#123;random.int[-5, 10]&#125;: 包含 -5 到 9 的整数\n$&#123;random.int(5) : 最大值是 5 的随机整数\nFail Fast Property Injection (快速失败的属性注入)对于需要注入属性的 Bean 来说, 注入和潜在的异常会在 Bean 被请求的时候才会发生\n为了在应用启动的时候检查 Bean 中的属性是否存在或是否可以转换或是否可以注入, 可以将 Bean 使用 @Context 进行修饰, 将 Bean 的生命周期绑定到 Context 启动时\nConfiguration Injection (配置注入)使用 @Value 注解将配置值注入到 Bean 中\nUsing the @Value Annotation (使用 @Value 注解)Example:\nimport io.micronaut.context.annotation.Valueimport jakarta.inject.Singleton@Singletonclass EngineImpl implements Engine &#123;    @Value(&#x27;$&#123;my.engine.cylinders:6&#125;&#x27;)    protected int cylinders    @Override    int getCylinders() &#123;        cylinders    &#125;    @Override    String start() &#123;        &quot;Starting V$cylinders Engine&quot;    &#125;&#125;\n\n必须使用 $&#123;...&#125; 的语法\n在 : 字符后面添加默认值\n@Value 的注解还可以用来注入一个静态值: @Value(&quot;10&quot;) int number\n这在注入一个包含静态内容和占位符的属性时非常有用: @Value(&quot;http://$&#123;my.host&#125;:$&#123;my.host&#125;&quot;) URL url\n如果默认值中包含了 : 字符, 则必须进行转义: @Value(&quot;$&#123;my.url:http://foo.com&#125;&quot;) URL url\n得益于 Micronaut 对注解元数据的广泛支持, 你可以在任何注解上使用占位符表达式:\n@Controller(&quot;$&#123;hello.controller.path:/hello&#125;&quot;)class HelloController &#123;&#125;\n\n@Client(&quot;$&#123;my.server.url:`http://localhost:8080`&#125;&quot;)interface HelloClient &#123;&#125;\n\nUsing the @Property Annotation (使用 @Property 注解)\nThis is because @Value only resolves placeholders within the value specified to it.\n\n@Value 注解必须使用 $&#123;...&#125; 语法来引用配置值, 如果传入普通字符串, 就只会将这个字符串注入到 Bean 属性中\n可以使用 @Property 注解来直接使用属性名称来引用属性值: @Property(name = &quot;my.engine.manufacturer&quot;) String manufacturer\n但是 @Property 不能指定默认值, 如果指定的属性名称没有对应的属性值, Bean 将会实例化失败, 可以使用 @Nullable 注解来说明属性值是可选的, 来防止注入失败\n@Property 注解还可以用来解析 sub maps:\ndatasources:  default:    name: &#x27;mydb&#x27;jpa:  default:    properties:      hibernate:        hbm2ddl:          auto: update        show_sql: true\n\n为了使用 hibernate 开头的属性, 这样使用 @Property 注解:\n@Property(name = &quot;jpa.default.properties&quot;)Map&lt;String, String&gt; jpaProperties;\n\n将会将 key 为 hibernate.hbm2dll.auto 和 hibernate.show_sql 的键值对放到 Map 中\n可以使用 @MapFormat 来指定 key 的形式\nConfiguration Properties (配置属性)通过创建一个使用 @ConfigurationProperties 注解修饰的类来创建类型安全的配置\nMicronaut 将会提供一个无反射的 @ConfigurationProperties Bean, 还会在编译时计算属性路径来进行评估, 极大地提高了加载效率\nExample:\nimport io.micronaut.context.annotation.ConfigurationPropertiesimport javax.validation.constraints.Minimport javax.validation.constraints.NotBlank@ConfigurationProperties(&quot;my.engine&quot;)   // @ConfigurationPropertis 注解使用配置前缀class EngineConfig &#123;    @NotBlank                           // 可以使用 javax.validation 注解来校验配置    String manufacturer = &quot;Ford&quot;        // 可以设置默认值到属性中    @Min(1L)    int cylinders    CrankShaft crankShaft = new CrankShaft()    @ConfigurationProperties(&#x27;crank-shaft&#x27;)             // 静态内部类提供嵌入式的配置    static class CrankShaft &#123;                Optional&lt;Double&gt; rodLength = Optional.empty()   // 可以使用 java.util.Optional 包装可选的配置值    &#125;&#125;\n\n一旦你准备好了一个 类型安全的 配置, 这个配置就可以像其他 Bean 被注入到 Bean 中\n属性值可以从其中一个 PropertySource 实例中提供:\nApplicationContext applicationContext = ApplicationContext.run(    [&#x27;my.engine.cylinders&#x27;: &#x27;8&#x27;],    &#x27;test&#x27;)def vehicle = applicationContext.getBean(Vehicle)println(vehicle.start())\n\n可以直接在 @Requires 中引用这个配置 Bean 来进行条件化加载: @Requires(bean=Config.class, beanProperty=&quot;propertyName&quot;, value=&quot;true&quot;)\n可以通过继承 @ConfigurationProperties Bean 来进行更复杂的配置\n例如, 一个使用 @ConfigurationProperties(&#39;bar&#39;) 修饰的子类 EngineConfig 将会解析所有在 my.engine.bar 下的属性\nIncludes Excludes (包含与排除)可以在 @ConfigurationProperties 中指定要包含或排除的属性, 在子类中也可以排除父类中的属性\n属性名称必须一一对应\nChange accessors style (改变访问风格)可以使用 @AccessorsStyle 注解来修改属性的访问方式\nimport io.micronaut.context.annotation.ConfigurationPropertis;import io.micronaut.core.annotation.AccessorsStyle;@AccessorsStyle(readPrefixes = &quot;&quot;, writePrefixes = &quot;&quot;)@ConfigurationProperties(&quot;my.engie&quot;)public class EngineConfig &#123;    String manufacturer    public String manufacturer() &#123; manufacturer &#125;&#125;\n\nProperty Type Conversion (属性类型转换)Micronaut 使用 ConversionService Bean 来在解析配置属性时进行转换\n你可以通过实现 TypeConverter 接口来注册额外的转换器\nMicronaut 提供了一些内置的转换器\nDuration Conversion (持续时间转换)持续时间可以通过添加一个单位来进行指定\nTable - Duration Conversion:\n\n\n\nConfiguration Value\nResulting Value\n\n\n\n10ms\nDuration of 10 milliseconds\n\n\n10m\nDuration of 10 minutes\n\n\n10s\nDuration of 10 seconds\n\n\n10d\nDuration of 10 days\n\n\n10h\nDuration of 10 hours\n\n\n10ns\nDuration of 10 nanoseconds\n\n\nPT15M\nDuration of 15 minutes using ISO-8601 format\n\n\nExample - Configure the default HTTP Client read timeout:\nmicronaut:    http:        client:            read-timeout: 15s\n\nList or Array Conversion (列表和数组的转换)使用泛型来转换配置\nExample - Specifying lists or arrays in YAML:\nmy:    app:        integers:            - 1            - 2        urls:            - http://foo.com            - http://bar.com\n\nExample - Java properties file format:\nmy.app.integers=1,2my.app.urls=http://foo.com,http://bar.com\n\nExample - Specifying lists or arrays in Java properties using index:\nmy.app.integers[0]=1my.app.integers[1]=2\n\nExample - Defining properties to bind to with the target type supplied via generics:\nList&lt;Integer&gt; integers;List&lt;URL&gt; urls;\n\nReadable Bytes (可读的字节)在 setter 方法参数上使用 @ReadableBytes 注解来允许使用可读性的字节语法来声明属性值:\npublic void setMaxContentLength(@ReadableBytes int maxContentLength) &#123;    this.maxContentLength = maxContentLength&#125;\n\n可以这样配置 micronaut.http.client.max-content-length 的属性值:\nTable - @ReadableBytes Conversion:\n\n\n\nConfiguration Value\nResulting Value\n\n\n\n10mb\n10 megabytes\n\n\n10kb\n10 kilobytes\n\n\n10gb\n10 gigabytes\n\n\n1024\nA raw byte length\n\n\nFormatting Dates (格式化的日期)@Format 注解可以用在 setter 方法参数来将指定格式的日期绑定到 java.time 类型对象上:\nExample - Using @Format for Dates:\npublic void setMyDate(@Format(&quot;yyyy-MM-dd&quot;) LocalDate date) &#123;    this.myDate = date;&#125;\n\nConfiguration Builder (配置构建器)import io.micronaut.context.annotation.ConfigurationBuilderimport io.micronaut.context.annotation.ConfigurationProperties@ConfigurationProperties(&#x27;my.engine&#x27;) // class EngineConfig &#123;    @ConfigurationBuilder(prefixes = &quot;with&quot;) //     EngineImpl.Builder builder = EngineImpl.builder()    @ConfigurationBuilder(prefixes = &quot;with&quot;, configurationPrefix = &quot;crank-shaft&quot;) //     CrankShaft.Builder crankShaft = CrankShaft.builder()    SparkPlug.Builder sparkPlug = SparkPlug.builder()    @ConfigurationBuilder(prefixes = &quot;with&quot;, configurationPrefix = &quot;spark-plug&quot;) //     void setSparkPlug(SparkPlug.Builder sparkPlug) &#123;        this.sparkPlug = sparkPlug    &#125;&#125;\n\nMapFormat (Map 格式)将配置以 flat map 或者 nested map 的形式应用到一个 Bean 中\n因为有些第三方库可以接收 Map 作为配置参数\n使用 @MapFormat 注解来绑定一个 Map 到单独一个配置属性中, 然后指定是否接受为一个 flat map 还是一个 nested map\nExample:\nimport io.micronaut.context.annotation.ConfigurationPropertiesimport io.micronaut.core.convert.format.MapFormatimport javax.validation.constraints.Min@ConfigurationProperties(&#x27;my.engine&#x27;)class EngineConfig &#123;    @Min(1L)    int cylinders    @MapFormat(transformation = MapFormat.MapTransformation.FLAT)    Map&lt;Integer, String&gt; sensors&#125;@Singletonclass EngineImpl implements Engine &#123;    @Inject    EngineConfig config    @Override    Map getSensors() &#123;        config.sensors    &#125;    @Override    String start() &#123;        &quot;Engine Starting V$config.cylinders [sensors=$&#123;sensors.size()&#125;]&quot;    &#125;&#125;ApplicationContext applicationContext = ApplicationContext.run(    [&#x27;my.engine.cylinders&#x27;: &#x27;8&#x27;,     &#x27;my.engine.sensors&#x27;  : [                                0: &#x27;thermostat&#x27;,                                1: &#x27;fuel pressure&#x27;                            ]    ],    &#x27;test&#x27;)def vehicle = applicationContext.getBean(Vehicle)println(vehicle.start())\n\nCustom Type Converters (自定义类型转换器)注册一个实现 TypeConverter 接口的 Bean, 实现 convert() 方法\nUsing @EachProperty to Drive Configuration (使用 @EachProperty 来驱动配置)使用 @EachProperty 注解来为一个配置属性中的每个子属性创建一个 ConfigurationProperties Bean:\nExample - Using @EachProperty:\nimport io.micronaut.context.annotation.EachPropertyimport io.micronaut.context.annotation.Parameter@EachProperty(&quot;test.datasource&quot;)class DataSourceConfiguration &#123;    final String name    URI url = new URI(&quot;localhost&quot;)    // The @Parameter annotation can be used to inject the name of the sub-property that defines the name of the bean (which is also the bean qualifier)    DataSourceConfiguration(@Parameter String name) throws URISyntaxException &#123;        this.name = name    &#125;&#125;ApplicationContext applicationContext = ApplicationContext.run(    PropertySource.of(        &#x27;test&#x27;,        [            &#x27;test.datasource.one.url&#x27;: &#x27;jdbc:mysql://localhost/one&#x27;,            &#x27;test.datasource.two.url&#x27;: &#x27;jdbc:mysql://localhost/two&#x27;,        ]    ))when:Collection&lt;DataSourceConfiguration&gt; beansOfType = applicationContext.getBeansOfType(DataSourceConfiguration.class)assertEquals(2, beansOfType.size())DataSourceConfiguration firstConfig = applicationContext.getBean(        DataSourceConfiguration.class,        Qualifiers.byName(&quot;one&quot;) // Individual beans can be retrieved by using the byName qualifier)then:new URI(&quot;jdbc:mysql://localhost/one&quot;) == firstConfig.getUrl()\n\nList-Based Binding (基于列表的绑定)@EachProperty 默认是绑定一个 Map 风格的配置, Key 是 Bean 的命名 qualifier\n如果要从一个 List 来进行绑定:\nimport io.micronaut.context.annotation.EachPropertyimport io.micronaut.context.annotation.Parameterimport io.micronaut.core.order.Orderedimport java.time.Duration@EachProperty(value = &quot;ratelimits&quot;, list = true)class RateLimitsConfiguration implements Ordered &#123;    private final Integer index    Duration period    Integer limit    RateLimitsConfiguration(@Parameter Integer index) &#123;        this.index = index    &#125;    @Override    int getOrder() &#123; index &#125;&#125;\n\nUsing @EachBean to Drive Configuration (使用 @EachBean 来驱动配置)将 @EachProperty 注解和 @EachBean 注解搭配使用, 来将 @EachProperty 注解生成的多个配置 Bean 来生成多个 Bean\n@Factoryclass DataSourceFactory &#123;    @EachBean(DataSourceConfiguration)  // 2    DataSource dataSource(DataSourceConfiguration configuration) &#123;  // 3        URI url = configuration.url        return new DataSource(url)    &#125;&#125;\n\n2 : @EachBean 注解指明了将会为每个 DataSourceConfiguration Bean 创建一个新的 DataSource Bean\n3 : DataSourceConfiguration 实例作为一个方法参数注入, 用来驱动每个 javax.sql.DataSource 的配置\n@BeanProperty 要求 父Bean 要有一个 @Named qualifier, 因为这个 qualifier 由 @EachBean 创建的每个 Bean 继承\nImmutable Configuration (不可变配置)有两种方式来定义不可变配置, 推荐定义一个使用 @ConfigurationProperties 注解修饰的接口:\nExample - @ConfigurationProperties 注解:\nimport io.micronaut.context.annotation.ConfigurationPropertiesimport io.micronaut.core.bind.annotation.Bindableimport javax.validation.constraints.Minimport javax.validation.constraints.NotBlankimport javax.validation.constraints.NotNull@ConfigurationProperties(&quot;my.engine&quot;)       // 这个注解接收一个前缀并声明在一个接口上interface EngineConfig &#123;    @Bindable(defaultValue = &#x27;Ford&#x27;)        // 使用 @Bindable 注解来设置一个默认值    @NotBlank                               // 校验注解也是可以使用的    String getManufacturer()    @Min(1L)    int getCylinders()    @NotNull    CrankShaft getCrankShaft()              // 指定一个引用到另一个 @ConfigurationProperties Bean    @ConfigurationProperties(&quot;crank-shaft&quot;)    static interface CrankShaft &#123;           // 可以内嵌一个不可变配置        Optional&lt;Double&gt; getRodLength()     // 可以将配置值包装为一个 Optional, 或者使用 @Nullable 注解来修饰    &#125;&#125;\n\nMicronaut 将会为这个接口创建一个编译时的实现, 将所有的 getter 方法调用委托给 Environment 接口的 getProperty(..) 方法\n这样做的好处是如果应用的配置是可以变的话(例如请求 /refresh 端点), 注入的接口将会自动获取到最新的值\n如果尝试声明任何其他不是 getter 方法的抽象方法, 将会导致编译时异常抛出(支持default methods)\n另一个方法来实现不可变配置是定义一个类并使用 @ConfigurationInject 注解在一个 @ConfigurationProperties 或 @EachProperty 注解修饰的 Bean 的构造方法上. 略\nCustomizing accessors (自定义访问器)使用 @AccessorsStyle 注解来定义属性的访问前缀\nimport io.micronaut.context.annotation.ConfigurationProperties;import io.micronaut.core.annotation.AccessorsStyle;import io.micronaut.core.bind.annotation.Bindable;import javax.validation.constraints.Min;import javax.validation.constraints.NotBlank;import javax.validation.constraints.NotNull;import java.util.Optional;@ConfigurationProperties(&quot;my.engine&quot;) @AccessorsStyle(readPrefixes = &quot;read&quot;) public interface EngineConfigAccessors &#123;    @Bindable(defaultValue = &quot;Ford&quot;)    @NotBlank    String readManufacturer();     @Min(1L)    int readCylinders();     @NotNull    CrankShaft readCrankShaft();     @ConfigurationProperties(&quot;crank-shaft&quot;)    @AccessorsStyle(readPrefixes = &quot;read&quot;)     interface CrankShaft &#123;        Optional&lt;Double&gt; readRodLength();     &#125;&#125;\n\nBootstrap Configuration (启动配置)在一个 Application context 创建之前, 一个 bootstrap context 将会被创建, 用来存储必要的配置, 用来获取关于主 Context 的额外的配置\n通常这些额外配置在一些远程源上\nbootstrap context 是否开启取决于以下条件, 以下条件按顺序进行检查:\n\nBOOTSTRAP_CONTEXT_PROPERTY 系统属性是否配置了\napplication context builder 选项 bootstrapEnvironment 是否有设置\nBootstrapPropertySourceLoader Bean 是否存在, 通常这个 Bean 来自 micronaut-discovery-client 依赖\n\n配置属性必须在 application context 配置文件解析之前提供, 例如在使用分布式配置时, 配置属性被保存在一个 bootstrap configuration file 中\n一旦明确了 bootstrap context 是开启的, bootstrap 配置文件将会使用普通 application 配置的规则进行读取, 唯一的不同是前缀(bootstrap 代替 application)\n文件名称前缀 bootstrap 使用系统属性 micronaut.bootstrap.name 来配置\nbootstrap context configuration 自动被带到 main context, 所以没有必要在 main context 中重复这些配置属性\nbootstrap context configuration 比 main context configuration 有更高的优先级, 这意味着如果一个配置属性要在两个 context 出现, 将这个属性配置放到 bootstrap context configuration 中\nBootstrap Context Beans (Bootstrap 上下文中的 Bean)一个 Bean 要被解析在 bootstrap context 中, 这个 Bean 必须使用 @BootstrapContextCompatible 注解来修饰\n特别是任何参与到获取分布式配置的 Bean 必须要使用这个注解\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Aspect Oriented Programming","url":"/micronaut/micronaut-aspect-oriented-programming/","content":"\n\n\nAspect Oriented Programming\nAround Advice (环绕通知)\nWriting Around Advice (编写环绕通知)\nCustomizing Proxy Generation (自定义代理的生成)\nAOP Advice on @Factory Beans (在 @Factory Beas 上的 AOP 通知)\n\n\nIntroduction Advice (引入 Advice)\nMethod Adapter Advice (方法适配器 Advice)\nBean Life Cycle Advice (Bean 生命周期 Advice)\nValidation Advice (校验 Advice)\nCache Advice (缓存 Advice)\nCache Annotations (缓存注解)\nConfiguration Caches (配置缓存)\nNaming Caches (命名缓存)\n\n\nDynamic Cache Creation (动态缓存创建)\n\n\nRetry Advice (重试 Advice)\nSimple Retry (简单重试)\nReactive Retry (响应式重试)\nCircuit Breaker (断路器)\nFactory Bean Retry (工厂 Bean 重试)\nRetry Events (重试事件)\n\n\nScheduled Tasks (定期任务)\nUsing the @Scheduled Annotation (使用 @Scheduled 注解)\nScheduling at a Fixed Rate (在一个固定频率上调度)\nScheduling with a Fixed Delay (在一个固定的延迟后调度)\nScheduling a Cron Task (在 Cron 配置的时间上调度)\nScheduling with only a Initial Delay (在仅仅一个延迟之后进行调度)\n\n\nProgrammatically Scheduling Tasks (编程式任务调度)\nConfiguring Scheduled Tasks with Annotation Metadata (使用注解元数据配置调度任务)\nConfiguring the Scheduled Task Thread Pool (配置调度任务线程池)\nHandling Exceptions (处理异常)\nBridging Spring AOP (桥接 Spring AOP)\n\n\n\n\n\n\n\nAspect Oriented Programming\nGenerally AOP can be thought of as a way to define cross-cutting concerns (logging, transactions, tracing, etc.) separate from application code in the form of aspects that define advice.\n\n通常来说 AOP 可以被认为是定义横切关注点(日志, 事务, 跟踪等)的一种方式, 它以定义通知的方面的形式与应用程序代码分开\n通常有两种形式的 通知(advice):\n\n环绕通知(Around Advice), 包装一个方法或类\n引导通知(Introduction Advice), 引入一个新的行为到一个类中\n\n在现代的 Java 应用程序中, 声明 通知(advice) 通常使用注解的形式. Java 世界中最出名的注解通知(advice)可能是 @Transactional, 这个注解标定了 Spring 和 Grails 应用程序中的事务边界\n传统 AOP 实现的缺点是非常依赖运行时代理创建和使用反射, 拖慢了应用程序的性能, 使调试更加困难, 增加了内存消耗\nMicronaut 尝试解决这些问题, 通过提供一个简单的不使用反射的编译时 AOP API\nAround Advice (环绕通知)声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\n环绕通知允许你包装一个方法的行为\nWriting Around Advice (编写环绕通知)第一步是编写一个触发 MethodInterceptor 的注解:\nExample - Around Advice Annotation:\nimport io.micronaut.aop.Aroundimport java.lang.annotation.*import static java.lang.annotation.ElementType.*import static java.lang.annotation.RetentionPolicy.RUNTIME@Documented@Retention(RUNTIME)         // 保留策略必须为 RUNTIME@Target([TYPE, METHOD])     // 声明注解应用于类和方法上@Around                     // 使用 @Around 注解来告诉 Micronaut 这个注解是环绕通知的@interface NotNull &#123;&#125;\n\n第二步是实现一个 MethodInterceptor:\nExample - MethodInterceptor:\nimport io.micronaut.aop.InterceptorBeanimport io.micronaut.aop.MethodInterceptorimport io.micronaut.aop.MethodInvocationContextimport io.micronaut.core.annotation.Nullableimport io.micronaut.core.type.MutableArgumentValueimport jakarta.inject.Singleton@Singleton@InterceptorBean(NotNull)   // 1class NotNullInterceptor implements MethodInterceptor&lt;Object, Object&gt; &#123;     // 2    @Nullable    @Override    Object intercept(MethodInvocationContext&lt;Object, Object&gt; context) &#123;        Optional&lt;Map.Entry&lt;String, MutableArgumentValue&lt;?&gt;&gt;&gt; nullParam = context.parameters                                                                                .entrySet()                                                                                .stream()                                                                                .filter(&#123;entry -&gt;                                                                                    MutableArgumentValue&lt;?&gt; argumentValue = entry.value                                                                                    return Objects.isNull(argumentValue.value)                                                                                &#125;)                                                                                .findFirst()        // 3        if (nullParam.present()) &#123;            throw new IllegallArgumentException(&quot;Null parameter [$&#123;nullParam.get().key&#125;] not allowed&quot;)      // 4        &#125;        return context.proceed()        // 5    &#125;&#125;\n\n1 : @InterceptorBean 注解用来指明当前 interceptor 和哪个注解关联. @InterceptorBean 是一个元注解, 默认作用域是 @Singleton, 因此如果要在每个关联拦截的地方创建一个新的拦截器, 使用 @Prototype 注解来修饰当前拦截器\n2 : 一个实现了 MethodInterceptor 接口的拦截器\n3 : 传入的 MethodInvocationContext 用来寻找第一个为 null 的参数\n4 : 如果有一个参数是 null 的, 那么抛出一个异常\n5 : 否则调用 proceed() 方法来继续进行方法执行\nMicronaut 的 AOP 拦截器不使用反射, 增强了运行性能, 减少了堆栈跟踪大小, 加强了调试能力\n将注解应用到目标类上来使新的 MethodInterceptor 工作:\nExample - Around Advice Usage:\nimport jakarta.inject.Singleton@Singletonclass NotNullExample &#123;    @NotNull    void doWork(String taskName) &#123;        println &quot;Doing job: $taskName&quot;    &#125;&#125;\n\n无论何时将 NotNullExample Bean 注入到另外一个类中时, 都会注入一个编译时生成的代理, 这个代理使用前面定义的 @NotNull 通知包装方法调用\n测试:\nvoid &quot;test not null&quot;() &#123;    when:    def applicationContext = ApplicationContext.run()    def exampleBean = applicationContext.getBean(NotNullExample)    exampleBean.doWork(null)    then:    IllegalArgumentException e = thrown()    e.message == &#x27;Null parameter [taskName] not allowed&#x27;    cleanup:    applicationContext.close()&#125;\n\n因为 Micronaut 的注入发生在编译时, 所以通常来说通知应该打包到一个独立的 JAR 文件中, 这个 JAR 文件应该存在于 classpath 上, 在上面的测试类编译时\n测试代码和通知代码不应该在同一个代码库因为你不想测试代码在通知代码之前被编译\nCustomizing Proxy Generation (自定义代理的生成)\nThe default behaviour of the Around annotation is to generate a proxy at compile time that is a subclass of the proxied class.\n\nAround 注解的默认行为是在编译时生成一个代理, 这个代理是被代理类的一个子类\n换句话说, 在上面的例子中, 一个编译时的 NotNullExample 类的子类会被创建, 它的代理方法使用拦截器处理逻辑进行包装, 方法的原始行为通过调用 super 来执行\n这种行为更加高效, 因为只需要一个 Bean 实例, 但是在不同的应用场景下, 你可能希望修改这种行为\n@Around 注解支持多个属性来允许你修改这个行为, 包括:\n\nproxyTarget, 默认为 false, 如果设置为 true, 代理将会委托给原始的 Bean 实例, 而不是委托给一个子类来调用 super\nhotswap, 默认为 false, 和 proxyTarget=true 一样, 但除此之外代理还会实现 HotSwappableInterceptedProxy 来包装每个方法在一个 ReentrantReadWriteLock 中, 并允许在运行时切换(swapping)目标实例(target instance)\nlazy, 默认为 false, 默认情况下 Micronaut 在 proxy 被创建的时候 eagerly 初始化 proxy target, 如果设置为 true 那么 proxy target 将会被延迟地解析, 在每个方法调用的时候\n\nAOP Advice on @Factory Beans (在 @Factory Beas 上的 AOP 通知)Bean Factories 上的 AOP advice 语义和不同的类是不一样的:\n\n使用于 @Factory Bean 类级别上的 AOP advice 将 advice 作用于 Factory 本身, 而不是 Factory 中使用 @Bean 注解修饰的任何 Bean\n使用于一个使用了作用域修饰的方法上的 AOP advice 将会应用由 Factory 提供的 AOP advice\n\nExample - AOP Advice at the type level of a @Factory:\n@Timed          // logs the time it takes to create MyBean bean@Factoryclass MyFactory &#123;    @Prototype    MyBean myBean() &#123;        new MyBean()    &#125;&#125;\n\nExample - AOP Advice at the method level of a @Factory:\n@Factoryclass MyFactory &#123;    @Timed      // logs the time it takes to execute the public methods of the MyBean bean, but not the bean creation    @Prototype    MyBean myBean() &#123;        new MyBean()    &#125;&#125;\n\n\nThe rationale for this behaviour is that you may at times wish to apply advice to a factory and at other times apply advice to the bean produced by the factory.\n\n这种行为的基本原理是, 有时你可能希望将 advice 应用到一个 Factory, 而有时则希望将 advice 应用到 Factory 产生的 Bean 上\n现在不能将方法级别的 advice 应用到 @Factory Bean 上, 所有用于 Factory 的 advice 必须应用在类级别上\n你可以通过将方法定义为 non-public 来控制哪个方法是否要应用 advice, non-public 说明方法不应用 advice\nIntroduction Advice (引入 Advice)\nIntroduction advice is distinct from Around advice in that it involves providing an implementation instead of decorating.\n\nIntroduction Advice 和 Around Advice 不同的地方是它提供一个实现而不是包装\nIntroduction Advice 的例子是 Spring Data, Spring Data 为你实现了持久化逻辑\n另一个例子是 Micronaut 的 @Client 注解, Micronaut 在编译时为你实现 HTTP client 接口\n第一步是定义一个注解:\nExample - Introduction Advice Annotation:\nimport io.micronaut.aop.Introductionimport io.micronaut.context.annotation.Beanimport java.lang.annotation.Documentedimport java.lang.annotation.Retentionimport java.lang.annotation.Targetimport static java.lang.annotation.ElementType.ANNOTATION_TYPEimport static java.lang.annotation.ElementType.METHODimport static java.lang.annotation.ElementType.TYPEimport static java.lang.annotation.RetentionPolicy.RUNTIME@Introduction       // The introduction advice is annotated with Introduction@Bean               // The Bean annotation is added so that all types annotated with @Stub become beans@Documented@Retention(RUNTIME)@Target([TYPE, ANNOTATION_TYPE, METHOD])@interface Stub &#123;    String value() default &quot;&quot;&#125;\n\n第二步是定义一个类, 实现 MethodInterceptor 接口, 引用上面定义的注解:\nimport io.micronaut.aop.MethodInterceptorimport io.micronaut.aop.MethodInvocationContextimport io.micronaut.aop.InterceptorBeanimport io.micronaut.core.annotation.Nullableimport jakarta.inject.Singleton@Singleton@InterceptorBean(Stub)  // The InterceptorBean annotation is used to associate the interceptor with the @Stub annotationclass StubIntroduction implements MethodInterceptor&lt;Object, Object&gt; &#123;   // The class is annotationed with @Singleton and implements the MethodInterceptor interface    @Nullable    @Override    Object intercept(MethodInvocationContext&lt;Object, Object&gt; context) &#123;        context.getValue(stub, context.returnType.type)                 // The value of the @Stub annotation is read from the context and an attempt made to convert the value to the return type               .orElse(null)                                            // Otherwise null is returned    &#125;&#125;\n\n最后在抽象类或者接口上使用第一步中创建的 @Stub 来使用这个 Introduction advice:\n@Stubinterface StubExample &#123;    @Stub(&quot;10&quot;)    int getNumber()    LocalDateTime getDate()&#125;\n\n所有委托给 StubIntroduction 类的抽象方法会被实现\nExample - Testing Introduction Advice:\nwhen:def stubExample = applicationContext.getBean(StubExample)then:stubExample.number == 10stubExample.date == null\n\n如果 Introduction Advice 不能实现一个方法, 那么调用 MethodInvocationContext 的 proceed() 方法, 这个方法会让其他 Introduciton Advice 拦截器来实现这个方法, 如果没有 Advice 能够实现这个方法将会抛出一个 UnsupportedOperationException\n如果有多个 Introduction Advice, 你可以重写 MethodInterceptor 的 getOrder() 方法来控制 Advice 的优先级\nMethod Adapter Advice (方法适配器 Advice)基于一个方法上存在的注解来创建一个新的 Bean\n例如, 每个方法上的 @EventListener 注解会创建一个 ApplicationEventListener 接口的实现来调用这个被修饰的方法\nimport io.micronaut.context.event.StartupEventimport io.micronaut.runtime.event.annotation.EventListener@EventListenervoid onStartup(StartupEvent event) &#123;&#125;\n\n上面的代码片段中表示, 在 ApplicationContext 启动的时候将会运行 onStartup() 方法中的逻辑\n@EventListener 注解的存在导致了 Micronaut 去创建一个新的类来实现 ApplicationEventListener 并调用定义在 Bean 中的 onStartup() 方法\n@EventListener 注解简单地使用了 @Adapter 注解来指明它适配哪个 SAM(Simple Abstract Method) 类\nimport io.micronaut.aop.Adapter;import io.micronaut.context.event.ApplicationEventListener;import io.micronaut.core.annotation.Indexed;import java.lang.annotation.*;import static java.lang.annotation.RetentionPolicy.RUNTIME;@Documented@Retention(RUNTIME)@Target(&#123;ElementType.ANNOTATION_TYPE, ElementType.METHOD&#125;)@Adapter(ApplicationEventListener.class)    // The @Adapter annotation indicates which SAM type to adapt, in this case ApplicationEventListener@Indexed(ApplicationEventListener)@Inheritedpublic @interface EventListener &#123;&#125;\n\nMicronaut 还会自动校准 SAM 接口的泛型, 如果 SAM 接口声明了泛型\n根据这个机制可以定义自定义注解, 使用 @Adapter 注解和一个 SAM 接口来在编译时自动实现 Bean\n参考 ApplicationEventListener 获取更多信息\nBean Life Cycle Advice (Bean 生命周期 Advice)有 3 种方式可以将 Advice 应用到 Bean 的生命周期中:\n\n拦截 Bean 的创建\n拦截 Bean 的 @PostConstruct 调用\n拦截 Bean 的 @PreDestroy 调用\n\nMicronaut 通过定义额外的 @InterceptorBinding 元注解来支持这 3 种场景\nimport io.micronaut.aop.*import io.micronaut.context.annotation.Prototypeimport java.lang.annotation.*@Retention(RetentionPolicy.RUNTIME)@AroundConstruct                                                // 1@InterceptorBinding(kind = InterceptorKind.POST_CONSTRUCT)      // 2@InterceptorBinding(kind = InterceptorKind.PRE_DESTROY)         // 3@Prototype                                                      // 4@interface ProductionBean &#123;&#125;\n\n1 : The @AroundConstruct annotation is added to indicate that interception of the constructor should occur\n2 : An @InterceptorBinding definition is used to indicate that @PostConstruct interception should occur\n3 : An @InterceptorBinding definition is used to indicate that @PreDestroy interception should occur\n4 : The bean is defined as @Prototype so a new instance is required for each injection point\n然后将这个注解 @ProductionBean 应用到目标类上:\nimport io.micronaut.context.annotation.Parameterimport jakarta.annotation.PreDestroy@ProductBean                                    // 1class Product &#123;    final String productName    boolean active = false    Product(@Parameter String productName) &#123;    // 2        this.productName = productName    &#125;    @PreDestroy                                 // 3    void disable() &#123;        active = false    &#125;&#125;\n\n1 : The @ProductBean annotation is defined on a class of type Product\n2 : The @Parameter annotation indicates that this bean requires an argument to complete constructions\n3 : Any @PreDestroy or @PostConstruct methods are executed last in the interceptor chain\n然后定义 ConstructorInterceptor Bean 来拦截构造器, 定义 MethodInterceptor Bean 来拦截 @PostConstruct 或 @PreDestroy\n下面例子的 Factory 定义一个 ConstructorInterceptor 来拦截 Product 实例的构造并将这些实例注册给一个假想的 ProductService 来验证产品名称:\nExample - Defining a constructor interceptor:\nimport io.micronaut.aop.*import io.micronaut.context.annotation.Factory@Factoryclass ProductInterceptors &#123;    private final ProductService productService    ProductInterceptors(ProductService productService) &#123;        this.productService = productService    &#125;    @InterceptorBean(ProductBean.class)    ConstructorInterceptor&lt;Product&gt; aroundConstruct() &#123;        return &#123; context -&gt;            final Object[] parameterValues = context.parameterValues            final Object parameterValue = parameterValues[0]            if (parameterValue == null || parameterValues[0].toString().isEmpty()) &#123;                throw new IllegallArgumentException(&quot;Invalid product name&quot;)            &#125;            String productName = parameterValues[0].toString().toUpperCase()            parameterValues[0] = productName            final Product product = context.proceed()            productService.addProduct(product)            return product        &#125;    &#125;    @InterceptorBean(ProductBean.class)    MethodInterceptor&lt;Product, Object&gt; aroundInvoke() &#123;        return &#123; context -&gt;            final Product product = context.getTarget()            switch (context.kind) &#123;                case InterceptorKind.POST_CONSTRUCT:                    product.setActive(true)                    return context.proceed()                case InterceptorKind.PRE_DESTROY:                    productService.removeProduct(product)                    return context.proceed()                default:                    return context.proceed()            &#125;        &#125;    &#125;&#125;\n\nValidation Advice (校验 Advice)校验 Advice 是基于 Bean Validation JSR 380 的\n使用 javax.validation 注解, 例如 @NotNull, @Min, @Max\nMicronaut 为 javax.validation 注解提供原生支持, 通过提供 micronaut-validation 依赖:\nimplementation(&quot;io.micronaut:micronaut-validation&quot;)\n\n或者使用完整的 JSR 380 规范:\nimplementation(&quot;io.micronaut:micronaut-hibernate-validator&quot;)\n\nCache Advice (缓存 Advice)Micronaut 在 io.micronaut.cache 包中提供缓存注解\nCacheManager 接口允许根据需要插入不同的缓存实现\nSyncCache 接口提供一个同步的 API 用来缓存, 同时 AsyncCache API 允许非阻塞的操作\nCache Annotations (缓存注解)支持如下缓存注解:\n\n@Cacheable : 指明一个方法在指定缓存中是可缓存的\n@CachePut : 指明一个方法调用的返回值应该被缓存起来. 不像 @Cacheable 那样, 方法的执行永远不会被跳过\n@CacheInvalidate: 指明方法的调用应该导致一个或多个缓存无效\n\n使用上面其中一个注解会激活 CacheInterceptor\n如果方法的返回类似是非阻塞类型, 则缓存生成的结果\n如果缓存实现支持非阻塞操作, 那么缓存值可以不阻塞的方式进行读取\nConfiguration Caches (配置缓存)默认情况下, 在应用配置中 Caffeine 被用来创建缓存:\nExample - Cache Configuration Example:\nmicronaut:    caches:        my-cache:            maximum-size: 20\n\nNaming Caches (命名缓存)在 micronaut.caches 下使用 kebab-case 方式定义缓存的名称\n如果你使用了驼峰命名, 这个驼峰名称将会被转换为 kebeb-case\n例如, myCache 转换为 my-cache\nkebab-case 形式的名称必须在 @Cacheable 注解中用来引用缓存\n要配置一个和 maximumWeight 配置一起使用的 weigher, 创建一个实现 io.micronaut.caffeine.cache.Weigher 的 Bean\n要关联一个给定的 weigher 到一个指定的缓存上, 使用 @Named(&lt;cache name&gt;) 注解来修饰这个 weigher Bean\n没有 named qualifier 的 weigher 将会应用到所有没有一个 named weigher 的缓存中\n如果没有 weigher Bean, 那么将会使用一个默认实现\nDynamic Cache Creation (动态缓存创建)在缓存不能提前配置的情况下, 可以注册一个 DynamicCacheManager Bean\n当尝试获取一个还没有提前定义的缓存时, 动态缓存管理器将会被调用来创建并返回一个缓存\n默认情况下, 如果没有其他动态缓存管理器定义在应用中, Micronaut 注册一个 DefaultDynamicCacheManager 实例使用默认值来创建 Caffeine 缓存\nRetry Advice (重试 Advice)Micronaut 提供了 Retryable 注解来进行操作重试\nSimple Retry (简单重试)应用重试最简单的方式是在一个类或方法上使用 @Retryable 注解进行修饰\n@Retryable 注解默认会重试三次, 每次重试之间的使用一秒的指数级进行延迟\n第一次尝试使用 1 秒延迟, 第二次延迟使用 2 秒延迟, 第三次延迟使用 3 秒延迟\nExample - Simple Retry:\n@RetryableList&lt;Book&gt; listBooks()\n\n如果上面例子中的 listBooks() 方法抛出一个 RuntimeException, 它将会重试直到达到最大的尝试次数\n@Retryable 注解的 multiplier 值可以用来配置一个 乘法器(multiplier) 来计算每次重试之间的延迟, 支持指数级重试\n要自定义重试行为, 设置 attempts 和 delay 属性:\n@Retryable(attempts = &quot;5&quot;, delay = &quot;2s&quot;)Book findBook(String title) &#123;&#125;\n\n还可以在上面两个属性中使用属性占位符:\n@Retryable(attempts = &#x27;$&#123;book.retry.attempts:3&#125;&#x27;, delay = &#x27;$&#123;book.retry.delay:1s&#125;&#x27;)Book findBook(String title) &#123;&#125;\n\nReactive Retry (响应式重试)@Retryable 注解还可以应用到返回响应式类型的方法上, 例如 Publisher, Flux, Flowable\n@RetryableFlux&lt;Book&gt; streamBooks() &#123;&#125;\n\nCircuit Breaker (断路器)Circuit Breaker 模式的设计目的是通过允许一定数量的失败请求, 然后就打开一个断路, 该断路在允许额外的的重试尝试之前保持打开一段时间, 从而解决失败重试请求过多的问题\n@CircuitBreaker 注解是 @Retryable 注解的变体, 这个注解有一个 reset 成员属性来指定断路器在重置之前要打开多久, 默认是 20 秒\nExample - Applying CircuitBreaker Advice:\n@CircuitBreaker(reset = &quot;30s&quot;)List&lt;Book&gt; findBooks() &#123;&#125;\n\n上面例子中将重试 findBooks() 方法 3 次, 然后打开断路器 30 秒, 并抛出原始的异常, 防止大量潜在的下行数据请求, 例如 HTTP 请求, I&#x2F;O 操作冲垮系统\nFactory Bean Retry (工厂 Bean 重试)当 @Retryable 应用到 Bean 工厂方法上时, 它的行为就像将这个注解放在要返回的类型上\n重试行为将会在返回对象上的方法被调用时被应用\nBean Factory 本身是不可以重试的, 如果你想要实现重试创建 Bean 的功能, 你应该将这个行为委托给另一个使用了 @Retryable 注解的单例Bean\nExample:\n@Factory                                            // 1public class Neo4jDriverFactory &#123;    @Retryable(ServiceUnavailableException.class)   // 2    @Bean(preDestroy = &quot;close&quot;)    public Driver buildDriver() &#123;&#125;&#125;\n\n1 : A factory bean is created that defines methods that create beans\n2 : The @Retryable annotation is used to catch exceptions thrown from methods executed on the Driver\nRetry Events (重试事件)可以注册 RetryEventListener 实例作为 Bean 来监听每次一个操作重试时产生的 RetryEvent 事件\n除此之外, 还可以注册监听 CircuitOpenEvent 事件的监听器来监听断路器开启事件, 或监听  CircuitClosedEvent 断路器关闭事件\nScheduled Tasks (定期任务)Micronaut 提供一个 Scheduled 注解来定期调度后台任务\nUsing the @Scheduled Annotation (使用 @Scheduled 注解)@Scheduled 注解可以被添加到 Bean 上面的任何一个方法, 应该设置注解上 fixedRate,fixedDelay,cron 中的一个成员属性\nBean 的作用域影响行为, 一个 @Singleton Bean 在每次定期方法执行时共享状态(实例的字段), 一个 @Prototype Bean 在每次执行时创建一个新的 Bean 实例\nScheduling at a Fixed Rate (在一个固定频率上调度)使用 fixedRate 成员属性进行配置:\n@Scheduled(fixedRate = &quot;5m&quot;)void everyFiveMinutes() &#123;&#125;\n\n上面的例子中每五分钟执行一次方法\nScheduling with a Fixed Delay (在一个固定的延迟后调度)Example - Fixed Delay:\n@Scheduled(fixedDelay = &quot;5m&quot;)void fiveMinutesAfterLastExecution() &#123;&#125;\n\n在上一次任务执行结束五分钟后再次执行这个任务\nScheduling a Cron Task (在 Cron 配置的时间上调度)Example:\n@Scheduled(cron = &quot;0 15 10 ? * MON&quot;)void everyMondayAtTenFifteenAm() &#123;&#125;\n\n上面的例子中, 任务在应用程序的时区的每个星期一早上的十点十分执行\nScheduling with only a Initial Delay (在仅仅一个延迟之后进行调度)在应用启动后运行任务一次, 使用 initialDelay 成员属性:\nExample - Initial Delay:\n@Scheduled(initialDelay = &quot;1m&quot;)void onceOneMinuteAfterStartup() &#123;&#125;\n\n上面例子的任务只运行一次, 在服务启动一分钟之后开始运行\nProgrammatically Scheduling Tasks (编程式任务调度)使用 TaskScheduler Bean:\n@Inject@Named(TaskExecutors.SCHEDULED)TaskScheduler taskScheduler\n\nConfiguring Scheduled Tasks with Annotation Metadata (使用注解元数据配置调度任务)为了让你的应用程序任务是可配置的, 你可以使用注解元数据和属性占位符配置:\n@Scheduled(fixedRate = &#x27;$&#123;my.task.rate:5m&#125;&#x27;, initialDelay = &#x27;$&#123;my.task.delay:1m&#125;&#x27;)void configuredTask() &#123;&#125;\n\nConfiguring the Scheduled Task Thread Pool (配置调度任务线程池)通过 @Scheduled 执行的任务默认运行在一个配置了可用处理器数两倍的线程数的 ScheduledExecutorService 上\n可以在 application.yml 中配置这个线程池:\nExample - Configuring Scheduled Task Thread Pool:\nmicronaut:    executors:        scheduled:            type: scheduled            core-pool-size: 30\n\nTable - Configuration Properties for UserExecutorConfiguration:\n\n\n\nProperty\nType\nDescription\n\n\n\nmicronaut.executors.*.n-threads\njava.lang.Integer\n\n\n\nmicronaut.executors.*.type\nExecutorType\n\n\n\nmicronaut.executors.*.parallelism\njava.lang.Integer\n\n\n\nmicronaut.executors.*.core-pool-size\njava.lang.Integer\n\n\n\nmicronaut.executors.*.thread-factory-class\njava.lang.Class\n\n\n\nmicronaut.executors.*.name\njava.lang.String\nSets the executor name.\n\n\nmicronaut.executors.*.number-of-threads\njava.lang.Integer\nSets the number of threads for FIXED. Default value (2 * Number of processors available to the Java virtual machine)\n\n\nHandling Exceptions (处理异常)默认情况下, Micronaut 包含了一个实现了 TaskExceptionHandler 接口的 DefaultTaskExceptionHandler Bean 来简单地日志记录执行调度任务产生的异常\nBridging Spring AOP (桥接 Spring AOP)可以在 Micronaut 中使用 Spring 中不直接依赖 Spring 容器的功能\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Cloud Native Features","url":"/micronaut/micronaut-cloud-native-features/","content":"\n\n\nCloud Native Features (云原生特性)\nCloud Configuration (云配置)\nUsing Cloud Instance Metadata (使用云实例元数据)\nDistributed Configuration (分布式配置)\nHashiCorp Consul Support (HashiCorp Consul 支持)\nStarting Consul (开启 Consul)\nEnabling Distributed Configuration with Consul (使用 Consul 开启分布式配置)\nStoring Configuration as Key&#x2F;Value Pairs (将配置作为键值对进行保存)\nStoring Configuration in YAML, JSON etc (存储配置在 YAML, JSON等)\nStoring Configuration as File References (将配置作为文件引用进行存储)\n\n\nHashiCorp Vault Support (HashiCorp 保险库支持)\nSpring Cloud Config Support (Spring Cloud 配置支持)\nAWS Parameter Store Support (AWS 参数存储支持)\nOracle Cloud Vault Support (Oracle Cloud Vault 支持)\nGoogle Cloud Pub&#x2F;Sub Support (Google Cloud Pub&#x2F;Sub 支持)\nKubernetes Support (Kubernetes 支持)\n\n\nService Discovery (服务发现)\nConsul Support (Consul 支持)\nEureka Support (Eureka 支持)\nKubernetes Support (Kubernetes 支持)\nAWS Route 53 Support (AWS Route 53 支持)\nManual Service Discovery Configuration (手动服务发现配置)\n\n\nClient Side Load Balancing (客户端侧负载均衡)\nNetflix Ribbon Support (Netflix Ribbon 支持)\n\n\nDistributed Tracing (分布式追踪)\n\n\n\n\n\nCloud Native Features (云原生特性)声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\n\nThe majority of JVM frameworks in use today were designed before the rise of cloud deployments and microservice architectures.\n\n今天使用的大多数 JVM 框架都是在云部署和微服务架构兴起之前设计的\n使用这些框架构建的应用都是为了部署在传统 Java 容器中的\n所以, 这些框架中的云支持通常作为附加组件而不是核心设计功能提供\nMicronaut 为了构建用于云的微服务而从零开始设计. 因此, 你的应用本身可以使用许多通常需要外部库或服务的关键功能\n\nTo override one of the industry’s current favorite buzzwords, Micronaut applications are “natively cloud-native”.\n\n为了超越业界当前最流行的框架之一, Micronaut 应用程序是 “本地化云原生” 的\n下面是一些已经直接集成在 Micronaut 运行时的特定于云的功能 (cloud-specific features):\n\n分布式配置 (Distributed Configuration)\n服务发现 (Service Discovery)\n客户端侧的负载均衡 (Client-Side Load-Balancing)\n分布式追踪 (Distributed Tracing)\n无服务功能 (Serverless Functions)\n\nCloud Configuration (云配置)为云构建的应用程序通常需要适应在云环境中运行, 以分布式方式读取和共享配置, 并在必要时将配置外部化到环境 (environment) 中\n\nMicronaut’s Environment concept is by default Cloud platform-aware and makes a best effort to detect the underlying active environment.\n\nMicronaut 的 Environment 概念默认是云平台感知的, 并尽最大努力检测底层激活的环境 (environment)\n然后可以使用 @Requires 注解来 条件化加载 bean 定义. 即在对应的云环境中使用 @Requires 注解来激活对应的环境支持\n下表中总结了 Environment 接口中的常量并提供一个例子:\nTable - Micronaut Environment Detection:\n\n\n\nConstant\nDescription\nRequires Example\nEnvironment name\n\n\n\nANDROID\nThe application is running as an Android application\n@Requires(env = Environment.ANDROID)\nandroid\n\n\nTEST\nThe application is running within a JUnit or Spock test\n@Requires(env = Environment.TEST)\ntest\n\n\nCLOUD\nThe application is running in a Cloud environment (present for all other cloud platform types)\n@Requires(env = Environment.CLOUD)\ncloud\n\n\nAMAZON_EC2\nRunning on Amazon EC2\n@Requires(env = Environment.AMAZON_EC2)\nec2\n\n\nGOOGLE_COMPUTE\nRunning on Google Compute\n@Requires(env = Environment.GOOGLE_COMPUTE)\ngcp\n\n\nKUBERNETES\nRunning on Kubernetes\n@Requires(env = Environment.KUBERNETES)\nk8s\n\n\nHEROKU\nRunning on Heroku\n@Requires(env = Environment.HEROKU)\nheroku\n\n\nCLOUD_FOUNDRY\nRunning on Cloud Foundry\n@Requires(env = Environment.CLOUD_FOUNDRY)\npcf\n\n\nAZURE\nRunning on Microsoft Azure\n@Requires(env = Environment.AZURE)\nazure\n\n\nIBM\nRunning on IBM Cloud\n@Requires(env = Environment.IBM)\nIBM\n\n\nDIGITAL_OCEAN\nRunning on Digital Ocean\n@Requires(env = Environment.DIGITAL_OCEAN)\ndigitalocean\n\n\nORACLE_CLOUD\nRunning on Oracle Cloud\n@Requires(env = Environment.ORACLE_CLOUD)\noraclecloud\n\n\n注意, 你可以激活多个环境, 例如, 运行在 AWS 上的 Kubernetes 中\n除此之外, 使用上表中常量名称, 你可以创建用于指定环境的配置文件, 例如, 创建了一个 src/main/resources/application-gcp.yml 文件, 这个文件就只会在运行于 Google Compute 时加载\n\nAny configuration property in the Environment can also be set via an environment variable. For example, setting the CONSUL_CLIENT_HOST environment variable overrides the host property in ConsulConfiguration.\n\nEnvironment 中的任何配置属性可以通过一个环境变量来设置. 例如, 设置 CONSUL_CLIENT_HOST 环境变量来覆盖 ConsulConfiguration 中的 host 属性\nUsing Cloud Instance Metadata (使用云实例元数据)当 Micronaut 检测到它在支持的云平台上运行时, 它会在启动时填充接口 ComputeInstanceMetadata\n\nAs of Micronaut 2.1.x this logic depends on the presence of the appropriate core Cloud module for Oracle Cloud, AWS, or GCP.\n\n从 Micronaut 2.1.x 开始, 这个逻辑取决于是否存在 用于Orcale Cloud,AWS或GCP的 适当的云模块核心\n所有这些数据都合并到正在运行的 ServiceInstance 的 metadata 属性中\n\nIf you connect remotely via a client, the instance metadata can be referenced once you have retrieved a ServiceInstance from either the LoadBalancer or DiscoveryClient APIs.\n\n如果你通过 client 进行远程连接, 则可以在你从 LoadBalancer 或 DiscoveryClient API 检索到 ServiceInstance 后引用实例元数据\n\nThe Netflix Ribbon client-side load balancer can be configured to use the metadata to do zone-aware client-side load balancing.\n\nNetflix Ribbon 客户端负载均衡器可以配置为使用元数据进行区域感知客户端负载均衡. 参考 Client-Side Load Balancing\n\nTo obtain metadata for a service via Service Discovery use the LoadBalancerResolver interface to resolve a LoadBalancer and obtain a reference to a service by identifier\n\n要通过服务发现获取服务的元数据, 使用 LoadBalanceResolver 接口来解析 LoadBalancer 并通过标识符获取对服务的引用:\nExample - Obtaining Metadata for a Service instance:\nLoadBalancer loadBalancer = loadBalancerResolver.resolve(&quot;some-service&quot;)Flux.from(        loadBalancer.select()    )    .subscribe((instance) -&gt;        ConvertibleValues&lt;String&gt; metaData = instance.getMetadata()    )\n\n\nThe EmbeddedServerInstance is available through event listeners that listen for the ServiceReadyEvent.\n\n通过监听 ServiceReadyEvent 的事件监听器可以获取 EmbeddedServerInstance\n\nThe @EventListener annotation makes it easy to listen for the event in your beans.\n\n@EventListener 注解让你在 Bean 中监听事件更容易\n要获取本地运行的 server 的元数据, 使用用于 ServiceReadyEvent 的 EventListener:\nExample - Obtaining Metadata for a Local Server:\n@EventListenervoid onServiceStarted(ServiceReadyEvent event) &#123;    ServiceInstance serviceInstance = event.getSource()    ConvertibleValues&lt;String&gt; metadata = serviceInstance.getMetadata()&#125;\n\nDistributed Configuration (分布式配置)\nAs you can see, Micronaut features a robust system for externalizing and adapting configuration to the environment inspired by similar approaches in Grails and Spring Boot.\n\n正如你所见, Micronaut 有一个强大的系统来外部化和可调整的配置\n如果要在多个微服务中共享配置, Micronaut 包含了分布式配置的的 APIs\nConfigurationClient 接口有一个 getPropertySources 方法, 可以实现这个方法来读取解析来自分布式源的配置\ngetPropertySources 方法返回一个输出0个或多个 [PropertySource](https://docs.micronaut.io/latest/api/io/micronaut/context/env/PropertySource.html 的 Publisher\n默认的实现是 DefaultCompositeConfigurationClient, 这个 client 合并所有注册的 ConfigurationClient beans 到单独一个 bean 中\n你可以实现你自己的 ConfigurationClient, 或者使用 Micronaut 提供的实现\nHashiCorp Consul Support (HashiCorp Consul 支持)Consul 是 HashiCorp 提供的一个流行的服务发现和分布式配置 server\nMicronaut 提供一个原生的 ConsulClient, 这个 client 使用 Micronaut 对 Declarative HTTP Clinets 的支持\nStarting Consul (开启 Consul)开始使用 Consul 最快的方法是通过 Docker: docker run -p 8500:8500 consul\n或者, 你可以 安装并运行一个本地 Consul 实例\nEnabling Distributed Configuration with Consul (使用 Consul 开启分布式配置)如果你使用 Micronaut CLI 创建你的项目, 添加 config-consul 特性来在你的项目中开启 Consul 的分布式配置: mn create-app my-app --features config-consul\n要开启分布式配置, 创建一个 src/main/resources/bootstrap.yml 配置文件并开启配置客户端( configuration client ):\n// bootstrap.ymlmicronaut:    application:        name: hello-world    config-client:        enabled: trueconsul:    client:        defaultZone: &quot;$&#123;CONSUL_HOST:localhost&#125;:$&#123;CONSUL_PORT:8500&#125;&quot;\n\n在开启分布式配置之后, 在 Consul 的键值对存储( key&#x2F;value store )中保存用来共享的配置\nStoring Configuration as Key&#x2F;Value Pairs (将配置作为键值对进行保存)其中一种方式是直接在 Consul 中存储 keys 和 values. 在这个方法中, Micronaut 默认在 Consul /config 目录中搜索配置\n可以通过设置 consul.client.config.path 来修改搜索的路径\n在 /config 目录中, Micronaut 按优先级在如下目录中搜索值:\nTable - Configuration Resolution Precedence:\n\n\n\nDirectory\nDescription\n\n\n\n&#x2F;config&#x2F;application\nConfiguration shared by all applications\n\n\n&#x2F;config&#x2F;application,prod\nConfiguration shared by all applications for the prod Environment\n\n\n&#x2F;config&#x2F;[APPLICATION_NAME]\nApplication-specific configuration, example &#x2F;config&#x2F;hello-world\n\n\n&#x2F;config&#x2F;[APPLICATION_NAME],prod\nApplication-specific configuration for an active Environment\n\n\nAPPLICATION_NAME 的值是你在 bootstrap.yml 中配置的 micronaut.application.name 的任何值\n举个例子, 使用 cURL 命令来在 /config/application 目录中存储一个 key 为 foo.bar, value 为 myvalue 的属性:\nExample - Using cURL to Write a Value:\ncurl -X PUT -d @- localhost:8500/v1/kv/config/application/foo.bar &lt;&lt;&lt; myvalue\n\n然后定义 @Value(&quot;$&#123;foo.bar&#125;&quot;) 或者调用 environment.getProperty(&#39;foo.bar&#39;) 来从 Consul 中解析并获取 myvalue 值\nStoring Configuration in YAML, JSON etc (存储配置在 YAML, JSON等)一些 Consul 用户更喜欢将配置存储在某个格式的 blob (二进制大对象) 中, 例如 YAML\nMicronaut 支持这种模式并支持以 YAML, JSON, Java properties 格式存储配置\nConfigDiscoveryConfiguration 有一些配置选项用来配置怎样检测( discovered )分布式配置:\n可以设置 consul.client.config.format 选项来配置属性使用哪个格式来来读\nExample - 使用 JSON 格式的配置:\n# applicaton.ymlconsul:    client:        config:            format: JSON\n\n然后就可以将 JSON 格式的配置写到 Consul 中:\ncurl -X PUT localhost:8500/v1/kv/config/application \\-d @- &lt;&lt; EOF&#123; &quot;foo&quot;: &#123;&quot;bar&quot;: &quot;myvalue&quot;&#125; &#125;EOF\n\nStoring Configuration as File References (将配置作为文件引用进行存储)另一个流行的选项是 git2consul, 这个选项将 Git 仓库的内容镜像到 Consul 的键值存储\n你可以设置一个包含类似 application.yml, hello-world-test.json 等文件的 Git 仓库, 然后这些文件的内容会被拷贝到 Consul\n在这种情景中, Consul 中的每个 key 代表着一个有扩展名的文件, 例如 /config/application.yml, 并且必须配置 FILE 格式:\n# application.ymlconsul:    client:        config:            format: FILE\n\nHashiCorp Vault Support (HashiCorp 保险库支持)Micronaut 内置 HashiCorp Valut 作为一个分布式配置源\n要开启 Vault Configuration 支持, 创建一个 src/main/resources/bootstrap.yml 配置文件并添加如下配置:\nExample - Integrating with HashiCorp Vault:\nmicronaut:    application:        name: hello-world    config-client:        enabled: truevault:    client:        config:            enabled: true\n\n参看 configuration reference 获取所有配置选项\nMicronaut 为应用使用配置 micronaut.application.name 来从 Vault 中查找属性源\nTable - Configuration Resolution Precedence:\n\n\n\nDirectory\nDescription\n\n\n\n/application\nConfiguration shared by all applications\n\n\n/[APPLICATION_NAME]\nApplication-specific configuration\n\n\n/application/[ENV_NAME]\nConfiguration shared by all applications for an active environment name\n\n\n/[APPLICATION_NAME]/[ENV_NAME]\nApplication-specific configuration for an active environment name\n\n\n查看 Documentation for HashiCorp Vault 获取更多关于怎样配置 server 的信息\nSpring Cloud Config Support (Spring Cloud 配置支持)从 1.1 版本开始, Micronaut 为那些没有切换到像 Consul 这样的专用的更完整的解决方案的人提供了原生 Spring Cloud 支持\n要开启 Spring Cloud 配置支持, 创建一个 src/main/resources/bootstrap.yml 配置文件并并添加如下配置:\nExample - Integrating with Spring Cloud Configuration:\nmicronaut:    application:        name: hello-world    config-client:        enabled: truespring:    cloud:        config:            enabled: true            uri: http://localhost:8888/            retry-attempts: 4 # optional, number of times to retry            retry-delay: 2s # optional, delay between retries\n\nMicronaut 使用配置 micronaut.application.name 来为应用从使用 spring.cloud.config.uri 配置的 Spring Cloud 配置 server 中搜寻属性源\n查看 Documentation for Spring Cloud Config Server 获取有关如何设置服务器的更多信息\nAWS Parameter Store Support (AWS 参数存储支持)略\nOracle Cloud Vault Support (Oracle Cloud Vault 支持)Secure Distributed Configuration with Oracle Cloud Vault\nGoogle Cloud Pub&#x2F;Sub Support (Google Cloud Pub&#x2F;Sub 支持)Micronaut GCP Pub&#x2F;Sub\nKubernetes Support (Kubernetes 支持)Kubernetes Configuration Client\nService Discovery (服务发现)服务发现使微服务可以发现彼此, 而不需要知道物理地址或关联的服务的 IP 地址\nMicronaut 集成了多个工具和库, 查看 Micronaut Service Discovery documentation 获取更多信息\nConsul Support (Consul 支持)查看 Micronaut Consul documentation\nEureka Support (Eureka 支持)查看 Micronaut Eureka documentation\nKubernetes Support (Kubernetes 支持)Kubernetes 是一个容器运行时 ,包含许多功能, 例如内置了服务发现和分布式配置\n\nMicronaut includes first-class integration with Kubernetes.\n\nMicronaut 包含与 Kubernetes 的一级集成\n查看 Micronaut Kubernetes documentation 获取更多信息\nAWS Route 53 Support (AWS Route 53 支持)略\nManual Service Discovery Configuration (手动服务发现配置)\nIf you do not wish to involve a service discovery server like Consul or you interact with a third-party service that cannot register with Consul you can instead manually configure services that are available via Service discovery.\n\n如果你不想使用一个像 Consul 这样的服务发现 server, 或者你和一个第三方服务交互, 这个第三方服务不能注册到 Consul 中, 你可以改为手动配置通过服务发现而可用的服务\n为了做到这个, 使用 micronaut.http.services 设置:\nExample - Manually configuring services:\nmicronaut:    http:        services:            foo:                urls:                    - http://foo1                    - http://foo2\n\n然后使用 @Client(&quot;foo&quot;) 注解来注入一个 client, 这个 client 会使用上面的配置来在两个配置的 servers 之间进行负载均衡\n当使用 @Client 进行服务发现时, 在注解中必须使用 kebab-case 来指定 service id\n你可以在生产中通过指定一个环境变量 MICRONAUT_HTTP_SERVICES_FOO_URLS=http://prod1,http://prod2 来覆盖这个配置\n请注意, 默认情况下, 不会使用健康检查来判断服务是否可操作\n\nYou can alter that by enabling health checking and optionally specifying a health check path (the default is &#x2F;health):\n\n可以通过开启健康检查并可选地指定一个健康检查路径( 默认为 /health ):\nExample - Enabling Health Checking:\nmicronaut:    http:        services:            foo:                health-check: true      # Whether to health check the service                health-check-interval: 15s      # The interval between checks                health-check-uri: /health       # The URI of the health check request\n\nMicronaut 启动一个后台线程来检查 service 的健康状态, 如果任何一个配置的 services 响应一个错误代码, 它们就会被从可用 services 列表中移除\nClient Side Load Balancing (客户端侧负载均衡)当从 Consul, Eureka, 或其他服务发现 servers 中 discovering services 时, DiscoveryClient 输出一个可用的 ServiceInstance 列表\n\nMicronaut by default automatically performs Round Robin client-side load balancing using the servers in this list.\n\nMicronaut 默认使用这个列表中的 servers 执行客户端侧轮询负载均衡\n\nThis combined with Retry Advice adds extra resiliency to your Microservice infrastructure.\n\n这个和 Retry Advice 相结合, 为你的微服务基础架构增加了额外的弹性\n由 LoadBalancer 接口处理负载均衡, 这个接口有一个 LoadBalancer.select() 方法来返回一个 Publisher, 这个 Publisher 输出一个 ServiceInstance\n返回 Publisher 是因为选择一个 ServiceInstance 的过程可能导致一个网络操作, 取决于所采用的 Service Discovery 策略\nLoadBalancer 接口的默认实现是 DiscoveryClientRoundRobinLoadBalancer. 你可以使用另一个实现来代替这个策略, 这个实现自定义了客户端侧负载均衡在 Micronaut 中是怎样处理的, 因为有许多不同方式来优化负载均衡\n例如, 你可能希望在特定区域中的服务之间进行负载均衡, 或者在具有最佳整体响应时间的服务器之间进行负载均衡\n要代替 LoadBalancer, 定义一个 Bean 来 replaces DiscoveryClientLoadBalanceFactory. 实际上, 这正是 Netflix Ribbon 支持所做的事情\nNetflix Ribbon Support (Netflix Ribbon 支持)如果你使用 Micronaut CLI 创建项目, 添加 netflix-ribbon 特性来配置 Netflix Ribbon 到你的项目中:\nmn create-app my-app --features netflix-ribbon\n\n\nNetflix Ribbon is an inter-process communication library used at Netflix with support for customizable load balancing strategies.\n\nNetflix Ribbon 是 Netflix 使用的一个进程间通信库, 支持可定制的负载均衡策略\n如果你在应用程序如何执行客户端负载均衡方面需要更多的灵活性, 你可以使用 Micronaut 的 Netflix Ribbon 支持\n要增加 Ribbon 支持到你的应用中, 添加 netflix-ribbon 配置到你的构建中:\nimplementation(&quot;io.micronaut.netflix:micronaut-netflix-ribbon&quot;)\n\nLoadBalancer 现在的实现将会是 RibbonLoadBalancer 实例\nRibbon 的 配置选项 可以在配置中使用 ribbon 命名空间来进行设置:\nExample - Configuring Ribbon:\n# application.ymlribbon:    VipAddress: test    ServerListRefreshInterval: 2000\n\n每个被发现的 client 都可以在 ribbon.clients 下面进行配置. 例如给定一个 @Client(id = &quot;hello-world&quot;), 你可以这样配置 Ribbon 设置:\nExample - Per Client Ribbon Settings:\nribbon:    clients:        hello-world:            VipAddress: test            ServerListRefreshInterval: 2000\n\n\nBy default Micronaut registers a DiscoveryClientServerList for each client that integrates Ribbon with Micronaut’s DiscoveryClient.\n\n默认情况下, Micronaut 为每个 将Ribbon和Micronaut的DiscoveryClient集成的 client注册一个DiscoveryClientServerList\nDistributed Tracing (分布式追踪)查看文档 Micronaut Tracing 获取更多关于添加分布式追踪到你的应用的信息\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Configurations","url":"/micronaut/micronaut-configurations/","content":"\n\n\nConfigurations\nConfigurations for Reactive Programming (响应式编程的配置)\nReactor Support (Reactor 支持)\nRxJava 3 Support (RxJava 3 支持)\nRxJava 2 Support (RxJava 2 支持)\n\n\nConfigurations for Data Access (数据访问的配置)\nConfiguring a SQL Data Source (配置一个 SQL 数据源)\nConfiguring a JDBC DataSource (配置一个 JDBC 数据源)\n\n\nConfiguring Hibernate (配置 Hibernate)\nSetting up a Hibernate&#x2F;JPA EntityManager (配置一个 Hibernate&#x2F;JPA EntityManager)\nUsing GORM for Hibernate (为 Hibernate 使用 GORM)\n\n\nConfiguring MongoDB (配置 MongoDB)\nSetting up the Native MongoDB Driver (配置原生 MongoDB 驱动)\n\n\nConfiguring Neo4j (配置 Neo4j)\nConfiguring Postgres (配置 Postgres)\nConfiguring the Reactive Postgres Client (配置流式 Postgres 客户端)\n\n\nConfiguring Redis (配置 Redis)\nConfiguring Lettuce\n\n\nConfiguring Cassandra (配置 Cassandra)\nConfiguring Liquibase (配置 Liquibase)\nConfiguring Flyway (配置 Flyway)\n\n\n\n\n\n\n\nConfigurations声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\nMicronaut 提供了许多内置配置来开启与常见数据库或其他 servers 的集成\nConfigurations for Reactive Programming (响应式编程的配置)Project Reactor 被 Micronaut 内置使用\n但是要在 Controller 或 HTTP client 方法中使用 Reactor 或其他响应式库 (例如 RxJava) 类型, 需要包含对应的依赖到你的构建中\nReactor Support (Reactor 支持)要添加 Reactor 的支持 添加如下模块:\nimplementation(&quot;io.micronaut.reactor:micronaut-reactor&quot;)\n要使用 Reactor HTTP client, 添加如下依赖:\nimplementation(&quot;io.micronaut.reactor:micronaut-reactor-http-client&quot;)\n查看 Micronaut Reactor 获取更多信息\nRxJava 3 Support (RxJava 3 支持)要添加 RxJava3 的支持 添加如下模块:\nimplementation(&quot;io.micronaut.rxjava3:micronaut-rxjava3&quot;)\n要使用 RxJava3 HTTP client, 添加如下依赖:\nimplementation(&quot;io.micronaut.rxjava3:micronaut-rxjava3-http-client&quot;)\n查看 Micronaut RxJava 3 获取更多信息\nRxJava 2 Support (RxJava 2 支持)对 RxJava 1 的遗留支持通过添加如下模块:\nimplementation(&quot;io.micronaut.rxjava1:micronaut-rxjava1&quot;)\n查看 Micronaut RxJava 1 获取更多信息\nConfigurations for Data Access (数据访问的配置)下表总结了要添加到构建以启用它们的配置模块和依赖\nTable - Data Access Configuration Modules:\n\n\n\nDependency\nDescription\n\n\n\nio.micronaut.sql:micronaut-jdbc-dbcp\nConfigures SQL DataSources using Commons DBCP\n\n\nio.micronaut.sql:micronaut-jdbc-hikari\nConfigures SQL DataSources using Hikari Connection Pool\n\n\nio.micronaut.sql:micronaut-jdbc-tomcat\nConfigures SQL DataSources using Tomcat Connection Pool\n\n\nio.micronaut.sql:micronaut-hibernate-jpa\nConfigures Hibernate&#x2F;JPA EntityManagerFactory beans\n\n\nio.micronaut.groovy:micronaut-hibernate-gorm\nConfigures GORM for Hibernate for Groovy applications\n\n\nio.micronaut.mongodb:micronaut-mongo-reactive\nConfigures the MongoDB Reactive Driver\n\n\nio.micronaut.groovy:micronaut-mongo-gorm\nConfigures GORM for MongoDB for Groovy applications\n\n\nio.micronaut.neo4j:micronaut-neo4j-bolt\nConfigures the Bolt Java Driver for Neo4j\n\n\nio.micronaut.groovy:micronaut-neo4j-gorm\nConfigures GORM for Neo4j for Groovy applications\n\n\nio.micronaut.sql:micronaut-vertx-mysql-client\nConfigures the Reactive MySQL Client\n\n\nio.micronaut.sql:micronaut-vertx-pg-client\nConfigures the Reactive Postgres Client\n\n\nio.micronaut.redis:micronaut-redis-lettuce\nConfigures the Lettuce driver for Redis\n\n\nio.micronaut.cassandra:micronaut-cassandra\nConfigures the Datastax Java Driver for Cassandra\n\n\n例如, 要添加 MongoDB 的支持, 添加如下依赖:\n// build.gradlecompile &quot;io.micronaut.mongodb:micronaut-mongo-reactive&quot;\n\n对于 Groovy 用户, Micronaut 对 GORM 提供了额外支持\n对于 Hibernate 的 GORM, 你不能同时有 hibernate-jpa 和 hibernate-gorm 依赖\n下面的章节更加深入每个实现的配置选项的细节和暴露出来的 Beans\nConfiguring a SQL Data Source (配置一个 SQL 数据源)可以使用当前默认支持的三种实现之一来配置 JDBC 数据源 - Apache DBCP2, Hikari 和 Tomcat\nConfiguring a JDBC DataSource (配置一个 JDBC 数据源)如果你使用 Micronaut CLI 来创建你的项目, 那么你可以添加 jdbc-tomcat,jdbc-hikari,jdbc-dbcp 中的一个特性来预配置一个简单的 JDBC 连接池以及一个默认的 H2 数据库驱动到你的项目中:\nmn create-app my-app --features jdbc-tomcat\n\n\nTo get started, add a dependency for one of the JDBC configurations that corresponds to the implementation you will use. Choose one of the following:\n\n首先, 为其中一个 对应你要使用的实现的 JDBC 配置添加一个依赖, 选择下面中的一个:\nruntimeOnly(&quot;io.micronaut.sql:micronaut-jdbc-tomcat&quot;)\nruntimeOnly(&quot;io.micronaut.sql:micronaut-jdbc-hikari&quot;)\nruntimeOnly(&quot;io.micronaut.sql:micronaut-jdbc-dbcp&quot;)\nruntimeOnly(&quot;io.micronaut.sql:micronaut-jdbc-ucp&quot;)\n然后, 添加一个 JDBC 驱动依赖到你的构建中. 例如, 添加 H2 In-Memory Database:\nruntimeOnly(&quot;com.h2database:h2&quot;)\n查看 Micronuat SQL libraries 项目的 Configuration JDBC 章节获取更多信息\nConfiguring Hibernate (配置 Hibernate)Setting up a Hibernate&#x2F;JPA EntityManager (配置一个 Hibernate&#x2F;JPA EntityManager)如果你使用 Micronaut CLI 创建你的项目, 添加 hibernate-jpa 功能来包含一个 Hibernate JPA 配置到你的项目中:\nmn create-app my-app --features hibernate-jpa\n\n\nMicronaut includes support for configuring a Hibernate &#x2F; JPA EntityManager that builds on the SQL DataSource support.\n\nMicronaut 包括了配置一个构建在 SQL DataSource support 上的 Hibernate&#x2F;JPA EntityManager 的支持\nMicronaut 可以配置一个构建于 SQL DataSource support 的Hibernate&#x2F;JPA EntityManager\n一旦你已经 配置一个或多个数据源 来使用 Hibernate, 那就添加 hibernate-jpa 依赖到你的构建中:\nimplementation(&quot;io.micronaut.sql:micronaut-hibernate-jpa&quot;)\nUsing GORM for Hibernate (为 Hibernate 使用 GORM)对于 Groovy 用户和熟悉 Grails 框架的用户, 可以使用对 GORM for Hibernate 的特殊支持\n要为 Hibernate 使用 GORM 不要包含 Micronaut 内置的 SQL Support 和 hibernate-jpa 依赖, 因为 GORM 本身负责创建 &#96;&#96;DataSource,SessionFactory&#96;等\n如果你使用 Micronaut CLI 创建项目, 添加 hibernate-gorm 功能来包含 GORM, 一个基础的连接池配置和一个默认的 H2 数据库驱动到你的项目中:\nmn create-app my-app --features hibernate-gorm\nConfiguring MongoDB (配置 MongoDB)Setting up the Native MongoDB Driver (配置原生 MongoDB 驱动)如果你使用 Micronaut CLI 创建项目, 添加 mongo-reactive 功能来配置原生 MongoDB 驱动到你的项目中:\nmn create-app my-app --features mongo-reactive\nMicronaut 可以自动配置原生 MongoDB Java 驱动. 要使用这个, 添加如下依赖到你的构建中:\nimplementation(&quot;io.micronaut.mongodb:micronaut-mongo-reactive&quot;)\n然后在 application.yml 中配置 MongoDB server 的 URI:\nExample - Configuring a MongoDB server:\nmongodb:    uri: mongodb://username:password@localhost:27017/databaseName\n\nmongodb.uri 使用 MongoDB Connection String 格式\n然后一个非阻塞的响应式流 MongoClient 就可以在依赖注入中使用\n要使用阻塞驱动, 在 mongo-java-driver 上为您的构建添加依赖项:\ncompile &quot;org.mongodb:mongo-java-client&quot;\n然后阻塞的 MongoDB 将会在注入中可用\n查看 Micronaut MongoDB 文档获取更多配置与在 Micronaut 中使用 MongoDB 的信息\nConfiguring Neo4j (配置 Neo4j)Micronaut 支持为流行的 Neo4j 图形数据库自动配置 Neo4j Bolt 驱动\n如果你使用 Micronaut CLI 创建项目, 添加 neo4j-bolt 功能来配置 Neo4j Bolt 驱动到你的项目中:\nmn create-app my-app --features neo4j-bolt\n要配置 Neo4j Bolt 驱动, 首先添加 neo4j-bolt 模块到你的构建中:\nimplementation(&quot;io.micronaut:micronaut-neo4j-bolt&quot;)\n然后在 application.yml 中配置 Neo4j server 的 URI:\nExample - Configuring neo4j.uri\nneo4j:    uri: bolt://localhost\n\nneo4j.uri 设置的格式必须是 Neo4j 文档的 Connection URIs 章节中描述的格式\n一旦上面的配置就绪, 你就可以注入一个 org.neo4j.driver.v1.Driver Bean 实例, 这个 bean 同时提供同步阻塞 API 和基于 CompletableFuture 的非阻塞 API\n查看 Micronaut Neo4j 文档获取更多关于配置和在 Micronaut 中使用 Neo4j 的信息\nConfiguring Postgres (配置 Postgres)Micronaut 通过 vertx-pg-client 支持流式的非阻塞 client 来连接 Postgres, 这个 client 可以使用一个线程来处理多个数据库连接\nConfiguring the Reactive Postgres Client (配置流式 Postgres 客户端)如果你使用 Micronaut CLI 创建项目, 添加 vertx-pg-client 功能来配置响应式 Postgres 客户端到你的项目中:\nmn create-app my-app --features vertx-pg-client\n要配置流式 Postgres 客户端, 首先添加 vertx-pg-client 模块到你的构建中:\ncompile &quot;io.micronaut.sql:micronaut-vertx-pg-client&quot;\n查看 Micronaut SQL libraries 项目的 Configuring Reactive Postgres 章节获取更多信息\nConfiguring Redis (配置 Redis)Micronaut 通过 redis-lettuce 模块为 Redis 自动配置 Lettuce 驱动\nConfiguring Lettuce如果你使用 Micronaut CLI 创建项目, 添加 redis-lettuce 功能来配置 Lettuce 驱动到你的项目中:\nmn create-app my-app --features redis-lettuce\n要配置 Lettuce 驱动, 首先添加 redis-lettuce 模块到你的项目中:\ncompile &quot;io.micronaut.redis:micronaut-redis-lettuce&quot;\n然后在 application.yml 中配置 Redis server 的 URI:\nredis:    uri: redis://localhost\n\nredis.uri 配置必须是 Lettuce wiki 的 Connection URIs 章节中描述的格式\n查看 Micronaut Redis 获取更多信息\nConfiguring Cassandra (配置 Cassandra)如果你使用 Micronaut CLI 创建项目, 添加 cassandra 功能来包含 Cassandra 配置到你的项目中:\nmn create-app my-app --features cassandra\n查看 Micronaut Cassandra Module 文档获取更多信息\nConfiguring Liquibase (配置 Liquibase)要配置 Micronaut 集成 Liquibase, 查看 these instructions\nConfiguring Flyway (配置 Flyway)要配置 Micronaut 集成 Flyway, 查看 these instructions\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Internationalization","url":"/micronaut/micronaut-internationalization/","content":"\n\n\nInternationalization\nResource Bundles (资源包)\nLocalized Message Source (本地化信息资源)\n\n\n\n\n\nInternationalization声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\nResource Bundles (资源包)一个资源包是一个包含特定区域数据的 Java properties 文件\n给定如下资源包:\nsrc/main/resources/io/micronaut/docs/i18n/messages_en.properties\nhello=Hellohello.name=Hello &#123;0&#125;\n\nsrc/main/resources/io/micronaut/docs/i18n/messages_es.properties\nhello=Holahello.name=Hola &#123;0&#125;\n\n使用 ResourceBundleMessageSource, 一个 MessageSource 接口的实现, 这个类简化了 Resource Bundles 的访问并提供了缓存功能, 来访问之前的消息\n不要在每次你获取一个消息的时候实例化一个新的 ResourceBundleMessageSource\n实例化它一次, 例如在一个 factory 中进行实例化\nExample - MessageSource Factory:\nimport io.micronaut.context.MessageSourceimport io.micronaut.context.annotation.Factoryimport io.micronaut.context.i18n.ResourceBundleMessageSourceimport jakarta.inject.Singleton@Factoryclass MessageSourceFactory &#123;    @Singleton    MessageSource createMessageSource() &#123;        new ResourceBundleMessageSource(&quot;io.micronaut.docs.i18n.messages&quot;)    &#125;&#125;\n\n然后可以获取应用了本地化的消息\nExample - ResourceBundleMessageSource:\nexpect:messageSource.getMessage(&#x27;hello&#x27;, MessageContext.of(new Locale(&#x27;es&#x27;))).get() == &#x27;Hola&#x27;and:messageSource.getMessage(&#x27;hello&#x27;, MessageContext.of(Locale.ENGLISH)).get() == &#x27;Hello&#x27;\n\nLocalized Message Source (本地化信息资源)LocalizedMessageSource 是一个 @RequestScope bean, 你可以注入到你的 Controllers 中, 这个 bean 使用 Micronaut Locale Resolution 来为当前 HTTP 请求解析本地化信息\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Inversion of Control","url":"/micronaut/micronaut-inversion-of-control/","content":"\n\n\nInversion of Control\nInjectable Container Types (可以注入的容器类型)\nCollection Ordering (容器中 Bean 的顺序)\nInjecting a Bean by Order (按顺序注入一个 Bean)\n\n\nBean Qualifiers Bean (限定符)\nQualifying By Name (通过名字来限定)\nQualifying By Annotation (通过注解来限定)\nQualifier By Annotation Members (通过注解的属性成员来限定)\nQualifying by Generic Type Arguments (通过泛型参数来限定)\nPrimary and Secondary Beans (主要的和次要的 Bean)\nInjecting Any Bean (注入任意 Bean)\n\n\nLimiting Injectable Types (限制注入的类型)\nScopes (作用域)\nBuilt-In Scopes (内建的作用域)\nEager Initialization of Singletons (单例的饿式初始化)\n\n\nRefreshable Scope (可刷新的作用域)\nScopes on Meta Annotations (元注解上的作用域)\n\n\nBean Factories Bean (工厂)\nProgrammatically Disabling Beans (编程方式来无效化 Beans)\nInjection Point (注入点)\nBeans from Fields (在字段中声明 Beans)\nPrimitive Beans and Arrays (原始类型的和数组类型的 Bean)\n\n\nConditional Beans (条件化加载 Beans)\nConfiguration Requirements (配置要求)\nAdditional Notes on Property Requirements (属性要求上额外的信息)\nReferencing bean properties in @Requires (在 @Requires 注解中引用 Bean 属性)\n\n\nDebugging Conditional Beans (调试条件化的 Beans)\n\n\nBean Replacement (Bean 替代)\nFactory Replacement (Factory 替代)\nDefault Implementation (默认实现)\n\n\nBean Configurations (Bean 配置)\nLife-Cycle Methods (生命周期方法)\nWhen The Context Starts (Context 启动时)\nWhen The Context Closes (Context 关闭时)\n\n\nContext Events (Context 事件)\nPublishing Events (发布事件)\nListening for Events (监听事件)\n\n\nBean Events (Bean 事件)\nBean Introspection (Bean 内省)\nMaking a Bean Available for Introspection (让一个 Bean 可用于反射)\nUse the @Introspected Annotation (使用 @Introspected 注解)\nBean Fields (Bean 字段)\nConstructor Methods (构造方法)\nStatic Creator Methods (静态构造方法)\nEnums (枚举)\nUse the @Introspected Annotation on a Configuration Class (在一个配置类上使用 @Introspected 注解)\nWrite an AnnotationMapper to Introspect Existing Annotations (编写一个 AnnotationMapper 来内省一个已存在的注解)\nThe BeanWrapper API (BeanWrapper API)\nJackson and Bean Introspection (Jackson 和 Bean 内省)\n\n\nBean Validation (Bean 校验)\nValidating Bean Methods (检验 Bean 的方法)\nValidating Data Classes (校验数据类)\nValidation Configuration Properties (校验属性配置)\nDefining Additional Constraints (定义额外的约束)\nValidating Annotations at Compile Time (在编译时校验注解)\n\n\nBean Annotation Metadata (Bean 注解元数据)\nAnnotation Inheritance (注解继承)\nAliasing or Mapping Annotations (取别名or映射注解)\n\n\nImporting Beans from Libraries (从一个库中导入 Beans)\n\n\n\n\n\nInversion of Control声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\nMicronaut 使用编译时数据来实现依赖注入\nInjectable Container Types (可以注入的容器类型)Table 1.Injectable Container Types - 可以注入的容器类型:\n\n\n\nType\nDescription\nExample\n\n\n\njava.util.Optional\nAn Optional of a bean. empty() is injected if the bean is doesn’t exist\nOptional&lt;Engine&gt;\n\n\njava.lang.Collection\nAn Collection or subtype of Collection\nCollection&lt;Engine&gt;\n\n\njava.util.stream.Stream\nA lazy Stream of beans\nStream&lt;Engine&gt;\n\n\nArray\nA native array of beans of a given type\nEngine[]\n\n\nProvider\nA javax.inject.Provider if a circular dependency requires it, or to instantiate a prototype for each get call\nProvider&lt;Engine&gt;\n\n\nProvider\nA jakarta.inject.Provider if a circular dependency requires it or to instantiate a prototype for each get call\nProvider&lt;Engine&gt;\n\n\nBeanProvider\nA io.micronaut.context.BeanProvider if a circular dependency requires it or to instantiate a prototype for each get call\nBeanProvider&lt;Engine&gt;\n\n\n推荐使用 BeanProvider\n当使用 java.lang.Collection,java.util.stream.Stream,Array 来注入 Beans 时, 当前类不会被注入到这些集合中:\n@Singletonclass AggregateEngine implements Engine &#123;    @Inject    List&lt;Engine&gt; engines    // engines 中不会包含当前类 AggregateEngine 的实例 Bean    @Override    public void start() &#123;        engines.forEach(Engine::start)    &#125;&#125;\n\n\nA prototype bean will have one instance created per place the bean is injected.\n\n一个 prototype bean 将会在每个注入的地方创建一个实例\n\nWhen a prototype bean is injected as a provider, each call to get() creates a new instance.\n\n当一个 prototype bean 作为一个 provider 来进行注入时, 每次调用 get() 方法会创建一个新的实例\nCollection Ordering (容器中 Bean 的顺序)使用集合来注入 Beans 时, 默认是没有对 Beans 进行排序的\nBeans 可以实现 Ordered 接口来进行排序注入\n或者使用 @Order 注解来声明注入顺序, 在通过 Factory 来创建 Class 位于第三方库的 Beans 时非常有用:\nExample - Factory with @Order:\nimport io.micronaut.context.annotation.Factoryimport io.micronaut.core.annotation.Orderimport jakarta.inject.Singletonimport java.time.Duration@Factoryclass RateLimitsFactory &#123;    @Singleton    @Order(20)    LowRateLimit rateLimit2() &#123;        new LowRateLimit(Duration.ofMinutes(50), 100)    &#125;    @Singleton    @Order(10)    HighRateLimit rateLimit1() &#123;        new HighRateLimit(Duration.ofMinutes(50), 1000)    &#125;&#125;\n\n在注入一个 RateLimit 集合的 Beans 时, 将会使用 @Order 中的 value 值的 正序(asc) 来进行排序\nInjecting a Bean by Order (按顺序注入一个 Bean)在注入单个 Bean 实例时, @Order 注解可以用来声明哪个 Bean 具有更高的优先级\nBean Qualifiers Bean (限定符)当你需要注入一个有多个实现的接口的 Bean 时, 你需要使用一个 qualifier(限定词, 限定语)\nQualifying By Name (通过名字来限定)interface Engine &#123; //     int getCylinders()    String start()&#125;@Singletonclass V6Engine implements Engine &#123; //     int cylinders = 6    @Override    String start() &#123;        &quot;Starting V6&quot;    &#125;&#125;@Singletonclass V8Engine implements Engine &#123; //     int cylinders = 8    @Override    String start() &#123;        &quot;Starting V8&quot;    &#125;&#125;@Singletonclass Vehicle &#123;    final Engine engine    @Inject Vehicle(@Named(&#x27;v8&#x27;) Engine engine) &#123; //         this.engine = engine    &#125;    String start() &#123;        engine.start() //     &#125;&#125;\n\n@Named qualifier 的值 v8 加上 类Engine 构成 v8Engine, 再使用大小写不敏感的判断: v8Engine &#x3D;&#x3D; V8Engine, 所以注入的是 Engine 的 V8Engine 实现\n还可以在类上使用 @Named 来明确声明这个 Bean 的名称, 以便在注入时使用这个名称\nQualifying By Annotation (通过注解来限定)通过使用 @Qualifier 注解来声明自定义的注解来进行 qualify\nimport jakarta.inject.Qualifierimport java.lang.annotation.Retentionimport static java.lang.annotation.RetentionPolicy.RUNTIME@Qualifier@Retention(RUNTIME)@interface V8 &#123;&#125;@Inject Vehicle(@V8 Engine engine) &#123; this.engine = engine &#125;\n\nQualifier By Annotation Members (通过注解的属性成员来限定)使用注解中的值来进行 qualify\nimport io.micronaut.context.annotation.NonBindingimport jakarta.inject.Qualifierimport java.lang.annotation.Retentionimport static java.lang.annotation.RetentionPolicy.RUNTIME@Qualifier // @Retention(RUNTIME)@interface Cylinders &#123;    int value();    @NonBinding //     String description() default &quot;&quot;;&#125;\n\nCylinders 注解中声明了 value 和 description 属性\n@Singleton@Cylinders(value = 6, description = &quot;6-cylinder V6 engine&quot;)  // class V6Engine implements Engine &#123; //     @Override    int getCylinders() &#123;        return 6    &#125;    @Override    String start() &#123;        return &quot;Starting V6&quot;    &#125;&#125;@Singleton@Cylinders(value = 8, description = &quot;8-cylinder V8 engine&quot;) // class V8Engine implements Engine &#123; //     @Override    int getCylinders() &#123;        return 8    &#125;    @Override    String start() &#123;        return &quot;Starting V8&quot;    &#125;&#125;@Inject Vehicle(@Cylinders(8) Engine engine) &#123;    this.engine = engine&#125;\n\n通过 @Cylinders(8) 中的属性值 8 来指明使用 V8Engine 实现\nQualifying by Generic Type Arguments (通过泛型参数来限定)可以通过泛型来进行 qualify\ninterface CylinderProvider &#123;    int getCylinders()&#125;interface Engine&lt;T extends CylinderProvider&gt; &#123; //     default int getCylinders() &#123; cylinderProvider.cylinders &#125;    default String start() &#123; &quot;Starting $&#123;cylinderProvider.class.simpleName&#125;&quot; &#125;    T getCylinderProvider()&#125;class V8 implements CylinderProvider &#123;    @Override    int getCylinders() &#123; 8 &#125;&#125;@Singletonclass V8Engine implements Engine&lt;V8&gt; &#123;  //     @Override    V8 getCylinderProvider() &#123; new V8() &#125;&#125;@InjectVehicle(Engine&lt;V8&gt; engine) &#123;    this.engine = engine&#125;\n\nPrimary and Secondary Beans (主要的和次要的 Bean)在接口有多个实现 Bean 时, 使用 @Primary 注解来声明其中一个 Bean 是主要 Bean, 优先级最高\n使用 @Secondary 注解来声明其中一个 Bean 是次要 Bean\nInjecting Any Bean (注入任意 Bean)注入任意一个 Bean 实现\n@Any qualifier 通常和 BeanProvider 来一起使用, 用于一些动态的判断场景\nimport io.micronaut.context.BeanProviderimport io.micronaut.context.annotation.Anyimport jakarta.inject.Singleton@Singletonclass Vehicle &#123;    final BeanProvider&lt;Engine&gt; engineProvider    Vehicle(@Any BeanProvider&lt;Engine&gt; engineProvider) &#123; //         this.engineProvider = engineProvider    &#125;    void start() &#123;        engineProvider.ifPresent(Engine::start) //     &#125;&#125;\n\nengineProvider.ifPresent(Engine::start) 会在 Bean 存在的时候才进行方法的调用\n还可以同时使用多个满足条件的 Bean:\nvoid startAll() &#123;    if (engineProvider.isPresent()) &#123;        engineProvider.each &#123; it.start() &#125;    &#125;&#125;\n\nLimiting Injectable Types (限制注入的类型)使用 @Bean 注解来限定允许注入的接口或类, 而不是具体的类型\n@Singleton@Bean(typed = Engine) // class V8Engine implements Engine &#123;  //     @Override    String start() &#123; &quot;Starting V8&quot; &#125;    @Override    int getCylinders() &#123; 8 &#125;&#125;\n\n@Bean(typed = Engine) 限定了只能使用 Engine 接口来进行依赖注入, 而不能使用 V8Engine 类来进行依赖注入\nV8Engine 类必须实现 @Bean 注解中声明的类或接口, 否则将会产生编译时异常\nScopes (作用域)Built-In Scopes (内建的作用域)Table - Micronaut Built-in Scopes\n\n\n\nType\nDescription\n\n\n\n@Singleton\nSingleton scope indicates only one instance of the bean will exist\n\n\n@Context\nContext scope indicates that the bean will be created at the same time as the ApplicationContext (eager initialization)\n\n\n@Prototype\nPrototype scope indicates that a new instance of the bean is created each time it is injected\n\n\n@Infrastructure\nInfrastructure scope represents a bean that cannot be override or replaced using @Replaces because it is critical to the functioning of the system\n\n\n@ThreadLocal\n@ThreadLocal scope is a custom scope that associates a bean per thread via a ThreadLocal\n\n\n@Refreshable\n@Refreshable scope is a custom scope that allows a bean’s state to be refreshed via the /refresh endpoint\n\n\n@RequestScope\n@RequestScope scope is a custom scope that indicates a new instance of the bean is created and associated with each HTTP request\n\n\n@Prototype 注解是 @Bean 注解的同义词, 因为默认的 scope 是 prototype 的\n可以通过定义一个实现了 CustomScope 接口的 @Singleton Bean 来添加额外的 scope\n默认情况下, 在启动一个 ApplicationContext 时, 将会延迟与按需创建 @Singleton scope 的 Bean\n可以使用 @Context 注解来将 Bean 的生命周期绑定到 ApplicationContext 上, 换句话说, 就是在 ApplicationContext 启动的时候创建这个 Bean\n或者, 使用 @Parallel 注解来修饰一个 @Singleton scope 的 Bean, 允许并行初始化这个 Bean\n如果你的 Bean 在并行初始化的时候失败了, 那么整个 Application 将会自动关闭\nEager Initialization of Singletons (单例的饿式初始化)通过 ApplicationContextBuilder 接口来进行配置\nExample - Enabling Eager Initialization of Singletons:\npublic class Application &#123;    public static void main(String[] args) &#123;        Micronaut.build(args)                 .eagerInitSingletons(true)                 .mainClass(Application.class)                 .start();    &#125;&#125;\n\n在 Serverless Functions 中:\nExample - Override of newApplicationContextBuilder():\npublic class MyFunctionHandler extends MicronautRequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; &#123;    @Nonnull    @Override    protected ApplicationContextBuilder newApplicationContextBuilder() &#123;        ApplicationContextBuilder builder = super.newApplicationContextBuilder();        builder.eagerInitSingletons(true);        return builder;    &#125;&#125;\n\n@ConfigurationReader Beans 例如 @EachProperty,@ConfigurationProperties 是 Singleton Beans. 为了 饥饿地初始化(eagerly init configuration) 这些配置 Beans 但保持其他 Singleton Beans 延迟初始化, 使用 eagerInitConfiguration:\nExample - Enabling Initialization of Configuration:\npublic class Application &#123;    public static void main(String[] args) &#123;        Micronaut.build(args)                 .eagerInitConfiguration(true)                 .mainClass(Application.class)                 .start();    &#125;&#125;\n\nRefreshable Scope (可刷新的作用域)Refreshable scope 是一个自定义的 scope, 允许 Bean 的状态通过如下方式来进行刷新:\n\n/refresh endpoint\n发布一个 RefreshEvent 事件\n\n@Refreshablestatic class WeatherService &#123;    String forecast    @PostConstruct    void init() &#123;        forecast = &quot;Scattered Clouds $&#123;new SimpleDateFormat(&#x27;dd/MMM/yy HH:mm:ss.SSS&#x27;).format(new Date())&#125;&quot;    &#125;    String latestForecast() &#123; forecast &#125;&#125;\n\n当调用 /refresh endpoint 或者触发一个 RefreshEvent 事件时, 当前的 WeatherService 实例将会失效, 一个新的实例对象将会在下次请求这个实例时创建\n触发 RefreshEvent 事件: applicationContext.publishEvent(new RefreshEvent())\nScopes on Meta Annotations (元注解上的作用域)可以在元注解上声明 Scope, 元注解上声明的 Scope 将会应用到所有被这个注解修饰的类上\nExample:\nimport io.micronaut.context.annotation.Requiresimport jakarta.inject.Singletonimport java.lang.annotation.Documentedimport java.lang.annotation.Retentionimport static java.lang.annotation.RetentionPolicy.RUNTIME@Requires(classes = Car.class)@Singleton@Documented@Retention(RUNTIME)@interface Driver &#123;&#125;\n\nExample - 使用这个元注解:\n@Driver@Prototype      // 这个例外声明的 Scope 将不会生效, Foo 类的 Scope 为 @Driver 中声明的 Singletonclass Foo &#123;&#125;\n\n为了使得 Scope 可以被覆盖, 使用 @DefaultScope 注解:\n@Requires(classes = Car.class)@DefaultScope(Singleton.class)@Documented@Retention(RUNTIME)@interface Driver &#123;&#125;\n\nBean Factories Bean (工厂)一个 Factory 是一个使用 @Factory 注解修饰的类, 这个类提供一个或多个使用 Scope 注解修饰的方法, 所以这个类是用来声明 Bean 的, 通常用于将第三方库中的类声明为 Bean\n@Factoryclass EngineFactory &#123;    @Singleton    Engine v8Engine(CrankShaft crankShaft) &#123;        new V8Engine(crankShaft)    &#125;&#125;\n\nFactory 中的方法的参数被解析为 Bean 并进行了注入, 例如上面例子中的 CrankShaft crankShaft\n在 Factory 中应该使用方法参数来注入这个 Factory 中的其他 Bean, 而不是调用 Factory 中的方法\n为了使得 Factory 中的 Bean 可以参与到应用程序上下文的关闭过程, 应该使用 @Bean 注解并配置 @Bean 注解的 preDestroy 参数来指明关闭时要执行的方法\nProgrammatically Disabling Beans (编程方式来无效化 Beans)Factory 方法可以抛出一个 DisabledBeanException 来有条件地无效化 Beans\n建议使用 @Requires 来条件化创建 Beans\n只有在 @Requires 无法使用的时候才通过在 Factory 方法中抛出异常的方式来条件化创建 Beans\nExample:\ninterface Engine &#123;    Integer getCylinders()&#125;@EachProperty(&quot;engines&quot;)class EngineConfiguration implements Toggleable &#123;    boolean enabled = true    @NotNull    Integer cylinders&#125;@Factoryclass EngineFactory &#123;    @EachBean(EngineConfiguration)    Engine buildEngine(EngineConfiguration engineConfiguration) &#123;        if (engineConfiguration.enabled) &#123;            (Engine)&#123;-&gt; engineConfiguration.cylinders&#125;        &#125; else &#123;            throw new DisabledBeanException(&quot;Engine configuration disabled&quot;)        &#125;    &#125;&#125;\n\nInjection Point (注入点)在注入一个 Bean 时, 通过这个 Bean 上的注解的值来决定哪个 Bean 需要进行实例化\nExample - 声明一个有值的注解:\n@Documented@Retention(RUNTIME)@Target(ElementType.PARAMETER)@interface Cylinders &#123;    int value() default 8&#125;\n\n\nThe above annotation could be used to customize the type of engine we want to inject into a vehicle at the point at which the injection point is defined:\n\n@Singletonclass Vehicle &#123;    private final Engine engine    Vehicle(@Cylinders(6) Engine engine) &#123;        this.engine = engine    &#125;    String start() &#123;        return engine.start()    &#125;&#125;\n\n\nTo implement this use case, define a factory that accepts the InjectionPoint instance to analyze the defined annotation values:\n\n@Factoryclass EngineFactory &#123;    @Prototype    Engine v8Engine(InjectionPoint&lt;?&gt; injectPoint, CrankShaft crankShaft) &#123;        final int cylinders = injectPoint.getAnnotationMetadata()                                         .intValue(Cylinders.class)                                         .orElse(8)        switch (cylinders) &#123;            case 6: return new V6Engine(crankShaft)            case 8: return new V8Engine(crankShaft)            default:                throw new IllegalArgumentException(&quot;Unsupported number of cylinders specified: $cylinders&quot;)        &#125;    &#125;&#125;\n\n使用 @Prototype 注解来使得方法在每一个 注入点(injection point) 都会被调用; 如果 V8Engine 和 V6Engine 需要是 Singleton 的, 那么要在 Factory 中使用 Map 来保证实例只创建了一次\nBeans from Fields (在字段中声明 Beans)在 Micronaut 3.0 或以上版本中, 可以通过在字段(fields)上声明 @Bean 注解来从字段(fields)中提供 Bean\n更推荐的做法是使用 Factory 来创建 Bean, 但通过字段来提供 Bean 可以提供更大的灵活性来简化测试代码编写:\nExample - 通过 Bean 字段来提供 Mock Bean:\nimport io.micronaut.context.annotation.*import io.micronaut.test.extensions.spock.annotation.MicronautTestimport spock.lang.Specificationimport jakarta.inject.Inject@MicronautTestclass VehicleMockSpec extends Specification &#123;    @Requires(beans = VehicleMockSpec.class)    @Bean    @Replaces(Engine.class)    Engine mockEngine = &#123;-&gt; &quot;Mock Started&quot;&#125; as Engine   // A bean is defined from a field that replaces the existing Engine    @Inject    Vehicle vehicle    void &quot;test start engine&quot;() &#123;        given:            final String result = vehicle.start()        expect:            result == &#x27;Mock Started&#x27;    &#125;&#125;\n\n只支持 non-primitive 类型的 public 或者 package protected 的 fields\nPrimitive Beans and Arrays (原始类型的和数组类型的 Bean)从 Micronaut 3.1 开始支持从 Factory 中定义和注入原始类型和数组类型\nimport io.micronaut.context.annotation.Beanimport io.micronaut.context.annotation.Factoryimport jakarta.inject.Named@Factoryclass CylinderFactory &#123;    @Bean    @Named(&#x27;V8&#x27;)    final int v8 = 8    @Bean    @Named(&#x27;V6&#x27;)    final int v6 = 6&#125;@Singletonclass v8Engine &#123;    private final int cylinders    V8Engine(@Named(&#x27;V8&#x27;) int cylinders) &#123;        this.cylinders = cylinders    &#125;    int getCylinders() &#123; cylinders &#125;&#125;\n\n原始类型和数组类型 Bean 有如下限制:\n\nAOP advice 无法应用在原始类型或其包装类型上\n\nDue to the above custom scopes that proxy are not supported\n\n\n\nThe @Bean(preDestroy&#x3D;..) member is not supported\n\n\n\nConditional Beans (条件化加载 Beans)有时候你希望有条件地加载一个 Bean, 例如基于 classpath, configuration, bean 的优先级\n@Requires 注解提供了在 Bean 上定义一个或多个条件的能力\n@Singleton@Requires(beans = DataSource)@Requires(property = &#x27;datasource.url&#x27;)class JdbcBookService implements BookService &#123;    DataSource datasource&#125;\n\n如果有多个 Bean 要求相同的条件, 可以使用元注解来声明这些条件:\n@Requires(beans = DataSource)@Requires(property = &#x27;datasource.url&#x27;)@Documented@Retention(RetentionPolicy.RUNTIME)@Target([ElementType.PACKAGE, ElementType.TYPE])@interface RequiresJdbc &#123;&#125;@RequiresJdbcpublic class JdbcBookService implements BookService &#123;&#125;\n\nConfiguration Requirements (配置要求)Table - Using @Requires\n\n\n\nRequirement\nExample\n\n\n\nRequire the presence of one or more classes\n@Requires(classes=javax.servlet.Servlet)\n\n\nRequire the absence of one or more classes\n@Requires(missing=javax.servlet.Servlet)\n\n\nRequire the presence of one or more beans\n@Requires(beans=javax.servlet.DataSource)\n\n\nRequire the absence of one or more beans\n@Requires(missingBeans=javax.servlet.DataSource)\n\n\nRequire the environment to be applied\n@Requires(env=&quot;test&quot;)\n\n\nRequire the environment not to be applied\n@Requires(notEnv=&quot;test&quot;)\n\n\nRequire the presence of another configuration package\n@Requires(configuration=&quot;foo.bar&quot;)\n\n\nRequire the absence of another configuration package\n@Requires(missingConfiguration=&quot;foo.bar&quot;)\n\n\nRequire particular SDK version\n@Requires(sdk=Sdk.JAVA, value=&quot;1.8&quot;)\n\n\nRequires classes annotated with the given annotations to be available to the application via package scanning\n@Requires(entities=javax.persistence.Entity)\n\n\nRequire a property with an optional value\n@Requires(property=&quot;data-source.url&quot;)\n\n\nRequire a property to not be part of the configuration\n@Requires(missingProperty=&quot;data-source.url&quot;)\n\n\nRequire the presence of one or more files in the file system\n@Requires(resources=&quot;file:/path/to/file&quot;)\n\n\nRequire the presence of one or more classpath resouces\n@Requires(resources=&quot;classpath:myFile.properties&quot;)\n\n\nRequire the current operating system to be in the list\n@Requires(os=&#123;Requires.Family.WINDOWS&#125;)\n\n\nRequire the current operating system to not be in the list\n@Requires(notOs=&#123;Requires.Family.WINDOWS&#125;)\n\n\nRequires bean to be present in case no beanProperty specified\n@Requires(bean=Config.class)\n\n\nRequires the specified property of bean to be present\n@Requires(bean=Config.class, beanProperty=&quot;enabled&quot;)\n\n\nAdditional Notes on Property Requirements (属性要求上额外的信息)@Requires(property = &#x27;foo&#x27;)@Requires(property = &#x27;foo&#x27;, value = &#x27;John&#x27;)@Requires(property = &#x27;foo&#x27;, value = &#x27;John&#x27;, defaultValue = &#x27;John&#x27;)@Requires(property = &#x27;foo&#x27;, notEquals=&#x27;Sally&#x27;)\n\nReferencing bean properties in @Requires (在 @Requires 注解中引用 Bean 属性)@Requires(bean=Config.class, beanProperty=&#x27;foo&#x27;)@Requires(bean=Config.class, beanProperty=&#x27;foo&#x27;, value = &#x27;John&#x27;)@Requires(bean=Config.class, beanProperty=&#x27;foo&#x27;, notEquals = &#x27;Sally&#x27;)\n\n通过 getter 方法来读取 Bean 属性\n在编译时进行检查\n会检查 Bean 属性是否为 null\nDebugging Conditional Beans (调试条件化的 Beans)开启 io.micronaut.context.condition 包的日志 DEBUG 输出来观察 Beans 因为什么原因而没有被加载\n// logback.xml&lt;logger name=&quot;io.micronaut.context.condition&quot; level=&quot;DEBUG /&gt;\n\nBean Replacement (Bean 替代)Micronaut 的依赖注入没有 Bean名称 和 加载顺序 的概念\nMicronaut 的 Bean 有一个 类型 和 Qualifier\n你不能使用一个完全不同类型的 Bean 来覆盖一个 Bean\nMicronaut 提供 @Replaces 注解来进行 Bean 覆盖\nExample - 通过在一个 Bean 上声明 @Replaces 注解来覆盖一个已存在的 Bean:\n// 要被 replace 的类@Singleton@Requires(beans = DataSource)@Requires(property = &quot;datasource.url&quot;)class JdbcBookService implements BookService &#123;&#125;// 为了进行测试, 在 src/test/groovy 中这个 JdbcBookService 类@Replaces(JdbcBookService.class)@Singletonclass MockBookService implements BookService &#123;    Map&lt;String, Book&gt; bookMap = [:]    @Override    Book findBook(String title) &#123; bookMap[title] &#125;&#125;\n\nFactory Replacement (Factory 替代)覆盖 Factory 中生成的 Bean\nExample - 要被覆盖的 Factory:\n@Factoryclass BookFactory &#123;    @Singleton    Book novel() &#123; new Book(&#x27;A Great Novel&#x27;) &#125;    @Singleton    TextBook textBook() &#123; new TextBook(&#x27;Learning 101&#x27;) &#125;&#125;\n\nExample - 覆盖 Factory 中的 Bean:\n@Factoryclass TextBookFactory &#123;    @Singleton    @Replaces(value = TextBook, factory = BookFactory)    TextBook textBook() &#123; new TextBook(&#x27;Learning 305&#x27;) &#125;&#125;\n\nBookFactory 中的 novel() 方法没有被覆盖\nDefault Implementation (默认实现)当暴露一个 API 时, 可能不希望将一个 interface 的默认实现作为公开 API 的一部分. 这样做可以防止用户去替换默认的实现类, 因为用户不能引用到这个类\n解决方法是使用 @DefaultImplementation 注解修饰一个接口, 指明用户使用 @Replaces(YourInterface.class) 时覆盖了哪个接口实现\nExample:\nimport io.micronaut.context.annotation.DefaultImplementation@DefaultImplementation(DefaultResponseStrategy)interface ResponseStrategy &#123;&#125;// The default implementation@Singletonclass DefaultResponseStrategy implements ResponseStrategy &#123;&#125;\n\nExample - The custom implementation:\nimport io.micronaut.context.annotation.Replacesimport jakarta.inject.Singleton@Singleton@Replaces(ResponseStrategy)class CustomResponseStrategy implements ResponseStrategy &#123;&#125;\n\nBean Configurations (Bean 配置)在包级别上进行配置, 使得配置作用于包中所有的 Bean\nExample:\n// package-info.groovy@Configuration@Requires(beans = javax.sql.Datasource)package my.package\n\n在上面的例子中, 指明了 my.package 中的所有的 Bean 只有在 javax.sql.DataSource 类存在时才进行加载\nLife-Cycle Methods (生命周期方法)When The Context Starts (Context 启动时)使用 jakarta.annotation.PostConstruct 注解来在 Bean 构造之后调用一个方法:\nimport jakarta.annotation.PostConstructimport jakarta.inject.Singleton@Singletonclass V8Engine implements Engine &#123;    int cylinders = 8    boolean initialized = false //     @Override    String start() &#123;        if (!initialized) &#123;            throw new IllegalStateException(&quot;Engine not initialized!&quot;)        &#125;        return &quot;Starting V8&quot;    &#125;    @PostConstruct    void initialize() &#123;        initialized = true    &#125;&#125;\n\n\nA method is annotated with @PostConstruct and will be invoked once the object is constructed and fully injected.\n\nWhen The Context Closes (Context 关闭时)使用 javax.annotation.PreDestroy 注解来在一个 Context 关闭之后调用一个方法\nimport jakarta.annotation.PreDestroyimport jakarta.inject.Singletonimport. java.util.concurrent.atomic.AtomicBoolean@Singletonclass PreDestroyBean implements AutoCloseable &#123;    AtomicBoolean stopped = new AtomicBoolean(false)    @PreDestroy    @Override    void close() throws Exception &#123;        stopped.compareAndSet(false, true)    &#125;&#125;\n\n\nA method is annotated with @PreDestroy and will be invoked when the context is closed.\n\n在 Factory 类中, @Bean 注解中的 preDestroy 值告诉 Micronaut 去执行哪个方法:\nimport io.micronaut.context.annotation.Beanimport io.micronaut.context.annotation.Factoryimport jakarta.inject.Singleton@Factoryclass ConnectionFactory &#123;    @Bean(preDestroy = &#x27;stop&#x27;)    @Singleton    Connection connection() &#123; new Connection() &#125;&#125;// The Connection Beanclass Connection &#123;    AtomicBoolean stopped = new AtomicBoolean(false)    void stop() &#123;         stopped.compareAndSet(false, true)    &#125;&#125;\n\n通过 Context 来关闭一个 Bean, 简单地实现 Closeable 或 AutoCloseable 接口是不够的, 必须使用上面提到的其中一个方法\nContext Events (Context 事件)Micronaut 通过 Context 来提供一个通用事件系统\nApplicationEventPublisher API 用来发布事件\nApplicationEventListener API 用来监听事件\n用户可以自定义事件\nPublishing Events (发布事件)Example - Publishing an Event:\nclass SampleEvent &#123;    String message = &#x27;Something happened&#x27;&#125;import io.micronaut.context.event.ApplicationEventPublisherimport jakarta.inject.Injectimport jakarta.inject.Singleton@Singletonclass SampleEventEmitterBean &#123;    @Inject    ApplicationEventPublisher&lt;SampleEvent&gt; eventPublisher    void publishSampleEvent() &#123;        eventPublisher.publishEvent(new SampleEvent())    &#125;&#125;\n\n注入一个 ApplicationEventPublisher Bean 来进行事件发布\nApplicationEventPublisher 的泛型代表了要发布的事件类型\n使用 ApplicationEventPublisher.#publishEvent 方法来发布对应类型的事件\n发布事件默认是同步的(synchronous)\n\nThe publishEvent method will not return until all listeners have been executed. Move this work off to a thread pool if it is time-intensive\n\npublishEvent 方法在所有监听器执行完之前不会返回. 如果这个工作是时间敏感型的, 将这个工作移到一个线程池中执行\nListening for Events (监听事件)要监听一个事件, 注册一个实现了 ApplicationEventListener 接口的 Bean, ApplicatoinEventListener 的泛型代表了要监听的事件类型\nExample - Listening for Events with ApplicationEventListener:\nimport io.micronaut.context.event.ApplicationEventListenerimport io.micronaut.docs.context.events.SampleEvent // 自定义的事件import jakarta.inject.Singleton@Singletonclass SampleEventListener implements ApplicationEventListener&lt;SampleEvent&gt; &#123;    int invocationCounter = 0    @Override    void onApplicationEvent(SampleEvent event) &#123;        invocationCounter++    &#125;&#125;\n\nExample - 测试事件发布接收:\nimport io.micronaut.context.ApplicationContextimport io.micronaut.docs.context.events.SampleEventEmitterBeanimport io.micronaut.docs.context.events.SampleEventListenerimport spock.lang.Specificationclass SampleEventListenerSpec extends Specification &#123;    void &#x27;test event listener is notified&#x27;() &#123;        given:            ApplicationContext context = ApplicationContext.run()            SampleEventEmitterBean emitter = context.getBean(SampleEventEmitterBean)            SampleEventListener listener = context.getBean(SampleEventListener)                expect:            listener.invocationCounter == 0                when:            emitter.publishSampleEvent()        then:            listener.invocationCounter == 1                cleanup:            context.close()    &#125;&#125;\n\n可以使用 ApplicationEventListener.#supports 方法来判断一个事件是否可以处理\n如果你不想实现一个接口, 或者利用其中一个内建事件如 StartupEvent 和 ShutdownEvent , 那么使用 @EventListener 注解\nExample - Listening for Events with @EventListener:\nimport io.micronaut.docs.context.events.SampleEventimport io.micronaut.context.event.StartupEventimport io.micronaut.context.event.ShutdownEventimport io.micronaut.runtime.event.annotation.EventListener@Singletonclass SampleEventListener &#123;    int invocationCounter = 0    @EventListener    void onSampleEvent(SampleEvent event) &#123;        invocationCounter++    &#125;    @EventListener    void onStartupEvent(StartupEvent event) &#123;        // startup logic here    &#125;    @EventListener    void onShutdownEvent(ShutdownEvent event) &#123;        // shutdown logic here    &#125;&#125;\n\n如果事件监听器需要执行一段时间, 可以使用 @Async 注解来将操作运行在一个不同的线程上面:\nExample - Asynchronously listening for Events with @EventListener:\nimport io.micronaut.docs.context.events.SampleEventimport io.micronaut.runtime.event.annotation.EventListenerimport io.micronaut.scheduling.annotation.Async@Singletonclass SampleEventListener &#123;    AtomicInteger invocationCounter = new AtomicInteger(0)    @EventListener    @Async    void onSampleEvent(SampleEvent event) &#123; invocationCounter.getAndIncrement() &#125;&#125;import io.micronaut.context.ApplicationContextimport io.micronaut.docs.context.events.SampleEventEmitterBeanimport spock.lang.Specificationimport spock.util.concurrent.PollingConditionsclass SampleEventListenerSpec extends Specification &#123;    void &#x27;test event listener is notified&#x27;() &#123;        given:            def context = ApplicationContext.run()            def emitter = context.getBean(SampleEventEmitterBean)            def listener = context.getBean(SampleEventListener)        expect:            listener.invocationCounter.get() == 0        when:            emitter.publishSampleEvent()                then:            new PollingConditions(timeout: 5).eventually &#123;                listener.invocationCounter.get() == 1            &#125;        cleanup:            context.close()    &#125;&#125;\n\n事件监听器默认运行在 scheduled executor 上, 可以在 application.yml 上配置这个线程池:\nExample - Configuring Scheduled Task Thread Pool:\nmicronaut:    executors:        scheduled:            type: scheduled            core-pool-size: 30\n\nBean Events (Bean 事件)你可以使用如下接口来挂接(hook)到 Beans 的创建中:\n\nBeanInitializedEventListener : 允许属性都设置后之后, 在 @PostConstruct 事件 hooks 之前修改和替代一个 Bean\nBeanCreatedEventListener : 允许在 Bean 完全初始化了与所有的 @PostConstruct hooks 都执行了之后修改和替代一个 Bean\n\nBeanInitializedEventListener 接口通常和 Factory Bean 结合使用\nclass V8Engine implements Engine &#123;    final int cylinders = 8    double rodLength     @Override    String start() &#123;        return &quot;Starting V$cylinders [rodLength=$rodLength]&quot;    &#125;&#125;@Factoryclass EngineFactory &#123;    private V8Engine engine    double rodLength = 5.7    @PostConstruct    void initialize() &#123;        engine = new V8Engine(rodLength: rodLength)    &#125;    @Singleton    Engine v8Engine() &#123; engine &#125;&#125;@Singletonclass EngineInitializer implements BeanInitializedEventListener&lt;EngineFactory&gt; &#123;    @Override    EngineFactory onInitialized(BeanInitializingEvent&lt;EngineFactory&gt; event) &#123;        EngineFactory engineFactory = event.bean        engineFactory.rodLength = 6.6        engineFactory    &#125;&#125;\n\nBeanCreatedEventListener 接口更典型的使用是用来装饰或增强一个完全初始化好的 Bean, 例如创建一个 Proxy\nBean 事件监听器在 类型转换器(type converters) 之前进行初始化. 如果你的监听器依赖类型转换, 或者依赖配置属性Bean, 或其他任何机制, 你可能会得到一个关于类型转换的异常\nBean Introspection (Bean 内省)从 Micronaut 1.1 开始, 包含了一个关于 JDK 的 Introspector 的编译时替代品\nBeanIntrospector 和 BeanIntrospection 接口允许不使用反射或缓存的反射元数据来查找 Bean 的内省信息来实例化 Bean 和读写 Bean 的属性, 反射或缓存的反射元数据会在大型 Beans 中消耗大量的内存\nMaking a Bean Available for Introspection (让一个 Bean 可用于反射)不像 JDK 的 Introspector, 每个类不是自动地可用于反射的\n为了让一个类可用于反射, 你必须至少要在你的构建中开启 Micronaut 的注解处理器(micronaut-inject-java&#x2F;micronaut-inject-groovy), 并确保运行时有一个 micronaut-core 的依赖\nExample - For Java:\nannotationProcessor(&quot;io.micronaut:micronaut-inject-java:3.4.0&quot;)\n\nExample - For Groovy:\ncompileOnly(&quot;io.micronaut:micronaut-inject-groovy:3.4.0&quot;)\n\nExample - micronaut-core 依赖:\nruntimeOnly(&quot;io.micronaut:micronaut-core:3.4.0&quot;)\n\nUse the @Introspected Annotation (使用 @Introspected 注解)@Introspected 注解可以在任何类上, 使得这个类可用于内省(introspection)\nimport groovy.transform.Canonicalimport io.micronaut.core.annotation.Introspected@Introspected@Canonicalclass Person &#123;    String name    int age = 18    Person(String name) &#123;        this.name = name    &#125;&#125;\n\n一旦在编译时提供了内省数据, 就可以使用 BeanIntrospection API 来进行获取:\ndef introspection = BeanIntrospection.getIntrospection(Person)Person person = introspection.instantiate(&quot;John&quot;)println(&quot;Hello $person.name&quot;)BeanProperty&lt;Person, String&gt; property = introspection.getRequiredProperty(&quot;name&quot;, String)property.set(person, &quot;Fred&quot;)String name = property.get(person)println(&quot;Hello $person.name&quot;)\n\n可以搭配 io.micronaut.core.annotation.AccessorsStyle 注解来修改属性的读写方法前缀: @AccessorsStyle(readPrefixes = &quot;&quot;, writePrefixes = &quot;&quot;)\nBean Fields (Bean 字段)默认情况下 Java 内省只会将 JavaBean 的 getter&#x2F;setter 或 Java 16 record components 看作是 Bean 属性\n可以在类中使用 @Introspected 注解的 accessKind 成员来定义 public 或 package protected fields:\nimport io.micronaut.core.annotation.Introspected@Introspected(accesskind = Introspected.AccessKind.FIELD)class User &#123;    public final String name    // Final fields are treated like read-only properties    public int age = 18         // Mutable fields are treated like read-write properties    User(String name) &#123;        this.name = name    &#125;&#125;\n\nConstructor Methods (构造方法)对于有多个构造方法的类来说, 在要使用的构造方法上添加 @Creator 注解\nimport io.micronaut.core.annotation.Creatorimport io.micronaut.core.annotation.Introspectedimport javax.annotation.concurrent.Immutable@Introspected@Immutableclass Vehicle &#123;    final String name    final String model    final int axles    Vehicle(String make, String model) &#123;        this(make, model, 2)    &#125;    @Creator        // The @Creator annotation denotes which constructor to use    Vehicle(String make, String model, int axles) &#123;        this.make = make        this.model = model        this.axles = axles    &#125;&#125;\n\n这个类没有默认的构造方法, 所以不使用参数调用 instantiate 方法将会抛出 InstantiationException\nStatic Creator Methods (静态构造方法)@Creator 注解可以用在静态方法上来创建类实例\nimport io.micronaut.core.annotation.Creatorimport io.micronaut.core.annotation.Introspectedimport javax.annotation.concurrent.Immutable@Introspected@Immutableclass Business &#123;    final String name    private Business(String name) &#123;        this.name = name    &#125;    @Creator        // The @Creator annotation is applied to the static method which instantiates the class    static Business forName(String name) &#123;        new Business(name)    &#125;&#125;\n\nEnums (枚举)内省一个枚举也是可以的\n添加 @Introspected 注解到枚举类上, 然后这个枚举类就可以通过标准的 valueOf() 方法来进行构造\nUse the @Introspected Annotation on a Configuration Class (在一个配置类上使用 @Introspected 注解)如果你想要内省的类是已经编译好的, 或者是一个第三方库的类, 一个替代的选项是定义一个配置类, 并使用 @Introspected 注解的 classes 成员属性\nimport io.micronaut.core.annotation.Introspected@Introspected(classes = Person)class PersonConfiguration &#123;&#125;\n\nPersonConfiguration 类为 Person 类生成了内省信息\n还可以使用 @Introspected 注解的 packages 属性来为某个包下所有的类生成内省信息, 注意这还是一个实验特性\nWrite an AnnotationMapper to Introspect Existing Annotations (编写一个 AnnotationMapper 来内省一个已存在的注解)如果你想默认为一个已存在的注解进行内省, 你可以编写一个 AnnotationMapper\n一个例子是 EntityIntrospectedAnnotationMapper, 这个 Mapper 确保了所有使用 @javax.persistence.Entity 注解的 Beans 都默认被内省了\nAnnotationMapper 必须存在于 annotation processor classpath\nThe BeanWrapper API (BeanWrapper API)一个 BeanProperty 提供了读写类中一个属性值的原始访问方式, 没有提供任何自动类型转换\n传递给 set&#x2F;get 方法的值应该与底层属性类型相匹配, 否则会发生异常\n为了提供额外的类型转换智能, BeanWrapper 接口允许包装现有的 Bean 实例, 读写 Bean 属性, 并在必要时执行类型转换\nfinal BeanWrapper&lt;Person&gt; wrapper = BeanWrapper.getWrapper(new Person(&quot;Fred&quot;))wrapper.setProperty(&quot;age&quot;, &quot;20&quot;)int newAge = wrapper.getRequiredProperty(&quot;age&quot;, Integer)println(&quot;Person&#x27;s age now $newAge&quot;)\n\nJackson and Bean Introspection (Jackson 和 Bean 内省)Jackson 被配置为使用 BeanIntrospection API 来读写属性值与构造对象, 结果就是无反射的序列化&#x2F;反序列化\n从性能的角度来看, 这是有益的, 并且需要更少的配置来正确地与运行时操作, 例如 GraalVM native\nBean Validation (Bean 校验)从 Micronaut 1.2 开始, Micronaut 内置了校验那些使用了 javax.validation 注解修饰的 Beans 的支持\n最小化的配置是包含 micronaut-validation 模块作为编译时依赖:\nimplementation(&quot;io.micronaut:micronaut-validation&quot;)\n\nMicronaut 现在的实现不是完全遵循 Bean Validator 规范的, 因为这个规范重度依赖基于反射的 APIs\n现在还不支持如下特性:\n\n泛型参数类型上的注解, 因为现在只有 Java 支持这个特性\n任何与 constraint metadata API 的交互, 因为 Micronaut 使用编译时生成的元数据\n基于 XML 的配置\n使用 io.micronaut.validation.validator.constraints.ConstraintValidator 来代替 javax.validation.ConstraintValidator, Micronaut 的 ConstraintValidator 支持编译时的校验注解\n\n如果需要完全的 Bean Validator 2.0 规范, 添加 micronaut-hibernate-validator 模块到你的构建中, 代替 Micronaut 的实现:\nimplementation(&quot;io.micronaut.beanvalidation:micronaut-hibernate-validator&quot;)\n\nValidating Bean Methods (检验 Bean 的方法)在方法参数上使用 javax.validation 注解, 可以检验任何声明为 Micronaut Bean 的类的方法\nExample - Validating Methods:\nimport jakarta.inject.Singletonimport javax.validation.constraints.NotBlank@Singletonclass PersonService &#123;    void sayHello(@NotBlank String name) &#123;        println &quot;Hello $name&quot;    &#125;&#125;\n\n如果一个校验错误产生, 将会抛出一个 javax.validation.ConstraintViolationException\nValidating Data Classes (校验数据类)为了校验数据类, 例如 POJOs (通常用于 JSON 交换), 这个类必须使用 @Introspected 注解进行修饰\n如果这个类是外部的, 则通过 @Introspected 注解进行 import\nExample - POJO Validation:\nimport io.micronaut.core.annotation.Introspectedimport javax.validation.constraints.Minimport javax.validation.constraints.NotBlank@Introspectedclass Person &#123;    @NotBlank    String name    @Min(19L)    int age&#125;\n\n如果要手动校验这个类, 使用注入的 Validator 实例:\n@Inject Validator validatorvoid &#x27;test person is validated with validator&#x27;() &#123;    when: &#x27;The person is validated&#x27;        def constraintViolation = validator.validate(new Person(name: &#x27;&#x27;, age: 10))    then: &#x27;A validation error occurs&#x27;        constraintViolations.size() == 2&#125;\n\n或者在 Bean 方法上, 使用 javax.validation.Valid 来触发级联校验:\n@Singletonclass PersonService &#123;    void sayHello(@Valid Person person) &#123;        println &quot;Hello $person.name&quot;    &#125;&#125;\n\nValidation Configuration Properties (校验属性配置)还可以校验使用了 @ConfigurationProperties 注解修饰的类的属性来确保配置正确\n推荐将 @ConfigurationProperties 注解和 @Context 注解一起使用来确保校验在启动时进行\nDefining Additional Constraints (定义额外的约束)为了定义额外的约束, 创建一个新的注解:\nimport javax.validation.Constraintimport java.lang.annotation.Retentionimport static java.lang.annotation.RetentionPolicy.RUNTIME@Retention(RUNTIME)@Constraint(validatedBy = [])   // 这个注解要使用 `javax.validation.Constraint` 类修饰@interface DurationPattern &#123;    String message() default &quot;invalid duration (&#123;validatedValue&#125;)&quot;  // 2&#125;\n\n2 : A message template can be provided in a hard-coded manner as above. If none is specified, Micronaut tries to find a message using ClassName.message using the MessageSource interface (optional)\n一旦你定义了一个注解, 那么实现一个 ConstraintValidator 来校验这个注解\n你可以直接创建一个 Bean 来直接实现这个接口, 或者创建一个 Factory 来返回一个或多个校验器\n推荐使用 Factory 的方式来定义多个校验器:\nimport io.micronaut.context.annotation.Factoryimport io.micronaut.core.annotation.AnnotationValueimport io.micronaut.validation.validator.constraints.ConstraintValidatorimport io.micronaut.validation.validator.constraints.ConstraintValidatorContextimport jakarta.inject.Singleton@Factoryclass MyValidatorFactory &#123;    @Singleton    ConstraintValidator&lt;DurationPattern, CharSequence&gt; durationPatternValidator() &#123;        return &#123; CharSequence value,                 AnnotationValue&lt;DurationPattern&gt; annotation,                 ConstraintValidatorContext context -&gt;            context.messageTemplate(&quot;invalid duration (&#123;validatedValue&#125;), additional custom message&quot;)   // 1            return value == null || value.toString() ==~ /^PT?[\\d]+[SMHD]&#123;1&#125;$/        &#125; as ConstraintValidator&lt;DurationPattern, CharSequence&gt;    &#125;&#125;\n\n1 : Override the default message template with an inline call for more control over the validation error message. (Since 2.5.0)\n使用这个注解:\n@Singletonclass HolidayService &#123;    String startHoliday(@NotBlank String person,                        @DurationPattern String duration) &#123;        final Duration d = Duration.parse(duration)        return &quot;Person $person is off on holiday for $&#123;d.toMinutes()&#125; minutes&quot;    &#125;&#125;\n\nValidating Annotations at Compile Time (在编译时校验注解)通过添加 micronaut-validation 到注解处理器类路径上 ,你可以使用 Micronaut 的校验器来在编译时校验注解元素\nannotationProcessor(&quot;io.micronaut:micronaut-validation&quot;)\n\nMicronaut 会在编译时校验使用了 javax.validation 修饰的注解值:\nimport java.lang.annotation.Retentionimport static java.lang.annotation.RetentionPolicy.RUNTIME@Retention(RUNTIME)@interface TimeOff &#123;    @DurationPattern    String duration()&#125;\n\n如果 duration 是一个属性占位符, 例如  @TimeOff(duration=&quot;$&#123;my.value&#125;&quot;), 校验将会在运行时进行\n为了在编译时使用一个自定义的 ConstraintValidator, 你必须将校验器定义为一个类:\nimport io.micronaut.core.annotation.NonNullimport io.micronaut.core.annotation.Nullableimport io.micronaut.core.annotation.AnnotationValueimport io.micronaut.validation.validator.constraints.ConstraintValidatorimport io.micronaut.validation.validator.constraints.ConstraintValidatorContextclass DurationPatternValidator implements ConstraintValidator&lt;DurationPattern, CharSequence&gt; &#123;    @Override    boolean isValid(            @Nullable CharSequence value,            @NonNull AnnotationValue&lt;DurationPattern&gt; annotationMetadata,            @NonNull ConstraintValidatorContext context) &#123;        return value == null || value.toString() ==~ /^PT?[\\d]+[SMHD]&#123;1&#125;$/    &#125;&#125;\n\n除此之外:\n\nDefine a META-INF&#x2F;services&#x2F;io.micronaut.validation.validator.constraints.ConstraintValidator file that references the class.\nThe class must be public and have a public no-argument constructor\nThe class must be on the annotation processor classpath of the project to be validated.\n\nBean Annotation Metadata (Bean 注解元数据)BeanContext API 可以用来获取一个实现了 AnnotationMetadata 接口的 BeanDefinition 的引用\nExample - 获取所有使用了一个特定注解修饰的 Bean 定义 - Lookup Bean Definitions by Stereotype:\nBeanContext beanContext = ... // obtain the bean contextCollection&lt;BeanDefinition&gt; definitions = beanContext.getBeanDefinitions(Qualifiers.byStereotype(Controller.class))for (BeanDefinition definition : definitions) &#123;    AnnotationValue&lt;Controller&gt; controllerAnn = definition.getAnnotation(Controller.class)&#125;\n\n上面的例子获取到了所有直接或间接使用 @Controller 注解修饰的 BeanDefinition 实例\nAnnotation Inheritance (注解继承)Example - Defining Inherited Meta Annotations:\nimport io.micronaut.context.annotation.AliasForimport io.micronaut.context.annotation.Requiresimport io.micronaut.core.annotation.AnnotationMetaimport jakarta.inject.Namedimport jakarta.inject.Singletonimport java.lang.annotation.Inheritedimport java.lang.annotation.Retentionimport java.lang.annotation.RetentionPolicy@Inherited@Retention(RetentionPolicy.RUNTIME)@Requires(property = &quot;datasource.url&quot;)@Named@Singleton@interface SqlRepository &#123;    @AliasFor(annotation = Named.class, member = AnnotationMetadata.VALUE_MEMBER)    String value() default &quot;&quot;;&#125;\n\nExample - Using Inherited Meta Annotations on a Super Class:\n@SqlRepositoryabstract class BaseSqlRepository &#123;&#125;\n\nExample - Inheriting Annotations in s Child Class:\nimport jakarta.inject.Namedimport javax.sql.DataSource@Named(&quot;bookRepository&quot;)class BookRepository extends BaseSqlRepository &#123;    private final DataSource dataSource    BookRepository(DataSource dataSource) &#123;        this.dataSource = dataSource    &#125;&#125;\n\n\nA child class must at least have one bean definition annotation such as a scope or qualifier.\n\nAliasing or Mapping Annotations (取别名or映射注解)public @interface Client &#123;    /**     * @return The URL or service ID of the remote service     */    @AliasFor(member = &quot;id&quot;)     String value() default &quot;&quot;;    /**     * @return The ID of the client     */    @AliasFor(member = &quot;value&quot;)     String id() default &quot;&quot;;&#125;\n\n\nWith these aliases in place, whether you define @Client(“foo”) or @Client(id&#x3D;”foo”), both the value and id members will be set, making it easier to parse and work with the annotation.\n\nImporting Beans from Libraries (从一个库中导入 Beans)可以使用 @Import 注解来导入外部库中,已编译的使用了 JSR-330 注解的 Bean\nBean 导入现在只支持 Java 语言\n例如, 为了导入 JSR-330 TCK 到应用中, 添加 TCK 的依赖:\nimplementation(&quot;io.micronaut:jakarta.inject&quot;)\n\n然后在 Applicatoin 类上定义 @Import 注解:\npackage example;import io.micronaut.context.annotation.Import;@Import(    packages = &#123;        &quot;org.atinject.tck.auto&quot;,        &quot;org.atinject.tck.auto.accessories&quot;    &#125;,    annotated = &quot;*&quot;)public class Applicatoin &#123;&#125;\n\npackages 不会进行递归扫描, 因此需要手动指定子包\n默认情况下, Micronaut 只会导入一个 scope 或 qulifier 的类, 所以要在 annotated 上使用 * 来导入所有类型的 Bean\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Language Support","url":"/micronaut/micronaut-language-support/","content":"\n\n\nLanguage Support\nMicronaut for Java (用于 Java 的 Micronaut)\nUsing Micronaut with Java 9+ (在 Java 9+ 中使用 Micronaut)\nThe javax.annotation package\n\n\nIncremental Annotation Processing with Gradle (使用 Gradle 进行增量注解处理)\nUsing Project Lombok (使用 Lombok 项目)\nConfiguring an IDE (配置 IDE)\nRetaining Parameter Names (保留参数名称)\n\n\nMicronaut for Groovy (用于 Groovy 的 Micronaut)\nGroovy-Specific Modules (Groovy 的特有模块)\nGroovy Support in the CLI (CLI 中的 Groovy 支持)\nProgrammatic Routes with GroovyRouteBuilder (使用 GroovyRouteBuilder 的程序化路由)\nUsing GORM in a Groovy application (在一个 Groovy 应用程序中使用 GORM)\nServerless Functions with Groovy (使用 Groovy 的无服务函数)\n\n\nMicronaut for Kotlin (用于 Kotlin 的 Micronaut)\nMicronaut for GraalVM (用于 GraalVM 的 Micronaut)\nGetting Started (开始)\nMicroservices as GraalVM native images (作为 GraalVM 原生镜像的微服务)\nGetting Started with Micronaut and GraalVM (Micronaut 和 GraalVM 入门)\nBuilding a Native Image Using Docker (构建一个使用 Docker 的原生镜像)\nBuilding a Native Image Without Using Docker (构建一个不使用 Docker 的原生镜像)\nUnderstanding Micronaut and GraalVM (理解 Micronaut 和 GraalVM)\nAdding Additional Classes for Reflective Access (为反射访问添加额外的类)\nGenerating Native Images (生成原生镜像)\nResource file generation (资源文件生成)\n\n\nGraalVM and Micronaut FAQ (GraalVM 和 Micronaut 常见问题解答)\nHow does Micronaut manage to run on GraalVM? (Micronaut 如何在 GraalVM 上运行?)\nHow can I make a Micronaut application that uses picocli run on GraalVM? (如何让使用 Picocli 的 Micronaut 应用程序运行在 GraalVM 上)\nWhat about other Third-Party Libraries? (那第三方类库呢)\nI Get a “Class XXX is instantiated reflectively…” Exception. What do I do? (我遇到了一个 “Class XXX is instantiated reflectively…” 异常. 我要怎么办)\nWhat if I want to set the heap’s maximum size with -Xmx, but I get an OutOfMemoryError? (如果我想要使用 -Xmx 设置最大堆内存, 但我得到一个 OutOfMemoryError)\n\n\n\n\n\n\n\n\n\nLanguage Support声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\nMicronaut 支持任何实现了 Java Annotation Processor API 的 JVM 语言\n尽管 Groovy 没有支持这个 API, 但是特别的支持已经通过使用 AST transformations 来构建\n当前支持的语言有: Java, Groovy, Kotlin (通过 kapt 工具)\n\nTheoretically any language that supports a way to analyze the AST at compile time could be supported.\n\n理论上, 任何支持在编译时分析 AST 的语言都可以被支持\n\nThe io.micronaut.inject.writer package includes language-neutral classes that build BeanDefinition classes at compile time using the ASM tool.\n\nio.micronaut.inject.writer 包 包括了与语言无关的类, 这些类在编译时使用 ASM 工具构建 BeanDefinition 类\n接下来的部分介绍了通过特定语言使用 Micronaut 的功能和注意事项\nMicronaut for Java (用于 Java 的 Micronaut)对于 Java, Micronaut 使用一个 Java BeanDefinitionInjectProcessor 注解处理器来在编译时处理类并生成 BeanDefinition 类\n这里最大的优点是在编译时付出了少量成本, 当在运行时 Micronaut 基本上是无反射的, 快速的且内存消耗非常少\nUsing Micronaut with Java 9+ (在 Java 9+ 中使用 Micronaut)Micronaut 是使用 Java 8 构建的, 但在 Java 9 和更高版本中也正常运行\nMicronaut 生成的类与同一个包中的现有类 并排 放置, 因此不会违反有关 Java 模块系统的任何内容\n将 Java 9+ 与 Micronaut 一起使用时有一些注意事项\nThe javax.annotation package如果你使用 Micronaut CLI 创建项目, 如果你使用 Java 9+, 那么 javax.annotation 依赖会自动添加到你的项目中\njavax.annotation, 包含了 @PostConstruct,@PreDestroy 等, 已经从核心 JDK 迁移到一个 module 中了\n一般来说, 应该避免使用这个包中的注解, 应该使用等价的 jakarta.annotation 包\nIncremental Annotation Processing with Gradle (使用 Gradle 进行增量注解处理)Micronaut 支持 Gradle incremental annotation processing, 这个处理通过只编译修改了的类, 避免完全重编译来提供构建速度\n\nHowever, the support is disabled by default since Micronaut allows the definition of custom meta-annotations (to for example define custom AOP advice) that need to be configured for processing.\n\n但是, 默认情况下禁用了该支持, 因为 Micronaut 允许定义需要被配置以进行处理的自定义元注解 (例如定义自定义 AOP advice)\n下面的例子展示了如何为你在 com.example 包下的自定义注解开启并配置增量式注解处理:\nExample - Enabling Incremental Annotation Processing:\n// build.gradletasks.withType(JavaCompile) &#123;    options.compilerArgs = [        &#x27;-Amicronaut.processing.incremental=true&#x27;,        &#x27;-Amicronaut.processing.annotations=com.example.*&#x27;    ]&#125;\n\n如果你不为你的自定义注解开启处理, Micronaut 将会忽略这些注解, 这将有可能破坏你的应用\nUsing Project Lombok (使用 Lombok 项目)Project Lombok 是一个流行的 Java 库, 通过注解处理器添加了一些有用的 AST transformations 到 Java 语言中\n因为 Micronaut 和 Lombok 都使用了注解处理器, 所以在配置 Lombok 时需要特别小心来确保 Lombok 处理器在 Micronaut 处理器之前运行\n如果使用 Gradle, 添加如下依赖:\nExample - Configuring Lombok in Gradle:\n// build.gradlecompileOnly &#x27;org.projectlombok:lombok:1.18.12&#x27;annotationProcessor &#x27;org.projectlombok:lombok:1.18.12&#x27;// Micronaut processor defined after LombokannotationProcessor &#x27;io.micronaut:micronaut-inject-java&#x27;\n\n如果使用 Maven:\n&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;    &lt;artifactId&gt;lombok&lt;/artifactId&gt;    &lt;version&gt;1.18.12&lt;/version&gt;    &lt;scope&gt;provided&lt;/scope&gt;  &lt;/dependency&gt;&lt;/dependencies&gt;...&lt;annotationProcessorPaths combine.self=&quot;override&quot;&gt;  &lt;path&gt;    &lt;!-- must precede micronaut-inject-java --&gt;    &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;    &lt;artifactId&gt;lombok&lt;/artifactId&gt;    &lt;version&gt;1.18.12&lt;/version&gt;  &lt;/path&gt;  &lt;path&gt;    &lt;groupId&gt;io.micronaut&lt;/groupId&gt;    &lt;artifactId&gt;micronaut-inject-java&lt;/artifactId&gt;    &lt;version&gt;$&#123;micronaut.version&#125;&lt;/version&gt;  &lt;/path&gt;    &lt;path&gt;    &lt;groupId&gt;io.micronaut&lt;/groupId&gt;    &lt;artifactId&gt;micronaut-validation&lt;/artifactId&gt;    &lt;version&gt;$&#123;micronaut.version&#125;&lt;/version&gt;  &lt;/path&gt;&lt;/annotationProcessorPaths&gt;\n\n在所有情况下, Micronaut 处理器必须配置在 Lombok 处理器之后. 反转这个顺序的话声明的依赖将不生效\nConfiguring an IDE (配置 IDE)查看 IDE Setup 获取更多信息\nRetaining Parameter Names (保留参数名称)Java 的默认情况下, 在编译时方法参数的参数名称数据不会被保留\n如果你没有显式定义参数名称且依赖于已编译的外部 JAR, 这对于 Micronaut 来说可能是一个问题\n考虑如下接口:\ninterface HelloOperations &#123;    @Get(&quot;/hello/&#123;name&#125;&quot;)    String hello(String name);&#125;\n\n在编译时, 参数名称 name 丢失, 并在之后编译或通过反射读取时变为 arg0\n要避免这个问题, 有两个选择\n你可以显式声明参数名称:\ninterface HelloOperations &#123;    @Get(&quot;/hello/&#123;name&#125;&quot;)    String hello(@QueryValue(&quot;name&quot;) String name);&#125;\n\n或者, 使用建议的在编译所有字节码时使用 -parameters 标志到 javac 命令中. 参考 Obtaining Names of Method Parameters\n例如在 build.gradle 中进行设置:\ncompileJava.options.compileArgs += &#x27;-parameters&#x27;\n\nMicronaut for Groovy (用于 Groovy 的 Micronaut)\nGroovy has first-class support in Micronaut.\n\nGroovy 在 Micronaut 中是一级支持\nGroovy-Specific Modules (Groovy 的特有模块)有额外的 Groovy 特有模块来改善整体体验\nTable - Groovy-Specific Modules:\n\n\n\nDependency\nDescription\n\n\n\nio.micronaut:micronaut-inject-groovy\nIncludes AST transformations to generate bean definitions. Should be compileOnly on your classpath\n\n\nio.micronaut:micronaut-runtime-groovy\nAdds the ability to specify configuration under src/main/resources in Groovy (i.e. application.groovy)\n\n\nio.micronaut:micronaut-function-groovy\nIncludes AST transformations that make it easier to write Functions for AWS Lambda\n\n\n最常用的模块是 micronaut-inject-groovy, 这个模块为 Groovy 类开启了依赖注入和 AOP\nGroovy Support in the CLI (CLI 中的 Groovy 支持)Micronaut Command Line Interface 包括了对 Groovy 的特殊支持\n要创建一个 Groovy 应用程序, 使用 groovy 语言选项. 例如:\nExample - Create a Micronaut Groovy application:\nmn create-app hello-world --lang Groovy\n这个命令会创建一个 Groovy 项目, 使用 Gradle 进行构建. 使用 -build maven 标志来创建一个使用 Maven 进行构建的项目\n一旦你使用 groovy 特性创建了应用程序, 像 create-controller,create-client 等等的命令会创建 Groovy 文件而不是 Java 文件\n下面的例子展示了使用 CLI 的交互模式:\nExample - Create a bean:\n$mn| Starting interactive mode...| Enter a command name to run. Use TAB for completion:mn&gt;create-bean         create-client       create-controllercreate-job          helpmn&gt; create-bean helloBean| Rendered template Bean.groovy to destination src/main/groovy/hello/world/HelloBean.groovy\n\n创建的 Groovy bean 是这样子的:\npackage hello.worldimport jakarta.inject.Singleton@Singletonclass HelloBean &#123;&#125;\n\nGroovy 自动导入 groovy.lang.Singleton, 这个注解会和 jakarta.inject.Singleton 注解冲突. 确保在定义一个 Micronaut 单例 bean 时使用 jakarta.inject.Singleton 来避免意外的行为\nExample - Create a client:\nmn&gt; create-client hello| Rendered template Client.groovy to destination src/main/groovy/hello/world/HelloClient.groovy\n\n生成的 client 是这样子的:\npackage hello.worldimport io.micronaut.http.client.annotation.Clientimport io.micronaut.http.annotation.Getimport io.micronaut.http.HttpStatus@Client(&quot;hello&quot;)interface HelloClient &#123;    @Get(&quot;/&quot;)    HttpStatus index()&#125;\n\nExample - Create a Controller:\nmn&gt; create-controller hello| Rendered controller to src/main/groovy/hello/world/HelloController.groovy| Rendered test to src/test/groovy/hello/world/HelloControllerSpec.groovy\n\n生成的 Controller 是这样子的:\npackage hello.worldimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Get@Controller(&quot;/hello&quot;)class HelloController &#123;    @Get(uri=&quot;/&quot;, produces=&quot;text/plain&quot;)    String index() &#123;        &quot;Example Response&quot;    &#125;&#125;\n\n生成的 ControllerSpec 是这样子的:\npackage hello.worldimport io.micronaut.http.client.annotation.Clientimport io.micronaut.runtime.server.EmbeddedServerimport io.micronaut.test.extensions.spock.annotation.MicronautTestimport io.micronaut.http.client.HttpClientimport io.micronaut.http.HttpResponseimport io.micronaut.http.HttpStatusimport spock.lang.AutoCleanupimport spock.lang.Specificationimport spock.lang.Sharedimport jakarta.inject.Inject@MicronautTestclass HelloControllerSpec extends Specification &#123;    @Shared @Inject    EmbeddedServer embeddedServer    @Shared @AutoCleanup @Inject @Client(&quot;/&quot;)    HttpClient client    void &quot;test index&quot;() &#123;        given:        HttpResponse response = client.toBlocking().exchange(&quot;/hello&quot;)        expect:        response.status == HttpStatus.OK    &#125;&#125;\n\nProgrammatic Routes with GroovyRouteBuilder (使用 GroovyRouteBuilder 的程序化路由)\nIf you prefer to build your routes programmatically (similar to Grails UrlMappings), a special io.micronaut.web.router.GroovyRouteBuilder exists that has some enhancements to make the DSL better.\n\n如果你更喜欢以编程方式构建你的路由 (类似 Grails UrlMappings), 那么有一个特殊的 io.micronaut.web.router.GroovyRouteBuilder, 它具有一些增强功能来使 DSL 更加好\nExample - Using GroovyRouteBuilder:\n@Singletonstatic class MyRoutes extends GroovyRouteBuilder &#123;    MyRoutes(ApplicationContext beanContext) &#123;        super(beanContext)    &#125;    @Inject    void bookResources(BookController bookController, AuthorController authorController) &#123;        GET(bookController) &#123;            POST &#x27;/hello&#123;/message&#125;&#x27;, bookController.&amp;hello  // 1        &#125;        GET(bookController, ID) &#123;                           // 2            GET(authorController)        &#125;    &#125;&#125;\n\n1 : You can use injected controllers to create routes by convention and Groovy method references to create routes to methods\n2 : The ID property can be used to reference include an &#123;id&#125; URI variable\n上面的例子产生如下路由:\n\n/book 映射到 BookController.index()\n/book/hello/&#123;message&#125; 映射到 BookController.hello(String)\n/book/&#123;id&#125; 映射到 BookController.show(String id)\n/book/&#123;id&#125;/author 映射到 AuthorController.index\n\nUsing GORM in a Groovy application (在一个 Groovy 应用程序中使用 GORM)GORM 是一个数据访问工具, 一开始是作为 Grails 的一部分创建的\nGORM 支持多种数据库类型\n下面的表格中总结了使用 GORM 需要的模块, 和到文档的链接\nTable - GORM Modules:\n\n\n\nDependency\nDescription\n\n\n\nio.micronaut.groovy:micronaut-hibernate-gorm\nConfigures GORM for Hibernate for Groovy applications. See the Hibernate Supoort docs\n\n\nio.micronaut.groovy:micronaut-mongo-gorm\nConfigures GORM for MongoDB for Groovy applications. See the Mongo Support docs\n\n\nio.micronaut.groovy:micronaut-neo4j-gorm\nConfigures GORM for Neo4j for Groovy applications. See the Neo4j Support docs\n\n\n一旦你按照上表中的链接的说明配置了 GORM 实现, 你就可以使用 GORM 所有功能\nGORM Data Services 同样可以参与到依赖注入和生命周期方法:\nExample - GORM Data Service VehicleService.groovy:\n@Service(Vehicle)abstract class VehicleService &#123;    @PostConstruct    void init() &#123;&#125;    abstract Vehicle findVehicle(@NotBlank String name)    abstract Vehicle saveVehicle(@NotBlank String name)&#125;\n\nServerless Functions with Groovy (使用 Groovy 的无服务函数)微服务应用只是使用 Micronaut 的其中一种方式\n还可以将它用于 AWS Lambda 等 Serverless Functions 上\n\nWith the function-groovy module, Micronaut features enhanced support for functions written in Groovy.\n\n借助 function-groovy 模块, Micronaut 增强了对用 Groovy 编写的函数的支持\n查看 Serverless Functions 获取更多信息\nMicronaut for Kotlin (用于 Kotlin 的 Micronaut)略\nMicronaut for GraalVM (用于 GraalVM 的 Micronaut)GraalVM 是一个来自 Oracle 的通用虚拟机, 支持跨语言运行时环境, 可以将 Java 应用程序编译成原生机器代码\n所有 Micronaut 应用程序可以使用 GraalVM 来运行, 但是已经向 Micronaut 添加了特殊支持, 以支持使用 GraalVM’s native-image tool 运行 Micronaut 应用程序\nMicronaut 现在支持 22.0.0.2 版本的 GraalVM, 开发团队正在改进每个新版本的支持\n\nDon’t hesitate to report issues however if you find any problem.\n\nMicronaut 的许多模块和第三方库已经通过验证可以与 GraalVM 一起使用:\n\nHTTP server\nHTTP client\nFunction support\nMicronaut Data JDBC\nJPA\nService Discovery\nRabbitMQ\nViews\nSecurity\nZipkin\netc\n\n\nSupport for other modules is evolving and will improve over time.\n\n对其他模块的支持正在发展, 将会持续改进\nGetting Started (开始)GraalVM 的 native-image 工具的只支持 Java 和 Kotlin 项目. Groovy 重度依赖反射, 而反射在 GraalVM 中仅有部分的支持\n要开始使用 GraalVM, 请先安装 GraalVM SDK\nMicroservices as GraalVM native images (作为 GraalVM 原生镜像的微服务)Getting Started with Micronaut and GraalVM (Micronaut 和 GraalVM 入门)从 Micronaut 2.2 版本开始, 所有 Micronaut 应用程序已经使用 Micronaut Gradle 或 Micronaut Maven 插件构建为原生镜像\n首先, 创建一个新项目:\nExample - Creating a GraalVM Native Microservice:\nmn create-app hello-world\n可以使用 --build maven 来构建一个 Maven 项目\nBuilding a Native Image Using Docker (构建一个使用 Docker 的原生镜像)要使用 Gradle 和 Docker 构建原生镜像, 请运行:\nExample - Building a Native Image with Docker and Gradle:\n./gradlew dockerBuildNative\n\n要使用 Maven 和 Docker 构建原生镜像, 请运行:\nExample - Building a Native Image with Docker and Maven:\n./mvnw package -Dpackaging=docker-native\n\nBuilding a Native Image Without Using Docker (构建一个不使用 Docker 的原生镜像)要构建不使用 Docker 的原生镜像, 请先安装 GraalVM SDK\nExample - Installing GraalVM 22.0.0.2 with SDKman:\nsdk install java 22.0.0.2.rll-grlsdk use java 22.0.0.2.r11-grl\n\nnative-image 工具是从基础 GraalVM 发行版中提取的, 可以作为插件使用, 要安装这个工具 ,请运行:\nExampel - Installing native-imaeg tool:\ngu install native-image\n\n现在你可以通过使用 Gradle 运行 nativeCompile task 来构建原生镜像:\nExample - Creating native image with Gradle:\n./gradlew nativeCompile\n\n原生镜像将会被构建在 build/native/nativeCompile 目录中\n要使用 Maven 和 Micronaut Maven 插件创建一个原生镜像, 使用 native-image 打包格式:\nExample - Creating native image with Maven:\n./mvnw package -Dpackaging=native-image\n\n原生镜像将会被构建在 target 目录中\n在 build/native/nativeCompile 或 target 目录中运行原生镜像:\nExample - Run native image:\n./hello-world\n\nUnderstanding Micronaut and GraalVM (理解 Micronaut 和 GraalVM)Micronaut 本身不依赖反射和动态类加载, 所以它可以自动和 GraalVM native 一起使用, 但是 Micronaut 使用的一些第三方库可能需要额外的关于使用反射的额外输入\nMicronaut 包含了一个注解处理器来帮助生成 reflect-config.json 元数据文件, 这个文件会自动被 native-image 工具读取:\nannotationProcessor(&quot;io.micronaut:micronaut-graal&quot;)\n这个处理器将会生成:\n\n类构建目录 (build classes directory) 中的 META-INF/native-image 目录中生成一个 reflect-config.json 文件\n\n类构建目录在 Gradle 中是 build/classes/java/main, 在 Maven 中是 target/classes\n例如, 有如下类:\npackage example;import io.micronaut.core.annotation.ReflectiveAccess;@ReflectiveAccessclass Test &#123;&#125;\n\n上面的例子中将会导致 example.Test 中的 public methods,declared fields,declared constructors 被包含到 reflect-config.json 文件中\n如果你有更进一步的要求, 且希望包含指定的 fields 或 methods, 在任何 constructor,field,method 上使用 @ReflectiveAccess 注解来包含特定的 field,constructor,method\n要提供你自己的 reflect.json, 添加一个 src/main/graal/reflect.json, 这个文件将会自动被读取\nAdding Additional Classes for Reflective Access (为反射访问添加额外的类)\nTo inform Micronaut of additional classes to be included in the generated reflect.json file at compile time, either annotate a class with @ReflectiveAccess or @TypeHint.\n\n为了在编译时通知 Micronaut 在生成的 reflect.json 文件中包含额外的类, 请使用 @ReflectiveAccess 或 @TypeHint\n\nBoth allows for reflective access, and the latter is typically used on a module or Application class to include classes that are needed reflectively.\n\n这两个注解都允许反射访问, @TypeHint 通常用于模块或应用程序类以包含反射所需的类\n例如, 下面的例子来自于 Micronaut 的 Jackson 模块:\n@TypeHint(    value = &#123;   // 1        PropertyNamingStrategy.UpperCamelCaseStrategy.class,        ArrayList.class,        LinkedHashMap.class,        HashSet.class    &#125;,    accessType =TypeHint.AccessType.ALL_DECLARED_CONSTRUCTORS   // 2)\n\n1 : The value memeber specifies which classes require reflection.\n2 : The accessType member specifies if only classloading access is needed or whether full reflection on all public memebers is needed.\nGenerating Native Images (生成原生镜像)GraalVM 的 native-image 命令生成原生镜像\n你可以使用这个命令手动地生成你的原生镜像, 例如:\nExample - The native-image command:\nnative-image --class-path build/libs/hello-world-0.1-all.jar\n\nclass-path 参数用来引用 Micronaut 的 shaded JAR\n一旦镜像构建好了, 使用原生镜像名称来运行应用程序:\nExample - Running the Native Application:\n./hello-world\n\n正如你所看到的, 原生镜像在毫秒内启动, 并且内存消耗不包括 JVM 的内存消耗 (一个原生 Micronaut 应用程序仅需 20mb 内存来运行)\nResource file generation (资源文件生成)从 Micronaut 3.0 开始后, resource-config.json 文件的自动生成现在是 Gradle 和 Maven 插件的一部分了\nGraalVM and Micronaut FAQ (GraalVM 和 Micronaut 常见问题解答)How does Micronaut manage to run on GraalVM? (Micronaut 如何在 GraalVM 上运行?)Micronaut 提供了不使用反射的依赖注入和AOP运行时. 这使得 Micronaut 应用程序更加容易运行在 GraalVM 上, 因为在原生镜像中的反射有很大的限制\nHow can I make a Micronaut application that uses picocli run on GraalVM? (如何让使用 Picocli 的 Micronaut 应用程序运行在 GraalVM 上)Picocli 提供了一个带有生成 GraalVM 反射配置文件工具的 picocli-codegen 模块\n这个工具可以手动运行, 也可以作为构建的一部分自动运行\n这个模块的 README 包含代码片段的使用说明, 用于配置 Gradle 和 Maven 以在构建过程中自动生成 cli-reflect.json 文件\n在运行 native-image 工具时添加生成的文件到 -H:ReflectionConfigurationFiles 选项中\nWhat about other Third-Party Libraries? (那第三方类库呢)Micronaut 不能保证第三方类库可以运行在 GraalVM SubstrateVM 上, 每个类库要自己去实现支持\nI Get a “Class XXX is instantiated reflectively…” Exception. What do I do? (我遇到了一个 “Class XXX is instantiated reflectively…” 异常. 我要怎么办)如果你遇到这样的异常:\nClass myclass.Foo[] is instantiated reflectively but was never registered. Register the class by using org.graalvm.nativeimage.RuntimeReflection\n你需要手动调整生成的 reflect.json 文件. 对于普通类, 你需要添加一个 entry 到 数组中:\n[    &#123;        &quot;name&quot;: &quot;myclass.Foo&quot;,        &quot;allDeclaredConstructors&quot;: true    &#125;]\n\n对于必须使用 Java JVM 内部数组形式的数组的情况, 这样子设置:\n[    &#123;        &quot;name&quot;: &quot;[Lmyclass.foo&quot;,        &quot;allDeclaredConstructors&quot;: true    &#125;]\n\nWhat if I want to set the heap’s maximum size with -Xmx, but I get an OutOfMemoryError? (如果我想要使用 -Xmx 设置最大堆内存, 但我得到一个 OutOfMemoryError)如果你在用来构建原生镜像的 Dockerfile 中设置了最大堆内存, 你很有可能得到一个运行时错误:\njava.lang.OutOfMemoryError: Direct buffer memory\n这个问题是因为 Netty 尝试使用默认配置 io.netty.allocator.pageSize 和 io.netty.allocator.maxOrder 为每个块分配 16MB 内存:\nint defaultChunkSize = DEFAULT_PAGE_SIZE &lt;&lt; DEFAULT_MAX_ORDER; // 8192 &lt;&lt; 11 = 16MB\n最简单的解决方案是在你的 Dockerfile 的 entrypoint 中指定 io.netty.allocator.maxOrder. 一个可行的例子是 -Xmx64m:\nENTRYPOINT [&quot;/app/application&quot;, &quot;-Xmx64m&quot;, &quot;-Dio.netty.allocator.maxOrder=8&quot;]\n更进一步, 你可以尝试使用 io.netty.allocator.numHeapArenas 或者 io.netty.allocator.numDirectArenas. 你可以在 official documentation 中找到更多关于 Netty 的 PooledByteBufAllocator 信息\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Logging","url":"/micronaut/micronaut-logging/","content":"\n\n\nLogging\nLogging Messages (记录日志信息)\nConfiguration (配置)\nDisabling a Logger with Properties (使用属性来关闭一个 Logger)\n\n\nLogback (Logback)\nLogging System (日志系统)\n\n\n\n\n\nLogging声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\nMicronaut 使用 Slf4j 来记录信息\n通过 Micronaut Launch 创建的应用使用的默认实现是 Logback\n但是也支持其他任何的 Slf4j 实现\nLogging Messages (记录日志信息)要记录日志信息, 使用 Slf4j 的 LoggerFactory 来为你的类获取一个 logger\nimport org.slf4j.Loggerimport org.slf4j.LoggerFactoryclass LoggerExample &#123;    private static Logger logger = LoggerFactory.getLogger(LoggerExample.class)    static void main(String[] args) &#123;        logger.debug &quot;Debug message&quot;        logger.info &quot;Info message&quot;        logger.error &quot;Error message&quot;    &#125;&#125;\n\nConfiguration (配置)日志级别可以通过定义在 application.yml (和环境变量) 的属性来进行配置, 使用 logger.levels 前缀\nlogger:    levels:        foo.bar: ERROR\n\n同样的配置可以通过设置环境变量 LOGGER_LEVELS_FOO_BAR 来完成\n注意当前无法为非常规前缀 (例如 foo.barBaz) 设置日志级别\nDisabling a Logger with Properties (使用属性来关闭一个 Logger)要关闭一个 Logger, 你需要设置 logger 级别为 OFF:\nlogger:    levels:        io.verbose.logger.who.CriedWolf: OFF    # 1\n\n1 : 这将会关闭 io.verbose.logger.who.CriedWolf 类的所有日志输出\n注意, 通过配置控制日志界别的能力是被 LoggingSystem 接口控制的\n当前, Micronaut 包含了一个实现来允许为 Logback 库设置日志级别\n如果你使用其他库, 你需要提供一个实现这个接口的 bean\nLogback (Logback)要使用 logback 库, 添加如下配置到你的构建中:\nimplementation(&quot;ch.qos.logback:logback-classic&quot;)\n如果 logback.xml 文件还未存在, 那么放置一个 logback.xml 文件到资源目录中并修改你需要的内容:\nExample - src/main/resources/logback.xml:\n&lt;configuration&gt;    &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;        &lt;withJansi&gt;true&lt;/withJansi&gt;        &lt;encoder&gt;            &lt;pattern&gt;%cyan(%d&#123;HH:mm:ss.SSS&#125;) %gray([%thread]) %highlight(%-5level) %magenta(%logger&#123;36&#125;) - %msg%n            &lt;/pattern&gt;        &lt;/encoder&gt;    &lt;/appender&gt;    &lt;root level=&quot;info&quot;&gt;        &lt;appender-ref ref=&quot;STDOUT&quot;/&gt;    &lt;/root&gt;&lt;/configuration&gt;\n\n要修改特定类或包名的日志级别, 可以添加这样一个 logger entry 到 configuration 块中:\n&lt;configuration&gt;    &lt;logger name=&quot;io.micronaut.context&quot; level=&quot;TRACE&quot;/&gt;&lt;/configuration&gt;\n\nLogging System (日志系统)\nThe Micronaut Framework has a notion of a logging system.\n\nMicronaut 有日志系统的概念\n\nIn short, it is a simple API to be able to set log levels in the logging implementation at runtime.\n\n简单来说, 有一个简单的 API 可以在运行时在日志实现中设置日志级别\n\nDefault implementations are provided for Logback and Log4j2\n\n默认为 Logback 和 Log4j2 提供了实现\n\nThe behavior of the logging system can be overridden by creating your own implementation of LoggingSystem and replace the implementation being used with the @Replaces annotation.\n\n日志系统的行为可以通过创建你自己的 LoggingSystem 接口实现并使用 @Replaces 注解来代替原来的实现来覆盖\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Management & Monitoring","url":"/micronaut/micronaut-management-and-monitoring/","content":"\n\n\nManagement &amp; Monitoring\nCreating Endpoints (创建端点)\nThe Endpoints Annotation (端点注解)\nExample of custom Endpoint (自定义端点的例子)\n\n\nEndpoint Methods (端点方法)\nRead Methods (读方法)\nWrite Methods (写方法)\nDelete Methods (删除方法)\n\n\nEndpoint Sensitivity (端点敏感性)\nEndpoint Configuration (端点配置)\n\n\nBuilt-In Endpoints (内置端点)\nManagement Port (管理端口)\nJMX (JMX)\nThe Beans Endpoint (Beans 端点)\nConfiguration (配置)\nCustomization (自定义)\n\n\nThe Info Endpoint (Info 端点)\nConfiguration (配置)\nCustomization (自定义)\nProvided Info Sources (提供的 Info 源)\nConfiguration Info Source (配置 Info 源)\nConfiguration (配置)\n\n\nGit Info Source (Git Info Source)\nConfiguration (配置)\n\n\nBuild Info Source (构建 Info Source)\nConfiguration (配置)\n\n\n\n\n\n\nThe Health Endpoint (健康端点)\nConfiguration (配置)\nCustomization (自定义)\nProvided Indicators (提供的指示器)\nDisk Space (磁盘空间)\nJDBC (JDBC)\nDiscovery Client (发现客户端)\n\n\n\n\nThe Metrics Endpoint (指标端点)\nThe Refresh Endpoint (刷新端点)\nConfiguration (配置)\n\n\nThe Routes Endpoint (路由端点)\nConfiguration (配置)\nCustomization (自定义)\n\n\nThe Loggers Endpoint (日志端点)\nConfiguration (配置)\nCustomization (自定义)\n\n\nThe Caches Endpoint (缓存端点)\nThe Server Stop Endpoint (服务停止端点)\nConfiguration (配置)\n\n\nThe Environment Endpoint (环境端点)\nConfiguration (配置)\nGetting information about the environment (获取关于环境的信息)\nGetting information about a particular PropertySource (获取特定的 PropertySource 信息)\n\n\nThe ThreadDump Endpoint (线程转储端点)\nConfiguration (配置)\nCustomization (自定义)\n\n\n\n\n\n\n\n\n\nManagement &amp; Monitoring声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\n如果你使用 Micronaut CLI 创建项目, 使用 management 功能来配置 management endpoints 到你的项目中:\nmn create-app my-app --features management\n受 Spring Boot 和 Grails 的启发, Micronaut management 依赖添加了对通过 endpoints 监控你的应用程序的支持\nendpoints: 一个特殊的 URIs, 返回关于应用程序的健康和状态细节\nmanagement endpoints 同时和 Micronaut 的 security 依赖集成, 允许在你的安全系统中将敏感数据限制于授权的用户 (查看 安全章节中的Built-in Endpoints Access)\n要使用 management 功能, 添加如下依赖到你的构建中:\nimplementation(&quot;io.micronaut:micronaut-management&quot;)\nCreating Endpoints (创建端点)除了 内建的 endpoints, management 依赖还提供了自定义 endpoints 的支持\n这可以像内置 endpoints 一样启用和配置, 并可用于检索和返回任何指标或其他应用程序数据\nThe Endpoints Annotation (端点注解)可通过使用 @Endpoint 注解修饰一个类来创建一个 endpoint, 至少要提供一个 endpoint id\nExample - FooEndpoint.java\n@Endpoint(&quot;foo&quot;)class FooEndpoint &#123;&#125;\n\n如果提供一个 String 参数给注解, 那么这个 String 就作为 endpoint id\n可以提供额外命名的参数给注解. @Endpoint 其他可能的参数都展示在下表中:\nTable - Endpoint Arguments:\n\n\n\nArgument\nDescription\nEndpoint Example\n\n\n\nString id\nThe endpoint (or name)\n@Endpoint(id &#x3D; “foo”)\n\n\nString prefix\nPrefix used for configuring the endpoint (see Endpoint Configuration)\n@Endpoint(prefix &#x3D; “foo”)\n\n\nboolean defaultEnabled\nSets whether the endpoint is enabled when no configuration is set (see Endpoint Configuration)\n@Endpoint(defaultEnabled &#x3D; false)\n\n\nboolean defaultSensitive\nSets whether the endpoint is sensitive if no configuration is set (see Endpoint Configuration)\n@Endpoint(defaultSensitive &#x3D; false)\n\n\nExample of custom Endpoint (自定义端点的例子)下面的例子中的 Endpoint 类创建了一个可以在 /date 访问的端点:\nExample - CurrentDateEndpoint:\nimport io.micronaut.management.endpoint.annotation.Endpoint@Endpoint(    id = &#x27;date&#x27;,    prefix = &#x27;custom&#x27;,    defaultEnabled = true,    defaultSensitive = false)class CurrentDateEndpoint &#123;&#125;\n\nEndpoint Methods (端点方法)Endpoints 响应 GET(读取), POST(写), DELETE(删除) 请求\n要从一个 endpoint 中返回响应, 使用如下注解修饰它的 public 方法:\nTable - Endpoint Method Annotations:\n\n\n\nAnnotation\nDescription\n\n\n\n@Read\nResponds to GET requests\n\n\n@Write\nResponds to POST requests\n\n\n@Delete\nResponds to DELETE requests\n\n\nRead Methods (读方法)使用 @Read 注解修饰一个方法使得这个方法响应 GET 请求\nExample - CurrentDateEndpoint:\nimport io.micronaut.management.endpoint.annotation.Endpointimport io.micronaut.management.endpoint.annotation.Read@Endpoint(id = &#x27;date&#x27;,          prefix = &#x27;custom&#x27;,          defaultEnabled = true,          defaultSensitive = false)class CurrentDateEndpoint &#123;        private Date currentDate    @Read    Date currentDate() &#123; currentDate &#125;&#125;\n\n上面的方法响应如下请求:\ncurl -X GET localhost:38238/date1526085903689\n\n@Read 注解接受一个可选的 produces 参数, 用来设置从方法返回的类型的 media type (默认是 application/json)\nExample - CurrentDateEndpoint:\nimport io.micronaut.management.endpoint.annotation.Endpointimport io.micronaut.management.endpoint.annotation.Readimport io.micronaut.http.MediaTypeimport io.micronaut.management.endpoint.annotation.Selector@Endpoint(id = &#x27;date&#x27;,          prefix = &#x27;custom&#x27;,          defaultEnabled = true,          defaultSensitive = false)class CurrentDateEndpoint &#123;        private Date currentDate    @Read(produces = MediaType.TEXT_PLAIN)    Date currentDate(@Selector String prefix) &#123;         &quot;$prefix: $currentDate&quot;    &#125;&#125;\n\n上面的方法响应如下的请求:\ncurl -X GET localhost:8080/date/the_date_isthe_date_is: Fri May 11 19:24:21 CDT\n\nWrite Methods (写方法)使用 @Write 注解修饰一个方法使得这个方法响应 POST 请求\nExample - CurrentDateEndpoint:\nimport io.micronaut.management.endpoint.annotation.Endpointimport io.micronaut.management.endpoint.annotation.Writeimport io.micronaut.http.MediaTypeimport io.micronaut.management.endpoint.annotation.Selector@Endpoint(id = &#x27;date&#x27;,          prefix = &#x27;custom&#x27;,          defaultEnabled = true,          defaultSensitive = false)class CurrentDateEndpoint &#123;    private Date currentDate    @Write    String reset() &#123;        currentDate = new Date()        &#x27;Current date reset&#x27;    &#125;&#125;\n\n上面的例如响应如下的请求:\ncurl -X POST http://localhost:93284/dateCurrent date reset\n\n@Write 注解接受一个可选的 consumes 参数来设置这个方法接受的 media type (默认为 application/json)\nExample - MessageEndpoint:\nimport io.micronaut.management.endpoint.annotation.Endpointimport io.micronaut.management.endpoint.annotation.Writeimport io.micronaut.http.MediaType@Endpoint(id = &#x27;message&#x27;,          defaultSensitive = false)class MessageEndpoint &#123;    String message    @Write(        consumes = MediaType.APPLICATION_FORM_URLENCODED,        produces = MediaType.TEXT_PLAIN    )    String updateMessage(String newMessage) &#123;        message = newMessage        &#x27;Message updated&#x27;    &#125;&#125;\n\n上面的方法响应如下的请求:\ncurl -X POST http://localhost:65013/message -H &#x27;Content-Type: application/x-www-form-urlencoded&#x27; -d $&#x27;newMessage=A new message&#x27;Message updated\n\nDelete Methods (删除方法)使用 @Delete 注解修饰一个方法使得这个方法响应 DELETE 请求\nExample - MessageEndpoint:\nimport io.micronaut.management.endpoint.annotation.Endpointimport io.micronaut.management.endpoint.annotation.Delete@Endpoint(id = &#x27;message&#x27;,          defaultSensitive = false)class MessageEndpoint &#123;    String message    @Delete    String deleteMessage() &#123;        message = null        &#x27;Message deleted&#x27;    &#125;&#125;\n\n上面的方法响应如下的请求:\ncurl -X DELETE http://localhost:65013/messageMessage deleted\n\nEndpoint Sensitivity (端点敏感性)可以通过 endpoint 注解和配置来控制整个 endpoint 的敏感性\n但是, 单个方法可以独立于整个 endpoint 进行配置\n@Sensitive 注解可以应用到方法上来控制方法的敏感性\nExample - AlertsEndpoint:\nimport io.microanut.http.MediaTypeimport io.micronaut.management.endpoint.annotation.Deleteimport io.micronaut.management.endpoint.annotation.Endpointimport io.micronaut.management.endpoint.annotation.Readimport io.micronaut.management.endpoint.annotation.Sensitiveimport io.micronaut.management.endpoint.annotation.Writeimport java.util.concurrent.CopyOnWriteArrayList@Endpoint(id = &#x27;alerts&#x27;, defaultSensitive = false)  // 1class AlertsEndpoint &#123;    private final List&lt;String&gt; alerts = new CopyOnWriteArrayList&lt;&gt;()    @Read    List&lt;String&gt; getAlerts() &#123; alerts &#125;    @Delete    @Sensitive(true)    // 2    void clearAlerts() &#123; alerts.clear() &#125;    @Write(consumes = MediaType.TEXT_PLAIN)    @Sensitive(property = &#x27;add.sensitive&#x27;, defaultValue = true)     // 3    void addAlerts(String alert) &#123; alerts &lt;&lt; alert &#125;&#125;\n\n1 : endpoint 默认为不敏感的, 并且使用默认的前缀 (prefix) endpoints\n2 : 这个方法总是敏感的, 不管其他任何因素\n3 : property 的值被附加到前缀 (prefix) 和 id 以查找配置值\n如果配置 key endpoints.alerts.add.sensitive 有进行设置, 那这个 key 对应的值将指明 addAlert 方法的敏感性\n\nendpoint 是第一个标记 (token), 因为这是 @Endpoint 注解中默认的前缀值, 并且在这个例子中没有明确指定前缀值\nalerts 是第二个标记 (token), 因为这是 endpoint 的 id\nadd.sensitive 是最后一个标记 (token), 因为这是设置到 @Sensitive 注解的 property 成员的值\n\n如果配置 key 没有设置, 会使用 defaultValue (默认为 true)\nEndpoint Configuration (端点配置)具有 endpoints 前缀的 endpoints 可以通过它们默认的 endpoint id 来进行配置\n如果存在 id 为 foo 的 endpoint, 可以通过 endpoints.foo 进行配置\n除此之外, 可以通过 all 前缀来提供默认值\nExample - FooEndpoint.java:\n@Endpoint(&quot;foo&quot;)class FooEndpoint &#123;&#125;\n\n默认情况下, 这个 endpoint 是开启的\n要关闭这个 endpoint, 设置 endpoints.foo.enabled 为 false\n如果 endpoints.foo.enabled 没有设置, 但设置了 endpoints.all.enabled 为 false, 那么这个 endpoint 将会是关闭的\n特定 endpoint 的配置会覆盖 all 的配置. 如果 endpoints.foo.enabled 为 true 且 endpoints.all.enabled 为 false, 那么这个 foo endpoint 将会是开启的\n对于所有 endpoints, 可以设置如下配置值:\nendpoints:    &lt;any endpoint id&gt;:        enabled: Boolean        sensitive: Boolean\n\n所有 endpoints 的基础路径默认为 /\n如果你想 endpoints 在不同的基础路径下可用, 配置 endpoints.all.path\n例如, 如果 endpoints.all.path 设置为 /endpoints, 那么 foo endpoint 将会在 /endpoints/foo 路径下可访问\nBuilt-In Endpoints (内置端点)当 management 依赖添加到了你的项目中, 那么会默认开启如下内置 endpoints:\nTable - Default Endpoints:\n\n\n\nEndpoint\nURI\nDescription\n\n\n\nBeansEndpoint\n&#x2F;beans\nReturns information about the loaded bean definitions in the application (see BeansEndpoint)\n\n\nHealthEndpoint\n&#x2F;health\nReturns information about the “health” of the application (see HealthEndpoint)\n\n\nInfoEndpoint\n&#x2F;info\nReturns static information from the state of the application (see InfoEndpoint)\n\n\nLoggersEndpoint\n&#x2F;loggers\nReturns information about available loggers and permits changing the configured log level (see LoggersEndpoint)\n\n\nMetricsEndpoint\n&#x2F;metrics\nReturn the application metrics. Requires the micrometer-core configuration on the classpath\n\n\nRefreshEndpoint\n&#x2F;refresh\nRefreshes the application state (see RefreshEndpoint)\n\n\nRoutesEndpoint\n&#x2F;routes\nReturns information about URIs available to be called for your application (see RoutesEndpoint)\n\n\nThreadDumpEndpoint\n&#x2F;threaddump\nReturns information about the current threads in the application\n\n\n除此之外, management 依赖提供了如下默认不开启的内置 endpoints:\nTable - Disabled Endpoints:\n\n\n\nEndpoint\nURI\nDescription\n\n\n\nEnvironmentEndpoint\n&#x2F;env\nReturn information about the environment and its property sources (see EnvironmentEndpoint)\n\n\nCachesEndpoint\n&#x2F;caches\nReturns information about the caches and permits invalidating them (see CachesEndpoint)\n\n\nServerStopEndpoint\n&#x2F;stop\nShuts down the application server (see ServerStopEndpoint)\n\n\n可通过设置 endpoints.all.sensitive: false 来开启所有端点的不授权访问, 但是这必须非常小心地使用, 因为私有的和敏感的信息会被暴露\nManagement Port (管理端口)默认情况下, 所有 management endpoints 被暴露到和应用程序相同的端口\n可以通过设置 endpoints.all.port 属性来改变这个行为:\nendpoints:    all:        port: 8085\n\n在上面的例子中, management endpoints 只会暴露到端口 8085 上\nJMX (JMX)Micronaut 提供了向 JMX 注册 endpoints 的功能. 查看 JMX 来开始\nThe Beans Endpoint (Beans 端点)\nThe beans endpoint returns information about the loaded bean definitions in the application.\n\nBeans endpoint 返回关于在应用程序中加载的 bean 定义的信息\n默认返回的 bean 数据是一个对象, 其中 key 是 bean 定义类名, value 是一个有关 bean 的属性的对象\n要执行 beans endpoint, 发送一个 GET 请求到 /beans\nExample - 返回例子:\n&#123;    &quot;beans&quot;: &#123;        &quot;io.micronaut.http.server.netty.jackson.$JsonHttpContentSubscriberFactory$Definition&quot;: &#123;            &quot;dependencies&quot;: [                &quot;io.micronaut.http.server.HttpServerConfiguration&quot;,                &quot;io.micronaut.json.JsonMapper&quot;            ],            &quot;scope&quot;: &quot;javax.inject.Singleton&quot;,            &quot;type&quot;: &quot;io.micronaut.http.server.netty.jackson.JsonHttpContentSubscriberFactory&quot;        &#125;    &#125;&#125;\n\nConfiguration (配置)要配置 beans endpoint, 通过 endpoints.beans 添加配置:\nExample - Beans Endpoint Configuration:\nendpoints:    beans:        enabled: Boolean        sensitive: Boolean\n\nCustomization (自定义)\nThe beans endpoint is composed of a bean definition data collector and a bean data implementation.\n\nbeans endpoint 由一个 bean 定义数据收集器和一个 bean 数据实现组成\n\nThe bean definition data collector (BeanDefinitionDataCollector) is responsible for returning a publisher that returns the data used in the response.\n\nbean 定义数据收集器 (BeanDefinitionDataCollector) 负责返回一个 publisher, 这个 publisher 返回响应中使用的数据\n\nThe bean definition data (BeanDefinitionData) is responsible for returning data about an individual bean definition.\n\nbean 定义数据 (BeanDefinitionData) 负责返回关于单个 bean 定义的数据\n\nTo override the default behavior for either of the helper classes, either extend the default implementations (DefaultBeanDefinitionDataCollector, DefaultBeanDefinitionData), or implement the relevant interface directly.\n\n要覆盖任一助手类的默认行为, 请扩展默认实现 (DefaultBeanDefinitionDataCollector, DefaultBeanDefinitionData), 或直接实现相关接口\n\nTo ensure your implementation is used instead of the default, add the @Replaces annotation to your class with the value being the default implementation.\n\n为确保使用你的实现而不是默认实现, 将 @Replaces 注解添加到你的类上, 并将值作为默认实现\nThe Info Endpoint (Info 端点)info endpoint 返回应用程序状态的静态信息\n被暴露的 info 可以通过多个 “info sources” 提供\n要执行 info endpoint, 发送一个 GET 请求到 /info\nConfiguration (配置)要配置 info endpoint, 通过 endpoints.info 提供配置\nExample - Info Endpoint Configuration:\nendpoint:    info:        enabled: Boolean        sensitive: Boolean\n\nCustomization (自定义)info endpoint 包含一个 info 聚合器和多个 “info sources”\n要添加一个 info source, 创建一个实现 InfoSource 的类\n如果你的 info source 需要从 Java properties 文件获取数据, 那么继承 PropertiesInfoSource 接口, 这个接口提供了一个帮助方法来获取数据\n所有的 info source beans 都被集合到 info aggregator 中\n要提供你自己的 info aggregator 实现, 创建一个实现 InfoAggregator 接口并作为一个 bean 的类\n确保你的实现代替了默认的实现, 添加 @Replaces 注解到你的类上, 并且注解上的值是 默认实现\n默认的 info aggregator 返回一个 map, 这个 map 包含所有 info sources 提供的组合起来的属性\n这个 map 作为 JSON 从 /info endpoint 返回\nProvided Info Sources (提供的 Info 源)Configuration Info Source (配置 Info 源)ConfigurationInfoSource 返回在 info key 下面的配置属性 (configuration properties)\n除了 string, integer 和 boolean 类型的值 ,更复杂的属性可以在 JSON 输出中作为 map 暴露 (如果配置格式支持)\nExample - Info Source:\n# application.groovyinfo.demo.string = &quot;demo string&quot;info.demo.number = 123info.demo.map = [    key: &#x27;value&#x27;,    other_key: 123]\n\n上面的配置在 info endpoint 中作为 JSON 响应返回:\n&#123;    &quot;demo&quot;: &#123;        &quot;string&quot;: &quot;demo string&quot;,        &quot;number&quot;: 123,        &quot;map&quot;: &#123;            &quot;key&quot;: &quot;value&quot;,            &quot;other_key&quot;: 123        &#125;    &#125;&#125;\n\nConfiguration (配置)configuration info source 可以使用 endpoints.info.config.enabled  属性来关闭\nGit Info Source (Git Info Source)如果在 classpath 上存在 git.properties 文件, 那么 GitInfoSource 使用 git key 暴露这个文件中的值\n一个创建的 git.properties 文件必须配置为你的构建的一部分\nGradle 用户的一个简单选项是使用 Gradle Git Properties Plugin\nMaven 用户可以使用 Maven Git Commit ID Plugin\nConfiguration (配置)要指定一个另外的路径或另外的属性文件名称, 在 endpoints.info.git.location 属性中提供一个自定义值\nBuild Info Source (构建 Info Source)如果在 classpath 上存在 META-INF/build-info.properties 文件, 那么 BuildInfoSource 使用 build key 暴露这个文件中的值\n一个创建的 build-info.properties 文件必须配置为你的构建的一部分\nGradle 用户的一个简单选项是使用 Gradle Build Info Plugin\nMaven 用户可以使用 Spring Boot Maven Plugin\nConfiguration (配置)要指定属性文件另外的 路径&#x2F;名称, 在 endpoints.info.build.location 属性中提供一个自定义的值\nbuild info source 可以使用 endpoints.info.build.enabled 属性来关闭\nThe Health Endpoint (健康端点)health endpoint 返回关于应用程序的健康信息, 通过多个 “health indicators” 来指定\n要执行 health endpoint, 发送一个 GET 请求到 /health\n除此之外, health endpoint 还暴露 /health/liveness 和 /health/readiness “health indicators”\nConfiguration (配置)要配置 health endpoint, 通过 endpoints.health 提供配置\nExample - Health Endpoint Configuration:\nendpoints:    health:        enabled: Boolean        sensitive: Boolean        details-visible: String     # 1        status:            http-mapping: Map&lt;String, HttpStatus&gt;\n\n1 : One of DetailsVisibility\ndetails-visible 设置控制是否将 health 细节暴露给没有授权的用户\nExample - Using details-visible:\nendpoints:    health:        details-visible: ANONYMOUS\n\n\nexposes detailed information from the various health indicators about the health status of the application to anonymous unauthenticated users.\n\n将有关应用程序健康状态的各种健康指标的细节信息暴露给未授权用户\nendpoints.health.status.http-mapping 设置用来控制每个健康状态的返回状态码. 默认的状态码在下表中描述:\n\n\n\nStatus\nHTTP Code\n\n\n\nUP\nOK (200)\n\n\nUNKNOWN\nOK (200)\n\n\nDOWN\nSERVICE_UNAVAILABLE (503)\n\n\n你可以在 application.yml 中提供自定义映射:\nExample - Custom Health Status Codes:\nExample - Custom Health Status Codes:\nendpoints:    health:        status:            http-mapping:                DOWN:200\n\n上面的知道导致在 HealthStatus 是 DOWN 的时候返回 OK (200)\nCustomization (自定义)health endpoint 包含一个 health aggregator 和多个 health indicators\n要增加一个 health indicator, 创建一个实现 HealthIndicator 的 bean 类\n建议还要使用 @Liveness 或 @Readiness 标识符\n如果没有使用标识符, 那么这个 health indicator 将会是 /health 和 /health/readiness endpoints 的一部分\n基类 AbstractHealthIndicator 可用于子类以使这个实现过程更加容易\n所有的 health indicator beans 都被集合到 health aggregator\n要提供你自己实现的 health aggregator, 创建一个实现 HealthAggregator 接口的类并将其注册为一个 bean\n要确保你的实现替代了 health aggregator, 添加 @Replaces 注解到你的类上, 注解的值是默认的实现 DefaultHealthAggregator\n默认的 health aggregator 返回一个根据指标的健康状况计算的整体状况\n一个 health status 包含多种信息:\n\n\n\nName\nMeaning\n\n\n\nName\nThe name of the status\n\n\nDescription\nThe description of the status\n\n\nOperational\nWhether the functionality the indicator represents is functional\n\n\nSeverity\nHow severe the status. A higher number is more severe\n\n\n\nThe “worst” status is returned as the overall status\n\n“worst&#96; 状态作为整体状态返回\n\nA non-operational status is selected over an operational status\n\n在操作状态上选择 “非操作” 状态\n\nA higher severity is selected over a lower severity\n\n选择较高的严重性的而不是较低的严重性\nProvided Indicators (提供的指示器)所有 Micronaut 提供的 health indicators 被暴露在 /health 和 /health/readiness endpoints\nDisk Space (磁盘空间)一个 health indicator 被提供来指明应用程序的基于可用磁盘空间大小的健康状态\n可以在 endpoints.health.disk-space key 下面来配置磁盘空间 health indicator\nExample - Disk Space Indicator Configuration:\nendpoints:    health:        disk-space:            enabled: Boolean            path: String # The file path used to determine the disk space            threshold: String | Long # The minimum amount of free space\n\nthreshold 可以作为一个类似 “10MB”, “200KB” 的字符串来提供, 或使用字节数\nJDBC (JDBC)\nThe JDBC health indicator determines the health of your application based on the ability to successfully create connections to datasources in the application context.\n\nJDBC health indicator 指明了你的应用程序的健康状态, 基于在应用程序上下文中成功地创建数据库链接的能力\n唯一支持的配置选项是开启或关闭这个 indicator, 通过 endpoints.health.jdbc.enabled key\nDiscovery Client (发现客户端)如果你的应用程序使用了服务发现, 那么一个 health indicator 被用来监控 discovery client 的健康\n返回的数据可以包含一个可用服务的列表\nThe Metrics Endpoint (指标端点)通过集成 Micrometer ,Micronaut 可以暴露应用程序指标\n如果你使用 Micronaut CLI 创建项目, 添加 micrometer 的其中一个特性来开启指标并预配置选择的 registry 到你项目中:\nmn create-app my-app --features micrometer-atlas\nmetrics endpoint 返回关于应用程序的指标的信息\n要执行 metrics endpoint, 发送一个 GET 请求到 /metrics\n这个 endpoint 返回一个可用指标名称的列表\n你可以通过使用 /metrics/[name] 来获取特定的指标, 例如 /metrics/jvm.memory.used\n查看文档 Micronaut Micrometer 来获取一个 registries 列表和关于如何配置, 暴露, 自定义 metrics 输出的信息\nThe Refresh Endpoint (刷新端点)Refresh endpoint 刷新应用程序的状态, 导致所有上下文中的 Refreshable beans 被销毁并重新实例化直到下次请求\n这通过在应用上下文中发送一个 RefreshEvent 来完成\n要执行 refresh endpoint, 发送一个 POST 请求到 /refresh\ncurl -X POST http://localhost:8080/refresh\n在没有发送 body 的情况下执行时, endpoint 首先刷新 Environment 并执行 diff 以检测任何更改, 然后仅在检测到更改时执行刷新\n如果要不管环境变化, 跳过这个检查并刷新所有 @Refreshable beans (例如, 强制刷新来自第三方服务的缓存响应), 那么在 POST 请求 body 中添加一个 force 参数\ncurl -X POST http://localhost:8080/refresh -H &#39;Content-Type: application/json&#39; -d &#39;&#123;&quot;force&quot;: true&#125;&#39;\nConfiguration (配置)要配置 refresh endpoint, 通过 endpoints.refresh 应用配置:\nExample - Beans Endpoint Configuration:\nendpoints:    refresh:        enabled: Boolean        sensitive: Boolean\n\nThe Routes Endpoint (路由端点)Routes endpoint 返回关于你的应用程序中可用的可以被调用的 URIs 的信息\n默认情况下, 返回的数据包括 URI, 允许的方法, 允许的 method, 提供的 content types, 要被执行的方法的信息\n要执行 routes endpoint, 发送一个 GET 请求到 /routes\nConfiguration (配置)要配置 routes endpoint, 通过 endpoints.routes 应用配置:\nExample - Routes Endpoint Configuration:\nendpoints:    routes:        enabled: Boolean        sensitive: Boolean\n\nCustomization (自定义)routes endpoint 由一个路由数据收集者和一个路由数据实现组成\n路由数据收集者 (RouteDataCollector) 用来返回一个 publisher, 这个 publisher 返回在响应中使用的数据\n路由数据实现 (RouteData) 用来返回关于某个路由的数据\n要覆盖任一助手类的默认行为, 继承默认的 DefaultRouteDataCollector, DefaultRouteData, 或者直接实现相关的接口\n要确保你的实现已经替代了默认的实现, 添加 @Replaces 注解到你的类上, 使用默认的实现作为注解的值\nThe Loggers Endpoint (日志端点)loggers endpoint 返回关于应用程序中可用的 loggers 的信息, 并且允许配置它们的日志级别\nloggers endpoint 默认是关闭的, 必须使用 endpoints.loggers.enabled=true 设置来显式开启\n要按名称获取所有 loggers 的集合以及配置和有效的日志级别, 发送一个 GET请求到 /loggers\n这还提供了可用日志级别的列表:\n&#123;    &quot;levels&quot;: [        &quot;ALL&quot;,        &quot;TRACE&quot;,        &quot;DEBUG&quot;,        &quot;INFO&quot;,        &quot;WARN&quot;,        &quot;ERROR&quot;,        &quot;OFF&quot;,        &quot;NOT_SPECIFIED&quot;    ],    &quot;loggers&quot;: &#123;        &quot;ROOT&quot;: &#123;            &quot;configuredLevel&quot;: &quot;INFO&quot;,            &quot;effectiveLevel&quot;: &quot;INFO&quot;        &#125;,        &quot;io&quot;: &#123;            &quot;configuredLevel&quot;: &quot;NOT_SPECIFIED&quot;,            &quot;effectiveLevel&quot;: &quot;INFO&quot;        &#125;,        &quot;io.micronaut&quot;: &#123;            &quot;configuredLevel&quot;: &quot;NOT_SPECIFIED&quot;,            &quot;effectiveLevel&quot;: &quot;INFO&quot;        &#125;        // etc...    &#125;&#125;\n\n要获取特定 logger 的日志级别, 包含 logger 名称到你的 GET 请求中: curl http://localhost:8080/loggers/io.micronaut.http\n如果命名的 logger 不存在, 将会创建一个未指定 (例如, NOT_SPECIFIED) 配置日志级别 (它的有效日志级别通常会使用根日志级别)\n要更新单个 logger 的日志级别, 发送一个 POST 请求到命名的 logger  URL, 包含一个提供了日志级别配置的 body:\ncurl -i -X POST \\     -H &quot;Content-Type: application/json&quot; \\     -d &#x27;&#123; &quot;configuredLevel&quot;: &quot;ERROR&quot; &#125;&#x27; \\     http://localhost:8080/loggers/ROOT\n\n默认情况下, logger endpoint 不允许通过为授权用户修改日志级别, 即使 sensitive 设置为 false. 要允许修改日志级别, 你必须设置 endpoints.loggers.write-sensitive=false\nConfiguration (配置)Example - Loggers Endpoint Configuration:\nendpoints:    loggers:        enabled: Boolean        sensitive: Boolean        write-sensitive: Boolean\n\nCustomization (自定义)loggers endpoint 包含两个自定义的部分: 一个 LoggersManager 和一个 LoggingSystem\n查看 logging section of the documentation 获取自定义日志系统的更多信息\nLoggersManager 负责返回和设置日志级别. 如果默认实现不能满足你的需求, 提供一个你自己的实现并使用 @Replaces 注解替代掉 DefaultLoggersManager\nThe Caches Endpoint (缓存端点)cache endpoint 文档在 micronaut-cache project 中\nThe Server Stop Endpoint (服务停止端点)stop endpoint 关闭应用程序服务器\n要执行 stop endpoint, 发送一个 GET 请求到 /stop\nConfiguration (配置)要配置 stop endpoint, 通过 endpoints.stop 应用配置:\nExample - Stop Endpoint Configuration:\nendpoints:    stop:        enabled: Boolean        sensitive: Boolean\n\n默认情况下, stop endpoint 是关闭的, 必须明确开启才能使用\nThe Environment Endpoint (环境端点)environment endpoint 返回关于 Environment 和它的 PropertySources 的信息\nConfiguration (配置)要开启和配置 environment endpoint, 通过 endpoints.env 应用配置:\nExample -Environment Endpoint Configuration:\nendpoints:    env:        enabled: Boolean    # default: false        sensitive: Boolean  # default: true\n\n默认情况下, environment endpoint 会屏蔽所有的值. 要自定义这个屏蔽你需要提供一个实现了 EnvironmentEndpointFilter 的 bean\n第一个例子将会屏蔽所有的值, 除了前缀为 safe 的值:\nExample - First example of environment masking:\n@Singletonpublic class OnlySafePrefixedEnvFilter implements EnvironmentEndpointFilter &#123;    private static final Pattern SAFE_PREFIX_PATTERN = Pattern.compile(&quot;safe.*&quot;, Pattern.CASE_INSENSITIVE);    @Override    public void specifyFiltering(@NotNull EnvironmentFilterSpecification specification) &#123;        specification.maskAll()     // All values will be masked apart from the supplied patterns                     .exclude(SAFE_PREFIX_PATTERN);    &#125;&#125;\n\n还可以使用 maskNone– 来允许所有的纯文本值, 然后指定将被屏蔽的名称模式:\nExample - Deny instead of allow:\n@Singletonpublic class AllPlainExceptSecretOrMatchEnvFilter implements EnvironmentEndpointFilter &#123;    // Mask anything starting with `sekrt`    private static final Pattern SECRET_PREFIX_PATTERN = Pattern.compile(&quot;sekrt.*&quot;, Pattern.CASE_INSENSITIVE);    // Mask anything exactly matching `exact-match`    private static final String EXACT_MATCH = &quot;exact-match&quot;;    // Mask anything that starts with `private.`    private static final Predicate&lt;String&gt; PREDICATE_MATCH = name -&gt; name.startsWith(&quot;private.&quot;);    public void specifyFiltering(@NotNull EnvironmentFilterSpecification specification) &#123;        specification.maskNone()    // All values will be in plain-text apart from the supplied patterns                     .exclude(SECRET_PREFIX_PATTERN)                     .exclude(EXACT_MATCH)                     .exclude(PREDICATE_MATCH);    &#125;&#125;\n\n可以通过调用 legacyMasking– 方法应用合理的默认值. 这将会展示所有的值, 除了那些在名称中任何地方包含 password,credential,certificate,key,secret,token 的值\nGetting information about the environment (获取关于环境的信息)要执行 environment endpoint, 发送一个 GET 请求到 /env\nGetting information about a particular PropertySource (获取特定的 PropertySource 信息)要执行 endpoint, 发送一个 GET 请求到 /env/&#123;propertySourceName&#125;\nThe ThreadDump Endpoint (线程转储端点)threaddump endpoint 返回关于应用程序中运行线程的信息\n要执行 threaddump endpoint, 发送一个 GET 请求到 /threaddump\nConfiguration (配置)要配置 threaddump endpoint, 通过 endpoints.threaddump 应用配置\nExample - Threaddump Endpoint Configuration:\nendpoints:    threaddump:        enabled: Boolean        sensitive: Boolean\n\nCustomization (自定义)threaddump endpoint 委托给一个 ThreadInfoMapper, 这个 Mapper 负责转换 java.lang.management.ThreadInfo 对象为任何其他被发送的序列化对象\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Message-Driven Microservices","url":"/micronaut/micronaut-message-driven-microservices/","content":"\n\n\nMessage-Driven Microservices\nKafka Support (Kafka 支持)\nRabbitMQ Support (RabbitMQ 支持)\nNats.io Support (Nats.io 支持)\n\n\n\n\n\nMessage-Driven Microservices声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\n\nIn the past, with monolithic applications, message listeners that listened to messages from messaging systems would frequently be embedded in the same application unit.\n\n在过去, 对于单体应用, 监听来自消息系统的消息的消息监听器通常会嵌入到同一个应用单元中\n\nIn Microservice architectures it is common to have individual Microservice applications that are driven by a message system such as RabbitMQ or Kafka.\n\n在微服务架构中, 通常有由消息系统( 如果 RabbitMQ 或 Kafka )驱动的单独的微服务应用\n\nIn fact a Message-driven Microservice may not even feature an HTTP endpoint or HTTP server (although this can be valuable from a health check and visibility perspective).\n\n事实上, 消息驱动的微服务甚至可能没有 HTTP 端点或 HTTP server (尽管从健康检查和可见性的角度来看, 这可能很有价值)\nKafka Support (Kafka 支持)Micronaut 专门支持定义 Kafka 生产者和消费者实例\n使用 Kafka 构建的 Micronaut 应用可以在有或没有 HTTP server 的情况下进行部署\n借助 Micronaut 高效的编译时 AOP 和云原生特性, 编写使用极少资源的高效 Kafka 消费者应用程序轻而易举\n查看 Micronaut Kafka 获取更多关于如何使用 Micronaut 构建 Kafka 应用程序的信息\nRabbitMQ Support (RabbitMQ 支持)Micronaut 专门支持定义 RabbitMQ 生产者和消费者\n使用 RabbitMQ 构建的 Micronaut 应用可以在有或没有 HTTP server 的情况下进行部署\n借助 Micronaut 的高效编译时 AOP, 使用 RabbitMQ 从未如此简单, 通过响应式流增加了对 publisher confirm 和 RPC 的支持\n查看 Micronaut RabbitMQ 获取更多关于如何使用 Micronaut 构建 RabbitMQ 应用程序的信息\nNats.io Support (Nats.io 支持)Nats.io 是一个简单的, 安全的, 高性能的开源消息系统, 用于云原生应用, 物联网消息, 和微服务架构\nMicronaut 专门支持定义 Nats.io 生产者和消费者\n使用 Nat.io 构建的 Micronaut 应用可以在有或没有 HTTP server 的情况下进行部署\n借助 Micronaut 的高效编译时 AOP, 使用 Nats.io 从未如此简单, 通过响应式流增加了对 publisher confirm 和 RPC 的支持\n查看 Micronaut Nats 获取更多关于如何使用 Micronaut 构建 Nats.io 应用程序的信息\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Micronaut CLI","url":"/micronaut/micronaut-micronaut-cli/","content":"\n\n\nMicronaut CLI\nInteractive Mode (交互模式)\nHelp and Info (帮助信息)\nCreating a Project (创建一个项目)\nCreate Command Flags (创建命令标记)\nLanguage&#x2F;Test Features (语言&#x2F;测试功能)\nGroovy (Groovy)\nKotlin (Kotlin)\nBuild Tool (构建工具)\n\n\nCreate-Cli-App (创建命令行程序)\nCreate Function App (创建函数程序)\nContribute (贡献)\nComparing Versions (版本比较)\n\n\nFeatures (功能)\nCommands (命令)\nBase Commands (基础命令)\nCreate-Bean (创建 Bean)\nCreate-Job (创建 Job)\n\n\nHTTP-Related Commands (HTTP 相关的命令)\nCreate-Controller (创建 Controller)\nCreate-Client (创建 Client)\nCreate-Websocket-Server (创建 WebSocket 服务器)\nCreate-Websocket-Client (创建 WebSocket 客户端)\n\n\nCLI Project Commands (CLI 项目命令)\nCreate-Command (创建命令)\n\n\n\n\nReloading (重载)\nAutomatic Restart (自动重启)\nMaven Restart (Maven 重启)\nGradle Restart (Gradle 重启)\n\n\nJRebel (JRebel)\nInstall&#x2F;configure JRebel Agent (安装&#x2F;配置 JRebel 代理)\nGradle (Gradle)\nMaven (Maven)\n\n\n\n\nRecompiling with Gradle (使用 Gradle 进行重新编译)\nRecompiling with an IDE (使用 IDE 进行重新编译)\nIntellij (Intellij)\nEclipse (Eclipse)\n\n\n\n\nProxy Configuration (代理配置)\n\n\n\n\n\nMicronaut CLI声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\nMicronaut CLI 是创建新 Micronaut 项目的推荐方式\nCLI 包含了创建特定类型项目的命令, 允许你在构建工具, 测试框架, 甚至在应用程序使用的语言中进行选择\nCLI 还提供了命令来创建例如 controllers, client interfaces 和 serverless functions 等构件\n有一个用来代替 CLI 创建项目的网站. 查看 Micronaut Launch 来开始使用\n当 Micronaut 已经安装到了你的电脑上, 你可以通过 mn 命令来调用 CLI:\nmn create-app my-app\n\n一个 Micronaut CLI 项目可以通过 micronaut-cli.yml 文件来被识别, 如果项目是通过 CLI 来创建那么这个文件将会被包含到项目根目录中:\n# micronaut-cli.ymlapplicationType: defaultdefaultPackage: fucktestFramework: spocksourceLanguage: groovybuildTool: gradlefeatures: [annotation-api, app-name, gradle, groovy, groovy-application, http-client, jackson-databind, logback, management, micronaut-build, netty-server, readme, shade, spock, yaml]\n\nmicronaut-cli.yml 文件将会包含项目 profile (配置属性), 默认包和其他变量\n项目的默认包基于项目名称进行计算: mn create-app my-demo-app, 那么默认的包名是: my.demo.app\n你可以在创建项目的使用包名来前缀化应用程序名称的方式提供默认包名:\nmn create-app examle.my-demo-app\n\n那么默认的包名是 example\nInteractive Mode (交互模式)如果你不使用任何参数来运行 mn, 那么 Micronaut CLI 启动为交互模式\n这是一个类似 shell 的模式, 允许你运行多个 CLI 命令而不需要重新初始化 CLI 运行时, 这在你使用代码生成命令 (例如 create-controller), 创建多个项目, 或者仅仅探索 CLI 功能时非常合适\nTab 补全是开启的, 允许你按下 TAB 键来查看对于一个给定的命令和标记 (flag) 可能的选项\n$ mn| Starting interactive mode...| Enter a command name to run. Use TAB for completion:mn&gt;\n\nHelp and Info (帮助信息)一般使用信息可以通过在一个命令上使用 help 标记来查看\nmn&gt; create-app -hUsage: mn create-app [-hivVx] [--list-features] [-b=BUILD-TOOL] [--jdk=&lt;javaVersion&gt;] [-l=LANG]                     [-t=TEST] [-f=FEATURE[,FEATURE...]]... [NAME]Creates an application      [NAME]               The name of the application to create.  -b, --build=BUILD-TOOL   Which build tool to configure. Possible values: gradle, gradle_kotlin,                             maven.  -f, --features=FEATURE[,FEATURE...]  -h, --help               Show this help message and exit.  -i, --inplace            Create a service using the current directory      --jdk, --java-version=&lt;javaVersion&gt;                           The JDK version the project should target  -l, --lang=LANG          Which language to use. Possible values: java, groovy, kotlin.      --list-features      Output the available features and their descriptions  -t, --test=TEST          Which test framework to use. Possible values: junit, spock, kotest.\n\n在任何创建命令上使用 --list-features 标记来查看可用功能列表\nmn&gt; create-app --list-featuresAvailable Features(+) denotes the feature is included by default  Name                             Description  -------------------------------  ---------------  Cache  cache-caffeine                   Adds support for cache using Caffeine (https://github.com/ben-manes/caffeine)  cache-ehcache                    Adds support for cache using EHCache (https://www.ehcache.org/)  cache-hazelcast                  Adds support for cache using Hazelcast (https://hazelcast.org/)  cache-infinispan                 Adds support for cache using Infinispan (https://infinispan.org/)\n\nCreating a Project (创建一个项目)创建项目是 CLI 最主要的用法\n创建一个新项目最主要的命令是 create-app, 这个命令创建了一个通过 HTTP 进行通信的基础服务器应用程序 (standard server application)\n下表中展示了其他类型的应用程序:\nTable - Micronaut CLI Project Creation Commands\n\n\n\nCommand\nDescription\nOptions\nExample\n\n\n\ncreate-app\nCreates a basic Micronaut application\n[-l,--lang] [-t,--test] [-b,--build] [-f,--features] [-i,--inplace]\nmn create-app my-project --featuers mongo-reactive,security-jwt --build maven\n\n\ncreate-cli-app\nCreates a command-line Micronaut application\n[-l,--lang] [-t,--test] [-b,--build] [-f,--features] [-i,--inplace]\nmn create-cli-app my-project --features http-client,jdbc-hikari --build maven --lang kotlin --test kotest\n\n\ncreate-function-app\nCreates a Micronaut serverless function, using AWS by default\n[-l,--lang] [-t,--test] [-b,--build] [-f,--features] [-i,--inplace]\nmn create-function-app my-lambda-function --lang groovy --test spock\n\n\ncreate-messaging-app\nCreates a Micronaut application that only communicates via a messaging protocol. Uses kafka by default but can be switched to RabbitMQ with --features rabbitmq\n[-l,--lang] [-t,--test] [-b,--build] [-f,--features] [-i,--inplace]\nmn create-messaging-app my-broker --lang groovy -test spock\n\n\ncreate-grpc-app\nCreates a Micronaut application that uses gRPC\n[-l,--lang] [-t,--test] [-b,--build] [-f,--features] [-i,--inplace]\nmn create-grpc-app my-grpc-app --lang groovy --test spock\n\n\nCreate Command Flags (创建命令标记)create-* 命令生成一个基础 Micronaut 项目, 这个命令有可选的标记来指定功能, 语言, 测试框架和构建总局\n除了函数式项目的其他所有项目都包含一个默认的 Application 类来启动应用\nTable - Flags:\n\n\n\nFlag\nDescription\nExample\n\n\n\n-l, --lang\nLanguage to use for the project (one of java,groovy,kotlin, 默认是 java)\n–lang groovy\n\n\n-t, --test\nTest framework to use for the project (one of junit,spock, 默认是 junit)\n–test spock\n\n\n-b, --build\nBuild tool (one of gradle,gradle_kotlin,maven, 在语言是 java 和 groovy 的情况下默认是 gradle, 在语言是 kotlin 的情况下默认是 gradle_kotlin )\n–build maven\n\n\n-f, --features\nFeatures to use for the project, comma-separated\n--features security-jwt,mongo-gorm or -f security-jwt -f mongo-gorm\n\n\n-i, --inplace\nIf present, generates the project in the current directory (project name is optional if this flag is set)\n–inplace\n\n\n一旦创建好了, 应用程序可以使用 Application 类来启动, 或者通过对应的构建工具任务\nExample - Starting a Gradle project: ./gradlew run\nExample - Starting a Maven project: ./mvnw mn:run\nLanguage&#x2F;Test Features (语言&#x2F;测试功能)默认情况下, 创建命令生成一个 Java 应用程序, 并使用配置的 JUnit 作为测试框架\n所有选择的选项和使用的功能都作为属性保存在 micronaut-cli.yml 文件中:\napplicationType: defaultdefaultPackage: com.exampletestFramework: junitsourceLanguage: javabuildTool: gradlefeatures: [annotation-api, app-name, application, gradle, http-client, java, junit, logback, netty-server, shade, yaml]\n\n有一些命令依赖这个文件中的数据来决定它们是否可以执行\n例如, create-kafka-listener 命令要求 kafka 要在 features 列表中\nmicronaut-cli.yml 中的值被 CLI 用来进行代码生成\n在项目生成之后, 你可以编辑这些值来修改项目默认值, 但是你必须提供所需的依赖项 和&#x2F;或 配置才能使用你选择的 语言&#x2F;框架\n例如, 你可以修改 testFramework 属性为 spock 来使得 CLI 在运行命令 (例如 create-controller) 时生成 Spock 测试, 但是你需要添加 Spock 依赖到你的构建中\nGroovy (Groovy)要创建一个使用 Groovy 支持的应用 (默认使用 Spock), 通过 lang 标记使用适当的语言:\nmn create-app my-groovy-app --lang groovy\n\n这会包含 Groovy 和 Spock 依赖到你的项目中, 并写入适当的值到 micronaut-cli.yml\nKotlin (Kotlin)要创建一个使用 Kotlin 支持的应用 (默认使用 Kotest), 通过 lang 标记使用适当的语言:\nmn create-app my-groovy-app --lang kotlin\n\n这会包含 Kotlin 和 Kotest 依赖到你的项目中, 并写入适当的值到 micronaut-cli.yml\nBuild Tool (构建工具)默认情况下, create-app 创建一个 Gradle 项目, 生成一个 build.gradle 文件到项目根目录中\n要创建一个使用 Maven 构架工具的应用, 通过 build 标记使用适当的选项:\nmn create-app my-maven-app --build maven\n\nCreate-Cli-App (创建命令行程序)create-cli-app 命令创建一个 Micronaut 命令行应用程序 项目, 有选项标记来指定语言, 测试框架, 功能, 配置和构建工具\n默认情况下, 项目包含 picocli 功能来支持命令行选项解析\n项目将会包含一个 *Command 类 (基于项目的名称, 例如, hello-world 生成 HelloWorldCommand), 和一个关联的测试类来初始化命令和校验它可以解析命令行选项\n一旦创建, 应用程序可以使用 *Command 类来启动, 或者使用对应的构建工具任务\nExample - Starting a Gradle project: ./gradlew run\nExample - Starting a Maven project: ./mvnw mn:run\nCreate Function App (创建函数程序)create-function-app 命令生成一个 Micronaut function 项目, 为无服务环境优化, 有选项标记来指定语言, 测试框架, 功能和构建工具\n项目将会包含一个 *Function 类 (基于项目名称, 例如, hello-world 生成 HelloWorldFunction), 和一个关联的测试类来初始化 function 和校验它是否可以接收请求\n当前, AWS Lambda, Microsoft Azure 和 Google Cloud 是 Micronaut 功能支持的云提供商\n要使用其他云提供商, 添加其中一个功能: --features azure-function 或 --features google-cloud-function\nContribute (贡献)CLI 源代码在 https://github.com/micronaut-projects/micronaut-starter\n关于如何贡献或其他资源都在那儿\nComparing Versions (版本比较)\nThe easiest way to see version dependency updates and other changes for a new version of Micronaut is to produce one clean application using the older version and another using the newer version of the mn CLI, and then comparing those directories.\n\n查看新版本 Micronaut 的版本依赖关系更新和其他更改的最简单方法是使用旧版本生成一个干净的应用程序, 并使用新版本的 mn 命令生成另一个应用程序, 然后比较这些目录\nFeatures (功能)Feature : 功能; 特性\nFeature 包含额外的依赖和配置来在你的应用程序中启用指定功能\n\nMicronaut profiles define a large number of features, including features for many of the configurations provided by Micronaut, such as the Data Access Configurations\n\nMicronaut 配置文件定义了大量功能, 包括 Micronaut 提供的许多配置的功能, 例如数据访问配置\nmn create-app my-demo-app --features mongo-reactive\n\n这个命令在你的应用程序中为 MongoDB Reactive Driver 添加必要的依赖和配置\n你可以在你使用的创建命令上使用 --list-features 标记来查看可用的 features:\nmn create-app --list-features # Output will be supported features for the create-app commandmn create-function-app --list-features # Output will be supported features for the create-function-app command, different from above\n\nCommands (命令)你可以使用帮助标记查看可用命令的完整列表, 例如:\nmn -h\n\n所有的 代码生成命令 都遵循 micronaut-cli.yml 中编写的值. 例如, 假设有如下 micronaut-cli.yml 文件:\ndefaultPackage: example---testFramework: spocksourceLanguage: java\n\n根据上面的配置, create-bean 命令 (默认) 生成一个带有相关 Spock 测试类的 Java 类\n\nCommands accept arguments and these defaults can be overridden on a per-command basis\n\n命令接收参数, 并且可以在每个命令的基础上覆盖这些默认值\nBase Commands (基础命令)这些命令在 Micronaut 项目上下文中总是可使用的\nCreate-Bean (创建 Bean)Table - Create-Bean Flags\n\n\n\nFlag\nDescription\nExample\n\n\n\n-l, --lang\nThe language used for the bean class\n–lang groovy\n\n\n-f, --force\nWhether to overwrite existing files\n–force\n\n\ncreate-bean 命令创建一个简单的 Singleton 类\n它不会创建一个关联的测试:\nmn create-bean EmailService| Rendered template Bean.java to destination src/main/java/example/EmailService.java\n\nCreate-Job (创建 Job)Table - Create-Job Flags:\n\n\n\nFlag\nDescription\nExample\n\n\n\n-l, --lang\nThe language used for the job class\n–lang groovy\n\n\n-f, --force\nWhether to overwrite existing files\n–force\n\n\ncreate-job 命令生成一个简单的 Scheduled 类\n这个命令有一个 *Job 约定来生成类名\n这个命令不会创建一个关联的测试:\nmn create-job UpdateFeeds --lang groovy| Rendered template Job.groovy to destination src/main/groovy/example/UpdateFeedsJob.groovy\n\n会自动在 job 名称后面上添加 Job 后缀\nHTTP-Related Commands (HTTP 相关的命令)Create-Controller (创建 Controller)Table - Create-Controller Flags:\n\n\n\nFlag\nDescription\nExample\n\n\n\n-l, --lang\nThe language used for the controller\n–lang groovy\n\n\n-f, --force\nWhether to overwrite existing files\n–force\n\n\ncreaet-controller 命令生成一个 Controller 类\n这个命令有一个 *Controller 约定来生成类名\n这个命令会创建一个关联的测试来运行应用程序并初始化一个 HTTP client, 这个 client 可以发送请求给 controller:\nmn create-controller Book| Rendered template Controller.java to destination src/main/java/example/BookController.java| Rendered template ControllerTest.java to destination src/test/java/example/BookControllerTest.java\n\n会自动在 controller 名称后面上添加 Controller 后缀\nCreate-Client (创建 Client)Table - Create-Client Flags:\n\n\n\nFlag\nDescription\nExample\n\n\n\n-l,--lang\nThe language used for the client\n–lang groovy\n\n\n-f, --force\nWhether to overwrite existing files\n–force\n\n\ncreate-client 命令生成一个简单的 Client 接口\n这个命令有一个 *Client 约定来生成类名\n这个命令不会生成一个关联的测试类\nmn create-client Book| Rendered template Client.java to destination src/main/java/example/BookClient.java\n\nCreate-Websocket-Server (创建 WebSocket 服务器)Table - Create-Websocket-Server Flags:\n\n\n\nFlag\nDescription\nExample\n\n\n\n-l,--lang\nThe language used for the server\n–lang groovy\n\n\n-f, --force\nWhether to overwrite existing files\n–force\n\n\ncreate-websocket-server 命令生成一个简单的 ServerWebSocket 类\n这个命令有一个 *Server 约定来创建类名\n这个命令不会生成一个关联的测试类\nmn create-websocket-server MyChat| Rendered template WebsocketServer.java to destination src/main/java/example/MyChatServer.java\n\nCreate-Websocket-Client (创建 WebSocket 客户端)Table - Create-Websocket-Client Flags:\n\n\n\nFlag\nDescription\nExample\n\n\n\n-l, --lang\nThe language used for the client\n–lang groovy\n\n\n-f, --force\nWhether to overwrite existing files\n–force\n\n\ncreate-websocket-client 命令生成一个简单的 WebSocketClient 抽象类\n这个命令有一个 *Client 约定来生成类名\n这个命令不会创建一个关联的测试类\nmn create-websocket-client MyChat| Rendered template WebsocketClient.java to destination src/main/java/example/MyChatClient.java\n\nCLI Project Commands (CLI 项目命令)Create-Command (创建命令)Table - Create-Command Flags:\n\n\n\nFlag\nDescription\nExample\n\n\n\n-l, --lang\nThe language used for the command\n–lang groovy\n\n\n-f, --force\nWhether to overwrite existing files\n–force\n\n\ncreate-command 命令生成一个可以作为一个 picocli Command 执行的独立应用\n这个命令有一个 *Command 约定来生成类名\n这个命令生成一个关联的测试类来运行应用程序并校验设置的命令行选项\nmn create-command print| Rendered template Command.java to destination src/main/java/example/PrintCommand.java| Rendered template CommandTest.java to destination src/test/java/example/PrintCommandTest.java\n\n这个列表只是 Micronaut CLI 中代码生成命令的一小部分\n要查看 CLI 所有可用的上下文相关命令 (以及它们在什么情况下适用), 请查看 micronaut-starter 项目并找到扩展 CodeGenCommand 的类\napplies 方法指示命令是否可用\nReloading (重载)\nReloading (or “hot-loading”) refers to the framework reinitializing classes (and parts of the application) when changes to the source files are detected.\n\n重载 (或者热加载) 是指框架在检测到源文件发生修改时重新初始化类 (和应用程序的一部分)\n\nSince Micronaut prioritizes startup time and most Micronaut apps can start up within seconds, a productive workflow can often be had by restarting the application as changes are made\n\n因为 Micronaut 优先考虑启动事件, 并且大多数 Micronaut 应用程序可以在几秒内启动, 因此通常可以通过在进行修改时重新启动应用程序来获取高效的工作流程\n\nfor example, by running a test class within an IDE\n\n例如, 通过在 IDE 中运行测试类\n\nHowever, to have your changes automatically reloaded, Micronaut supports automatic restart and the use of third-party reloading agents.\n\n但是, 为了让你的修改自动重载, Micronaut 支持自动重启并使用第三方重载代理\nAutomatic Restart (自动重启)有多种方式来实现 JVM 上的类重载, 所有的方式都有它们的优点和缺点\n下面展示了可以不重启 JVM 实现重载的方式:\n\nJVM Agents : 可以使用像 JRebel 这样的 JVM agent, 但是这些 JVM agent 可能会产生异常错误, 不支持所有的 JDK 版本, 还可能导致缓存或陈旧 (stale) 的类\nClassLoader Reloading : 基于类加载器重载是大多数框架使用的流行的解决方案. 但是这也可能会导致缓存的或陈旧的 (stale) 的类, 内存泄露, 如果使用了不正确的类加载器还会出现奇怪的错误\nDebugger HotSwap : Java 调试器 (Java debugger) 支持在运行时热插拔, 当只能在一些场景下使用\n\n\nGiven the problems with existing solutions and a lack of a way built into the JVM to reload changes, the safest and best solution to reloading, and the one recommended by the Micronaut team, is to use automatic application restart via a third-party tool.\n\n鉴于现有解决方案存在的问题以及 JVM 中缺乏重载修改的方法, 最安全和最好的重载解决方案, 也是 Micronaut 团队推荐的解决方案, 是通过第三方工具来进行应用程序自动重启\n\nMicronaut’s startup time is fast and automatic restart leads to a clean slate without potential hard to debug problems or memory leaks cropping up.\n\nMicronaut 的启动时间很快, 并且自动重启会带来一个干净的状态, 不会出现潜在的难以调试的问题或内存泄露\nMaven Restart (Maven 重启)要在 Maven 使用自动重启应用程序, 使用 Micronaut Maven 插件 (在创建 Maven 项目时默认包含了) 并运行如下命令:\nExample - Using the Micronaut Maven Plugin:\n./mvnw mn:run\n\n每次你修改一个类, 插件会自动重启服务器\nGradle Restart (Gradle 重启)\nGradle automatic restart can be activated when using the Micronaut Gradle plugin by activating Gradle’s support for continuous builds via the -t flag\n\n使用 Micronaut Gradle 插件时, 可以通过 -t 标记来激活 Gradle 对持续构建的支持来开启 Gradle 自动重启:\nExample - Using Gradle for Automatic Restart:\n./gradlew run -t\n\n每次你修改一个类或者资源时, Gradle 会重新编译并重启应用程序\nJRebel (JRebel)\nJRebel is a proprietary reloading solution that involves an agent library, as well as sophisticated IDE support.\n\nJRebel 是一个专用的重新加载解决方案, 它涉及代理库以及复杂的 IDE 支持\nJRebel 文档包含了 IDE 集成和使用的详细步骤\n在这一节, 我们展示怎样为 Maven 和 Gradle 项目安装和配置代理\n如果你使用 Micronaut CLI 创建项目, 在你项目中添加 jrebel 功能来预配置 JRebel 重载\n注意你需要安装 JRebel 并在 gradle.properties 文件或 pom.xml 文件中配置正确的代理路径\nmn create-app my-app --features jrebel\n\nInstall&#x2F;configure JRebel Agent (安装&#x2F;配置 JRebel 代理)安装 JRebel 最简单的方式是从 JRebel download page 下载独立安装包. 解压缩下载的文件到便利的位置, 例如 ~/bin/jrebel\n安装目录包含了一个有代理文件的 lib 目录\n查看下表获取基于操作系统的合适代理:\nTable - JRebel Agent:\n\n\n\nOS\nAgent\n\n\n\nWindows 64-bit JDK\n[jrebel directory]\\lib\\jrebel64.dll\n\n\nWindows 32-bit JDK\n[jrebel directory]\\lib\\jrebel32.dll\n\n\nMac OS X 64-bit JDK\n[jrebel directory]&#x2F;lib&#x2F;libjrebel64.dylib\n\n\nMac OS X 32-bit JDK\n[jrebel directory]&#x2F;lib&#x2F;libjrebel32.dylib\n\n\nLinux 64-bit JDK\n[jrebel directory]&#x2F;lib&#x2F;libjrebel64.so\n\n\nLinux 32-bit JDK\n[jrebel directory]&#x2F;lib&#x2F;libjrebel32.so\n\n\n使用合适的代理路径, 并添加到你的项目构建中\nGradle (Gradle)增加路径到 gradle.properties 中, 作为 rebelAgent 属性:\nExample - gradle.properties:\n# Assuming installation path of ~/bin/jrebel/rebelAgent= -agentpath:~/bin/jrebel/lib/libjrebel64.dylib\n\n添加适合的 JVM 参数到 build.gradle (如果使用 CLI 功能就不是必要的)\nrun.dependsOn(generateRebel)if (project.hasProperty(&#x27;rebelAgent&#x27;)) &#123;    run.jvmArgs += rebelAgent&#125;\n\n你可以使用 ./gradlew run 来启动项目, 它将会包含这个代理\n查看 Gradle Reloading 或 IDE Reloading 上的章节来设置重编译\nMaven (Maven)相应地配置 Micronaut Maven 插件\n&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;  &lt;!-- ... --&gt;  &lt;build&gt;    &lt;plugins&gt;      &lt;!-- ... --&gt;      &lt;plugin&gt;        &lt;groupId&gt;io.micronaut.build&lt;/groupId&gt;        &lt;artifactId&gt;micronaut-maven-plugin&lt;/artifactId&gt;          &lt;configuration&gt;            &lt;jvmArguments&gt;              &lt;jvmArgument&gt;-agentpath:~/bin/jrebel/lib/jrebel6/lib/libjrebel64.dylib&lt;/jvmArgument&gt;            &lt;/jvmArguments&gt;          &lt;/configuration&gt;      &lt;/plugin&gt;      &lt;plugin&gt;        &lt;groupId&gt;org.zeroturnaround&lt;/groupId&gt;        &lt;artifactId&gt;jrebel-maven-plugin&lt;/artifactId&gt;        &lt;version&gt;1.1.10&lt;/version&gt;        &lt;executions&gt;          &lt;execution&gt;            &lt;id&gt;generate-rebel-xml&lt;/id&gt;            &lt;phase&gt;process-resources&lt;/phase&gt;            &lt;goals&gt;              &lt;goal&gt;generate&lt;/goal&gt;            &lt;/goals&gt;          &lt;/execution&gt;        &lt;/executions&gt;      &lt;/plugin&gt;      &lt;!-- ... --&gt;    &lt;/plugins&gt;  &lt;/build&gt;&lt;/project&gt;\n\nRecompiling with Gradle (使用 Gradle 进行重新编译)Gradle 支持 持续集成, 让你可以运行一个无论什么时候源文件修改时会被重新运行的任务\n要将这个和重载代理一起使用, 像平常一样运行应用程序(使用代理), 然后在另外一个终端用 持续模式(continuous mode) 来运行重编译任务\nExample - Run the app:\n./gradlew run\n\nExample - Run the recompilation:\n./gradlew -t classes\n\nclasses 任务会在每次一个源文件修改时重新运行, 使得重载代理获取到修改\nRecompiling with an IDE (使用 IDE 进行重新编译)如果你使用的构建工具, 例如 Maven, 不支持在文件修改时自动重新编译, 你可以使用你的 IDE 结合重新加载代理来重新编译类\nIntellij (Intellij)很不幸 Intellij 没有一个自动重建的选项用于运行的应用程序\n但是, 你可以使用 CMD-F9 或 CTRL-F9 来触发项目 “rebuild”\nEclipse (Eclipse)在 Project 菜单下, 开启 Build Automatically 选项. 这将会触发项目重新编译, 无论什么时候文件修改保存到了磁盘上\nProxy Configuration (代理配置)要配置 CLI 使用 HTTP 代理需要两个步骤\n配置选项可以通过 MN_OPTS 环境变量传递给 cli\n例如在 *nix 系统上:\nexport MN_OPTS=&quot;-Dhttps.proxyHost=127.0.0.1 -Dhttps.proxyPort=3128 -Dhttp.proxyUser=test -Dhttp.proxyPassword=test&quot;\n\n配置文件依赖项通过 HTTPS 解析, 因此代理端口和 Host 配置为 https\n但是用户名和密码使用 http 来指定\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Quick Start","url":"/micronaut/micronaut-quick-start/","content":"\n\n\nMicronaut Quick Start\nDeploying the Application\n部署到 Docker\n\n\n\n\n\n\n\nMicronaut Quick Start声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\nDeploying the Application\n./gradlew assemble\n./mvnw package\n\n运行: java -jar build/libs/hello-world-all.jar 或者 java -jar target/hello-world.jar\n部署到 Docker在 build.gradle 文件中添加如下配置:\ndockerBuild &#123;    images = [&quot;[REPO_URL]/[NAMESPACE]/my-image:$project.version&quot;]&#125;\n\n使用 dockerPush task 来构建一个 image: ./gradlew dockerPush\n使用 deploy task 来部署: ./gradlew deploy -Dpackaging=docker\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Serverless Functions","url":"/micronaut/micronaut-serverless-functions/","content":"\n\n\nServerless Functions\nAWS Lambda\nGoogle Cloud Function\nGoogle Cloud Run\nAzure Function\n\n\n\n\n\nServerless Functions声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\n\nServerless architectures, where you deploy functions that are fully managed by a Cloud environment and are executed in ephemeral processes, require a unique approach.\n\n无服务架构需要一种独特的方法, 你可以在其中部署完全由云环境管理并在临时进程中执行的功能\n\nTraditional frameworks like Grails and Spring are not really suitable since low memory consumption and fast startup time are critical, since the Function as a Service (FaaS) server typically spins up your function for a period using a cold start and then keeps it warm.\n\n像 Grails 和 Spring 这样的传统框架并不是真正适合, 因为低内存消耗和快速启动至关重要, 因为 Function as a Service( FaaS ) 服务器通常使用冷启动来启动你的 function 一段时间, 然后使其保持 warm\n\nMicronaut’s compile-time approach, fast startup time, and low memory footprint make it a great candidate for developing functions, and Micronaut includes dedicated support for developing and deploying functions to AWS Lambda, Google Cloud Function, Azure Function, and any FaaS system that supports running functions as containers (such as OpenFaaS, Rift or Fn).\n\nMicronaut 的编译时处理, 快速启动时间和低内存占用使其称为开发 functions 的理想选择, 并且 Micronaut 包含了对开发和部署 functions 到 AWS Lambda, Google Cloud Function, Azure Function 和任何支持将 functions 作为容器运行的 Faas 系统( 例如 OpenFaas, Rift, or Fn ) 的支持\n\nThere are generally two approaches to writing functions with Micronaut:\n\n通常有两个方式来使用 Micronaut 编写 functions:\n\n使用 function 平台的原生 API 编写的低级 functions\n像在典型的 Micronaut 应用中那样定义 controllers 并将其部署到 function 平台中的 高级 functions\n\n第一个方式的启动时间略少, 通常用于非 HTTP functions, 例如监听一个事件的或后台的 functions\n第二个方法仅适用于 HTTP functions, 对于想要获取现有应用程序的一部分并将其部署为无服务 function 的用户很有用. 如果冷启动性能会是一个问题, 那么建议考虑使用 GraalVM 来构建原生镜像( image )\nAWS Lambda使用 Micronaut AWS 子项目来实现对 AWS Lambda 的支持\nGoogle Cloud Function使用 Micronaut GCP 子项目来实现对 Google Cloud Function 的支持\nGoogle Cloud Run要部署到 Google Cloud Run 中, 推荐使用 JIB 来容器化你的项目\nExample - Using the CLI - Creating an application with JIB:\nmn create-app my-app --features jib\n\n设置好 JIB 之后, 要部署你的应用到 Google Container Registry, 运行:\n./gradlew jib\n\n然后现在就可以部署你的应用了:\ngcloud run deploy --image gcr.io/[PROJECT ID]/example --platform=managed --allow-unauthenticated\n\nAzure Function使用 Micronaut Azure 子项目来实现对 Azure Function 的支持\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 Standalone Command Line Applications","url":"/micronaut/micronaut-standalone-command-line-applications/","content":"\n\n\nStandalone Command Line Applications\nPicocli Support (Picocli 支持)\n\n\n\n\n\nStandalone Command Line Applications声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\n在某些情况下, 你可能希望创建与微服务架构交互的独立命令行 (CLI) 应用程序\n这样的应用程序有 调度任务, 批处理应用程序, 通用命令行应用程序\n所以使用一种健壮的方式来解析命令行选项和位置参数 (positional parameters) 是很重要的\nPicocli Support (Picocli 支持)Piocli 是一个命令行解析器, 支持 ANSI 颜色, 自动补全和嵌套子命令的使用帮助\nPiocli 有一个注解 API 来几乎无代码地创建命令行应用, 还有一个编程式 API 用来创建例如 Domain Specific Languages\n查看 documentation for the Picocli integration 获取更多信息\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 The HTTP Server","url":"/micronaut/micronaut-the-http-server/","content":"\n\n\nThe HTTP Server\nRunning the Embedded Server (运行内嵌的 Server)\nRunning Server on a Specific Port (在指定端口上运行 Server)\nHTTP Routing (HTTP 路由)\nURI Paths (URI 路径)\nURI Path Variables (URI 路径变量)\nURI Reserved Character Matching (URI 保留字符匹配)\nRouting Annotations (路由注解)\nMultiple URIs (多个 URI)\nBuilding Routes Programmatically (编程式地构建路由)\nRoute Compile-Time Validation (路由编译时校验)\nRouting non-standard HTTP methods (路由非标准 HTTP 方法)\n\n\nSimple Request Binding (简单请求绑定)\nBinding Annotations (绑定注解)\nStream Support (Stream 支持)\nBinding from Multiple Query values (使用多个请求值进行绑定)\nBinding from Multiple Bindable values (从多个可绑定值中进行绑定)\nBindable Types (可绑定类型)\nType-Based Binding Parameters (基于类型的参数绑定)\nVariable resolution (变量解析)\n\n\nCustom Argument Binding (自定义参数绑定)\nAnnotatedRequestArgumentBinder (注解修饰的请求参数绑定)\nTypedRequestArgumentBinder (请求参数类型绑定)\n\n\nHost Resolution (Host 解析)\nLocale Resolution (本地化解析)\nClient IP Address (客户端 IP 地址)\nThe HttpRequest and HttpResponse (HttpRequest 和 HttpResponse)\nResponse Status (响应状态)\nResponse Content-Type (响应的 Content-Type)\nAccepted Request Content-Type (可接受的请求 Content-Type)\nCustoming Processed Content Types (自定义处理的 Content-Type)\n\n\nReactive HTTP Request Processing (响应式 HTTP 请求处理)\nUsing the @Body Annotation (使用 @Body 注解)\nReactive Responses (响应式响应)\n\n\nJSON Binding with Jackson (使用 Jackson 进行 JSON 绑定)\nBinding using Reactive Frameworks (使用响应式框架进行绑定)\nBinding Using CompletableFuture (使用 CompletableFuture 进行绑定)\nBinding using POJOs (使用 POJO 进行绑定)\nJackson Configuration (Jackson 配置)\nFeatures (特性)\nFurther customing JsonFactory (更深入自定义 JsonFactory )\nSupport for @JsonView (@JsonView 的支持)\nBeans (Beans)\nService Loader (Service 加载器)\nNumber Precision (数值精确性)\n\n\n\n\nData Validation (数据校验)\nServing Static Resources (提供静态资源)\nError Handling (错误处理)\nStatus Handlers (状态处理器)\nLocal Error Handling (本地异常处理)\nGlobal Error Handling (全局异常处理)\nExceptionHandler (异常处理器)\nBuilt-In Exception Handlers (内置的异常处理器)\nCustom Exception Handler (自定义异常处理器)\n\n\nError Formatting (错误格式)\n\n\nAPI Versioning (API 版本控制)\nDefault Version (默认版本)\nVersioning Client Requests (版本化的客户端请求)\n\n\nHandling Form Data (处理表单数据)\nWriting Response Data (编写响应数据)\nPerforming Blocking I&#x2F;O (运行阻塞 I&#x2F;O)\nWritable (可写的)\nInputStream (输入流)\n404 Responses (404 响应)\n\n\n\n\nFile Uploads (文件上传)\nRoute Arguments (路由参数)\nChunk Data Types (块数据类型)\nWhole Data Types (完整数据类型)\n\n\nMultiple Uploads (多文件上传)\nDifferent Names (不同的名字)\nSame name (相同的名字)\n\n\nWhole Body Binding (完整 Body 绑定)\n\n\nFile Transfers (文件传输)\nSending File Objects (发送文件对象)\nSending an InputStream (发送一个 InputStream)\nCache Configuration (缓存配置)\n\n\nHTTP Filters (HTTP 过滤器)\nWriting a Filter (编写一个过滤器)\n\n\nHTTP Sessions (HTTP 会话)\nEnabling Sessions (开启会话)\nRedis Sessions (Redis 会话)\n\n\nConfiguring Session Resolution (配置会话解析)\nWorking with Sessions (使用会话)\nSession Clients (会话客户端)\nUsing @SessionValue (使用 @SessionValue 注解)\nSession Events (会话事件)\n\n\nServer Sent Events (Server 发送事件)\nWebSocket Support (WebSocket 支持)\nUsing @ServerWebSocket(使用 @ServerWebSocket 注解)\nThe @OnClose Method (@OnClose 方法)\nThe @OnMessage Method (@OnMessage 方法)\nThe @OnError Method (@OnError 方法)\nNon-Blocking Message Handling (非阻塞式信息处理)\n@ServerWebSocket and Scopes (@ServerWebSocket 和作用域)\nSharing Sessions with the HTTP Session (和 HTTP session 共享 session)\nUsing the CLI (使用 CLI)\nConnection Timeouts (连接超时)\n\n\nUsing @ClientWebSocket (使用 @ClientWebSocket)\nUsing the CLI (使用 CLI)\n\n\n\n\nHTTP&#x2F;2 Support (HTTP&#x2F;2 支持)\nConfiguring the Server for HTTP&#x2F;2 (为 HTTP&#x2F;2 配置 Server)\nHTTP&#x2F;2 Server Push Support (HTTP&#x2F;2 Server 推送支持)\n\n\nServer Events (Server 事件)\nConfiguring the HTTP Server (配置 HTTP Server)\nUsing Native Transports (使用原生传输)\nConfiguring Server Thread Pools (配置 Server 线程池)\nBlocking Operations (阻塞式操作)\n\n\nConfiguring the Netty Pipeline (配置 Netty 管道)\nConfiguring CORS (配置跨域请求)\nAllowed Origins (允许的源)\nAllowed Methods (允许的方法)\nAllowed Headers (允许的请求头)\nExposed Headers (暴露的请求头)\nAllow Credentials (允许 Credentials)\nMax age (最大 age)\nMultiple Header Values (多个 Header 值)\n\n\nSecuring the Server with HTTPS (使用 HTTPS 保护 Server)\nUsing a valid x509 certificate (使用一个有效的 x509 证书)\n\n\nUsing Java Keystore (使用 Java Keystore (JKS))\nRefreshing&#x2F;Reloading HTTPS Certificates (刷新&#x2F;重载 HTTPS 证书)\n\n\nEnabling HTTP and HTTPS (同时开启 HTTP 和 HTTPS)\nEnabling Access Logger (开启访问日志)\nFiltering access logs (过滤访问日志)\nLogback Configuration (Logback 配置)\nLog Format (日志格式)\n\n\nStarting Secondary Servers (开启二级服务)\n\n\nServer Side View Rendering (服务器端视图渲染)\nOpenAPI &#x2F; Swagger Support (OpenAPI &#x2F; Swagger 支持)\nGraphQL Support (GraphQL 支持)\n\n\n\n\n\nThe HTTP Server声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\n如果使用 create-app 命令创建项目, 那么默认包含 http-server 依赖\nMicronaut 包含了基于 Netty 的非阻塞 HTTP Server 和 Client API\nMicronaut 中 HTTP Server 的设计是为了在微服务之间交换信息而优化的, 特别是使用 JSON\nMicronaut 不是为了成为一个完全的服务端 MVC 框架\nHTTP Server 的目标是尽可能容易地暴露供 HTTP 客户端使用的 API, 不管它们是用什么语言写的\n要使用 HTTP Server 你需要在构建中添加 http-server-netty 依赖:\nimplementation(&quot;io.micronaut:micronaut-http-server-netty&quot;)\n\nRunning the Embedded Server (运行内嵌的 Server)为了运行 Server, 创建一个有 static void main 方法的 Application 类:\nExample - Micronaut Application Class:\nimport io.micronaut.runtime.Micronautclass Application &#123;    static void main(String... args) &#123;        Micronaut.run Application    &#125;&#125;\n\n要在单元测试中运行应用程序, 使用 EmbeddedServer 接口:\nExample - Micronaut Test Case:\nimport io.micronaut.http.HttpRequestimport io.micronaut.http.client.HttpClientimport io.micronaut.http.client.annotation.Clientimport io.micronaut.runtime.server.EmbeddedServerimport io.micronaut.test.extensions.spock.annotation.MicronautTestimport spock.lang.Specificationimport jakarta.inject.Inject@MicronautTestclass HelloControllerSpec extends Specification &#123;    @Inject    @AutoCleanup    EmbeddedServer embeddedServer   // 1    @Inject    @Client(&quot;/&quot;)    HttpClient client               // 2    void &#x27;test hello world response&#x27;() &#123;        expect:            client.toBlocking()     // 3                  .retrieve(HttpRequest.GET(&#x27;/hello&#x27;)) == &#x27;Hello World&#x27; // 4    &#125;&#125;\n\n1 : The EmbeddedServer is run and the Spock @AutoCleanup annotation ensures the server is stopped after the specification completes\n2 : The EmbeddedServer interface provides the URL of the server under test which runs on a random port\n3 : The test uses the Micronaut HTTP client to make the call\n4 : The retrieve method returns the response of the controller as a String\n如果没有明确的端口配置, 那么端口号默认为 8080\n如果是在 test 环境下运行应用, 端口号将会是随机的\n当应用程序上下文从测试类的上下文启动时, test 环境将会自动添加\nRunning Server on a Specific Port (在指定端口上运行 Server)默认情况下, Server 运行在 8080 端口\n通过如下配置指定运行的端口号:\nmicronaut:    server:        port: 8086\n\n也可以通过环境变量来配置: MICRONAUT_SERVER_PORT=8086\n配置运行在随机端口:\nmicronaut:    server:        port: -1\n\n如果多个 Server 同时启动在同一个端口, 设置一个明确的端口可能导致测试失败, 为了防止这样, 在 test 环境配置声明一个随机端口\nHTTP Routing (HTTP 路由)URI Paths (URI 路径)\nThe value of the @Controller annotation is a RFC-6570 URI template, so you can embed URI variables within the path using the syntax defined by the URI template specification.\n\n@Controller 注解的值是一个 RFC-6570 URI template, 所以你可以使用 URI template 规范定义的语法来内嵌 URI 变量到路径中\n许多其他的框架, 包括 Spring, 实现了 URI template 规范\n实际的实现是由 UriMatchTemplate 类处理的, 该类扩展了 UriTemplate\n你可以在应用中使用这个类来构建 URI, 例如:\ngiven:UriMatchTemplate template = UriMatchTemplate.of(&quot;/hello/&#123;name&#125;&quot;)expect:template.match(&quot;/hello/John&quot;).isPresent()           // 1template.expand([&quot;name&quot;: &quot;John&quot;]) == &quot;/hello/John&quot;  // 2\n\n1 : Use the match method to match a path\n2 : Use the expand method to expand a template into a URI\n可以使用 UriTemplate 类来构建路径, 用来包含到响应中\nURI Path Variables (URI 路径变量)URI 变量可以通过方法参数来引用\nExample - URI Variables:\nimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Getimport io.micronaut.http.annotation.PathVariable@Controller(&#x27;/issues&#x27;)class IssuesController &#123;    @Get(&#x27;/&#123;number&#125;&#x27;)   // a URI variables embedded in the URI named `number`    String issue(@PathVariable Integer number) &#123;    // The method argument can optionally be annotated with @PathVariable        &quot;Issue # $number !&quot;    &#125;&#125;\n\nExample - Testing URI Variables:\nimport io.micronaut.context.ApplicationContextimport io.micronaut.http.client.HttpClientimport io.micronaut.http.client.exceptions.HttpClientResponseExceptionimport io.micronaut.runtime.server.EmbeddedServerimport spock.lang.AutoCleanupimport spock.lang.Sharedimport spock.lang.Specificationclass IssuesControllerTest extends Specification &#123;    @Shared    @AutoCleanup // The server is cleaned up after the tests finish    EmbeddedServer embeddedServer = ApplicationContext.run(EmbeddedServer) // The embedded server is started    @Shared    @AutoCleanup // The client is cleaned up after the test finish    HttpClient client = HttpClient.create(embeddedServer.URL) // The HTTP client is started    void &quot;test issue&quot;() &#123;        when:        String body = client.toBlocking().retrieve(&quot;/issues/12&quot;) // The tests send a request to the URI `/issues/12`        then:        body != null        body == &quot;Issue # 12!&quot;    &#125;    void &quot;/issues/&#123;number&#125; with an invalid Integer number responds 400&quot;() &#123;        when:        client.toBlocking().exchange(&quot;/issues/hello&quot;)        then:        def e = thrown(HttpClientResponseException)        e.status.code == 400 // Another test asserts a 400 response is returned when an invalid number is sent in the URL    &#125;    void &quot;/issues/&#123;number&#125; without number responds 404&quot;() &#123;        when:        client.toBlocking().exchange(&quot;/issues/&quot;)        then:        def e = thrown(HttpClientResponseException)        e.status.code == 404 // The variables being present is required for the route to be executed    &#125;&#125;\n\n上面的 URI template 例子中的 number 变量是必选的\n可以使用如下语法指定可选的 URI template: /issues&#123;/number&#125;, 并使用 @Nullable 注解修饰 number 方法参数\nTable - URI Template Matching:\n\n\n\nTemplate\nDescription\nMatching URI\n\n\n\n/books/&#123;id&#125;\nSimple match\n/books/1\n\n\n/books/&#123;id:2&#125;\nA variable of two characters max\n/books/10\n\n\n/books&#123;/id&#125;\nAn optional URI variable\n/books/10 or /books\n\n\n/book&#123;/id:[a-zA-Z]+&#125;\nAn optional URI variable with regex\n/books/foo\n\n\n/books&#123;?max,offset&#125;\nOptional query parameters\n/books?max=10&amp;offset=10\n\n\n/books&#123;/path:.*&#125;&#123;.ext&#125;\nRegex path match with extension\n/books/foo/bar.xml\n\n\nURI Reserved Character Matching (URI 保留字符匹配)默认情况下, RFC-6570 URI template 规范定义的 URI 变量不能包含保留字符, 例如 /, ?等\n\nyou can use reserved expansion or matching using the + operator.\n\n你可以使用保留展开或使用操作符匹配\n例如 URI (/books/&#123;+path&#125;) 同时匹配 /books/foo 和 /books/foo/bar, 因为 + 表明变量 path 应该包括保留字符\nRouting Annotations (路由注解)Table - HTTP Routing Annotations:\n\n\n\nAnnotation\nHTTP Method\n\n\n\n@Delete\nDELETE\n\n\n@Get\nGET\n\n\n@Head\nHEAD\n\n\n@Options\nOPTIONS\n\n\n@Patch\nPATCH\n\n\n@Put\nPUT\n\n\n@Post\nPOST\n\n\n@Trace\nTRACE\n\n\n\nAll the method annotations default to /\n\n所有的方法注解默认为 /\nMultiple URIs (多个 URI)每个路由注解都支持多个 URI template\n对于每个 template, 会创建一个路由\n这个特性对于要修改 API 的路径非常有用, 这可以保持已有路径作为向后兼容\nimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Get@Controller(&quot;/hello&quot;)class BackwardCompatibleController &#123;    @Get(uris = [&quot;/&#123;name&#125;&quot;, &quot;/person/&#123;name&#125;&quot;])    String hello(String name) &#123;        &quot;Hello, $name&quot;    &#125;&#125;\n\n\nRoute validation is more complicated with multiple templates. If a variable that would normally be required does not exist in all templates, that variable is considered optional since it may not exist for every execution of the method.\n\n在多个 template 的情况下路由校验会更加复杂. 如果一个变量通常应该是必选的但是又不存在于所有的 template 中, 那这个变量被认为是可选的, 因为它可能不是在每次执行方法时都存在\nBuilding Routes Programmatically (编程式地构建路由)如果你不喜欢使用注解, 而是喜欢在代码中声明所有路由, 那么不用担心, Micronaut 有一个灵活的 RouteBuilder API 可以轻松地通过编程定义路由\n继承 DefaultRouteBuilder 并注入要进行路由的 Controller 到方法中, 然后定义路由:\nExample - URI Variables:\nimport io.micronaut.context.ExecutionHandleLocatorimport io.micronaut.core.convert.ConversionServiceimport io.micronaut.web.router.GroovyRouteBuilderimport jakarta.inject.Injectimport jakarta.inject.Singleton@Singletonclass MyRoutes extends GroovyRouteBuilder &#123;     // 路由定义必须是 DefaultRouteBuilder 的子类    MyRoutes(ExecutionHandleLocator executionHandleLocator,             UriNamingStrategy uriNamingStrategy,             ConversionService conversionService) &#123;        super(executionHandleLocator, uriNamingStrategy, conversionService)    &#125;    @Inject     // 使用 @Inject 注解注入 Controller 到方法参数中    void issuesRoutes(IssuesController issuesController) &#123;        GET(&quot;/issues/show/&#123;number&#125;&quot;, issuesController.&amp;issue)      // 必须使用全路径, 因为在这里并不知道 @Controller 注解中定义的值    &#125;&#125;\n\n不幸的是, 因为类型擦除, 一个 Java 方法 lambda 引用不能和 API 一起使用, 所以在 Java 中这个例子是这样的: GET(&quot;/issues/show/&#123;number&#125;&quot;, issuesController, &quot;issue&quot;, Integer.class);\n在 Groovy 中有一个 GroovyRouteBuilder 类可以被继承, 并允许传递 Groovy 方法应用\nRoute Compile-Time Validation (路由编译时校验)Micronaut 支持使用校验库在编译时校验路由参数\n首先, 在你的构建中添加 validation 依赖:\n// build.gradleannotationProccessor &quot;io.micronaut:micronaut-validation&quot;    // Java Onlykapt &quot;io.micronaut:micronaut-validation&quot;                    // Kotlin Onlyimplementation &quot;io.micronaut:micronaut-validation&quot;\n\n有了正确的依赖在 classpath 上, 路由参数将会在编译时被自动校验\n在如下情况中, 编译将会失败:\n\nURI template 中包含了一个可选的变量, 但是方法参数没有使用 @Nullable 注解修饰或者使用 java.util.Optional 包装\nURI template 包含一个方法中没有对应参数的变量\n\nRouting non-standard HTTP methods (路由非标准 HTTP 方法)@CustomHttpMethod 注解支持非标准 HTTP 方法, 并可使用于 Client 或 Server\n例如, RFC-4918 Webadv 规范要求额外的方法, 如 REPORT 或 LOCK:\n@CustomHttpMethod(method = &quot;LOCK&quot;, value = &quot;/&#123;name&#125;&quot;)String lock(String name)\n\n@CustomHttpMethod 注解可以使用在任何基础方法注解可以使用的地方, 包括 Controller 和声明式 HTTP 客户端\nSimple Request Binding (简单请求绑定)Binding Annotations (绑定注解)\nAll binding annotations support customization of the name of the variable being bound from with their name member.\n\n所有的绑定注解都支持将被绑定的变量使用它们的 name 成员属性来进行名称自定义\nTable - Parameter Binding Annotations:\n\n\n\nAnnotation\nDescription\nExample\n\n\n\n@Body\nBinds from the body of the request\n@Body String body\n\n\n@CookieValue\nBinds a parameter from a cookie\n@CookieValue String myCookie\n\n\n@Header\nBinds a parameter from an HTTP header\n@Header String requestId\n\n\n@QueryValue\nBinds from a request query parameter\n@QueryValue String myParam\n\n\n@Part\nBinds from a part of a multiple request\n@Part CompletedFileUpload file\n\n\n@RequestAttribute\nBinds from an attribute of the request. Attributes are typically created in filters\n@RequestAttribute String myAttribute\n\n\n@PathVariable\nBinds from the path of the request\n@PathVariable String id\n\n\n@RequestBean\nBinds any Bindable value to single Bean object\n@RequestBean MyBean bean\n\n\n在一个绑定注解中没有指定一个 value 时, 将会使用方法参数名称:\nExample - 下面例子中两个参数绑定都是一样的效果:\n@Get(&quot;/cookieName&quot;)String cookieName(@CookieValue(&quot;myCookie&quot;) String myCookie) &#123;&#125;@Get(&quot;/cookieInferred&quot;)String cookieInferred(@CookieValue String myCookie)\n\n由于连字符不可以使用在变量名称中, 所以有必要在注解中设置名称:\nExample - The following definitions are equivalent:\n@Get(&quot;/headerName&quot;)String headerName(@Header(&quot;Content-Type&quot;) String contentType) &#123;&#125;@Get(&quot;/headerInferred&quot;)String headerInferred(@Header String contentType)\n\nStream Support (Stream 支持)Micronaut 还支持绑定 body 到一个 InputStream 中\n如果方法是读取这个 Stream, 那么这个方法的执行要卸载(offloaded)到另一个线程池中, 避免阻塞 event loop\nExample - Performing Blocking I&#x2F;O With InputStream:\n@Post(value = &quot;/read&quot;, processes = MediaType.TEXT_PLAIN)@ExecuteOn(TaskExecutors.IO)    // 1String read(@Body InputStream inputStream) throws IOException &#123;     // 2    IOUtils.readText(new BufferedReader(new InputStreamReader(inputStream)))        // 3&#125;\n\n1 : The controller method is executed on the IO thread pool\n2 : The body is passed to the method as an input stream\n3 : The stream is read\nBinding from Multiple Query values (使用多个请求值进行绑定)与其从请求的单个部分绑定, 不如将所有查询值(例如)绑定到 POJO\n可以通过在 URI template 中使用分解操作符 ?pojo* 来实现\nExample - Binding Request parameters to POJO:\nimport io.micronaut.http.HttpStatusimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Getimport javax.annotation.Nullableimport javax.validation.Valid@Controller(&quot;/api&quot;)class BookmarkController &#123;    @Get(&quot;/bookmarks/list&#123;?paginationCommand*&#125;&quot;)    HttpStatus list(@Valid @Nullable PaginationCommond paginationCommand) &#123;        HttpStatus.OK    &#125;&#125;\n\nBinding from Multiple Bindable values (从多个可绑定值中进行绑定)除了仅仅绑定查询值, 还可以绑定任何 可绑定值 到一个 POJO 中(例如, 绑定 HttpRequest,@PathVariable,@QueryValue,@Header 到一个 POJO 中)\n这可以通过使用 @RequestBean 注解和一个自定义的 拥有可绑定注解的字段的 或 字段可通过类型(例如, HttpRequest,BasicAuth,Authentication)进行绑定的 Bean 类来实现\nExample - Binding Bindable values to POJO:\n@Controller(&quot;/api&quot;)class MovieTicketController &#123;    @Get(&quot;/movie/ticket/&#123;movieId&#125;&#123;?minPrice,maxPrice&#125;&quot;)    HttpStatus list(@Valid @RequestBean MovieTicketBean bean) &#123;    &#125;&#125;// Bean definition@Introspectedclass MovieTicketBean &#123;    private HttpRequest&lt;?&gt; httpRequest    @PathVariable    String movieId    @Nullable    @QueryValue    @PositiveOrZero    Double minPrice    @Nullable    @QueryValue    @PositiveOrZero    Double maxPrice&#125;\n\nBean 类必须使用 @Introspected 注解进行修饰\nBean 可以是如下之一:\n\n拥有 setter&#x2F;getter 方法的可变类\n拥有 getter 方法和一个包含所有字段入参的构造方法(或者 @Creator 注解修饰的构造方法和静态方法). 构造方法的入参必须与字段名称匹配, 以使对象可以不通过反射进行实例化\n\n因为 Java 没有包含参数名称在字节码中, 你在使用一个来自其他 Jar 文件中的不可变 Bean 类时必须使用 -parameters 参数来编译代码. 另一个选项是在你的源代码中继承这个 Bean 类\nBindable Types (可绑定类型)通常, 任何可以通过 ConversionService API 从字符串表示转换为 Java 类型的类都可以进行绑定\n这包含了大多数常用 Java 类型\n可以通过添加使用 @Singleton 注解修饰的 TypeConverter 接口实现 Bean 来注册额外的类型转换逻辑\nNull 值处理需要特别注意:\n@Get(&quot;/headerInferred&quot;)String headerInferred(@Header String contentType) &#123;&#125;\n\n在这里例子中,  如果 HTTP 请求的请求头中没有包含 Content-Type, 所以这个路由被认为是无效的, 因此将会返回 HTTP 400 BAD REQUEST\n简单地说, contentTyp 是必传的\n为了使 Content-Type 请求头是可选的, 可以使用 @Nullable 注解来进行声明:\n@Get(&quot;/headerInferred&quot;)String headerInferred(@Nullable @Header String contentType) &#123;&#125;\n\n除此之外, 任何满足 RFC-1123 规范的 DateTime 都可以绑定到一个入参上. 可以使用 @Format 注解来指定自定义的时间格式:\n@Get(&quot;/date&quot;)String date(@Header ZonedDateTime date) &#123;&#125;@Get(&quot;/dateFormat&quot;)String dateFormat(@Format(&quot;dd/MM/yyyy hh:mm:ss a z&quot;) @Header ZonedDateTime date) &#123;&#125;\n\nType-Based Binding Parameters (基于类型的参数绑定)有些参数只考虑它们的类型而不是它们的注解\n\n\n\nType\nDescription\nExample\n\n\n\nBasicAuth\nAllows binding of basic authorization credentials\nBasicAuth basicAuth\n\n\nVariable resolution (变量解析)Micronaut 尝试通过如下顺序来填充方法参数:\n\nURI 变量, 例如 /&#123;id&#125;\n如果请求是一个 GET 请求, 从请求参数中获取, 例如 ?foo=bar\n如果有一个 @Body 注解并且请求允许这个 body, 那么绑定这个 body 到 @Body 注解修饰的参数上\n如果请求可以有 body 但是没有使用 @Body 注解修饰参数, 那么就尝试解析 body(JSON 或 form data), 将方法参数绑定到 body\n最后, 如果方法参数无法被填充, 那么就返回 400 BAD REQUEST\n\nCustom Argument Binding (自定义参数绑定)\nMicronaut uses an ArgumentBinderRegistry to look up ArgumentBinder beans capable of binding to the arguments in controller methods.\n\nMicronaut 使用一个 ArgumentBinderRegistry 来查找能够绑定到 Controller 方法中的参数的 ArgumentBinder Bean\n\nThe default implementation looks for an annotation on the argument that is meta-annotated with @Bindable.\n\n默认的实现是先寻找修饰参数的 使用了@Bindable注解修饰的 注解\n\nIf one exists the argument binder registry searches for an argument binder that supports that annotation.\n\n如果找到一个使用了 @Bindable 注解修饰的注解, 那么 argument binder registry 将会寻找一个支持这个注解的 argument binder\n\nIf no fitting annotation is found Micronaut tries to find an argument binder that supports the argument type.\n\n如果没有找到使用 @Bindable 注解修饰的注解, 那么 Micronaut 将会尝试寻找一个支持参数类型的 argument binder\n\nAn argument binder returns a ArgumentBinder.BindingResult.\n\n一个 argument binder 返回一个 ArgumentBinder.BindingResult\n\nThe binding result gives Micronaut more information than just the value.\n\n这个 BindingResult 给 Micronaut 提供了更多的信息而不仅仅是值\n\nBinding results are either satisfied or unsatisfied, and either empty or not empty.\n\nBindingResult 不是 satisfied 就是 unsatisfied 的, 不是 empty 就是 not empty 的\n\nIf an argument binder returns an unsatisfied result, the binder may be called again at different times in request processing.\n\n如果一个 argument binder 返回一个 unsatisfied 结果, 这个 binder 可能会在处理请求的不同时候被再次调用\n\nArgument binders are initially called before the body is read and before any filters are executed.\n\nargument binders 在 body 被读取和在任何 filter 被执行之前被初始化调用\n\nIf a binder relies on any of that data and it is not present, return a ArgumentBinder.BindingResult#UNSATISFIED result.\n\n如果一个 binder 依赖于其中的任何数据, 而该数据不存在, 则返回一个 ArgumentBinder.BindingResult#UNSATISFIED\n\nReturning an ArgumentBinder.BindingResult#EMPTY or satisfied result will be the final result and the binder will not be called again for that request.\n\n返回一个 ArgumentBinder.BindingResult#EMPTY 或者 satisfied result 将是最终的 result, 在这个请求中 binder 不会再次被调用\n\nAt the end of processing if the result is still ArgumentBinder.BindingResult#UNSATISFIED, it is considered ArgumentBinder.BindingResult#EMPTY.\n\n在处理的最后如果结果仍然是 ArgumentBinder.BindingResult#UNSATISFIED, 这被认为是 ArgumentBinder.BindingResult#EMPTY\nAnnotatedRequestArgumentBinder (注解修饰的请求参数绑定)\nArgument binders that bind based on the presence of an annotation must implement AnnotatedRequestArgumentBinder, and can be used by creating an annotation that is annotated with Bindable.\n\n基于注解是否存在进行绑定的 argument binder 必须实现 AnnotatedRequestArgumentBinder, 可以通过创建一个被 @Bindable 注解修饰的注解来实现\nExample - An example of a binding annotation:\nimport groovy.transform.CompileStaticimport io.micronaut.context.annotation.AliasForimport io.micronaut.core.bind.annotation.Bindableimport java.lang.annotation.Retentionimport java.lang.annotation.Targetimport static java.lang.annotation.ElementType.ANNOTATION_TYPEimport static java.lang.annotation.ElementType.FIELDimport static java.lang.annotation.ElementType.PARAMETERimport static java.lang.annotation.RetentionPolicy.RUNTIME@CompileStatic@Target([FIELD, PARAMETER, ANNOTATION_TYPE])@Retention(RUNTIME)@Bindable // The bingding annotation must itself be annotated as Bindable@interface ShoppingCart &#123;    @AliasFor(annotation = Bindable, member = &quot;value&quot;)    String value() default &quot;&quot;&#125;\n\nExample - Example of annotated data binding:\nimport groovy.transform.CompileStaticimport io.micronaut.core.convert.ArgumentConversionContextimport io.micronaut.core.convert.ConversionServiceimport io.micronaut.core.type.Argumentimport io.micronaut.http.HttpRequestimport io.micronaut.http.bind.binders.AnnotatedRequestArgumentBinderimport io.micronaut.http.cookie.Cookieimport io.micronaut.jackson.serialize.JacksonObjectSerializerimport jakarta.inject.Singleton@CompileStatic@Singletonclass ShoppingCartRequestArgumentBinder        implements AnnotatedRequestArgumentBinder&lt;ShoppingCart, Object&gt; &#123; // 1    private final ConversionService&lt;?&gt; conversionService    private final JacksonObjectSerializer objectSerializer    ShoppingCartRequestArgumentBinder(            ConversionService&lt;?&gt; conversionService,            JacksonObjectSerializer objectSerializer) &#123;        this.conversionService = conversionService        this.objectSerializer = objectSerializer    &#125;    @Override    Class&lt;ShoppingCart&gt; getAnnotationType() &#123;        ShoppingCart    &#125;    @Override    BindingResult&lt;Object&gt; bind(            ArgumentConversionContext&lt;Object&gt; context,            HttpRequest&lt;?&gt; source) &#123; // 2        String parameterName = context.annotationMetadata                .stringValue(ShoppingCart)                .orElse(context.argument.name)        Cookie cookie = source.cookies.get(&quot;shoppingCart&quot;)        if (!cookie) &#123;            return BindingResult.EMPTY        &#125;        Optional&lt;Map&lt;String, Object&gt;&gt; cookieValue = objectSerializer.deserialize(                cookie.value.bytes,                Argument.mapOf(String, Object))        return (BindingResult) &#123; -&gt;            cookieValue.flatMap(&#123;value -&gt;                conversionService.convert(value.get(parameterName), context)            &#125;)        &#125;    &#125;&#125;\n\n1 : The custom argument binder must implement AnnotatedRequestArgumentBinder, including both the annotation type to trigger binder and the type of the argument expected\n2 : Ovrride the bind method with the custom argument binding logic\nExample - A controller operation with this annotated binding:\n@Get(&quot;/annotated&quot;)HttpResponse&lt;String&gt; checkSession(@ShoppingCart Long sessionId) &#123;&#125; // 1\n\n1 : The parameter is bound with the binder associated with @ShoppingCart. This takes precedence over a type-based binder, if applicable\nTypedRequestArgumentBinder (请求参数类型绑定)\nArgument binders that bind based on the type of the argument must implement TypedRequestArgumentBinder.\n\n基于参数类型进行绑定的 argument binder 必须实现 TypedRequestArgumentBinder\nExample - The POJO:\nimport io.micronaut.core.annotation.Introspected@Introspectedclass ShoppingCart &#123;    String sessionId    Integer total&#125;\n\nExample - The argument binder:\nimport io.micronaut.core.convert.ArgumentConversionContextimport io.micronaut.core.type.Argumentimport io.micronaut.http.HttpRequestimport io.micronaut.http.bind.binders.TypedRequestArgumentBinderimport io.micronaut.http.cookie.Cookieimport io.micronaut.jackson.serialize.JacksonObjectSerializerimport jakarta.inject.Singleton@Singletonclass ShoppingCartRequestArgumentBinder implements TypedRequestArgumentBinder&lt;ShoppingCart&gt; &#123;    private final JacksonObjectSerializer objectSerializer    ShoppingCartRequestArgumentBinder(JacksonObjectSerializer objectSerializer) &#123;        this.objectSerializer = objectSerializer    &#125;    @Override    BindingResult&lt;ShoppingCart&gt; bind(ArgumentConversionContext&lt;ShoppingCart&gt; context,                                     HttpRequest&lt;?&gt; source) &#123; //        Cookie cookie = source.cookies.get(&quot;shoppingCart&quot;)        if (!cookie) &#123;            return BindingResult.EMPTY        &#125;        return () -&gt; objectSerializer.deserialize( //                cookie.value.bytes,                ShoppingCart)    &#125;    @Override    Argument&lt;ShoppingCart&gt; argumentType() &#123;        Argument.of(ShoppingCart) //    &#125;&#125;\n\nExample - Usage:\n@Get(&quot;/typed&quot;)HttpResponse&lt;Map&lt;String, Object&gt;&gt; loadCart(ShoppingCart shoppingCart) &#123; //    HttpResponse.ok(            sessionId: shoppingCart.sessionId,            total: shoppingCart.total)&#125;\n\nHost Resolution (Host 解析)Micronaut 提供了一个 HttpHostResolver 接口实现来解析当前 Server 的 host 名称\n这个默认实现通过如下地方按顺序来寻找 host 信息:\n\n提供的配置\nForwarded header\nX-Forwarded- headers. 如果 X-Forwarded-Host header 没有提供, 另外的 X-Forwarded headers 被忽略\nHost header\n在请求的 URI 上的属性\n在内嵌的 server URI 上的属性\n\n\nThe behavior of which headers to pull the relevant data can be changed with the following configuration\n\n从 Header 中获取相关数据的行为可以通过如下配置进行更改:\nTable - Configuration Properties for HostResolutionConfiguration:\n\n\n\nProperty\nType\nDescription\n\n\n\nmicronaut.server.host-resolution\nHttpServerConfiguration$HostResolutionConfiguration\nThe host resolution configuration\n\n\nmicronaut.server.host-resolution.host-header\njava.lang.String\nThe header name that stores the host\n\n\nmicronaut.server.host-resolution.protocol-header\njava.lang.String\nThe header name that stores the protocol\n\n\nmicronaut.server.host-resolution.port-header\njava.lang.String\nThe header name that stores the port\n\n\nmicronaut.server.host-resolution.port-in-host\nboolean\nTrue if the host header supports a port\n\n\nmicronaut.server.host-resolution.allowed-hosts\njava.util.List\nThe list of allowed host regex patterns. Any resolved\n\n\n\nThe above configuration also supports an allowed host list.\n\n上面的配置中还提供了一个放行 host 列表\n\nConfiguring this list ensures any resolved host matches one of the supplied regular expression patterns.\n\n配置这个列表确保任何被解析的 host 匹配上提供的正则表达式中的一个\n\nThat is useful to prevent host cache poisoning attacks and is recommended to be configured.\n\n这在防止 host 缓存 poisoning attacks 是很有用的, 建议进行这个配置\nLocale Resolution (本地化解析)Micronaut 支持多种策略来在一个请求中解析 locales\n可以在请求上使用 getLocale-- 方法, 但是这只支持解析 Accept-Language header\n在其他场景中, locale 可能存在于 cookie, user’s session, 或者被设置为一个固定值\nHttpLocaleResolver 可以用来指明当前的 locale\n不需要直接使用 LocaleResolver API\n简单地在 Controller 方法中定义一个类型为 java.util.Locale 的参数, 这个参数将会自动被解析并注入\nExample - 控制怎样解析 locale 的配置选项- Configuration Properties for HttpLocaleResolutionConfigurationProperties:\n\n\n\nProperty\nType\nDescription\n\n\n\nmicronaut.server.locale-resolution\nHttpServerConfiguration$HttpLocaleResolutionConfigurationProperties\nThe locale resolution configuration; locale 解析配置\n\n\nmicronaut.server.locale-resolution.fixed\njava.util.Locale\nSet the language tag for the locale. Supports BCP 47 language tags (e.g. “en-US”) and ISO standard (e.g “en_US”); 为 locale 设置语言标签. 支持 BCP 47 语言标签(例如, “en-US”) 和 ISO 标准(例如, “en_US”)\n\n\nmicronaut.server.locale-resolution.session-attribute\njava.lang.String\nSets the key in the session to look for the locale; 设置在 session 中寻找 locale 的 key 值\n\n\nmicronaut.server.locale-resolution.cookie-name\njava.lang.String\nSets the name of the cookie that is used to store the locale; 设置保存 locale 的 Cookie 的名称\n\n\nmicronaut.server.locale-resolution.header\nboolean\nSet to true if the locale should be resolved from the Accept-Language header. Default value (true); 设置为 true 则 locale 应该从 Accept-Language header 中解析, 默认为 true\n\n\nmicronaut.server.locale-resolution.default-locale\njava.util.Locale\nSets the locale that will be used if the locale cannot be resolved through any means. Defaults to the system default; 设置默认的 locale, 默认为系统默认值\n\n\n\nIf multiple methods are configured, the fixed locale takes precedence, followed by session&#x2F;cookie, then header.\n\n如果有配置了多个方法, 则那个固定值优先级最高, 按 session&#x2F;cookie, header 的顺序\nClient IP Address (客户端 IP 地址)Micronaut 提供了一个 HttpClientAddressResolver 实现来解析一个 HTTP 请求的起始 IP 地址\n默认实现在如下地方中按顺序解析客户端地址:\n\n配置的 header\nForwarded header\nX-Forwarded-For header\n请求上面的远程地址\n\n第一个优先级 header 名称可以使用 micronaut-server.client-address-header 来配置\nThe HttpRequest and HttpResponse (HttpRequest 和 HttpResponse)如果你需要对请求处理有更多的控制, 你可以编写一个方法接受一个完整的 HttpRequest\n事实上, 有一些高级接口可以绑定到 Controller 方法参数上:\nTable - Bindable Micronaut Interfaces:\n\n\n\nInterface\nDescription\nExample\n\n\n\nHttpRequest\nThe full HttpRequest\nString hello(HttpRequest request)\n\n\nHttpHeaders\nAll HTTP headers present in the request\nString hello(HttpHeaders headers)\n\n\nHttpParameters\nAll HTTP parameters (either from URI variables or request parameters) present in the request\nString hello(HttpParameters params)\n\n\nCookies\nAll Cookies present in the request\nString hello(Cookies cookies)\n\n\n如果需要请求的 body, HttpRequest 应该使用一个具体的泛型来进行定义, 例如 HttpRequest&lt;MyClass&gt; request. 否则, 请求的 body 可能是不可用的\n除此之外, 为了完全控制输出的 HTTP 响应, 你可以使用 HttpResponse 的静态工厂方法来返回一个 MutableHttpResponse\nExample - Request and Response:\nimport io.micronaut.http.HttpRequestimport io.micronaut.http.HttpResponseimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Getimport io.micronaut.http.context.ServerRequestContextimport reactor.core.publisher.Mono@Controller(&quot;/request&quot;)class MessageController &#123;    @Get(&quot;/hello&quot;)     HttpResponse&lt;String&gt; hello(HttpRequest&lt;?&gt; request) &#123;        String name = request.parameters                             .getFirst(&quot;name&quot;)                             .orElse(&quot;Nobody&quot;)        HttpResponse.ok(&quot;Hello $name !&quot;)                    .header(&quot;X-My-Header&quot;, &quot;Foo&quot;)    &#125;&#125;\n\n还可以从一个静态上下文 ServerRequestContext 中获取 HttpRequest:\nExample - Using the ServerRequestContext:\nimport io.micronaut.http.HttpRequestimport io.micronaut.http.HttpResponseimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Getimport io.micronaut.http.context.ServerRequestContextimport reactor.core.publisher.Mono@Controller(&quot;/request&quot;)class MessageController &#123;    @Get(&quot;/hello-static&quot;) //     HttpResponse&lt;String&gt; helloStatic() &#123;        HttpRequest&lt;?&gt; request = ServerRequestContext.currentRequest()                                                     .orElseThrow(() -&gt; new RuntimeException(&quot;No request present&quot;))        String name = request.parameters                             .getFirst(&quot;name&quot;)                             .orElse(&quot;Nobody&quot;)        HttpResponse.ok(&quot;Hello $name !&quot;)                    .header(&quot;X-My-Header&quot;, &quot;Foo&quot;)    &#125;&#125;\n\nMicronaut 框架使用 Project Reactor 作为默认的响应式流实现\nExample - Using the Project Reactor context:\nimport io.micronaut.http.HttpRequestimport io.micronaut.http.HttpResponseimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Getimport io.micronaut.http.context.ServerRequestContextimport reactor.core.publisher.Mono@Controller(&quot;/request&quot;)class MessageController &#123;    @Get(&quot;/hello-reactor&quot;)    Mono&lt;HttpResponse&lt;String&gt;&gt; helloReactor() &#123;        Mono.deferContextual(ctx -&gt; &#123; //             HttpRequest&lt;?&gt; request = ctx.get(ServerRequestContext.KEY) //             String name = request.parameters                    .getFirst(&quot;name&quot;)                    .orElse(&quot;Nobody&quot;)            Mono.just(HttpResponse.ok(&quot;Hello &quot; + name + &quot;!!&quot;)                    .header(&quot;X-My-Header&quot;, &quot;Foo&quot;))        &#125;)    &#125;&#125;\n\nResponse Status (响应状态)Micronaut Controller 默认使用 200 HTTP 状态进行响应\n如果 Controller 方法返回一个 HttpResponse, 使用 status() 方法来配置响应的状态码:\n@Get(value = &#x27;/http-response&#x27;, produces = MediaType.TEXT_PLAIN)HttpResponse httpResponse() &#123;    HttpResponse.status(HttpStatus.CREATED).body(&quot;success&quot;)&#125;\n\n还可以使用 @Status 注解:\n@Status(HttpStatus.CREATED)@Get(produces = MediaType.TEXT_PLAIN)String index() &#123; &quot;success&quot; &#125;\n\n或者使用一个 HttpStatus 作为方法返回值:\n@Get(&quot;/http-status&quot;)HttpStatus httpStatus() &#123;    HttpStatus.CREATED&#125;\n\nResponse Content-Type (响应的 Content-Type)Micronaut 的 Controller 的行为默认返回 applicatin/json 的 Content-Type\n可以使用 @Produces 注解指定返回的 Content-Type: @Produces(MediaType.TEXT_HTML)\n也可以使用 HTTP 方法注解的 produces 成员属性来指定返回的 Context-Type: @Get(value = &#39;/xml&#39;, produces = MediaType.TEXT_XML)\nAccepted Request Content-Type (可接受的请求 Content-Type)Micronaut 的 Controller 的行为默认消费 application/json 的 Content-Type\n可以使用 @Consumes 注解或者 HTTP 方法注解的 consumes 成员属性来指定要消费的 Content-Type\n@Consumes([MediaType.APPLICATION_FORM_URLENCODED, MediaType.APPLICATION_JSON])\n@Post(value = &quot;/member&quot;, consumes = MediaType.TEXT_PLAIN)\nCustoming Processed Content Types (自定义处理的 Content-Type)普通的 JSON 解析只有在 Content-Type 是 application/json 的时候才会发生\n其他 MediaTypeCodec 类也是一样的行为, 它们有预定义好的可以处理的 Content-Type\n为了扩展给定 codec 可以处理的媒体类型列表, 提供存储在 CodecConfiguration 的配置:\nmicronaut:    codec:        json:            additionalTypes:                - text/javascript\n\n当前支持的配置前缀是 json,json-stream,text-stream\nReactive HTTP Request Processing (响应式 HTTP 请求处理)Micronaut 建立在 Netty 上, Netty 被设计为围绕一个 Event loop 模型和非阻塞 I&#x2F;O\nMicronaut 在与请求线程(一个 Event Loop 线程)相同的线程中执行 @Controller Bean 中定义的代码\n如果你执行任何阻塞 I&#x2F;O 操作(例如和 Hibernate&#x2F;JPA&#x2F;JDBC 交互), 这就非常重要了, 你可以将这些操作卸载到一个独立的线程池, 这个线程池不会阻塞 Event loop\n比如下面的配置中配置了一个固定 75 个线程的 I&#x2F;O 线程池(类似传统阻塞 Server, 例如 Tomcat 将这个线程池用在 thread-pre-request 模型中):\nExample - Configuring the IO thread pool:\nmicronaut:    executors:        io:            type: fixed            nThreads: 75\n\n在 @Controller Bean 中有多个方式使用这个线程池, 最简单的方式是使用 @ExecuteOn 注解\n@ExecuteOn 注解可以声明在类级别和方法级别, 用来指明 Controller 的方法要运行在哪个配置的线程池上面:\nExample - Using @ExecuteOn\nimport io.micronaut.docs.http.server.reactive.PersonServiceimport io.micronaut.docs.ioc.beans.Personimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Getimport io.micronaut.scheduling.TaskExecutorsimport io.micronaut.scheduling.annotation.ExecuteOn@Controller(&quot;/executeOn/people&quot;)class PersonController &#123;    private final PersonService personService    PersonController(PersonService personService) &#123;        this.personService = personService    &#125;    @Get(&quot;/&#123;name&#125;&quot;)    @ExecuteOn(TaskExecutors.IO)    // The @ExecuteOn annotation is used to execute the operation on the I/O thread pool    Person byName(String name) &#123;        personService.findByName(name)    &#125;&#125;\n\n@ExecuteOn 注解的值可以是任何定义在 micronaut.executors 下命名的 executor\n一般而言, 对于数据库操作, 你希望配置一个与数据库连接池中指定的最大连接数相匹配的线程池\n除了使用 @ExecuteOn 注解的, 另一个选项是使用你选择的响应式库提供的功能\n响应式实现例如 Project Reactor 或 RxJava 提供了一个 subscribeOn 方法来让你可以修改使用哪个线程来执行用户代码:\nimport io.micronaut.docs.ioc.beans.Personimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Getimport io.micronaut.scheduling.TaskExecutorsimport jakarta.inject.Namedimport reactor.core.publisher.Monoimport reactor.core.scheduler.Schedulerimport reactor.core.scheduler.Schedulersimport java.util.concurrent.ExecutorService@Controller(&quot;/subscribeOn/people&quot;)class PersonController &#123;    private final Scheduler scheduler    private final PersonService personService    PersonController(        @Named(TaskExecutors.IO) ExecutorService executorService,   // The configured I/O executor service is injected        PersonService personService    ) &#123;        this.scheduler = Schedulers.fromExecutorService(executorService)        this.personService = personService    &#125;    @Get(&quot;/&#123;name&#125;&quot;)    Mono&lt;Person&gt; byName(String name) &#123;        return Mono.fromCallable(&#123;-&gt; personService.findByName(name)&#125;)   // The Mono::fromCallable method wraps the blocking operation                   .subscribeOn(scheduler)  // The Project Reactor subscribeOn method schedules the operation on the I/O thread poll    &#125;&#125;\n\nUsing the @Body Annotation (使用 @Body 注解)为了解析请求 body, 首先用 @Body 注解向 Micronaut 指示哪个参数来接收数据\nExample - Using the @Body annotation:\nimport io.micronaut.http.HttpResponseimport io.micronaut.http.MediaTypeimport io.micronaut.http.annotation.Bodyimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Postimport javax.validation.constraints.Size@Controller(&quot;/receive&quot;)class MessageController &#123;    @Post(value = &quot;/echo&quot;, consumes = MediaType.TEXT_PLAIN) // 1    String echo(@Size(max = 1024) @Body String text) &#123;      // 2        text    &#125;&#125;\n\n1 : @Post 注解和 text/plain 类型的 MediaType 一起使用 (默认是 applicatoin/json)\n2 : @Body 注解和 javax.validation.constraints.Size 一起使用, @Size 注解限制了 body 的最大大小为 1KB, 这个约束不会限制 Server 的 read&#x2F;buffered 数据的大小\n\nNote that reading the request body is done in a non-blocking manner in that the request contents are read as the data becomes available and accumulated into the String passed to the method.\n\n要注意, 读取请求 body 是以非阻塞方式完成的, 因为请求内容是在数据可用并累计到 传递给方法的字符串 中时读取的\n在 application.yml 中设置的 micronaut.server.maxRequestSize 限制了 Server read&#x2F;buffered 的数据大小, 默认最大请求大小是 10MB, @Size 不是这个这配置的代替\n\nRegardless of the limit, for a large amount of data accumulating the data into a String in-memory may lead to memory strain on the server.\n\n不管限制如何, 对于大量数据, 将数据累计到内存中的字符串可能会导致 Server 内存紧张\n一个更好做法是包含一个 Reactive 库到你的项目中, 例如 Reactor, RxJava, Akka, 这些库支持响应式流实现, 并在数据可用时将其流化\nExample - Using Reactive Streams to Read the request body:\nimport io.micronaut.http.HttpResponseimport io.micronaut.http.MediaTypeimport io.micronaut.http.annotation.Bodyimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Postimport javax.validation.constraints.Sizeimport org.reactivestrams.Publisherimport io.micronaut.core.async.annotation.SingleResultimport reactor.core.publisher.Flux@Controller(&quot;/receive&quot;)class MessageController &#123;    @Post(value = &quot;/echo-publisher&quot;, consumes = MediaType.TEXT_PLAIN)   // 1    @SingleResult    Publisher&lt;HttpResponse&lt;String&gt;&gt; echoFlow(@Body Publisher&lt;String&gt; text) &#123;    // 2        return Flux.from(text)                   .collect(    // 3                       &#123; x -&gt; new StringBuffer() &#125;,                       &#123; StringBuffer sb, String s -&gt; sb.append(s) &#125;                   )                   .map(                       &#123; buffer -&gt; HttpResponse.ok(buffer.toString()) &#125;                   )    &#125;&#125;\n\n1 : In this case the method is altered to receive and return an Publisher type\n2 : This example uses Project Reactor and returns a single item. Because of that the response type is annotated also with SingleResult. Micronaut only emits the response once the operation completes without blocking\n3 : The collect method is used to accumulate the date in this simulated example, but it could for example write the data to a logging service, database, etc. chunk by chunk\n\nBody arguments of types that do not require conversion cause Micronaut to skip decoding of the request.\n\n不需要转换的 Body 参数类型会导致 Micronaut 跳过对请求的解码\nReactive Responses (响应式响应)\nMicronaut supports returning common reactive types such as Mono (or Single Maybe Observable types from RxJava), an instance of Publisher or CompletableFuture from any controller method.\n\nMicronaut 支持返回普通响应式类型, 例如 Mono (或者 RxJava 中的 Single,Maybe,Observable), Controller 方法返回的一个 Publisher 或 CompletableFuture 实例\n要使用 Project Reactor 的 Flux 或 Mono, 要添加 Micronaut Reactor 依赖到项目中, 来添加必要的转换器\n要使用 RxJava 的 Flowable,Single,Maybe, 要添加 Micronaut RxJava 依赖到项目中, 来添加必要的转换器\n\nThe argument designated as the body of the request using the Body annotation can also be a reactive type or a CompletableFuture\n\n使用 @Body 注解指定为请求 body 的参数也可以是响应式类型或一个 CompletableFuture\n\nWhen returning a reactive type, Micronaut subscribes to the returned reactive type on the same thread as the request (a Netty Event Loop thread).\n\n当返回一个响应式类型时, Micronaut 在与请求相同的线程(一个 Netty Event Loop 线程)上订阅返回的响应类型\n\nIt is therefore important that if you perform any blocking operations, you offload those operations to an appropriately configured thread pool, for example using the Project Reactor or RxJava subscribeOn(..) facility or @ExecuteOn.\n\n因此, 重要的是, 如果你执行任何阻塞操作, 请将这些操作卸载到适当配置的线程池, 例如使用 Project Reactor 或 RxJava subscribeOn(..) 工具, 或者 @ExecuteOn\nTable - 一些常用返回类型和它们的处理 - Micronaut Response Types:\n\n\n\nType\nDescription\nExample Signature\n\n\n\nPublisher\nAny type that implements the Publisher interface\nPublisher&lt;String&gt; hello()\n\n\nCompletableFuture\nA Java CompletableFuture instance\nCompletableFuture&lt;String&gt; hello()\n\n\nHttpResponse\nAn HttpResponse and optional response body\nHttpResponse&lt;Publisher&lt;String&gt;&gt; hello()\n\n\nCharSequence\nAny implementation of CharSequence\nString hello()\n\n\nT\nAny simple POJO type\nBook show()\n\n\nJSON Binding with Jackson (使用 Jackson 进行 JSON 绑定)\nIn fact, the defaults in the Controller annotation specify that the controllers in Micronaut consume and produce JSON by default.\n\n实际上, @Controller 注解中默认指定 Micronaut 中的 Controller 默认消费和生成 JSON\n\nTo do so in a non-blocking manner, Micronaut builds on the Jackson Asynchronous JSON parsing API and Netty, such that the reading of incoming JSON is done in a non-blocking manner.\n\n为了以非阻塞的方式执行此操作, Micronaut 构建在 Jackson 异步 JSON 解析 API和 Netty 之上, 以便以非阻塞的方式读取传入的 JSON\nBinding using Reactive Frameworks (使用响应式框架进行绑定)从开发人员的角度来看, 你通常可以仅仅使用 POJO 和可选地使用一个响应式框架, 例如 RxJava 和 Project Reactor\nExample - A Controller that reads and saves incoming POJO in a non-blocking way from JSON - Using Reactive Streams to Read the JSON:\n@Controller(&quot;/people&quot;)class PersonController &#123;    Map&lt;String, Person&gt; inMemoryDatastore = new ConcurrentHashMap&lt;&gt;()    Publisher&lt;HttpResponse&lt;Person&gt;&gt; save(@Body Publisher&lt;Person&gt; person) &#123;  // 1        Mono.from(person)            .map(                &#123; p -&gt;                    inMemoryDatastore.put(p.getFirstName)   // 2                    HttpResponse.created(p)                 // 3                &#125;            )    &#125;&#125;\n\n1 : The method receives a Publisher which emits the POJO once the JSON has been read\n2 : The map method stores the instance in a Map\n3 : An HttpResponse is returned\nBinding Using CompletableFuture (使用 CompletableFuture 进行绑定)上面的例子可以使用 CompletableFuture API 来改写:\n@Controller(&quot;/people&quot;)class PersonController &#123;    Map&lt;String, Person&gt; inMemoryDatastore = new ConcurrentHashMap&lt;&gt;()    @Post(&quot;/saveFuture&quot;)    CompletableFuture&lt;HttpRespnose&lt;Person&gt;&gt; save(@Body CompletableFuture&lt;Person&gt; person) &#123;        person.thenApply(            &#123; p -&gt;                inMemoryDatastore.put(p.getFirstName(), p)                HttpResponse.created(p)            &#125;        )    &#125;&#125;\n\nBinding using POJOs (使用 POJO 进行绑定)Example - Binding JSON POJOs:\n@Controller(&quot;/people&quot;)class PersonController &#123;    Map&lt;String, Person&gt; inMemoryDatastore = new ConcurrentHashMap&lt;&gt;()    @Post    HttpResponse&lt;Person&gt; save(@Body Person person) &#123;        inMemoryDatastore.put(person.getFirstName(), person)        HttpResponse.created(person)    &#125;&#125;\n\n\nMicronaut only executes your method once the data has been read in a non-blocking manner.\n\nMicronaut 仅在以非阻塞方式读取数据后才执行你的方法\nJackson 生成的输出可以通过多种方式进行定制, 从定义 Jackson 模块到使用 Jackson 注释\nJackson Configuration (Jackson 配置)可以通过配置 JacksonConfiguration 类来配置 Jackson ObjectMapper\n所有的 Jackson 配置 key 都是以 jackson 开头:\n\n\n\nName\nType\nDescription\n\n\n\ndataFormat\nString\nThe data format\n\n\nlocale\nString\nUses Locale.forLanguageTag. Example: en-US\n\n\ntimeZone\nString\nUses TimeZone.getTimeZone. Example: PST\n\n\nserializationInclusion\nString\nOne of JsonInclude.Include. Example: ALWAYS\n\n\npropertyNamingStrategy\nString\nName of an instance of PropertyNamingStrategy. Example: SNAKE_CASE\n\n\ndefaultTyping\nString\nThe global for polymorphic(多态) type handling from enum ObjectMapper.DefaultTypeing. Example: NON_FINAL\n\n\nExample:\njackson:    serializationInclusion: ALWAYS\n\nFeatures (特性)所有的特性都可以通过配置它们的名称作为 key, 一个 boolean 值作为 value 来指明是否开启这个特性:\n\n\n\nName\nType\nMeaning\n\n\n\nserialization\nMap\nSerializationFeature\n\n\ndeserialization\nMap\nDeserializationFeature\n\n\nmapper\nMap\nMapperFeature\n\n\nparser\nMap\nJsonParser.Feature\n\n\ngenerator\nMap\nJsonGenerator.Feature\n\n\nfactory\nMap\nJsonFactory.Feature\n\n\nExample:\njackson:    serialization:        indentOutput: true        writeDatesAsTimestamps: false    deserialization:        useBigIntegerForInts: true        failOnUnknownProperties: false\n\nFurther customing JsonFactory (更深入自定义 JsonFactory )使用自定义的 JsonFactory Bean, 通过提供一个 BeanCreatedEventListener&lt;JsonFactory&gt; 来在启动时配置默认的 Bean\nSupport for @JsonView (@JsonView 的支持)如果在 application.yml 中配置了 jackson.json-view.enabled 为 true\n那么可以在 Controller 方法上使用 @JsonView 注解\nJackson 的 @JsonView 注解让你可以在每个响应上控制哪些属性要进行暴露\nBeans (Beans)除了通过配置的方式, 还可以通过注册 Bean 的方式来自定义 Jackson\n所有继承如下其中一个类的 Bean 都被注册到 object mapper 中:\n\nModule\nJsonDeserializer\nJsonSerializer\nKeyDeserializer\nBeanDeserializerModifier\nBeanSerializerModifier\n\nService Loader (Service 加载器)任何通过 service loader 加载的 module 都会被添加到默认 object mapper\nNumber Precision (数值精确性)在 JSON 解析时, 框架可能会转换任何输入的数据到一个中间对象模型中\n默认情况下, 这个模型使用 BigInteger,long,double 来表示数值\n例如, 即使反序列化的目标类型使用了 BigDecimal, 也可能会截断无法使用 double 表示的具有许多小数位的数字\n\nMetadata on the number of trailing zeroes (BigDecimal.precision()), e.g. the difference between 0.12 and 0.120, is also discarded\n\n关于尾部的0的元数据(BigDecimal.precision()), 例如 0.12 和 0.120 之间的区别也被丢弃\n如果你需要完整精确的数值类型, 使用如下配置:\njackson:    deserialization:        useBigIntegerForInts: true        useBigDecimalForFloats: true\n\nData Validation (数据校验)Micronaut 通过 micronaut-validation 依赖对 javax.validation 注解提供本地支持\nimplementation(&quot;io.micronaut:micronaut-validation&quot;)\n\n或者通过 micronaut-hibernate-validator 依赖提供完整的 JSR 380 实现:\nimplementation(&quot;io.micronaut.beanvalidation:micronaut-hibernate-validator&quot;)\n\n我们可以使用 javax.validation 注解校验参数并在类级别上使用 Validated 注解:\nimport io.micronaut.http.HttpResponseimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Getimport io.micronaut.validation.Validatedimport javax.validation.constraints.NotBlank@Validated  // Annotate controller with Validated@Controller(&quot;/email&quot;)class EmailController &#123;    @Get(&quot;/send&quot;)    HttpResponse send(@NotBlank String recipient,                      @NotBlank String subject) &#123;                          HttpResponse.ok(msg: &#x27;ok&#x27;)                      &#125;&#125;\n\n如果发生校验异常抛出了一个 javax.validation.ConstraintViolationException 异常, 默认使用内置的 io.micronaut.validation.exception.ConstraintExceptionHandler 来处理这个异常\n如果要使用你自己的 ExceptionHandler 来处理限制异常(constraint exception), 使用 @Replaces(ConstraintExceptionHandler.class) 带替换默认的异常处理器\n如果在 Controller 方法中使用 POJO 来接收参数, 那么像这样进行校验:\nimport io.micronaut.core.annotation.Introspectedimport javax.validation.constraints.NotBlank@Introspectedclass Email &#123;    @NotBlank   // 可以在你的 POJO 中使用 javax.validation 注解    String subject    @NotBlank   // 可以在你的 POJO 中使用 javax.validation 注解    String recipient&#125;\n\n然后在你的 Controller 上使用 @Validated 注解, 在绑定的 POJO 上使用 @Valid 注解:\nimport io.micronaut.http.HttpResponseimport io.micronaut.http.annotation.Bodyimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Postimport io.micronaut.validation.Validatedimport javax.validation.Valid@Validated // Annotate the controller with @Validated@Controller(&quot;/email&quot;)class EmailController &#123;    @Post(&quot;/send&quot;)    HttpResponse send(@Body @Valid Email email) &#123; // Annotate the POJO to validate with @Valid        HttpResponse.ok(msg: &quot;OK&quot;)    &#125;&#125;\n\nBean 注入支持通过 Hibernate Validator configuration 使用自定义限制(constraints)\nServing Static Resources (提供静态资源)静态资源解析是默认开启的. Micronaut 支持从 classpath 或 文件系统 中解析资源\nTable - Configuration Properties for StaticResourceConfiguration:\n\n\n\nProperty\nType\nDescription\n\n\n\nmicronaut.router.static-resources.*.enabled\nboolean\nSets whether this specific mapping is enabled. Default value true\n\n\nmicronaut.router.static-resources.*.paths\njava.util.List\nA list of paths either starting with classpath: or file:. You can serve files from anywhere on disk or the classpath. 例如 src/main/resources/public 对应 classpath:public\n\n\nmicronaut.router.static-resources.*.mapping\njava.lang.String\nThe path resources should be served from. Uses ant path matching. Default value /**\n\n\nError Handling (错误处理)Status Handlers (状态处理器)@Error 注解支持定义一个异常类或一个 HTTP 状态\n使用注解 @Error 修饰的方法必须定义在一个使用 @Controller 注解修饰的类中\n@Error 注解还支持指定 global 或 local, 默认是 local\n\nLocal error handlers only respond to exceptions thrown as a result of the route being matched to another method in the same controller.\n\n本地异常处理器只能处理同一个 Controller 中另外一个匹配路由结果的方法\n全局异常处理器可以响应所有抛出的异常\n在解析哪个处理器进行处理时, 优先使用本地异常处理器来处理异常\n在定义一个异常的异常处理器时, 你可以定义异常实例作为方法的参数进行传入, 然后可以删除掉注解中的异常属性\nLocal Error Handling (本地异常处理)Example - Local exception handler:\n@ErrorHttpResponse&lt;JsonError&gt; jsonError(HttpRequest request, JsonParseException e) &#123;    JsonError error = new JsonError(&quot;Invalid JSON: $e.message&quot;).link(Link.SELF, Link.of(request.uri))    HttpResponse.&lt;JsonError&gt;status(HttpStatus.BAD_REQUEST, &quot;Fix Your JSON&quot;).body(error)&#125;\n\nExample - Local status handler:\n@Error(status = HttpStatus.NOT_FOUND)HttpResponse&lt;JsonError&gt; notFound(HttpRequest request) &#123;    JsonError error = new JsonError(&quot;Person Not Found&quot;)    .link(Link.SELF, Link.of(request.uri))    HttpResponse.&lt;JsonError&gt;notFound().body(error)&#125;\n\nGlobal Error Handling (全局异常处理)Example - Global error handler:\n@Error(global = true)HttpResponse&lt;JsonError&gt; error(HttpRequest request, Throwable e) &#123;    JsonError error = new JsonError(&quot;Bad Things Happend: $e.message&quot;).link(Link.SELF, Link.of(request.uri))    HttpResponse.&lt;JsonError&gt;serverError().body(error)&#125;\n\nExample - Global status handler:\n@Error(status = HttpStatus.NOT_FOUND)HttpResponse&lt;JsonError&gt; notFound(HttpRequest request) &#123;    JsonError error = new JsonError(&quot;Person Not Found&quot;).link(Link.SELF, Link.of(request.uri))    HttpResponse.&lt;JsonError&gt;notFound().body(error)&#125;\n\nExceptionHandler (异常处理器)或者, 你可以实现一个 ExceptionHandler, 一个用于处理在执行 HTTP 请求期间发生的异常的通用钩子\nBuilt-In Exception Handlers (内置的异常处理器)Micronaut 内置了这些异常处理器:\n\n\n\nException\nHandler\n\n\n\njavax.validation.ConstraintViolationException\nConstraintExceptionHandler\n\n\nContentLengthExceededException\nContentLengthExceededHandler\n\n\nConversionErroException\nConversionErrorHandler\n\n\nDuplicateRoute\nDuplicateRouteHandler\n\n\nHttpStatusException\nhttpStatusHandler\n\n\ncom.fasterxml.jackson.core.JsonProcessingException\nJsonExceptionHandler\n\n\njava.net.URISyntaxException\nURISyntaxHandler\n\n\nUnsatisfiedArgumentException\nUnsatisfiedArgumentHandler\n\n\nUnsatisfiedRouteException\nUnsatisfiedRouteHandler\n\n\norg.grails.datasource.mapping.validation.ValidationException\nValidationExceptionHandler\n\n\nCustom Exception Handler (自定义异常处理器)假设你抛出一个自定义异常: class OutOfStockException extends RuntimeException &#123;&#125;\n要做到当抛出这个 OutOfStockException 时响应 400, 可以注册一个 ExceptionHandler:\n@Produces@Singleton@Requires(classes = [OutOfStockException, ExceptionHandler])class OutOfStockExceptionHandler implements ExceptionHandler&lt;OutOfStockException, HttpResponse&gt; &#123;    private final ErrorResponseProcessor&lt;?&gt; errorResponseProcessor    OutOfStockExceptionHandler(ErrorResponseProcessor&lt;?&gt; errorResponseProcessor) &#123;        this.errorResponseProcessor = errorResponseProcessor    &#125;    @Override    HttpResponse handle(HttpRequest request, OutOfStockException e) &#123;        errorResponseProcessor.processResponse(ErrorContext.builder(request)        .cause(e)        .errorMessage(&quot;No Stock available&quot;)        .build(), HttpResponse.badRequest())    &#125;&#125;\n\nError Formatting (错误格式)Micronaut 通过类型为 ErrorResponseProcessor 类型的 Bean 来提供错误响应体\n默认的响应体是 vnd.error, 可以通过实现 ErrorResponseProcessor 来控制响应\n\nIf customization of the response other than items related to the errors is desired, the exception handler that is handling the exception needs to be overridden.\n\n如果需要自定义响应而不是需要与错误相关的项目, 则需要覆盖处理异常的异常处理器\nAPI Versioning (API 版本控制)Micronaut 通过专用的 @Version 注解来支持 API 版本控制\nExample - Versioning an API:\nimport io.micronaut.core.version.annotation.Versionimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Get@Controller(&quot;/versioned&quot;)class VersionedController &#123;    @Version(&quot;1&quot;)    @Get(&quot;/hello&quot;)    String helloV1() &#123;        &quot;helloV1&quot;    &#125;    @Version(&quot;2&quot;)    @Get(&quot;/hello&quot;)    String helloV2() &#123;        &quot;helloV2&quot;    &#125;&#125;\n\n然后在 application.yml 中通过设置 micronaut.router.versioning.enabled 为 true 来开启版本控制:\nmicronaut:    router:        versioning:            enabled: true\n\n默认情况下 Micronaut 基于两种策略来解析版本值:\n\n基于一个名称为 X-API-VERSION 的 HTTP header\n基于一个名称为 api-version 的请求参数\n\n可以通过如下方式对这个策略进行配置:\nExample - Configuring Versioning:\nmicronaut:    router:        versioning:            enabled: true                   // Enables versioning            parameter:                enabled: false              // Enables or disables parameter-based versioning                names: &#x27;v,api-version&#x27;      // Specify the parameter names as a comma-separated list            header:                enabled: true               // Enables or disables header-based versioning                names:                      // Specify the header names as a list                    - &#x27;X-API-VERSION&#x27;                    - &#x27;Accept-Version&#x27;\n\n还可以通过实现 RequestVersionResolver 接口来接收一个 HttpRequest, 实现任何想要的策略\nDefault Version (默认版本)可以通过配置来提供一个默认版本:\nExample - Configuring Default Version:\nmicronaut:    router:        versioning:            enabled: true            default-version: 3\n\n如果满足以下的条件, 那么一个路由就是不匹配的:\n\n配置了默认的版本\n请求中没有版本值\n路由定义了一个版本\n路由版本没有匹配默认的版本\n\n如果传入的请求指定了一个版本, 那么默认的版本就不生效\nVersioning Client Requests (版本化的客户端请求)Micronaut 的响应式 HTTP 客户端还支持通过 @Version 注解对外向请求进行自动版本控制\n默认情况下 ,如果你使用 @Version 注解修饰一个客户端接口, 那 @Version 注解上的值将会被包含到 X-API-VERSION 请求头中\nExample:\nimport io.micronaut.core.version.annotation.Versionimport io.micronaut.http.annotation.Getimport io.micronaut.http.client.annotation.Clientimport reactor.core.publisher.Mono@Client(&quot;/hello&quot;)@Version(&quot;1&quot;)           // 1interface HelloClient &#123;    @Get(&quot;/greeting/&#123;name&#125;&quot;)    String sayHello(String name)    @Version(&quot;2&quot;)       // 2    @Get(&quot;/greeting/&#123;name&#125;&quot;)    Mono&lt;String&gt; sayHelloTwo(String name)&#125;\n\n1 : The @Version annotation can be used at the type level to specify the version to use for all methods\n2 : When defined at the method level it is used only for that method\n版本怎样在每个请求中发送的默认行为可以通过 DefaultClientVersioningConfiguration 进行配置:\nTable - Configuration Properties for DefaultClientVersioningConfiguration:\n\n\n\nProperty\nType\nDescription\n\n\n\nmicronaut.http.client.versioning.default.headers\njava.util.List\nThe list of request header names\n\n\nmicronaut.http.client.versioning.default.parameters\njava.util.list\nThe list of request query parameter names\n\n\n例如, 要使用 Accept-Version 作为请求头名称:\nExample - Configuring Client Versioning:\nmicronaut:    http:        client:            versioning:                default:                    headers:                        - &#x27;Accept-Version&#x27;                        - &#x27;X-API-VERSION&#x27;\n\ndefault key 关联到默认的配置\n可以指定 特定客户端 的配置, 通过使用传递给 @Client 注解的值(通常是 service ID):\nmicronaut:    http:        client:            versioning:                greeting-service:                    headers:                        - &#x27;Accept-Version&#x27;                        - &#x27;X-API-VERSION&#x27;\n\n上面的例子使用 greeting-service 来作为 key 名称, 这个名称可以用来配置一个使用 @Client(&#39;greeting-service&#39;) 修饰的客户端\nHandling Form Data (处理表单数据)为了使表单数据和 JSON 之间的自定义数据绑定模型保持一致, Micronaut 使用 Jackson 来实现来自表单提交的绑定数据\n这个做法的好处是同样的用于自定义 JSON 绑定的 Jackson 注解也可以用于表单提交\n实际上, 这意味着要绑定常规表单数据, 对先前 JSON 绑定代码的的唯一更改是更新所使用的 MediaType\nExample - Binding Form Data to POJOs:\n@Post(consumes = &#x27;application/form-data&#x27;)HttpResponse&lt;Person&gt; save(@Body Person person) &#123;&#125;\n\n为了避免 服务拒绝 攻击, 在绑定期间创建的集合类型数据和数组类型数据应该被限制, 通过在 application.yml 中配置 jackson.arraySizeThreshold\nExample - 绑定到方法的单个参数上; 还支持使用 Optional 包装参数:\n@Post(consumes = &#x27;application/form-data&#x27;)HttpResponse&lt;Person&gt; save(String firstName,                          String lastName,                          Optional&lt;Integer&gt; age) &#123;&#125;\n\nWriting Response Data (编写响应数据)\nMicronaut’s HTTP server supports writing chunks of response data by returning a Publisher that emits objects that can be encoded to the HTTP response.\n\nMicronaut 的 HTTP server 通过返回一个 发布者(Publisher) 来支持写入响应数据块, 该 发布者(Publisher) 输出可以编码为 HTTP 响应的对象\n下表总结了返回类型签名示例与 server 为了处理它们而表现出来的行为:\n\n\n\nReturn Type\nDescription\n\n\n\nPublisher&lt;String&gt;\nA Publisher that emits each chunk of content as a String\n\n\nFlux&lt;byte[]&gt;\nA Flux that emits each chunk of content as a byte[] without blocking\n\n\nFlux&lt;ByteBuf&gt;\nA Reactor Flux that emits each chunk as a Netty ByteBuf\n\n\nFlux&lt;Book&gt;\nWhen emitting a POJO, each emitted object is encoded as JSON by default without blocking\n\n\nFlowable&lt;byte[]&gt;\nA Flux that emits each chunk of content as a byte[] without blocking\n\n\nFlowable&lt;ByteBuf&gt;\nA Reactor Flux that emits each chunk as a Netty ByteBuf\n\n\nFlowable&lt;Book&gt;\nWhen emitting a POJO, each emitted object is encoded as JSON by default without blocking\n\n\n当返回一个响应式类型时, server 使用值为 chunked 的 Transfer-Encoding 并保持写入数据, 直到 Publisher 的 onComplete 方法被调用为止\nserver 从 Publisher 中请求一个 item, 进行写入(write), 然后再请求下一个 item, 以此来控制背压(back pressure)\n\nIt is up to the implementation of the Publisher to schedule any blocking I&#x2F;O work that may be done as a result of subscribing to the publisher.\n\n由 Publisher 的实现来调度所有阻塞 I&#x2F;O 工作, 这些阻塞工作可能作为一个订阅 Publisher 的结果来完成\nPerforming Blocking I&#x2F;O (运行阻塞 I&#x2F;O)在一些情况下, 你可能希望集成一个不支持 non-blocking I&#x2F;O 的库\nWritable (可写的)在这个场景下, 你可以在任何 Controller 方法中返回一个 io.micronaut.core.io.Writable 对象\nWritable 接口有多个签名来允许写入数据到传统的阻塞流, 例如 Writer 和 OutputStream\n当返回一个 Writable 时, 阻塞的 I&#x2F;O 操作被转移到 I&#x2F;O 线程池中, 所以 Netty 的 event loop 不会被阻塞\nExample - Performing Blocking I&#x2F;O With Writable:\nimport groovy.text.SimpleTemplateEngineimport groovy.text.Templateimport io.micronaut.core.io.Writableimport io.micronaut.http.MediaTypeimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Getimport io.micronaut.http.server.exceptions.HttpServerException@Controller(&quot;/template&quot;)class TemplateController &#123;    private final SimpleTemplateEngine templateEngine = new SimpleTemplateEngine()    private final Template template = initTemplate()    @Get(value = &#x27;/welcome&#x27;, produces = MediaType.TEXT_PLAIN)    Writable render() &#123;     // 2        &#123;            writer -&gt;            template.make(firstName: &quot;Fred&quot;, lastName: &quot;Flintstone&quot;)        // 3                    .writeTo(writer)        &#125;    &#125;    private Template initTemplate() &#123;        try &#123;            return templateEngine.createTemplate(&#x27;Dear $firstname $lastname. Nice to meet you.&#x27;)        &#125; catch (Exception e) &#123;            throw new HttpServerException(&#x27;Cannot create template&#x27;)        &#125;    &#125;&#125;\n\n2 : The Controller method returns a Writable\n3 : The returned function receives a Writer and calls writeTo on the template\nInputStream (输入流)另一个选项是返回一个输入流. 这在许多和其他暴露一个流的 API 交互的场景下是很有用的\nExample - Performing Blocking I&#x2F;O With InputStream:\n@Get(value = &#x27;/write&#x27;, produces = MediaType.TEXT_PLAIN)InputStream write() &#123;    byte[] bytes = &quot;test&quot;.getBytes(StandardCharsets.UTF_8)    new ByteArrayInputStream(bytes) // The input stream is returned and its contents will be the response body&#125;\n\n\nThe reading of the stream will be offloaded to the IO thread pool if the controller method is executed on the event loop.\n\n如果 Controller 方法是执行在 event loop 上时, 流的读取应该卸载到 IO 线程池中\n404 Responses (404 响应)在持久层找不到一个项目或类似的场景时, 返回一个 404 响应:\n@Controller(&quot;/books&quot;)class BooksController &#123;    @Get(&quot;/stock/&#123;isbn&#125;&quot;)    Map stock(String isbn) &#123;        null // Returning null triggers a 404(Not Found) response    &#125;    @Get(&quot;/maybestock/&#123;isbn&#125;&quot;)    Mono&lt;Map&gt; maybestock(String isbn) &#123;        Mono.empty() // Returning an empty Mono triggers a 404(Not Found) response    &#125;&#125;\n\n\nResponding with an empty Publisher or Flux results in an empty array being returned if the content type is JSON.\n\n如果 Content-Type 为 JSON, 使用空的 Publisher 或 Flux 进行响应会导致返回一个空的数组\nFile Uploads (文件上传)文件上传处理在 Micronaut 中有特殊的处理\n\nSupport is provided for streaming of uploads in a non-blocking manner through streaming uploads or completed uploads.\n\n通过流式上传或已完成的上传, 以非阻塞的方式提供对上传的流式支持\n为了从一个 multipart request 接收数据, 设置方法注解的 consumes 参数为 MULTIPART_FORM_DATA:\n@Post(consumes = MediaType.MULTIPART_FORM_DATA)HttpResponse upload() &#123;&#125;\n\nRoute Arguments (路由参数)方法参数类型决定了怎样接收一个文件\n\nData can be received a chunk at a time or when an upload is completed.\n\n可以一次接收一个数据块, 也可以在上传完成时接收数据\n如果路由参数名称不能或者不应该与请求中的 part 名称匹配的话, 添加 @Part 注解到参数中并指定请求中想要的名称\nChunk Data Types (块数据类型)\nPartData represents a chunk of data received in a multipart request.\n\nPartData 代表着 multipart request 中接收到的数据块\nPartData 接口方法转换数据为一个 byte[],InputStream,ByteBuffer\n只能从 PartData 中获取数据一次. 底层 buffer 已经被释放了, 导致之后的获取失败\n\nRoute arguments of type Publisher are treated as intended to receive a single file, and each chunk of the received file will be sent downstream.\n\nPublisher 类型的路由参数被视为旨在接收单个文件, 并且接收到的文件的每个块都将被发送到下游\n如果泛型类型不是 PartData, 将尝试使用 Micronaut 转换服务进行转换\n默认支持转换为 String 和 byte[]\n如果你需要关于一个上传的文件的元数据信息, 可以使用 StreamingFileUpload 类, 这个类继承了 Publisher, 拥有关于文件的信息, 例如 content type 和文件名称\nExample - Streaming file upload:\nimport io.micronaut.http.HttpResponseimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Postimport io.micronaut.http.multipart.StreamFileUploadimport org.reactivestreams.Publisherimport reactor.core.publisher.Monoimport static io.micronaut.http.HttpStatus.CONFLICTimport static io.micronaut.http.MediaType.MULTIPART_FORM_DATAimport static io.micronaut.http.MediaType.TEXT_PLAIN@Controller(&quot;/upload&quot;)class UploadController &#123;    @Post(value = &quot;/&quot;, consumes = MULTIPART_FORM_DATA, produces = TEXT_PLAIN)       // 1    Mono&lt;HttpResponse&lt;String&gt;&gt; upload(StreamingFileUpload file) &#123;       // 2        File tempFile = File.createTempFile(file.filename, &quot;temp&quot;)        Publisher&lt;Boolean&gt; uploadPublisher = file.transferTo(tempFile)      // 3        Mono.from(uploadPublisher)      // 4            .map(&#123; success -&gt;                if (success) &#123;                    HttpResponse.ok(&quot;Uploaded&quot;)                &#125; else &#123;                    HttpResponse.&lt;String&gt;status(CONFLICT).body(&quot;Upload Failed&quot;)                &#125;            &#125;)    &#125;&#125;\n\n1 : The method consumes MULTIPART_FORM_DATA\n2 : The method parameters match from attribute names. In this case file will match for example an &lt;input type=&quot;file&quot; name=&quot;file&quot;&gt;\n3 : The StreamingFileUpload.transferTo(File) method transfers the file to the server. The method returns a Publisher\n4 : The returned Mono subscribes to the Publisher and outputs a response once the the uplaod is complete, without blocking\n还可以传递一个 outupt stream 到 transferTo 方法\n\nThe reading of the file or stream will be offloaded to the IO thread pool to prevent the possibility of blocking the event loop\n\n文件或流的读取将会卸载到 IO 线程池, 避免可能的对 event loop 的阻塞\nExample - Streaming file upload:\n@Post(value = &quot;/&quot;, consumes = MULTIPART_FORM_DATA, produces = TEXT_PLAIN)    Mono&lt;HttpResponse&lt;String&gt;&gt; upload(StreamingFileUpload file) &#123;        OutputStream outputStream = new ByteArrayOutputStream()     // 3                Publisher&lt;Boolean&gt; uploadPublisher = file.transferTo(outputStream)      // 4        Mono.from(uploadPublisher)            .map(&#123; success -&gt;                if (success) &#123;                    HttpResponse.ok(&quot;Uploaded&quot;)                &#125; else &#123;                    HttpResponse.&lt;String&gt;status(CONFLICT).body(&quot;Upload Failed&quot;)                &#125;            &#125;)    &#125;\n\n3 : A stream is created to output the data to. In real world scenarios this would come from some other source\n4 : The StreamingFileUpload.transferTo(OutputStream) method transfer the file to the server. The method returns a Publisher\nWhole Data Types (完整数据类型)不是 Publisher 类型的路由参数导致路由执行延迟到上传结束\n将会尝试将接收到的数据转换为请求的类型\n默认支持转换为 String, byte[]\n除此之外, 如果一个支持文件的 media type 的 media type codec 已经注册, 那么文件可以转换为一个 POJO\n默认包含了一个 media type codec, 这个 codec 允许将 JSON 文件转换为 POJO\nExample - Receiving a byte array:\nimport io.micronaut.http.HttpResponseimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Postimport java.nio.file.Filesimport java.nio.file.Pathimport java.nio.file.Pathsimport static io.micronaut.http.MediaType.MULTIPART_FORM_DATAimport static io.micronaut.http.MediaType.TEXT_PLAIN@Controller(&quot;/upload&quot;)class BytesUploadController &#123;    @Post(value = &quot;/bytes&quot;, consumes = MULTIPART_FORM_DATA, produces = TEXT_PLAIN)    HttpResponse&lt;String&gt; uploadBytes(byte[] file, String fileName) &#123;        try &#123;            File tempFile = File.createTempFile(fileName, &quot;temp&quot;)            Path path = Paths.get(tempFile.absolutePath)            Files.write(path, file)            HttpResponse.ok(&quot;Uploaded&quot;)        &#125; catch (IOException e) &#123;            HttpResponse.badRequest(&quot;Upload Failed&quot;)        &#125;    &#125;&#125;\n\n如果你需要知道一个上传的文件的元数据信息, 使用 CompletedFileUpload 类拥有方法来获取文件的数据, 文件的信息, 例如 content type 和文件名\nExample - File upload with metadata:\n@Post(value = &quot;/bytes&quot;, consumes = MULTIPART_FORM_DATA, produces = TEXT_PLAIN)HttpResponse&lt;String&gt; uploadBytes(CompletedFileUpload file) &#123;        // 2    try &#123;        File tempFile = File.createTempFile(file.filename, &quot;temp&quot;)        Path path = Paths.get(tempFile.absolutePath)        Files.write(path, file.bytes)       // 3        HttpResponse.ok(&quot;Uploaded&quot;)    &#125; catch (IOException e) &#123;        HttpResponse.badRequest(&quot;Upload Failed&quot;)    &#125;&#125;\n\n2 : The method parameters match form attribute names. In this case the file will match for example an &lt;input type=&quot;file&quot; name=&quot;file&quot;&gt;\n3 : The CompletedFileUpload instance gives access to metadata about the upload as well as access to the file contents\n如果文件不会被读取, 那么文件对象上面的 discard 方法必须被调用, 以防止内存泄露\nMultiple Uploads (多文件上传)Different Names (不同的名字)如果一个 multipart request 有多个具有不同 part name 的上传, 在你的路由上创建一个参数来接收每个 part: HttpResponse upload(String title, String name)\n像上面例子中展示的, 一个路由方法签名期望接收两个 part, 一个名字为 title, 另一个名字为 name\nSame name (相同的名字)使用相同的 part name 来接收多个 part, 参数类型必须是 Publisher\n当以下方式之一使用时, Publisher 会为找到的具有指定名称的 part 输出一个 item\nPublisher 必须接受如下类型之一:\n\nStreamingFileUpload\nCompletedFileUpload\nCompletedPart for attributes\nAny POJO, assuming a media codec that supports the content type exists\nAnother Publiser that accepts one of the chunked data types described above\n\nExample:\nHttpResponse upload(Publisher&lt;StreamingFileUpload&gt; files)HttpResponse upload(Publisher&lt;CompletedFileUpload&gt; files)HttpResponse upload(Publisher&lt;MyObject&gt; files)HttpResponse upload(Publisher&lt;Publisher&lt;PartData&gt;&gt; files)HttpResponse upload(Publisher&lt;CompletedPart&gt; attributes)\n\nWhole Body Binding (完整 Body 绑定)\nWhen request part names aren’t known ahead of time, or to read the entire body, a special type can be used to indicate the entire body is desired.\n\n当一个 request part 的名字不能提前知道时, 或者需要读取整个 body, 就需要一个可以用来指向整个 body 的特殊类型\n如果一个路由的参数类型为 MultipartBody , 同时使用 @Body 注解, request 的每个 part 都会通过这个参数来输出\n一个 MultipartBody 是一个CompletedPart 的实例的 Publisher\nExample - Binding to the entire multipart body:\nimport io.micronaut.http.annotation.Bodyimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Postimport io.micronaut.http.multipart.CompletedFileUploadimport io.micronaut.http.multipart.CompletedPartimport io.micronaut.http.server.multipart.MultipartBodyimport org.reactivestreams.Subscriberimport org.reactivestreams.Subscriptionimport reactor.core.publisher.Monoimport static io.micronaut.http.MediaType.MULTIPART_FORM_DATAimport static io.micronaut.http.MediaType.TEXT_PLAIN@Controller(&#x27;/upload&#x27;)class WholeBodyUploadController &#123;    @Post(value = &#x27;/whole-body&#x27;, consumes = MULTIPART_FORM_DATA, produces = TEXT_PLAIN)    Mono&lt;String&gt; uploadBytes(@Body MultipartBody body) &#123;        Mono.&lt;String&gt;create(&#123; emitter -&gt;            body.subscribe(new Subscriber&lt;CompletedPart&gt;()&#123;                private Subscription s                @Override                void onSubscribe(Subscription s) &#123;                    this.s = s                    s.request(1)                &#125;                @Override                void onNext(CompletedPart completedPart) &#123;                    String partName = completedPart.name                    if (completedPart instanceof CompletedFileUpload) &#123;                        String originalFileName = completedPart.filename                    &#125;                &#125;                @Override                void onError(Throwable t) &#123; emitter.error(t) &#125;                @Override                void onComplete() &#123; emitter.success(&quot;Uploaded) &#125;            &#125;)        &#125;)    &#125;&#125;\n\nFile Transfers (文件传输)Micronaut 支持通过多种方式传递文件给客户端\nSending File Objects (发送文件对象)可以在 Controller 方法中返回一个 File 对象, 数据将会返回给客户端\n\nThe Content-Type header of file responses is calculated based on the name of the file.\n\n文件响应的 Content-Type header 是根据文件名计算的\n\nTo control either the media type of the file being sent, or to set the file to be downloaded (i.e. using the Content-Disposition header), instead construct a SystemFile with the file to use.\n\n要控制正在发送的文件的 media type, 或设置要下载的文件(即使用 Content-Disposition header), 请构造一个带有要使用的文件的 SystemFile\nExample - Sending a SystemFile:\n@Getpublic SystemFile download() &#123;    File file    return new SystemFile(file).attach(&quot;myfile.txt&quot;)    // or new SystemFile(file, MediaType.TEXT_HTML_PLAIN)&#125;\n\nSending an InputStream (发送一个 InputStream)在不能引用一个 File 对象的情况下, 例如 JAR 文件中的资源, Micronaut 支持传输 input streams\n为了在 Controller 方法中返回一个数据流, 构造一个 StreamedFile\nStreamedFile 的构造方法还支持接受一个 java.net.URL\nExample - Sending a StreamedFile:\n@Getpublic StreamedFile download() &#123;    InputStream inputStream    return new StreamedFile(inputStream, MediaType.TEXT_PLAIN_TYPE)    // An attach(String filename) method is also available to set the Content-Disposition&#125;\n\n如果要传输的文件没有修改过并且请求包含适当的 header , server 支持返回 304 (Not Modified) 响应\n除此, 如果客户端可以接受 encoded responses, Micronaut 在合适的情况下 encodes 文件\nEncoding 发生在文件是基于文本的并大于 1KB\n要 encoded 的数据的阈值是可以配置\n\nTo use a custom data source to send data through an input stream, construct a PipedInputStream and PipedOutputStream to write data from the output stream to the input. Make sure to do the work on a separate thread so the file can be returned immediately.\n\n要使用一个自定义数据源(data source)来从一个输入流中发送数据, 构造一个 PipedInputStream 和 PipedOutputStream 来从输出流写数据到输入流. 确保在另一个线程中完成这个工作, 以使文件可以马上被返回\nCache Configuration (缓存配置)默认地, 文件响应包含了缓存 headers\n下面的选项表明了 Cache-Control header 是怎样构建的\nTable - Configuration Properties for FileTypeHandlerConfiguration:\n\n\n\nProperty\nType\nDescription\n\n\n\nnetty.responses.file.cache-seconds\nint\nCache Seconds. Default value 60\n\n\nTable - Configuration Properties for CacheControlConfiguration:\n\n\n\nProperty\nType\nDescription\n\n\n\nnetty.responses.file.cache-control\nFileTypeHandlerConfiguration$CacheControlConfiguration\nSets the cache control configuration\n\n\nnetty.responses.file.cache-control.public\nboolean\nSets whether the cache control is public. Default value false\n\n\nHTTP Filters (HTTP 过滤器)Micronaut HTTP Server 支持以与 Java 应用程序中的 Servlet 过滤器相似(但响应式)的方式将过滤器应用于 请求&#x2F;响应 处理\n过滤器支持如下场景:\n\n装饰传入的 HttpRequest\n修改删除的 HttpResponse\n实现横切关注点(cross-cutting concerns), 例如安全(security), 追踪(tracing)\n\n对于一个 server 应用, 可以实现 HttpServerFilter 接口的 doFilter 方法\ndoFilter 方法接收 HttpRequest 和一个 ServerFilterChain 实例\n\nThe ServerFilterChain interface contains a resolved chain of filters where the final entry in the chain is the matched route. The ServerFilterChain.proceed(io.micronaut.http.HttpRequest) method resumes processing of the request.\n\nServerFilterChain 接口包含一个过滤器的解析链, 链的最后一个节点是匹配的路由. ServerFilterChain.proceed(io.micronaut.http.HttpRequest) 方法恢复对请求的处理\nproceed() 方法返回一个响应式流 Publisher 来输出要返回给客户端的响应\n\nImplementors of filters can subscribe to the Publisher and mutate the emitted MutableHttpResponse to modify the response prior to returning the response to the client.\n\n过滤器的实现者可以订阅 Publisher 并改变输出的 MutableHttpResponse 以在将响应返回给客户端之前修改响应\n过滤器执行在 event loop 中, 所以阻塞操作必须卸载到另外一个线程池中\nWriting a Filter (编写一个过滤器)不要在你的过滤器中阻塞底层的 Netty event loop\n相反, 一旦任何 I&#x2F;O 完成, 过滤器就应该继续执行\nExample - A TraceService Example using Reactive Streams:\nimport io.micronaut.http.HttpRequestimport org.slf4j.Loggerimport org.slf4j.LoggerFactoryimport jakarta.inject.Singletonimport reactor.core.publisher.Fluximport reactor.core.publisher.Monoimport reactor.core.scheduler.Schedulersimport java.util.concurrent.Callable@Singletonclass TraceService &#123;    private static final Logger LOG = LoggerFactory.getLogger(TraceService.class)    Flux&lt;Boolean&gt; trace(HttpRequest&lt;?&gt; request) &#123;        Mono.fromCallable(() -&gt; &#123;                               // 1            LOG.debug(&#x27;Tracing request: &#123;&#125;&#x27;, request.uri)            // trace logic here, potentially performing I/O     // 2            return true        &#125;)        .flux()        .subscribeOn(Schedulers.boundedElastic())               // 3    &#125;&#125;\n\n1 : The Mono type creates logic that executes potentially blocking operations to write the trace data from the request\n2 : Since this is just an example, the logic does nothing yet\n3 : The Schedulers.boundedElastic executes the logic\n然后将这个实现注入到过滤器中\nExample - HttpServerFilter:\nimport io.micronaut.http.HttpRequestimport io.micronaut.http.MutableHttpResponseimport io.micronaut.http.annotation.Filterimport io.micronaut.http.filter.HttpServerFilterimport io.micronaut.http.ServerFilterChainimport org.reactivestreams.Publisher@Filter(&#x27;/hello/*&#x27;)     // The Filter annotation defines the URI pattern(s) the filter matchesclass TraceFilter implements HttpServerFilter &#123;     // The class implements the HttpServerFilter interface    private final TraceService traceService    TraceFilter(TraceService traceService) &#123;        this.traceService = traceService    &#125;    @Override    Publisher&lt;MutableHttpResponse&lt;?&gt;&gt; doFilter(HttpRequest&lt;?&gt; request,                                               ServerFilterChain chain) &#123;        traceService.trace(request)                    .switchMap(&#123;chain.proceed(request)&#125;)                    // 2                    .doOnNext(&#123;it.headers.add(&quot;X-Trace-Enabled&quot;, &quot;true&quot;)&#125;)      // 3    &#125;&#125;\n\n2 : If the call succeeds, the filter resumes request processing using Project Reactor‘s switchMap method, which invokes the proceed method of the ServerFilterChain\n3 : Finally, the Project Reactor‘s doOnNext method adds a X-Trace-Enabled header to the response\n你可以使用任何支持 Reactive streams 规范的响应式框架\nFilter 通过设置 patternStyle 来使用不同风格的模式(pattern)来进行路径匹配\n默认情况下, Filter 使用 AntPathMatcher 进行路径匹配\n当使用 Ant 时, 映射匹配路径使用如下规则:\n\n? 匹配一个字符\n* 匹配 0 或 多个 字符\n** 匹配路径中的 0 或 多个 子目录\n\nTable - @Filter Annotation Path Matching:\n\n\n\nPattern\nExample Matched Paths\n\n\n\n/**\nany path\n\n\ncustomer/j?y\ncustomer&#x2F;joy, customer&#x2F;jay\n\n\ncustomer/*/id\ncustomer&#x2F;adam&#x2F;id, customer&#x2F;amy&#x2F;id\n\n\ncustomer/**\ncustomer&#x2F;adam, customer&#x2F;adam&#x2F;id, customer&#x2F;adam&#x2F;name\n\n\ncustomer/*/.html\ncustomer&#x2F;index.html, customer&#x2F;adam&#x2F;profile.html, customer&#x2F;adam&#x2F;job&#x2F;description.html\n\n\n另一个选择是基于正则表达式进行匹配. 要使用正则表达式, 设置 patternStyle = FilterPatternStyle.REGEX\npattern 属性接受一个正则表达式来匹配提供的 URLs (使用 Matcher#matches)\n更推荐使用 FilterPatternStyle.ANT 来进行模式匹配, 因为这比使用正则表达式性能更好. 只有在使用 Ant 的 pattern 无法满足需求时才使用正则表达式\n从 chain.proceed 返回的 Publisher 永远不要输出一个 error\n在上游过滤器输出一个 error 或者路由本身抛出异常的情况下, 应该输出 error responses 而不是 exception\n\nIn some cases it may be desirable to know the cause of the error response and for this purpose an attribute exists on the response if it was created as a result of an exception being emitted or thrown.\n\n在某些情况下, 可能需要知道导致 error response 的原因, 为此, 如果响应由于输出或抛出异常而建立的, 则在响应中包含一个属性\n\nThe original cause is stored as the attribute EXCEPTION.\n\n原始的原因作为 EXCEPTION attribute 保存\nHTTP Sessions (HTTP 会话)Micronaut 默认是一个无状态的 HTTP server\n根据你的应用要求, 你可能需要 HTTP Sessions 的概念\nMicronaut 包含一个 session 模块, 现在有两个实现:\n\n基于内存的 sessions : 如果你计划运行多个实例, 那么你应该将其与一个 sticky 的 session 代理结合使用\nRedis sessions : 使用 Redis 来存储 sessions, 使用非阻塞 I&#x2F;O 来读写 sessions 到 Redis\n\nEnabling Sessions (开启会话)开启基于内存的 sessions, 只需要添加 session 依赖:\nimplementation(&quot;io.micronaut:micronaut-session&quot;)\n\nRedis Sessions (Redis 会话)为了存储 Session 到 Redis 中, 使用 Micronaut Redis 模块\n添加 redis-lettuce 依赖到构建中:\n// build.gradlecompile &quot;io.micronaut:micronaut-session&quot;compile &quot;io.micronaut.redis:micronaut-redis-lettuce&quot;\n\n然后在 application.yml 中配置开启 Redis sessions:\nredis:    uri: redis://localhost:6379micronaut:    session:        http:            redis:                enabled: true\n\nConfiguring Session Resolution (配置会话解析)会话解析可以通过 HttpSessionConfiguration 进行配置\n默认情况下, sessions 使用 HttpSessionFilter 来进行解析\nHttpSessionFilter 通过 HTTP header(Authorization-Info 或 X-Auth-Token) 或者通过一个名字为 SESSION 的 Cookie 来寻找 session identifiers\n可以在 application.yml 配置文件中关闭 header 解析或 cookie 解析:\nmicronaut:    session:        http:            cookie: false            header: true\n\n还可以配置 header 和 cookie 的名字\nWorking with Sessions (使用会话)可以在 Controller 方法中通过类型为 Session 的参数获取一个 session:\nimport io.micronaut.session.Session        @Post(&quot;/cart/&#123;name&#125;&quot;)    Cart addItem(Session session, @NotBlank String name) &#123;        Cart cart = session.get(&quot;cart&quot;, Cart).orElseGet(&#123;            Cart newCart = new Cart()            session.put(&quot;cart&quot;, newCart)            newCart        &#125;)        cart.items &lt;&lt; name        cart    &#125;\n\n在上面的例子中, Session 被声明为一个必选参数, 所以为了执行 Controller 的这个方法, 一个 Session 将会被创建并保存到 SessionStore\n如果你不想创建非必要的 Session, 使用 @Nullable 注解修饰 Session 参数, 然后没有必要的话, 就不会创建并保存一个 session\nExample - Using @Nullable with Sessions:\n@Post(&quot;/cart/clear&quot;)void clearCart(@Nullable Session session) &#123;    session?.remove(ATTR_CART)&#125;\n\nSession Clients (会话客户端)如果客户端是 web 浏览器, 那么在 cookies 开启的情况下 sessions 是正常工作的\n但是, 对于编程式的 HTTP 客户端, 你需要在 HTTP 调用之间传播 session ID\n在上面的例子中, HTTP 客户端请求了 Controller 中的 addItem 方法后, 默认会接受到一个 AUTHORIZATION_INFO header:\nExample - Retrieving the AUTHORIZATION_INFO header:\nwhen: &quot;The shopping cart is retrieved&quot;HttpResponse&lt;Cart&gt; response = client.exchange(HttpRequest.GET(&#x27;/shopping/cart&#x27;), Cart).blockFirst()Cart cart = response.body()then: &quot;The shopping cart is present as well as a session id header&quot;response.header(HttpHeaders.AUTHORIZATION_INFO) != null     // The AUTHORIZATION_INFO header is present in the response\n\n然后在接下来的请求中重用已存在的 Session, 通过传递这个 AUTHORIZATION_INFO\nExample - Sending the AUTHORIZATION_INFO header:\nString sessionId = response.header(HttpHeaders.AUTHORIZATION_INFO)  // 从响应中获取 AUTHORIZATION_INFOresponse = client.exchange(HttpRequest.POST(&#x27;/shopping/cart/Apple&#x27;, &quot;&quot;)                                      .header(HttpHeaders.AUTHORIZATION_INFO, sessionId),       // 在发送请求时附加上 AUTHORIZATION_INFO session                           Cart)                 .blockFirst()cart = response.body()\n\nUsing @SessionValue (使用 @SessionValue 注解)可以使用 @SessionValue 注解代替显式地将 Session 注入到 Controller 的方法参数上\nExample - Using @SessionValue:\n@Get(&#x27;/cart&#x27;)@SessionValue(&#x27;cart&#x27;)   // 1Cart viewCart(@SessionValue @Nullable Cart cart) &#123;  // 2    cart ?: new Cart()&#125;\n\n1 : 作用于方法上的 @SessionValue 会将方法返回值保存到 Session 中. 注意, 作用于方法上时, 必须指定 attribute 的名称\n2 : @SessionValue 作用于 @Nullable 修饰的参数, 这会导致以非阻塞方式从 Session 中查找值并在存在时提供这个值. 在这个例子中, 没有指明 @SessionValue 的 value, 所以会使用参数名称来查找 attribute\nSession Events (会话事件)可以注册 ApplicationEventListener Beans 来监听 Session 相关的 位于io.micronaut.session.event包的 事件\nTable - Session Events:\n\n\n\nType\nDescription\n\n\n\nSessionCreatedEvent\nFired when a Session is created\n\n\nSessionDeletedEvent\nFired when a Session is deleted\n\n\nSessionExpiredEvent\nFired when a Session expires\n\n\nSessionDestroyedEvent\nParent of both SessionDeletedEvent and SessionExpiredEvent\n\n\nServer Sent Events (Server 发送事件)Micronaut HTTP server 支持使用 Event API 来输出 Server Sent Events (SSE)\n为了从 server 输出事件, 返回一个输出对象类型为 Event 的响应式流 Publisher\nPublisher 本身可以在一个后台任务中发送事件, 例如通过一个事件系统\n为了发送事件, 编写一个返回 Event 实例的 Publisher 的 Controller, 使用任何你喜欢的响应式库\nExample - Publishing Server Sent Events from a Controller:\nimport io.micronaut.http.MediaTypeimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Getimport io.micronaut.http.sse.Eventimport io.micronaut.scheduling.TaskExecutorsimport io.micronaut.scheduling.annotation.ExecuteOnimport org.reactivestreams.Publisherimport reactor.core.publisher.Flux@Controller(&quot;/headlines&quot;)class HeadlineController &#123;    @ExecuteOn(TaskExecutors.IO)    @Get(produces = MediaType.TEXT_EVENT_STREAM)    Publisher&lt;Event&lt;Headline&gt;&gt; index() &#123;    // 1        String[] versions = [&quot;1.0&quot;, &quot;2.0&quot;]  // 2        Flux.generate(                      // 3            () -&gt; 0,            (i, emitter) -&gt; &#123;                if (i &lt; versions.length) &#123;                    emitter.next(           // 4                        Event.of(new Headline(&quot;Micronaut $&#123;versions[i]&#125; Released&quot;, &quot;Come and get it&quot;))                    )                &#125; else &#123;                    emitter.complete()      // 5                &#125;                return i + 1            &#125;        )    &#125;&#125;\n\n1 : The controller method returns a Publisher of Event\n2 : A headline is emitted for each version of Micronaut\n3 : The Flux type’s generate method generates a Publisher. The generate method accepts an initial value and a lambda that accepts the value and a Emitter. Note that this example executes on the same thread as the controller action, but you could use subscribeOn or map an existing “hot” Flux\n4 : The Emitter interface onNext method emits objects of type Event. The Event.of(ET) factory method constructs the event.\n5 : The Emitter interface onComplete method indicates when to finish sending server sent events\n你很可能想要在一个不同的 executor 上调度 SSE 事件流, 上面的例子中使用了 @ExecutorOn 来在 I&#x2F;O executor 上执行流\n上面的例子发回一个类型为 text/event-stream 的响应, 每个 Event 输出转换为 JSON 的数据:\nExample - Server Sent Event Response Output:\ndata: &#123;&quot;title&quot;: &quot;Micronaut 1.0 Released&quot;, &quot;description&quot;: &quot;Come and get it&quot;&#125;data: &#123;&quot;title&quot;: &quot;Micronaut 2.0 Released&quot;, &quot;description&quot;: &quot;Come and get it&quot;&#125;\n\n\nYou can use the methods of the Event interface to customize the Server Sent Event data sent back, including associating event ids, comments, retry timeout, etc.\n\n你可以使用 Event 接口的方法来自定义 Server Sent Event 发回的数据, 包括关联的事件 id, comments, 重试时间等\nWebSocket Support (WebSocket 支持)Micronaut 专门支持创建 WebSocket 客户端和服务器\nio.micronaut.websocket.annotation 包中包含了定义客户端和服务端的注解\nUsing @ServerWebSocket(使用 @ServerWebSocket 注解)@ServerWebSocket 注解可以应用到任何类上, 而且应该映射到一个 WebSocket URI\nExample - WebSocket Chat:\nimport io.micronaut.websocket.WebSocketBroadcasterimport io.micronaut.websocket.WebSocketSessionimport io.micronaut.websocket.annotation.onCloseimport io.micronaut.websocket.annotation.OnMessageimport io.micronaut.websocket.annotation.OnOpenimport io.micronaut.websocket.annotation.ServerWebSocketimport java.util.function.Predicate@ServerWebSocket(&quot;/chat/&#123;topic&#125;/&#123;username&#125;&quot;)    // 1class ChatServerWebSocket &#123;    private final WebSocketBroadcaster broadcaster    ChatServerWebSocket(WebSocketBroadcaster broadcaster) &#123;        this.broadcaster = broadcaster    &#125;    @OnOpen     // 2    void onOpen(String topic, String username, WebSocketSession session) &#123;        String msg = &quot;[$username] Joined!&quot;        broadcaster.broadcastSync(msg, isValid(topic, session))    &#125;    @OnMessage // 3    void onMessage(String topic, String username, String message, WebSocketSession session) &#123;        String msg = &quot;[$username] $message&quot;        broadcaster.broadcastSync(msg, isValid(topic, session))     // 4    &#125;    @OnClose // 5    void onClose(String topic, String username, WebSocketSession session) &#123;        String msg = &quot;[$username] Disconnected!&quot;        broadcaster.broadcastSync(msg, isValid(topic, session))    &#125;    private Predicate&lt;WebSocketSession&gt; isValid(String topic, WebSocketSession session) &#123;        &#123; s -&gt; s != session &amp;&amp; topic.equalsIgnoreCase(s.uriVariables.get(&#x27;topic&#x27;, String, null)) &#125;    &#125;&#125;\n\n1 : The @ServerWebSocket annotation defines the path the WebSocket is mapped under. The URI can be a URI template\n2 : The @OnOpen annotation declares the method to invoke when the WebSocket is opened.\n3 : The @OnMessage annotation declares the method to invoke when a message is received\n4 : You can use a WebSocketBroadcaster to broadcast messages to every WebSocket session. You can filter which sessions to send to with a Predicate. Also, you could use the WebSocketSession instance to send a message to it with WebSocketSession::send\n5 : The @OnClose annotation declares the method to invoke when the WebSocket is closed\n查看 Micronaut Example 了解更详细的例子\n对于绑定, 每个 WebSocket 方法的方法参数可以是:\n\n一个来自 URI template 的变量 (在上面的例子中, topic 和 name 是 URI template 变量)\n一个 WebSocketSession 实例\n\nThe @OnClose Method (@OnClose 方法)@OnClose 方法可以可选地接收一个 CloseReason\n@OnClose 方法在 session 关闭之前被调用\nThe @OnMessage Method (@OnMessage 方法)@OnMessage 方法可以为 message body 定义一个参数. 这个参数可以是如下这些:\n\n一个 Netty 的 WebSocketFrame\n任何 Java 原始类型或简单类型 (例如 String). 事实上, 可以从 ByteBuf 转换的任何类型都行 (可以注册额外的 TypeConverter Beans 来支持一个自定义类型)\n一个 byte[], 一个 ByteBuf, 或者一个 Java NIO ByteBuffer\n一个 POJO, 在这个场景, 默认使用 JsonMediaTypeCodec 解码为 JSON. 你可以注册一个自定义的 codec, 并使用 @Consumes 注解来定义 Handler 的 content type\n一个 WebSocketPongMessage. 这是一个特别的例子: 方法不会接收原始信息, 而是处理作为对发送到客户端的 ping 的回复而到达的 WebSocket pong\n\nThe @OnError Method (@OnError 方法)一个使用 @OnError 注解修饰的方法可以用来实现自定义 error 处理\n@OnError 方法可以定义一个参数来接收要处理的异常类型\n如果没有 @OnError 处理方法, 且发生了一个没有覆盖到的异常, WebSocket 将会自动关闭\nNon-Blocking Message Handling (非阻塞式信息处理)上面例子中使用的 WebSocketBroadcaster 接口的 broadcastSync 的方法将会阻塞知道 broadcast 完成\n一个存在于 WebSocketSession 类似的 sendSync 方法通过阻塞的方式发送一个消息到单个接受者\n可以通过声明每个 WebSocket 处理方法返回 Publisher 或 Futuer 来实现非阻塞 WebSocket server\nExample - WebSocket Chat:\n@OnMessagePublisher&lt;Message&gt; onMessage(String topic,                             String username,                             Message message,                             WebSocketSession session) &#123;    String text = &quot;[$username] $message.text&quot;    Message message = new Message(text)    broadcaster.broadcast(newMessage, isValid(topic, session))&#125;\n\n上面的例子使用 boradcaset 方法, 这个方法创建一个 Publisher 实例并返回值给 Micronaut\nMicronaut 基于 Publisher 接口来异步地发送信息\n相似的方法 send 通过 Micronaut 返回值异步地发送单个信息\n为了在 Micronaut 注解的处理方法之外异步地发送信息, 可以使用分别位于 WebSocketBroadcaster 和 WebSocketSession 的 broadcastAsync 和 sendAsync 方法\n要进行阻塞式发送, 使用 broadcasterSync 和 sendSync 方法\n@ServerWebSocket and Scopes (@ServerWebSocket 和作用域)默认地, @ServerWebSocket 实例在所有的 WebSocket 连接中共享\n因此需要额外小心地同步本地状态来避免线程安全问题\n如果要每个连接一个实例, 使用 @Prototype 注解进行修饰. 这使得你可以从 @OnOpen 方法中获取 WebSocketSession 并将这个 session 赋值到 @ServerWebSocket 实例的字段中\nSharing Sessions with the HTTP Session (和 HTTP session 共享 session)\nThe WebSocketSession is by default backed by an in-memory map.\n\nWebSocketSession 默认由内存映射支持\n如果你添加了 session 模块, 你可以在 HTTP server 和 WebSocket server 之间共享 sessions\n当 sessions 通过持久化存储来实现时 (例如 Redis), 在每个信息被处理之后, session 会被更新到支持其的存储上\nUsing the CLI (使用 CLI)如果你使用 Application Type Micronaut Application 来创建项目, 那么可以使用 create-websocket-server 命令来创建一个使用 @ServerWebSocket 注解修饰的类:\nmn create-websocket-server MyChat| Rendered template WebSocketServer.java to destination src/main/java/example/MyChatServer.java\n\nConnection Timeouts (连接超时)默认情况下, Micronaut 在五分钟后使没有任何活动的空闲连接超时\n正常情况下这不会是一个问题, 因为浏览器会自动重新连接 WebSocket sessions\n你可以通过设置 micronaut.server.idle-timeout 来控制这个行为:\nExample - Setting the Connection Timeout for the Server:\nmicronaut:    server:        idle-timeout: 30m # 30 分钟\n\n如果设置为负数, 则代表不会超时\n如果使用 Micronaut 的 WebSocket 客户端, 可以这样设置客户端上的超时时间:\nExample - Setting the Connection Timeout for the Client:\nmicronaut:    http:        client:            read-idle-timeout: 30m # 30 分钟\n\nUsing @ClientWebSocket (使用 @ClientWebSocket)\nThe @ClientWebSocket annotation can be used with the WebSocketClient interface to define WebSocket clients.\n\n通过 WebSocketClient 接口配合 @ClientWebSocket 注解来定义 WebSocket 客户端\n可以使用 @Client 注解来注入一个 WebSocketClient 引用:\n@Inject@Client(&quot;http://localhost:8080&quot;)WebSocketClient webSocketClient\n\n这可以让你的 WebSocket 客户端使用相同的服务发现和负载均衡特性\n一旦你有了一个 WebSocketClient 接口的引用, 你可以使用 connect 方法来获取一个连接的 bean 实例, 这个 bean 实例使用 @ClientWebSocket 注解修饰\nExample - WebSocket Chat:\nimport io.micronaut.http.HttpRequestimport io.micronaut.websocket.WebSocketSessionimport io.micronaut.websocket.annotation.ClientWebSocketimport io.micronaut.websocket.annotation.OnMessageimport io.micronaut.websocket.annotation.OnOpenimport org.reactivestreams.Publisherimport reactor.core.publisher.Monoimport java.util.concurrent.ConcurrentLinkedQueueimport java.util.concurrent.Futureimport io.micronaut.core.async.annotation.SingleResult@ClientWebSocket(&quot;/chat/&#123;topic&#125;/&#123;username&#125;&quot;)    // 1abstract class ChatClientWebSocket implements AutoCloseable &#123;   // 2    private WebSocketSession session    private HttpRequest request    private String topic    private String username    private Collection&lt;String&gt; replies = new ConcurrentLinkedQueue&lt;&gt;()    @OnOpen    void onOpen(String topic,                String username,                WebSocketSession session,                HttpRequest request) &#123;      // 3        this.topic = topic        this.username = username        this.session = session        this.request = request    &#125;    String getTopic() &#123; topic &#125;    String getUsername() &#123; username &#125;    Collection&lt;String&gt; getReplies() &#123; replies &#125;    WebSocketSession getSession() &#123; session &#125;    HttpRequest getRequest &#123; request &#125;    @OnMessage    void onMessage(String message) &#123; replies &lt;&lt; message&#125;    // 4&#125;\n\n1 : The class is abstract (more on that later) and is annotated with @ClientWebSocket\n2 : The client must implements AutoCloseable and you should ensure that the connection is closed at some point\n3 : You can use the same annotations as on the server, in this case @OnOpen to obtain a reference to the underlying session\n4 : @OnMessage annotation defines the method that receives responses from the server\n你还可以定义抽象方法, 这些方法以 send 或 broadcast 开头, 这些方法将会在编译时自动被实现:\nExample - WebSocket Send Methods:\npublic abstract void send(String message)\n\n通过返回 void 来告诉 Micronaut 这个方法是阻塞式发送的\n同时, 可以定义方法返回 Future 或 Publisher:\npublic abstract reactor.core.publisher.Mono&lt;String&gt; send(String message)\n\npublic abstract java.util.concurrent.Future&lt;String&gt; sendAsync(String message)\n\n一旦你定义了一个客户端类, 你可以连接到客户端 Socket, 并开始发送信息:\nExample - Connecting a Client WebSocket:\nChatClientWebSocket chatClient = webSocketClient.connect(ChatClientWebSocket.class, &quot;/chat/football/fred&quot;).blockFirst();chatClient.send(&quot;Hello World!&quot;);\n\nUsing the CLI (使用 CLI)如果你使用 Micronaut CLI 来创建你的项目, 并且是默认 (service) profile, 你可以使用 create-websocket-client 命令来通过 WebSocketClient 创建一个抽象类:\nmn create-websocket-client MyChat| Rendered template WebSocketClient.java to destination src/main/java/example/MyChatClient.java\n\nHTTP&#x2F;2 Support (HTTP&#x2F;2 支持)从 Micronaut 2.x 开始, Micronaut 的基于 Netty 的 HTTP server 可以通过配置来支持 HTTP&#x2F;2\nConfiguring the Server for HTTP&#x2F;2 (为 HTTP&#x2F;2 配置 Server)第一步是配置支持的 HTTP 版本\nExample - Enabling HTTP&#x2F;2 Support:\nmicronaut:    server:        http-version: 2.0\n\n通过这个配置, Micronaut 开启了对 h2c (HTTP&#x2F;2 over cleartext) 协议的支持, 这对于开发来说很好\n因为浏览器不支持 h2c 但一般来说支持 HTTP&#x2F;2 over TLS (h2 协议), 推荐在生产环境开启 HTTPS 支持\n对于开发来说, 可以这样进行配置\nExample - Enabling h2 Protocol Support:\nmicronaut:    server:        http-version: 2.0        ssl:            enabled: true            buildSelfSigned: true\n\n对于生产环境, 参考 configuring HTTPS 章节\n如果你的开发环境使用的是 JDK8, 或许需要提高对 OpenSSL 的支持, 定义以下对 Netty Tomcat Native 的支持:\nruntimeOnly(&quot;io.netty:netty-tcnative:2.0.46.Final&quot;)runtimeOnly(&quot;io.netty:netty-tcnative-boringssl-static:2.0.46.Final&quot;)\n\n除此之外还要配置一个适合的你电脑系统架构的本地库依赖:\nruntimeOnly &quot;io.netty:netty-tcnative-boringssl-static:2.0.46.Final:$&#123;Os.isFamily(Os.FAMILY_MAC) ? (Os.isArch(&quot;aarch64&quot;) ? &quot;osx-aarch_64&quot; : &quot;osx-x86_64&quot;) : &#x27;linux-x86_64&#x27;&#125;&quot;\n\nHTTP&#x2F;2 Server Push Support (HTTP&#x2F;2 Server 推送支持)Micronaut 3.2 开始支持 server push\nserver push 允许单个请求触发多个响应. 最常使用在基于浏览器的资源 (browser based resources)\n目标是减少客户端的等待时间, 因为客户端不需要再手动请求资源\n一个新的接口 PushCapableHttpRequest 被创建来支持这个特性\n简单地添加一个 PushCapableHttpRequest 参数到 Controller 的方法上, 然后使用 PushCapableHttpRequest 上的 API 来触发额外请求\nPushCapableHttpRequest 继承了 HttpRequest, 所以没有必要在 Controller 方法参数上同时包含这两种类型的参数\n在触发额外请求前, 要调用 isServerPushSupported() 方法来确保这个特性是可用的\n一旦知道这个特性是可用的, 使用 serverPush(HttpRequest) 方法来触发额外请求 (additional requests). 例如, request.serverPush(HttpRequest.GET(&#39;/static/style.css&#39;))\nServer Events (Server 事件)HTTP Server 输出一系列事件, 这些事件都定义在 io.micronaut.runtime.server.event 包中, 可以为这些事件编写监听器\nTable - Server Events:\n\n\n\nEvent\nDescription\n\n\n\nServerStartupEvent\nEmitted when the server completes startup\n\n\nServerShutdownEvent\nEmitted when the server shuts down\n\n\nServerReadyEvent\nEmitted after all ServerStartupEvent listeners have been invoked and exposes the EmbeddedServerInstance\n\n\nServerStoppedEvent\nEmitted after all ServerShutdownEvent listeners have been invoked and exposes the EmbeddedServerInstance\n\n\n在 ServerStartupEvent 中进行重要的工作将会显著增加启动时间\nExample - Listening for Server Startup Events - 通过实现 ApplicationEventListener 的方式进行监听:\nimport io.micronaut.context.event.ApplicationEventListener@Singletonpublic class StartupListener implements ApplicationEventListener&lt;ServerStartupEvent&gt; &#123;    @Override    public void onApplicationEvent(ServerStartupEvent event) &#123;&#125;&#125;\n\nExample - 在任意 Bean 的方法上使用 @EventListener 注解监听 server 启动事件:\nimport io.micronaut.runtime.event.annotation.EventListenerimport io.micronaut.runtime.server.event.ServerStartupEventimport javax.inject.Singleton@Singletonpublic class MyBean &#123;    @EventListener    public void onStartup(ServerStartupEvent event) &#123;&#125;&#125;\n\nConfiguring the HTTP Server (配置 HTTP Server)HTTP Server 有很多的配置选项\n这些配置选项定义在 NettyHttpServerConfiguration 配置类中, 这个类继承了 HttpServerConfiguration\nExample - Configuring HTTP server settings:\nmicronaut:    server:        maxRequestSize: 1MB        host: localhost             // 1        netty:            maxHeaderSize: 500KB    // 2            worker:                threads: 8          // 3            childOptions:                autoRead: true      // 4\n\n1 : By default Micronaut binds to all network interfaces. Use localhost to bind only to loopback network interface\n2 : Maximum size for headers\n3 : Number of Netty worker threads\n4 : Auto read requset body\nNettyHttpServerConfiguration\n中的 getter 方法指示了配置属性\n例如, getMaxHeaderSize() 方法 对应 micronaut.server.netty.max-header-size Property\nUsing Native Transports (使用原生传输)\nThe native Netty transports add features specific to a particular platform, generate less garbage, and generally improve performance when compared to the NIO-based transport.\n\n原生 Netty 传输为特定平台添加特定功能, 与基于 NIO 的传输相比产生更少的垃圾, 并且总体上提高了性能\n为了开启原生传输, 首先需要添加依赖:\nx86 平台的 MacOS: runtimeOnly(&quot;io.netty:netty-transport-native-kqueue::osx-x86_64&quot;)\nM1 平台的 MacOS: runtimeOnly(&quot;io.netty:netty-transport-native-kqueue::osx-aarch_64&quot;)\nx86 平台的 Linux: runtimeOnly(&quot;io.netty:netty-transport-native-kqueue::linux-x86_64&quot;)\nARM64 平台的 Linux: runtimeOnly(&quot;io.netty:netty-transport-native-kqueue::linux-aarch_64&quot;)\n然后配置默认的 event loop group 倾向于原生传输:\nExample - Configuring The Default Event Loop to Prefer Native Transports:\nmicronaut:    netty:        event-loops:            default:                prefer-native-transport: true\n\n\nNetty enables simplistic sampling resource leak detection which reports there is a leak or not, at the cost of small overhead. You can disable it or enable more advanced detection by setting property netty.resource-leak-detector-level to one of: SIMPLE (default), DISABLED, PARANOID or ADVANCED\n\nNetty 支持简单的资源采样泄露检测, 它报告是否存在泄露, 当开销很小. 你可以通过将属性 netty.resource-leak-detector-level 设置为以下之一来禁用它或启用更高级的检测: SIMPLE(默认), DISABLED, PARANOID(偏执), ADVANCED(高级)\nConfiguring Server Thread Pools (配置 Server 线程池)HTTP Server 是构建在 Netty 上的, Netty 被设计作为一个使用 event loop 模型的非阻塞 I&#x2F;O 工具\nNetty worker event loop 使用名称为 default 的 event loop group. 可以通过 micronaut.netty.event-loops.default 属性来进行配置\n\nThe event loop configuration under micronaut.server.netty.worker is only used if the event-loop-group is set to a name which doesn’t correspond to any micronaut.netty.event-loops configuration.\n\n仅当 event-loop-group 设置为一个名称, 这个名称与任何 micronaut.netty.event-loops 配置都不匹配时, 才会使用 micronaut.server.netty.worker 下的 event loop 配置\n\nThis behavior is deprecated and will be removed in a future version.\n\n这个行为已经是过时的, 将会在将来的版本中移除\n\nUse micronaut.netty.event-loops.* for any event loop group configuration beyond setting the name through event-loop-group.\n\n为所有 event loop group 配置使用 micronaut.netty.event-loops.*, 而不是通过 event-loop-group 设置名称\n\nThis does not apply to the parent event loop configuration (micronaut.server.netty.parent).\n\n这不适用于父 event loop 配置 (micronaut.server.netty.parent)\nTable - Configuration Properties for Worker:\n\n\n\nProperty\nType\nDescription\n\n\n\nmicronaut.server.netty.worker\nNettyHttpServerConfiguration$Worker\nSets the worker event loop configuration\n\n\nmicronaut.server.netty.worker.event-loop-group\njava.lang.Strng\nSets the name to use\n\n\nmicronaut.server.netty.worker.threads\nint\nSets the number of threads for the event loop group\n\n\nmicronaut.server.netty.worker.io-ratio\njava.lang.Integer\nSets the I&#x2F;O ratio\n\n\nmicronaut.server.netty.worker.executor\njava.lang.String\nSets the name of the executor\n\n\nmicronaut.server.netty.worker.prefer-native-transport\nboolean\nSet whether to prefer the native transport if available\n\n\nmicronaut.server.netty.worker.shutdown-quiet-period\njava.time.Duration\nSet the shutdown quiet period\n\n\nmicronaut.server.netty.worker.shutdown-timeout\njava.time.Duration\nSet the shutdown timeout (must be &gt;&#x3D; shutdownQuietPeriod)\n\n\n\nThe parent event loop can be configured with micronaut.server.netty.parent with the same configuration options.\n\n父 event loop 可以通过相同的配置选项来使用 micronuat.server.netty.parent 进行配置\nExample - Using a different event loop for the server - server 可以配置为使用一个不同命名的 worker event loop:\nmicronaut:    server:        netty:            worker:                event-loop-group: other    netty:        event-loops:            other:                num-threads: 10\n\n线程数量的默认值是系统属性 io.netty.eventLoopThreads 的值, 如果这个系统属性没有配置, 则线程数量为可用处理器数量的两倍\nTable - Configuration Properties for DefaultEventLoopGroupConfiguration:\nProperty | Type | Descriptionmicronaut.netty.event-loops.*.num-threads | int |micronaut.netty.event-loops.*.io-ratio | java.lang.Integer |micronaut.netty.event-loops.*.prefer-native-transport | boolean |micronaut.netty.event-loops.*.executor | java.lang.String |micronaut.netty.event-loops.*.shutdown-quiet-period | java.time.Duration |micronaut.netty.event-loops.*.shutdown-timeout | java.time.Duration |\nBlocking Operations (阻塞式操作)当处理阻塞式操作, Micronaut 默认将这个操作转移到一个无边界的缓存的 I&#x2F;O 线程池\n你可以使用名称为 io 的 ExecutorConfiguration 配置这个 I&#x2F;O 线程池:\nExample - Configuring the Server I&#x2F;O Thread Pool:\nmicronaut:    executors:        io:            type: fixed            nThreads: 75\n\nConfiguring the Netty Pipeline (配置 Netty 管道)可以通过编写一个 Bean Event Listener 监听 ChannelPipelineCustomizer 的创建来自定义 Netty pipeline\nNetty HTTP server 和 client 实现了这个接口, 允许你自定义 Netty ChannelPipeline 并添加额外的处理器\nChannelPipelineCustomizer 接口为 Micronaut 注册的多个处理器的名称定义常量 (constants)\n下面的代码示例展示了注册包含了额外 Netty 处理器来处理请求响应日志的 Logbook 库\nExample - Customizing the Netty pipeline for Logbook:\nimport io.micronaut.context.annotation.Requiresimport io.micronaut.context.event.BeanCreatedEventimport io.micronaut.context.event.BeanCreatedEventListenerimport io.micronaut.http.netty.channel.ChannelPipelineCustomizerimport io.netty.channel.ChannelPipelineimport org.zalando.logbook.Logbookimport org.zalando.logbook.netty.LogbookClientHandlerimport org.zalando.logbook.netty.LogbookServerHandlerimport jakarta.inject.Singleton@Requires(beans = LogBook.class)@Singletonclass LogbookPipelineCustomizer implements BeanCreatedEventListener&lt;ChannelPipelineCustomizer&gt; &#123;    private final Logbook logbook    LogbookPipelineCustomizer(Logbook logbook) &#123;        this.logbook = logbook    &#125;    @Override    ChannelPipelineCustomizer onCreated(BeanCreatedEvent&lt;ChannelPipelineCustomizer&gt; event) &#123;        ChannelPipelineCustomizer customizer = event.bean        if (customizer.serverChannel) &#123;            customizer.doOnConnect( &#123; ChannelPipeline pipeline -&gt;                pipeline.addAfter(                        ChannelPipelineCustomizer.HANDLER_HTTP_SERVER_CODEC,                        &quot;logbook&quot;,                        new LogbookServerHandler(logbook)                )                return pipeline            &#125;)        &#125; else &#123;            customizer.doOnConnect(&#123; ChannelPipeline pipeline -&gt;                pipeline.addAfter(                        ChannelPipelineCustomizer.HANDLER_HTTP_CLIENT_CODEC,                        &quot;logbook&quot;,                        new LogbookClientHandler(logbook)                )                return pipeline            &#125;)        &#125;        return customizer    &#125;&#125;\n\nConfiguring CORS (配置跨域请求)Micronaut 开箱支持 CORS (Cross Origin Resource Sharing)\n默认情况下, CORS 请求是被拒绝的\n为了开启 CORS 请求, 修改你的配置:\nExample - CORS Configuration:\nmicronaut:    server:        cors:            enabled: true\n\n\nBy only enabling CORS processing, a “wide open” strategy is adopted that allows requests from any origin.\n\n仅通过启用 CORS 处理, 就采用了一个允许来自任何来源的请求的 “广泛开发” 策略\n为了修改所有来源或一个特定来源的设置, 通过提供一个或多个 configurations 来改变配置\n通过提供任何配置, 默认的 wide open 配置就不会被配置\nExample - CORS Configurations:\nmicronaut:    server:        cors:            configurations:                all:                    ...                web:                    ...                mobile:                    ...\n\n在上面的例子中, 提供了三个配置\n它们的名字 (all, web, mobile) 并不重要, 且在 Micronaut 内部没有意义\n\nThey are there purely to be able to easily recognize the intended user of the configuration.\n\n它们的存在纯粹是为了能够轻松识别配置的预期用户\n同样的配置属性可以应用于每个配置, 参考 CorsOriginConfiguration 获取可以定义的属性\n\nThe values of each configuration supplied will default to the default values of the corresponding fields.\n\n提供的每个配置的值将默认为 相应字段的 默认值\n\nWhen a CORS request is made, configurations are searched for allowed origins that match exactly or match the request origin through a regular expression.\n\n当发生一个 CORS 请求时, 将在配置中搜索与请求源完全匹配或通过正则表达式匹配的允许源\nAllowed Origins (允许的源)在一个给定的配置中允许任何源, 不要包含 allowedOrigins key 到你的配置中\n对于多个有效的源, 设置配置的 allowedOrigins key 为一个字符串列表. 每个值可以是一个静态值 (http://www.foo.com) 或者一个正则表达式 (^http(|s)://www\\.google\\.com$)\n正则表达式将被传递给 Pattern#compile 并使用 Matcher#matches 来和请求的源进行匹配\nExample - CORS Configuration:\nmicronaut:    server:        cors:            enabled: true            configurations:                web:                    allowedOrigins:                        - http://foo.com                        - ^http(|s):\\/\\/www\\.google\\.com$\n\nAllowed Methods (允许的方法)在一个给定的配置中允许任何请求方法, 不要包含 allowedMethods key 到你的配置中\n为了允许多个方法, 设置配置的 allowedMethods key 为一个字符串列表\nExample - CORS Configuration:\nmicronaut:    server:        cors:            enabled: true            configurations:                web:                    allowedMethods:                        - POST                        - PUT\n\nAllowed Headers (允许的请求头)在一个给定的配置中允许任何请求头, 不要包含 allowedHeaders key 到你的配置中\n为了允许多个请求头, 设置配置的 allowedHeaders key 为一个字符串列表\nExample - CORS Configuration:\nmicronaut:    server:        cors:            enabled: true            configurations:                web:                    allowedHeaders:                        - Content-Type                        - Authorization\n\nExposed Headers (暴露的请求头)\nTo configure the headers that are sent in the response to a CORS request through the Access-Control-Expose-Headers header, include a list of strings for the exposedHeaders key in your configuration. None are exposed by default.\n\n如果要配置 在对 CORS 请求的响应中 包含在 Access-Control-Expose-Headers header 的 header, 在你的配置中使用 exposedHeaders key 来包含一个字符串列表. 默认是不暴露任何 headers\nExample - CORS Configuration:\nmicronaut:    server:        cors:            enabled: true            configurations:                web:                    exposedHeaders:                        - Content-Type                        - Authorization\n\nAllow Credentials (允许 Credentials)Credentials : 证书\n对于 CORS 请求, 默认是允许 Credentials 的\n通过设置 allowCredentials 为 false 来不允许:\nmicronaut:    server:        cors:            enabled: true            configurations:                web:                    allowedCredentials: false\n\nMax age (最大 age)可以缓存的预检的请求默认最大 age 为 30 分钟\n通过指定秒数来修改这个行为:\nmicronaut:    server:        cors:            enabled: true            configurations:                web:                    maxAge: 3600 # 1 小时\n\nMultiple Header Values (多个 Header 值)默认情况下, 当一个 header 有多个值时, 多个 header 会被发送, 每个 header 有一个值\n可以设置配置选项修改这个行为来发送一个使用逗号分隔的列表作为值的 header\nmicronaut:    server:        cors:            single-header: true\n\nSecuring the Server with HTTPS (使用 HTTPS 保护 Server)Micronaut 提供开箱即用的 HTTPS 支持\n默认情况下, HTTPS 没有开启, 所有接受的请求都是使用 HTTP\n为了开启 HTTPS 支持, 要修改你的配置\nExample - HTTPS Configuration:\nmicronaut:    server:        ssl:            enabled: true            buildSelfSigned: true   // Micronaut will create a self-signed certificate\n\n默认情况下, 使用 HTTPS 支持的 Micronaut 在端口 8443 启动, 可以通过属性 micronaut.server.ssl.port 来修改这个端口号\nUsing a valid x509 certificate (使用一个有效的 x509 证书)可以配置 Micronaut 使用一个已存在的有效 x509 证书\n例如, 通过 Let’s Encrypt 创建了一个证书. 你将会需要 server.crt 和 server.key 文件, 然后将它们转换为一个 PKCS #12 文件\nopenssl pkcs12 -export \\-in server.crt \\ # 1-inkey server.key \\ # 2-out server.p12 \\ # 3-name someAlias \\ # 4-chain -CAfile ca.crt -caname root\n\n1 : The original server.crt file\n2 : The original server.key file\n3 : The server.p12 file to create\n4 : The alias for the certificate\n在创建 server.p12 文件时, 有必要定义一个密码, 稍后在 Micronaut 中使用证书时将会需要这个密码\n然后, 修改你的配置:\nExample - HTTPS Configuration:\nmicronaut:    ssl:        enabled: true        keyStore:            path: classpath:server.p12  # 1            password: mypassword        # 2            type: PKCS12\n\n1 : The p12 file. It can also be referenced as file:/path/to/the/file\n2 : The password defined during the export\n通过这个配置, 在 Micronaut 启动之后并访问 https://localhost:8443, 还是可以看到浏览器的 warning, 但是如果我们检查证书, 我们可以确认是我们刚刚创建的证书\n我们可以通过添加一个域名别名到 /etc/hosts 文件中来测试这个证书对于浏览器是有效的:\ncat /etc/hosts...127.0.0.1 my-domain.org...\n\nUsing Java Keystore (使用 Java Keystore (JKS))不推荐使用这个类型的证书, 因为格式是专有的\n推荐使用 PKCS12 格式\n但是 Micronaut 也支持 JKS\n例子省略\nRefreshing&#x2F;Reloading HTTPS Certificates (刷新&#x2F;重载 HTTPS 证书)在 HTTPS 证书过期后保持证书最新是一个挑战\n一个好的解决方案是 Automated Certificate Management Environment (ACME)\nMicronaut ACME Module 支持自动刷新来自证书颁发机构的证书\n如果不能使用证书认证机构, 那么你需要从硬盘中更新证书, 然后你要 使用 Micronaut 支持的 包含你的 HTTPS 配置定义的 keys的 Application Events 来触发一个 RefreshEvent\nMicronaut 将会从硬盘重新加载证书并应用新的配置到 server 中\n你还可以使用 Refresh Management Endpoint, 但这只在证书的硬盘物理地址改变的时候使用\n如下例子将会从硬盘上重新加载之前列出的 HTTPS 配置, 并将其应用到进来的请求\n这个代码应该运行在一个调度任务中, 来在证书改变时拉取证书\nExample - Manually Refreshing HTTPS configuration:\nimport jakarta.inject.Injectimport io.micronaut.context.evetn.ApplicationEventPublisherimport io.micronaut.runtime.context.scope.refresh.RefreshEvent@Inject ApplicationEventPublisher&lt;RefreshEvent&gt; eventPublishereventPublisher.publishEvent(new RefreshEvent(    Collections.singletonMap(&quot;micronaut.ssl&quot;, &quot;*&quot;)))\n\nEnabling HTTP and HTTPS (同时开启 HTTP 和 HTTPS)Micronaut 支持同时绑定 HTTP 和 HTTPS\n要开启多协议支持, 修改你的配置:\nExample - Dual Protocol Configuration:\nmicronaut:    server:        ssl:            enabled: true               # You must configure SSL for HTTPS to work            build-self-singed: true        dual-protocol: true             # Enabling both HTTP and HTTPS is an opt-in feature - setting the `dualProtocol` flag enbales it. By default Micronaut only enables one\n\n还可以自动将所有 HTTP 请求重定向到 HTTPS\nExample - Enable HTTP to HTTPS Redirects:\nmicronaut:    server:        ssl:            enabled: true            build-self-singed: true        dual-protocol: true        http-to-https-redirect: true\n\nEnabling Access Logger (开启访问日志)可以为 HTTP server 开启一个访问日志器 (access logger)\n在 application.yml 中开启和配置 access logger:\nmicronaut:    server:        netty:            access-logger:                enabled: true                   # Enables the access logger                logger-name: my-access-logger   # A logger name, optional, default is `HTTP_ACCESS_LOGGER`                log-format: common              # A log format, optional, default is Common Log Format\n\nFiltering access logs (过滤访问日志)如果你不想要记录证书路径访问日志, 你可以在配置中声明一个正则表达式过滤器:\nExample - Filtering the access logs:\nmicronaut:    server:        netty:            access-logger:                enabled: true                logger-name: my-access-logger                log-format: common                exclusions:                    - /health                    - /path/.+\n\nLogback Configuration (Logback 配置)除了开启 access logger, 你还必须为 指定的logger名称 或 默认的logger名称 添加一个 logger\n例如在 LogBack 中使用默认 logger名称:\nExample - Logback configuration:\n&lt;appender    name=&quot;httpAccessLogAppender&quot;    class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;    &lt;append&gt;true&lt;/append&gt;    &lt;file&gt;log/http-access.log&lt;/file&gt;    &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;        &lt;fileNamePattern&gt;            log/http-access-%d&#123;yyyy-MM-dd&#125;.log        &lt;/fileNamePattern&gt;        &lt;maxHistory&gt;            7        &lt;/maxHistory&gt;    &lt;/rollingPolicy&gt;    &lt;encoder&gt;        &lt;charset&gt;UTF-8&lt;/charset&gt;        &lt;pattern&gt;$msg%n&lt;/pattern&gt;    &lt;/encoder&gt;    &lt;immediateFlush&gt;true&lt;/immediateFlush&gt;&lt;/appender&gt;&lt;logger name=&quot;HTTP_ACCESS_LOGGER&quot; additivity=&quot;false&quot; level=&quot;info&quot;&gt;    &lt;appender-ref ref=&quot;httpAccessLogAppender&quot; /&gt;&lt;/logger&gt;\n\nLog Format (日志格式)语法是基于 Apache httpd log format 的\n可以使用如下通用语法模板的别名:\n\ncommon  : Common Log Format (CLF) 的 %h %l %u %t &quot;%r&quot; %s %b\ncombined : Combined Log Format 的 %h %l %u %t &quot;%r&quot; %s %b &quot;%&#123;Referer&#125;i&quot; &quot;%&#123;User-Agent&#125;i&quot;\n\nCLF 例子: 127.0.0.1 - frank [10/Oct/2000:13:55:36 -0700] &quot;GET /apache_pb.gif HTTP/1.0&quot; 200 2326\nCombined Log Format 例子: 127.0.0.1 - frank [10/Oct/2000:13:55:36 -0700] &quot;GET /apache_pb.gif HTTP/1.0&quot; 200 2326 &quot;http://www.example.com/start.html&quot; &quot;Mozilla/4.08 [en] (Win98; I ;Nav)&quot;\nStarting Secondary Servers (开启二级服务)Micronaut 支持使用 NettyEmbeddedServerFactory 接口编程式创建额外的 Netty servers\n这在你需要通过不同的端口开放不同的 servers, 并具有可能不相同的配置 (HTTPS, 线程资源等等)\n下面的例子中展示了怎样定义一个 Factory Bean 使用一个编程式创建的配置来开启一个额外的 server:\nExample - Programmatically creating Secondary servers:\nimport io.micronaut.context.annotation.Beanimport io.micronaut.context.annotation.Contextimport io.micronaut.context.annotation.Factoryimport io.micronaut.context.annotation.Requiresimport io.micronaut.context.env.Environmentimport io.micronaut.core.util.StringUtilsimport io.micronaut.discovery.ServiceInstanceListimport io.micronaut.discovery.StaticServiceInstanceListimport io.micronaut.http.server.netty.NettyEmbeddedServerimport io.micronaut.http.server.netty.NettyEmbeddedServerFactoryimport io.micronaut.http.server.netty.configuration.NettyHttpServerConfigurationimport io.micronaut.http.ssl.ServerSslConfigurationimport jakarta.inject.Named@Factoryclass SecondaryNettyServer &#123;    static final String SERVER_ID = &#x27;another&#x27;    @Named(SERVER_ID)    @Context    @Bean(preDestory = &quot;stop&quot;)  // 2    @Requires(beans = Environment.class)    NettyEmbeddedServer nettyEmbeddedServer(NettyEmbeddedServerFactory serverFactory) &#123;     // 3        def configuration = new NettyHttpServerConfiguration()  // 4        def sslConfiguration = new ServerSslConfiguration()     // 5        sslConfiguration.setBuildSelfSigned(true)        sslConfiguration.enabled = true        sslConfiguration.prot = -1 // random port        // configure server programmatically        final NettyEmbeddedServer embeddedServer = serverFactory.build(configuration, sslConfiguration)     // 6        embeddedServer.start()  // 7        return embeddedServer   // 8    &#125;    @Bean   // 9    ServiceInstanceList serviceInstanceList(        @Named(SERVER_ID) NettyEmbeddedServer nettyEmbeddedServer    ) &#123;        return new StaticServiceInstanceList(            SERVER_ID,            [ nettyEmbeddedServer.URI ]        )    &#125;&#125;\n\n2 : Define a @Context scoped bean using the server name and including preDestroy=&quot;stop&quot; to ensure the server is shutdown when the context is closed\n3 : Ineject the NettyEmbeddedServerFactory into a Factory Bean\n4 : Programmatically craete the NettyHttpServerConfiguration\n5 : Optionally create the ServerSslConfiguration\n6 : Use the build method to build the server instance\n7 : Start the server with the start methdo\n8 : Return the server instance as a managed bean\n9 : Optionally define an instance of ServiceInstanceList if you wish to inject HTTP Clients by the server name\n有了这个类, 当 ApplicationContext 启动时, server 也会使用适当的配置启动\n因为在第 9 步中定义了 ServiceInstanceList, 你可以在你的测试中注入一个 client 来测试这个二级 server:\nExample - Inject the server or client:\n@Client(path = &quot;/&quot;, id = SecondaryNettyServer.SERVER_ID)    // 1@InjectHttpClient httpClient@Named(SecondaryNettyServer.SERVER_ID)                      // 2EmbeddedServer embeddedServer\n\n1 : Use the server name to inject a client by ID\n2 : Use the @Named annotation as a qualifier to inject the embedded server instance\nServer Side View Rendering (服务器端视图渲染)参考 Micronaut Views 文档\nOpenAPI &#x2F; Swagger Support (OpenAPI &#x2F; Swagger 支持)参考文档\nGraphQL Support (GraphQL 支持)参考文档\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Micronaut 中文文档 The HTTP Client","url":"/micronaut/micronaut-the-http-client/","content":"\n\n\nThe HTTP Client\nUsing the Low-Level HTTP Client (使用低级别 HTTP Client)\nSending your first HTTP request (发送你的第一个 HTTP 请求)\nObtaining a HttpClient (获取一个 HttpClient)\nPerforming an HTTP GET (执行一个 HTTP GET 请求)\nDebugging &#x2F; Tracing the HTTP Client (调试 &#x2F; 跟踪 HTTP Client)\nClient Specific Debugging &#x2F; Tracing (指定的 Client 调试 &#x2F; 跟踪)\nCustomizing the HTTP Request (自定义 HTTP 请求)\nReading JSON Response (读取 JSON 响应)\nDecoding Other Content Types (解码其他 Content Types)\nReceiving the Full HTTP Response (接受完整的 HTTP 响应)\n\n\nPosting a Request Body (发送一个请求体)\nSending JSON (发送 JSON)\nUsing a URI Template (使用一个 URI 模板)\nSending Form Data (发送表单数据)\n\n\nMultipart Client Uploads (Multipart 客户端上传)\nStreaming JSON over HTTP (HTTP 上的流式 JSON)\nConfiguring HTTP clients (配置 HTTP clients)\nGlobal Configuration for All Clients (用于全部 Clients 的全局配置)\nClient Specific Configuration (特定 Client 配置)\nUsing HTTP Client Connection Pooling (使用 HTTP Client 连接池化)\nConfiguring Event Loop Groups (配置 Event Loop 组)\n\n\nError Responses (错误响应)\nBind Errors (绑定错误)\n\n\nProxying Requests with ProxyHttpClient (使用 ProxyingHttpClient 来代理请求)\nDeclarative HTTP Clients with @Client (使用 @Client 的声明式 HTTP 客户端)\nCustomizing Parameters Binding (自定义参数绑定)\nQuery values formatting (请求值格式化)\nType-Based Binding Parameters (基于类型的参数绑定)\nCustom Binding (自定义绑定)\nBinding By Annotation (通过注解进行绑定)\nBinding By Type (通过类型进行绑定)\n\n\nBinding On Method (在方法上进行绑定)\n\n\n\n\nStreaming with @Client (使用 @Client 进行流式处理)\nStreaming JSON with @Client (使用 @Client 进行 JSON 流式处理)\nStreaming Clients and Response Types (流式客户端和响应类型)\nStreaming Clients and Read Timeout (流式客户端和读取超时)\nStreaming Server Sent Events (流式服务发送事件)\n\n\nError Response (错误响应)\nCustomizing Request Headers (自定义请求头)\nPopulating Headers Using Configuration (使用配置来填充请求头)\nPopulating Headers using a Client Filter (使用一个客户端过滤器来填充请求头)\n\n\nCustomizing Jackson Settings (自定义 Jackson 设置)\nRetry and Circuit Breaker (重试与断路器)\nClient Fallbacks (客户端降级)\nNetflix Hystrix Support (网飞 Hystrix 的支持)\nUsing the @HystrixCommand Annotation (使用 @HystrixCommand 注解)\nEnabling Hystrix Stream and Dashboard (开启 Hystrix 流和仪表板)\n\n\n\n\nHTTP Clients Filters (HTTP 客户端过滤器)\nInjecting Another Client into a HttpClientFilter (注入另一个客户端到过滤器中)\nFilter Matching By Annotation (通过注解来进行过滤匹配)\n\n\nHTTP&#x2F;2 Support (HTTP&#x2F;2 的支持)\nHTTP Client Sample (HTTP 客户端例子)\n\n\n\n\n\nThe HTTP Client声明:\n\n本文由本人翻译自官方文档\n部分内容可能会有修改或删减, 一切以官方文档为准.\n本文翻译时 Micronaut 版本为 3.4.2\n\n如果你使用 Micronaut CLI 创建项目, 那么 http-client 依赖已经默认包含在你的项目中了\n\nClient communication between Microservices is a critical component of any Microservice architecture\n\n微服务客户端之间的通信是任何微服务架构的关键组件\n\nWith that in mind, Micronaut includes an HTTP client that has both a low-level API and a higher-level AOP-driven API.\n\n考虑到这一点, Micronaut 包含了一个 HTTP client, 这个 client 同时具有低级别 API 和高级的 AOP 驱动的 API\n无论你是否选择使用 Micronaut 的 HTTP server, 你都可能希望在你的应用程序中使用 Micronaut HTTP client, 因为它是一个功能丰富的客户端实现\n要使用这个 HTTP client, 在你的构建中添加 http-client 依赖:\nimplementation(&quot;io.micronaut:micronaut-http-client&quot;)\n\nUsing the Low-Level HTTP Client (使用低级别 HTTP Client)HttpClient 接口构成了低级别 API 的基础\nHttpClient 接口声明了一些方法来帮助简化 HTTP 请求的执行和接收响应\nHttpClient 接口中的大多数方法都返回响应式流 Publisher 实例, 这并不总是最有用的接口\nMicronaut 的 Reactor HTTP Client 依赖提供了一个名称为 ReactorHttpClient 的子接口. 这个子接口提供了 HttpClient 接口的变体来返回 Project Reactor,Flux 类型\nSending your first HTTP request (发送你的第一个 HTTP 请求)Obtaining a HttpClient (获取一个 HttpClient)有多个方法可以获取一个 HttpClient 引用. 最常用的方法是使用 @Client 注解\nExample - Injecting an HTTP client:\n@Inject@Client(&quot;https://api.twitter.com/1.1&quot;)HttpClient httpClient;@Inject@Client(&quot;$&#123;myapp.api.twitter.uri&#125;&quot;)HttpClient httpClient\n\n@Client 是一个自定义作用域, 管理了 HttpClient 实例的创建, 并确保 HttpClient 在应用关闭时停止\n@Client 注解的值可以是如下之一:\n\n一个绝对 URI, 例如 https://api.twitter.com/1.1\n一个相对 URI, 指向当前 server, 在测试的时候很有用\n一个服务标识(service identifier), 使用服务发现\n\n另一种创建方式是使用 HttpClient 的静态方法 create(), 这个方式需要你自己保证 client 在应用关闭时停止, 且不会为 client 创建进行依赖注入\nPerforming an HTTP GET (执行一个 HTTP GET 请求)使用 HttpClient 时, 通常有两个可用的方法\n第一个是 retrive() 方法, 这个方法执行一个 HTTP 请求, 并将 body 以你请求的任何类型 (默认为字符串) 作为 Publisher 返回\n\nPerform an HTTP request for the given request object emitting the full HTTP response from returned Publisher and converting the response body to the specified type.\n\nretrieve 方法接收一个 HttpRequest 或者一个 String URI 来指向你想要请求的端点\nExample - Using retrieve - Use retrieve to execute an HTTP GET and receive the response body as a String:\nwhen:String uri = UriBuilder.of(&quot;/hello/&#123;name&#125;&quot;)                       .expand(name: &quot;John&quot;)then:&quot;/hello/John&quot; == uriwhen:String result = client.toBlocking()                      .retrieve(uri)then:&quot;Hello John&quot; == result\n\n在上面的例子中, 调用了 toBlocking() 方法来返回一个阻塞版本的 client, 在生产代码中, 不要使用这个阻塞的 client, 应该直接使用非阻塞请求\nExample - Using the HTTP client without blocking:\nimport static io.micronaut.http.HttpRequest.GET@Get(&#x27;/hello/&#123;name&#125;&#x27;)@SingleResultPublisher&lt;String&gt; hello(String name) &#123;                      // 1    Mono.from(httpClient.retrieve(GET(&quot;/hello/&#123;name&#125;&quot;)))    // 2&#125;\n\n1 : The hello method returns a Mono which may or may not emit an item. If an item is not emitted, a 404 is returned\n2 : The retrieve method is called which returns a Flux. This has a firstElement method that returns the first emitted item or nothing\n通过使用 Reactor (或者 RxJava), 你可以很容易且高效地组合多个非阻塞 HTTP client 请求\nDebugging &#x2F; Tracing the HTTP Client (调试 &#x2F; 跟踪 HTTP Client)要调试从 HTTP client 发送和接收的请求, 可以在 logback.xml 中开启日志追踪:\n// logback.xml&lt;logger name=&quot;io.micronaut.http.client&quot; level=&quot;TRACE&quot;/&gt;\n\nClient Specific Debugging &#x2F; Tracing (指定的 Client 调试 &#x2F; 跟踪)要开启指定 client 的日志, 你可以为所有的 HTTP client 配置默认 logger\n也可以使用 Client-Specific Configuration 为不同 client 定义不同的 logger\nmicronaut:    http:        client:            logger-name: mylogger        services:            otherClient:                logger-name: other.client\n\n在 logback.xml 中开启日志记录:\n&lt;logger name=&quot;mylogger&quot; level=&quot;DEBUG&quot;/&gt;&lt;logger name=&quot;other.client&quot; level=&quot;TRACE&quot;/&gt;\n\nCustomizing the HTTP Request (自定义 HTTP 请求)HttpRequest 接口的静态方法 GET 构建了一个 MutableHttpRequest 实例\nMutableHttpRequest 实例是可以修改该的, 例如可以添加 headers, 自定义请求 body:\nExample - Passing an HttpRequest to retrieve:\nimport static io.micronaut.http.HttpRequest.GETFlux&lt;String&gt; response = Flux.from(    client.retrieve(        GET(&quot;/hello/John&quot;).header(&quot;X-My-Header&quot;, &quot;SomeValue&quot;)    ))\n\nReading JSON Response (读取 JSON 响应)微服务通常使用 JSON 等消息编码格式\nMicronaut 的 HTTP client 利用 Jackson 进行 JSON 解析, 因此 Jackson 可以解码的任何类型都可以作为第二个参数传入 retrieve() 方法:\nExample - 有一个 Controller 返回一个 JSON响应:\n@Get(&#x27;/greet/&#123;name&#125;&#x27;)Message greet(String name) &#123; new Message(&quot;Hello $name&quot;) &#125;import com.fasterxml.jackson.annotation.JsonCreatorimport com.fasterxml.jackson.annotation.JsonPropertyclass Message &#123;    final String text    @JsonCreator    Message(@JsonProperty(&quot;text&quot;) String text) &#123; this.text = text&#125;&#125;\n\n在 client 中你可以调用这个 Controller 的 endpoint 并使用 retrieve()方法 解码 JSON 为一个 Map\nExample - Decoding the response body to a Map:\nFlux&lt;Map&gt; response = Flux.from(    client.retrieve(        GET(&#x27;/greet/John&#x27;, Map)    ))\n\n可以使用 Argument.of() 方法来自定义 Map 的 key&#x2F;value 的类型:\nExample - Decoding the response body to Map:\nresponse = Flux.from(    client.retrieve(        GET(&#x27;/greet/John&#x27;),        Argument.of(Map, String, String)    // this method returns a Map where the key and value types are String    ))\n\n虽然将 JSON 作为 Map 进行获取是可取的, 但通常希望将对象解码为 POJO:\nExample - Decoding the response body to a POJO:\nwhen:Flux&lt;Message&gt; response = Flux.from(    client.retrieve(        GET(&#x27;/greet/John&#x27;),        Message    ))\n\n所以可以定义一个通用的 API 项目, 可以在这个项目中定义 定义API 的 interface 和 类\nDecoding Other Content Types (解码其他 Content Types)如果你要请求的服务使用的是自定义的 content type 而不是 JSON, 默认情况下 Micronaut 的 HTTP client 并不知道怎样去解析这样的类型\n通过注册一个 MediaTypeCodec Bean 来解决这个问题, 这个 Bean 会自动被发现并用于编解码消息\nReceiving the Full HTTP Response (接受完整的 HTTP 响应)有时候仅仅接收响应的 body 是不够的, 因为可能还需要获取响应的其他信息, 例如 headers, cookies\n这时, 可以使用 exchange() 方法:\nExample - Receiving the Full HTTP Response:\nwhen:Flux&lt;HttpResponse&gt; call = Flux.from(    client.exchange(            // The exchange method receieves the HttpResponse        GET(&#x27;/greet/John&#x27;),        Message    ))HttpResponse&lt;Message&gt; response = call.blockFirst()Optional&lt;Message&gt; message = response.getBody(Message)   // The body is retrieved using the getBody() method of the rsponsethen:HttpStatus.OK == response.getStatus()message.isPresent()&#x27;Hello John&#x27; == message.get().getText()\n\n上面的例子中获取了完整的 HttpResponse\nPosting a Request Body (发送一个请求体)HttpRequest 接口具有适用于所有不同 HTTP method 的工厂方法\nTable - HttpRequest Factory Methods:\n\n\n\nMethod\nDescription\nAllows Body\n\n\n\nHttpRequest.GET(java.lang.String)\nConstructs an HTTP GET request\nfalse\n\n\nHttpRequest.OPTIONS(java.lang.String)\nConstructs an HTTP OPTIONS request\nfalse\n\n\nHttpRequest.HEAD(java.lang.String)\nConstructs an HTTP HEAD request\nfalse\n\n\nHttpRequest.POST(java.lang.String, T)\nConstructs an HTTP POST request\ntrue\n\n\nHttpRequest.PUT(java.lang.String, T)\nConstructs an HTTP PUT request\ntrue\n\n\nHttpRequest.PATCH(java.lang.String, T)\nConstructs an HTTP PATCH request\ntrue\n\n\nHttpRequest.DELETE(java.lang.String)\nConstructs an HTTP DELETE request\ntrue\n\n\n存在一个 create() 方法来构造一个适用于任何 HttpMethod 类型的请求\n因为 POST,PUT,PATCH method 要求一个 body, 所以需要传入一个代表请求 body 的对象作为第二个参数\nExample - Sending a String body:\nimport static io.micronaut.http.HttpRequest.POSTFlux&lt;HttpResponse&lt;String&gt;&gt; call = Flux.from(    client.exchange(        POST(&#x27;/hello&#x27;, &#x27;Hello John&#x27;)                // 1            .contentType(MediaType.TEXT_PLAIN_TYPE)            .accept(MediaType.TEXT_PLAIN_TYPE),     // 2        String                                      // 3    ))\n\n1 : The POST method is used; the first argument is the URI and the second is the body\n2 : The content type and accepted type are set to text/plain (the default is application/json)\n3 : The expected response type is a String\nSending JSON (发送 JSON)要发送 JSON 数据, 传入要编码为 JSON 的对象(无论是 Map 还是 POJO), 只要 Jackson 能够对其进行编码\nExample - Sending a JSON body:\nFlux&lt;HttpResponse&lt;Message&gt;&gt; call = Flux.from(    client.exchange(        POST(&#x27;/greet&#x27;, new Message(&#x27;Hello John&#x27;)),  // 1        Message                                     // 2    ))\n\n1 : An instance of Message is created and passed to the POST method\n2 : The same class decodes the response\n上面的例子中, 如下的 JSON 被作为请求的 body:\n&#123;&quot;text&quot;: &quot;Hello John&quot;&#125;\n\nUsing a URI Template (使用一个 URI 模板)如果要在 URI 中包含一些对象的属性, 可以使用一个 URI template\n假设, 你有一个拥有 title 属性的 Book 类. 你可以在 URI template 中包含 title, 然后使用一个 Book 实例来填充这个 template 的 title\nExample - Sending a JSON body with a URI template:\nFlux&lt;HttpResponse&lt;Book&gt;&gt; call = Flux.from(    POST(&#x27;/amazon/book/&#123;title&#125;&#x27;, new Book(&#x27;The Stand&#x27;)),    Book)\n\nSending Form Data (发送表单数据)可以将一个 POJO 或 Map 编码为表单数据而不是 JSON\n仅需要在 POST 请求中将 Content-Type 设置为 application/x-www-form-urlencoded\nExample - Sending a Form Data:\nFlux&lt;HttpResponse&lt;Book&gt;&gt; call = client.exchange(    POST(&#x27;/amazon/book/&#123;title&#125;&#x27;, new Book(&#x27;The Stand&#x27;))        .contentType(MediaType.APPLICATION_FORM_URLENCODED),    Book)\n\nMultipart Client Uploads (Multipart 客户端上传)Micronaut HTTP client 支持 multipart request\n要构建一个 multipart request, 将 Content-Type 设置为 multipart/form-data, 并设置 body 为一个 MultipartBody 实例\nExample - Creating the body:\nimport io.micronaut.http.multipart.CompletedFileUploadimport io.micronaut.http.multipart.StreamingFileUploadimport io.micronaut.http.client.multipart.MultipartBodyimport org.reactivestreams.PublisherFile file = new File(uploadDir, &#x27;data.txt&#x27;)file.text = &#x27;test file&#x27;file.createdNewFile()MultipartBody requestBody = MultipartBody.builder()             // 1                                         .addPart(              // 2                                             &quot;data&quot;,                                             file.name,                                             MediaType.TEXT_PLAIN_TYPE,                                             file                                         )                                         .build()               // 3\n\n1 : Create a MultipartBody builder for adding parts to the body\n2 : Add a part to the body, in this cases a file. There are different variations of this method in MultipartBody.Builder\n3 : The build method assembles all parts from the builder into a MultipartBody. At least one part is required\nExample - Creating a request:\nHttpRequest.POST(&#x27;/multipart/upload&#x27;, requestBody)           .contentType(MediaType.MULTIPART_FORM_DATA_TYPE)\n\nStreaming JSON over HTTP (HTTP 上的流式 JSON)Micronaut 的 HTTP client 包括通过 ReactorStreamingHttpClient 接口支持的 HTTP 上的流式传输数据, 这个接口包含了特定于流的方法:\nTable - HTTP Streaming Methods:\n\n\n\nMethod\nDescription\n\n\n\ndataStream(HttpRequest&lt;I&gt; request)\nReturns a stream of data as a Flux of ByteBuffer\n\n\nexchangeStream(HttpRequest&lt;I&gt; request)\nReturns the HttpResponse wrapping a Flux of ByteBuffer\n\n\njsonStream(HttpResponse&lt;I&gt; request)\nReturns a non-blocking stream of JSON objects\n\n\n要使用 JSON streaming, 在 server 中声明一个 Controller 方法, 这个方法 produces 的 Content-Type 是 application/x-json-stream\nExample - Streaming JSON on the Server:\nimport io.micronaut.http.MediaTypeimport io.micronaut.http.annotation.Controllerimport io.micronaut.http.annotation.Getimport reactor.core.publisher.Fluximport reactor.core.publisher.Monoimport java.time.Durationimport java.time.ZonedDateTimeimport java.time.temporal.ChronoUnitimport java.util.concurrent.TimeUnit@Get(value = &#x27;/headlines&#x27;, processes = MediaType.APPLICATION_JSON_STREAM)           // 1Flux&lt;Headline&gt; streamHeadlines() &#123;    Mono.fromCallable(&#123;            // 2            new Headline(text: &quot;Latest Headline at $&#123;ZonedDateTime.now()&#125;&quot;)        &#125;)        .repeat(100)               // 3        .delayElements(Duration.of(1, ChronoUnit.SECONDS))  // 4&#125;\n\n1 : The streamHeadlines method produces application/x-json-stream; processes : Shortcut that allows setting both the consumes() and produces() settings to the same media type.\n2 : A Flux is created from a Callable function\n3 : The Flux repeats 100 times\n4 : The Flux emits items with a delay of one second between each\n在客户端, 使用 jsonSteam 来订阅(subscribe)这个流, 每次 server 输出一个 JSON 对象, 客户端将会解码并消费这个对象\nExample - Streaming JSON on the Client:\nFlux&lt;Headline&gt; headlineStream = Flux.from(    client.jsonStream(  // 1        GET(&#x27;streaming/headlines&#x27;),        Headline    ))CompletableFuture&lt;Headline&gt; future = new CompletableFuture&lt;&gt;()  // 2headlineStream.subscribe(    new Subscribe&lt;Headline&gt;() &#123;        @Override        void onSubscribe(Subscription s) &#123; s.request(1) &#125;   //3         @Override        void onNext(Headline headline) &#123; println &quot;Received Headline = $headline.text&quot;; future.complete(headline) &#125;  // 4        @Override        void onError(Throwable t) &#123; future.completeExceptionally(t) &#125;   // 5        @Override        void onComplete() &#123;&#125;    // 6    &#125;)\n\n1 : The jsonStream method returns a Flux\n2 : A CompletableFuture is used to receive a value, but what you do with each emitted item is application-specific\n3 : The Subscription requests a single item. You can use the Subscription to regulate(调节) back pressure and demand\n4 : The onNext method is called when an item is emitted\n5 : The onError method is called when an error occurs\n6 : The onComplete method is called when all Headine instances have been emitted\nConfiguring HTTP clients (配置 HTTP clients)Global Configuration for All Clients (用于全部 Clients 的全局配置)默认的 HTTP client 配置是 DefaultHttpClientConfiguration\n允许配置所有的 HTTP client 的默认行为\nExample - Altering default HTTP client configuration:\n// application.ymlmicronaut:    http:        client:            read-timeout: 5s\n\n上面的例子中设置了 HttpClientConfiguration 的属性\nClient Specific Configuration (特定 Client 配置)有多个选项来为每个 client 设定不同的配置\n可以在 application.yml 中手动配置服务发现并应用到每个 client 配置中:\nExample - Manually configuring HTTP services:\nmicronaut:    http:        services:            foo:                urls:                    - https://foo1                    - https://foo2                read-timeout: 5s    # The read timeout is applied to the foo client\n\n\nThis client configuration can be used in conjunction with the @Client annotation, either by injecting an HttpClient directly or use on a client interface.\n\n这个客户端配置可以与 @Client 注解一起使用, 可以通过直接注入一个 HttpClient 或在一个 client 接口上使用\n\nIn any case, all other attributes on the annotation will be ignored except the service id.\n\n在任何情况下, 注解上的所有属性都将被忽略, 除了 service id\n然后, 注入命名的 client 配置:\nExample - Injecting an HTTP client:\n@Client(&quot;foo&quot;) @Inject ReactorHttpClient httpClient\n\n你还可以定义一个继承 HttpClientConfiguration 的 Bean, 并确保使用 javax.inject.Named 注解为这个 Bean 合适地命名:\nExample - Defining an HTTP client configuration bean:\n@Named(&quot;twitter&quot;)@Singletonclass TwitterHttpClientConfiguration extends HttpClientConfiguration &#123;    public TwitterHttpClientConfiguration(ApplicationConfiguration configuration) &#123;        super(configuration)    &#125;&#125;\n\n如果你通过 @Client 使用服务发现注入一个命名为 twitter 的 service, 那么这个配置将会被采用:\nExample - Injecting an HTTP client:\n@Client(&quot;twitter&quot;) @Inject ReactorHttpClient httpClient\n\n或者, 如果你不使用服务发现, 你可以使用 @Client 注解的 configuration 成员属性来引用一个特定类型:\nExample - Injecting an HTTP client:\n@Client(    value = &quot;https://api.twitter.com/1/1&quot;,    configuration = TwitterHttpClientConfiguration.class)@InjectReactorHttpClient httpClient\n\nUsing HTTP Client Connection Pooling (使用 HTTP Client 连接池化)一个处理大量请求的 client 将会从开启 HTTP client 连接池化中获益\n如下例子中为 foo client 开启池化:\nExample - Manually configuring HTTP services:\nmicronaut:    http:        services:            foo:                urls:                    - http://foo1                    - http://foo2                pool:                    enabled: true           # Enables the pool                    max-connections: 50     # Sets the maximum number of connections in the pool\n\n查看 ConnectionPoolConfiguration 获取可用池化配置选项细节信息\nConfiguring Event Loop Groups (配置 Event Loop 组)默认情况下, Micronaut 让 worker 线程和所有 HTTP client 线程共享一个通用 Netty EventLoopGroup\n这个 EventLoopGroup 可以通过 micronaut.netty.event-loops.default 属性来进行配置:\nExample - Configuring The Default Event Loop:\nmicronaut:    netty:        event-loops:            default:                num-threads: 10                prefer-native-transport: true\n\n可以使用 micronaut.netty.event-loops 设置来配置一个或多个额外 Event Loop\n下表中总结了可用的属性\nTable - Configuration Properties for DefaultEventLoopGroupConfiguration:\n\n\n\nProperty\nType\n\n\n\nmicronaut.netty.event-loops.*.num-threads\nint\n\n\nmicronaut.netty.event-loops.*.io-ratio\njava.lang.Integer\n\n\nmicronaut.netty.event-loops.*.prefer-native-transport\nboolean\n\n\nmicronaut.netty.event-loops.*.executor\njava.lang.String\n\n\nmicronaut.netty.event-loops.*.shutdown-quiet-period\njava.time.Duration\n\n\nmicronaut.netty.event-loops.*.shutdown-timeout\njava.time.Duration\n\n\n例如, 如果你与 HTTP client 的交互涉及到 CPU 密集型工作, 为一个或所有 client 配置一个单独的 EventLoopGroup 可能是值得的\n下面的例子中配置了一个额外的 event loop group, 它的名字是 other, 有 10 个线程:\nExample - Configuring Additional Event Loops:\nmicronaut:    netty:        event-loops:            other:                num-threads: 10                prefer-native-transport: true\n\n一旦额外的 event loop group 配置好了, 就可以修改一个 HTTP client 的配置来使用它:\nExample - Altering the Event Loop Group used by Clients:\nmicronaut:    http:        client:            event-loop-group: other\n\nError Responses (错误响应)如果一个 HTTP 响应返回一个 400 代码或更高的代码, 将会创建一个 HttpClientResponseException\n这个 Exception 包含了原始的响应\n这个 Exception 如何抛出取决于方法的返回值\n对于阻塞式 client, Exception 被抛出, 调用者要捕捉并处理它\n对于响应式 client, Exception 作为一个 Error 并通过 Publisher 进行传递\nBind Errors (绑定错误)通常你想消费一个 endpoint 并在请求成功时绑定到一个 POJO 中, 在出现错误时绑定到另一个 POJO 中:\n@Controller(&#x27;/books&#x27;)class BookController &#123;    @Get(&#x27;/&#123;isbn&#125;&#x27;)    HttpResponse find(String isbn) &#123;        if (isbn == &quot;1680502395&quot;) &#123;            Map&lt;String, Object&gt; m = [                status  : 401,                error   : &quot;Unauthorized&quot;,                message : &quot;No message available&quot;,                path    : &quot;/books/$isbn&quot;            ]            return HttpResponse.status(HttpStatus.UNAUTHORIZED)                               .body(m)        &#125;        return HttpResponse.ok(new Book(&quot;1491950358&quot;, &quot;Building Microservices&quot;))    &#125;&#125;\n\ndef &quot;after an HttpClientException the response body can be bound to a POJO&quot;() &#123;    when:    client.toBlocking()          .exchange(              HttpRequest.GET(&quot;/books/1680502395&quot;),              Argument.of(Book),        // Success Type              Argument.of(CustomError)  // Error Type          )    then:    def e = thrown(HttpClientResponseException)    e.response.status == HttpStatus.UNAUTHORIZED    when:    Optional&lt;CustomError&gt; jsonError = e.response.getBody(CustomError)    then:    jsonError.get().status == 401    jsonError.get().error == &#x27;Unauthorized&#x27;    jsonError.get().message == &#x27;No message available&#x27;    jsonError.get().path == &#x27;/books/1680502395&#x27;&#125;\n\nProxying Requests with ProxyHttpClient (使用 ProxyingHttpClient 来代理请求)\nA common requirement in Microservice environments is to proxy requests in a Gateway Microservice to other backend Microservices.\n\n微服务环境中一个常见要求是将网关微服务中的请求代理其他后端微服务中\n普通的 HttpClient API 被设计为围绕简化消息交换, 不是被设计为代理请求的\n\nFor this case, use the ProxyHttpClient, which can be used from a HTTP Server Filter to proxy requests to backend Microservices.\n\n对于代理的情况, 使用 ProxyHttpClient, 它被用来从 HTTP Server 过滤器中代理请求到后端微服务\nExample - Proxy filter that rewrites original requests - 重写 /proxy URI 为 /real URI:\nimport io.micronaut.core.async.publisher.Publishersimport io.micronaut.core.util.StringUtilsimport io.micronaut.http.HttpRequestimport io.micronaut.http.MutableHttpResponseimport io.micronaut.http.annotation.Filterimport io.micronaut.http.client.ProxyHttpClientimport io.micronaut.http.filter.HttpServerFilterimport io.micronaut.http.filter.ServerFilterChainimport io.micronaut.http.uri.UriBuilderimport io.micronaut.runtime.server.EmbeddedServerimport org.reactivestreams.Publisher@Filter(&#x27;/proxy/**&#x27;)class ProxyFilter implements HttpServerFilter &#123;     // The filter extends HttpServerFilter    private final ProxyHttpClient client    private final EmbeddedServer embeddedServer    ProxyFilter(ProxyHttpClient client,             // The ProxyHttpClient is injected into the constructor                EmbeddedServer embeddedServer) &#123;        this.client = client        this.embeddedServer = embeddedServer    &#125;    @Override    Publisher&lt;MutableHttpResponse&lt;?&gt;&gt; doFilter(HttpRequest&lt;?&gt; request,                                               ServerFilterChain chain) &#123;        Publisher.map(            client.proxy(                           // The proxy method proxies the request                request.mutate()                    // The request is mutated to modify the URI and include an additional header                       .uri &#123; UriBuilder b -&gt;       // The UriBuilder API rewrites the URI                            b.with &#123;                                scheme(&quot;http&quot;)                                host(embeddedServer.host)                                port(embeddedServer.port)                                replacePath(StringUtils.prependUri(                                    &quot;/real&quot;,                                    request.path.substring(&quot;/proxy&quot;.length())                                ))                            &#125;                       &#125;                       .header(&quot;X-My-Request-Header&quot;, &quot;XXX&quot;)    // Additional request and response headers are included            ),            &#123; it.header(&quot;X-My-Response-Header&quot;, &quot;YYY&quot;) &#125;        )    &#125;&#125;\n\nProxyHttpClient API 是一个低级别 API, 可以使用来构建一个高级别的抽象, 例如一个 API 网关\nDeclarative HTTP Clients with @Client (使用 @Client 的声明式 HTTP 客户端)本质上说, @Client 注解可以被声明在任何接口或抽象类上, 通过使用 AOP, 在编译时实现其中的抽象方法, 极大地简化了 HTTP Client 的创建\n首先声明一个 POJO:\nclass Pet &#123;    String name    int age&#125;\n\n然后声明一个接口来保存 Pet 实例:\nimport io.micronaut.http.annotation.Postimport io.micronaut.validation.Validatedimport org.reactivestreams.Publisherimport io.micronaut.core.async.annotation.SingleResultimport javax.validation.constraints.Minimport javax.validation.constraints.NotBlank@Validatedinterface PetOperations &#123;    @Post    @SingleResult    Publisher&lt;Pet&gt; save(@NotBlank String name,                        @Min(1L) int age)&#125;\n\n注意这个接口如何使用 Micronaut 的 HTTP 注解, 这些注解可以在服务端和客户端中使用\n你还可以使用 javax.validation 约束来校验参数\n注意有些注解, 例如 @Produces 和 @Consumes, 在服务端和客户端有不同的语义例如, @Produces 在服务端作用于一个 Controller 方法上时指明这个方法的返回值是如何格式化的当 @Produces 在客户端时指明方法参数是如何格式化后在发送给服务端\n除此之外, 要使用 javax.validation 功能, 添加 validation 模块到你的构建中:\nimplementation(&quot;io.micronaut:micronaut-validation&quot;)\n\n在服务端的 Micronaut 中你可以使用 PetOperations 接口:\nimport io.micronaut.http.annotation.Controllerimport org.reactivestreams.Publisherimport io.micronaut.core.async.annotation.SingleResultimport reactor.core.publisher.Mono@Controller(&#x27;/pets&#x27;)class PetController implements PetOperations &#123;    @Override    @SingleResult    Publisher&lt;Pet&gt; save(String name, int age) &#123;        Pet pet = new Pet(name: name, age: age)        // save to database or something        return Mono.just(pet)    &#125;&#125;\n\n你可以定义一个声明式 client 在 src/test/java 包中, 使用 @Client 注解来修饰这个 client 以使其在编译时自动实现:\nimport io.micronaut.http.client.annotation.Clientimport org.reactivestreams.Publisherimport io.micronaut.core.async.annotation.SingleResult@Client(&#x27;/pets&#x27;)    // The Client annotation is used with a value relative to the current server, in this case /petsinterface PetClient extends PetOperations &#123;    @Override    @SingleResult    Publisher&lt;Pet&gt; save(String name, int age)&#125;\n\n一旦你定义了一个 client, 你就可以在任何需要的地方使用 @Inject 注解来使用它\n下面的表格展示了 @Client 注解的方法的返回值类型:\nTable - Micronaut Response Types:\n\n\n\nType\nDescription\nExample Signature\n\n\n\nPublisher\nAny type that implements the Publisher interface\nFlux&lt;String&gt; hello()\n\n\nHttpResponse\nAn HttpResponse and optional response body type\nMono&lt;HttpResponse&lt;String&gt;&gt; hello()\n\n\nPublisher\nA Publisher implementation that emits a POJO\nMono&lt;Book&gt; hello()\n\n\nCompletableFuture\nA Java CompletableFuture instance\nCompletableFuture&lt;String&gt; hello()\n\n\nCharSequence\nA blocking native type. Such as String\nString hello()\n\n\nT\nAny simple POJO type\nBook show()\n\n\n\nNote that returning any other type results in a blocking request and is not recommended other than for testing.\n\n请注意, 返回任何其他类型会导致阻塞请求, 并且不建议用于测试以外的其他类型\nCustomizing Parameters Binding (自定义参数绑定)使用方法参数来表示 POST 请求的 body:\n@Post@SingleResultPublisher&lt;Pet&gt; save(@NotBlank String name,                    @Min(1L) int age)\n\nsave 方法默认使用如下 JSON 执行一个 HTTP POST 请求:\n&#123;    &quot;name&quot;: &quot;Dino&quot;,    &quot;age&quot;: 10&#125;\n\n但是, 你可能希望自定义作为正文, 参数, URI变量等发送的内容\n@Client 注解在这方法非常灵活, 支持与 Micronaut 的 HTTP server 相同的 io.micronaut.http.annotation\nExample - 定义一个 URI模板, name 参数作为 URI模板 的一部分 而 @Body 声明发送给 server 的内容, 有 Pet POJO 表示:\n@Post(&#x27;/&#123;name&#125;&#x27;)Mono&lt;Pet&gt; save(    @NotBlank String name,  // 1    @Body @Valid Pet pet    // 2)\n\n1 : The name parameter, included as part of the URI, and declared @NotBlank\n2 : The pet parameter, used to encode the body and declared @Valid\nTable - Parameter Binding Annotations:\n\n\n\nAnnotation\nDescription\nExample\n\n\n\n@Body\nSpecific the parameter for the body of the request\n@Body String body\n\n\n@CookieValue\nSpecific parameters to be sent as cookies\n@CookieValue String myCookie\n\n\n@Header\nSpecific parameters to be sent as HTTP headers\n@Header String requestId\n\n\n@QueryValue\nCustomizes the name of the URI parameter to bind from\n@QueryValue(&quot;userAge&quot;) Integer age\n\n\n@PathVariable\nBinds a parameter exclusively from a Path Variable\n@PathVariable Long id\n\n\n@RequestAttribute\nSpecific parameters to be set as request attributes\n@RequestAttribute Integer locationId\n\n\n始终使用 @Produces 或 @Consumes, 而不是提供一个 Content-Type 或 Accept 的 header\nQuery values formatting (请求值格式化)@Format 注解可以和 @QueryValue 注解一起使用来格式化 query values\n支持的 values 是: csv, ssv, pipes, multi, deep-object. 和 Open API v3 请求参数的 style 属性相似\n格式化只能应用于 java.lang.Iterable, java.util.Map, 使用了 @Introspected 注解的 POJO\nTable - 不同值会怎样被格式化:\n\n\n\nFormat\nIterable example\nMap or POJO example\n\n\n\nOriginal value\n[“Mike”, “Adam”, “Kate”]\n{“name”: “Mike”, “age”: 30}\n\n\n“CSV”\n“param&#x3D;Mike,Adam,Kate”\n“param&#x3D;name,Mike,age,30”\n\n\n“SSV”\n“param&#x3D;Mike Adam Kate”\n“param&#x3D;name Mike age 30”\n\n\n“PIPES”\n“param&#x3D;Mike\nAdam\n\n\n“MULTI”\n“param&#x3D;Mike&amp;param&#x3D;Adam&amp;param&#x3D;Kate”\n“name&#x3D;Mike&amp;age&#x3D;30”\n\n\n“DEEP_OBJECT\n“param[0]&#x3D;Mike&amp;param[1]&#x3D;Adam&amp;param[2]&#x3D;Kate”\n“param[name]&#x3D;Mike&amp;param[age]&#x3D;30”\n\n\nType-Based Binding Parameters (基于类型的参数绑定)有一些参数通过它们的类型而不是它们的注解来识别\nTable - Parameter types and their purpose:\n\n\n\nType\nDescription\nExample\n\n\n\nBasicAuth\nSets the Authorization header\nBasicAuth basicAuth\n\n\nHttpHeaders\nAdds multiple headers to the request\nHttpHeaders headers\n\n\nCookies\nAdds multiple cookies to the request\nCookies cookie\n\n\nCookie\nAdds a cookie to the request\nCookie cookie\n\n\nLocale\nSets the Accept-Language header. Annotate with @QueryValue or @PathVariable to populate a URI variable\nLocale locale\n\n\nCustom Binding (自定义绑定)ClientArgumentRequestBinder API 绑定 client 参数到请求中\n在绑定处理时自动使用作为一个 Bean 进行注册的自定义绑定类\n将会优先搜索基于注解绑定器, 其次搜索基于类型的绑定器\nBinding By Annotation (通过注解进行绑定)要根据参数上的注解控制参数如何绑定到请求上, 请创建 AnnotatedClientArgumentRequestBinder 类型的 Bean\n所有的注解都必须使用 @Bindable 注解进行修饰\nExample - Client with @Metadata Argument:\n@Client(&#x27;/&#x27;)interface MetadataClient &#123;    @Get(&#x27;/client/bind&#x27;)    String get(@Metadata Map metadata)&#125;\n\nExample - @Metadata Annotation:\nimport io.micronaut.core.bind.annotation.Bindableimport java.lang.annotation.Documentedimport java.lang.annotation.Retentionimport java.lang.annotation.Targetimport static java.lang.annotation.ElementType.PARAMETERimport static java.lang.annotation.RetentionPolicy.RUNTIME@Documented@Retention(RUNTIME)@Target(PARAMETER)@Bindable@interface Metadata &#123;&#125;\n\n如果没有任何额外的代码, client 将会尝试将转换 metadata 为字符串并将其作为一个 query parameter 进行附加\n在这个例子中, 这并不是我们想要的效果, 所以要自定义一个 binder\n下面的 binder 处理传递给 clients 的使用了 @Metadata 注解修饰参数, 然后修改请求来包含一个想要的 header.\nbinder 实现可以修改为接收除 Map 之外的更多类型的数据\nExample - Annotation Argument Binder:\nimport io.micronaut.core.annotation.NonNullimport io.micronaut.core.convert.ArgumentConversionContextimport io.micronaut.core.naming.NameUtilsimport io.micronaut.core.util.StringUtilsimport io.micronaut.http.MutableHttpRequestimport io.micronaut.http.client.bind.AnnotatedClientArgumentRequestBinderimport io.micronaut.http.client.bind.ClientRequestUriContextimport org.jetbrains.annotation.NotNullimport jakarta.inject.Singleton@Singletonclass MetadataClientArgumentBinder implements AnnotatedClientArgumentRequestBinder&lt;Metadata&gt; &#123;    final Class&lt;Metadata&gt; annotationType = Metadata    @Override    void bind(@NotNull ArgumentConversionContext&lt;Object&gt; context,              @NotNull ClientRequestUriContext uriContext,              @NotNull Object value,              @NotNull MutableHttpRequest&lt;?&gt; request) &#123;        if (value instanceof Map) &#123;            for (entry in value.entrySet()) &#123;                String key = NameUtils.hyphenate(StringUtils.capitalize(entry.key as String), false)                request.header(&quot;X-Metadata-$key&quot;, entry.value as String)            &#125;        &#125;    &#125;&#125;\n\nBinding By Type (通过类型进行绑定)为了根据参数的类型绑定到请求, 创建一个类型为 TypedClientArgumentRequestBinder 的 Bean\nExample - Client With Metadata Argument:\n@Client(&#x27;/&#x27;)interface MetadataClient &#123;    @Get(&#x27;/client/bind&#x27;)    String get(Metadata metadata)&#125;\n\n如果没有任何额外的代码, client 将会尝试将转换 metadata 为字符串并将其作为一个 query parameter 进行附加\n在这个例子中, 这并不是我们想要的效果, 所以要自定义一个 binder\n下面例子中的 binder 处理类型为 Metadata 的传递给 client 的参数, 并修改请求为包含想要的 header:\nExample - Typed Argument Binder:\nimport io.micronaut.core.annotation.NonNullimport io.micronaut.core.convert.ArgumentConversionContextimport io.micronaut.core.type.Argumentimport io.micronaut.http.MutableHttpRequestimport io.micronaut.http.client.bind.ClientRequestUriContextimport io.micronaut.http.client.bind.TypedClientArgumentRequestBinderimport jakarta.inject.Singleton@Singletonclass MetadataClientArgumentBinder implements TypedClientArgumentRequestBinder&lt;Metadata&gt; &#123;    @Override    @NonNull    Argument&lt;Metadata&gt; argumentType() &#123; Argument.of(Metadata) &#125;    @Override    void bind(@NonNull ArgumentConversionContext&lt;Metadata&gt; context,              @NonNull ClientRequestUriContext uriContext,              @NonNull Metadata value,              @NonNull MutableHttpRequest&lt;?&gt; request) &#123;        request.header(&quot;X-Metadata-Version&quot;, value.version.toString())        request.header(&quot;X-Metadata-Deployment-Id&quot;, value.deploymentId.toString())    &#125;&#125;\n\nBinding On Method (在方法上进行绑定)也可以创建一个 binder, 通过方法上的请求注解来更改请求\nExample - Client With Annotated Method:\n@Client(&#x27;/&#x27;)public interface NameAuthorizedClient &#123;    @Get(&#x27;/client/authorized-resource&#x27;)    @NameAuthorization(name = &#x27;Bo&#x27;)    String get()&#125;\n\nExample - @NameAuthorization Annotation Definition:\n@Documented@Retention(RUNTIME)@Target(METHOD)@Bindable@interface NameAuthorization &#123;    @AliasFor(member = &quot;name&quot;)    String value() default &quot;&quot;    @AliasFor(member = &quot;value&quot;)    String name() default &quot;&quot;&#125;\n\nExample - Specific the behaviour:\n@Singletonpublic class NameAuthorizationBinder implements AnnotatedClientRequestBinder&lt;NameAuthorization&gt; &#123;    @NotNull    @Override    Class&lt;NameAuthorization&gt; getAnnotationType() &#123; NameAuthorization.class &#125;    @Override    void bind(        @NonNull MethodInvocationContext&lt;Object, Object&gt; context,        @NonNull ClientResponseUriContext uriContext,        @NonNull MutableHttpRequest&lt;?&gt; request    ) &#123;        context.getValue(NameAuthorization.class)               .ifPresent(name -&gt; uriContext.addQueryParameter(&quot;name&quot;, String.valueOf(name)))    &#125;&#125;\n\nStreaming with @Client (使用 @Client 进行流式处理)@Client 注解还可以处理流式 HTTP 响应\nStreaming JSON with @Client (使用 @Client 进行 JSON 流式处理)可以定义一个 client 来返回一个无界的 Publisher, 例如 Reactor 的 Flux 或 RxJava 的 Flowable\nExample:\nimport io.micronaut.http.annotation.Getimport io.micronaut.http.client.annotation.Clientimport org.reactivestreams.Publisherimport static io.micronaut.http.MediaType.APPLICATION_JSON_STREAM@Client(&#x27;/streaming&#x27;)interface HeadlineClient &#123;    @Get(value = &#x27;/headlines&#x27;, processes = APPLICATION_JSON_STREAM)     // 1    Publisher&lt;Headline&gt; streamHeadlines()                               // 2&#125;\n\n1 : The @Get method processes responses of type APPLICATION_JSON_STREAM\n2 : The return type is Publisher\nExample - Test - Streaming HeadlineClient:\nvoid &quot;test client annotation streaming&quot;() throws Exception &#123;    when:    def headlineClient = embeddedServer.applicationContext                                       .getBean(HeadlineClient)    Mono&lt;Headline&gt; firstHeadline = Mono.from(headlineClient.streamHeadlines())    Headline headline = firstHeadline.block()    then:    headline    headline.text.startsWith(&quot;Latest Headline&quot;)&#125;\n\nStreaming Clients and Response Types (流式客户端和响应类型)在上面的例子中, 是期望 server 返回一个 JSON 对象流的, 并且 Content-Type 为 applicatoin/x-json-stream, 例如:\nExample - A JSON Stream:\n&#123;&quot;title&quot;: &quot;The Stand&quot;&#125;&#123;&quot;title&quot;: &quot;The Shining&quot;&#125;\n\n一系列 JSON 对象实际上不是有效的 JSON, 因此响应的 Content-Type 不能是 application/json\n有效的 JSON 返回应该是返回一个数组:\nExample - A JSON Array:\n[    &#123;&quot;title&quot;: &quot;The Stand&quot;&#125;,    &#123;&quot;title&quot;: &quot;The Shining&quot;&#125;]\n\n然而, Micronuat 的客户端确实支持通过 application/x-json-stream 传输单个 JSON 对象以及使用 application/json 定义的 JSON 数组\n如果 server 返回 application/json 且返回一个 non-single Publisher, client 在数组元素可用时对其进行流式传输\nStreaming Clients and Read Timeout (流式客户端和读取超时)当流式传输来自服务器的响应时, 底层的 HTTP client 不会应用默认的 HttpClientConfiguration 中的 readTimeout 设置, 因为流式响应的读取之间的延迟可能与正常的读取不同\n作为代替, read-idle-timeout 设置(默认为 5 分钟) 指明了在一个连接空闲之后什么时候进行关闭\n如果你从 server 流式传输数据, 每个数据之间定义了超过 5 分钟的延迟, 那么你可以调整 readIdleTimeout\nExample - Adjusting the readIdleTimeout:\nmicronaut:    http:        client:            read-idle-timeout: 10m\n\nStreaming Server Sent Events (流式服务发送事件)\nMicronaut features a native client for Server Sent Events (SSE) defined by the interface SseClient.\n\nMicronaut 具有用于由 SseClient 接口定义的 Server Sent Events (SSE) 的原生客户端\n\nYou can use this client to stream SSE events from any server that emits them.\n\n你可以使用这个客户端从任何输出 SSE 的 Server 中流式传输 SSE\n尽管 SSE 流通常被浏览器 EventSource 消费, 但在一些场景下你可能需要通过 SseClient 来消费 SSE 流, 例如在单元测试中, 或在作为请求其他服务的网关 Micronaut 中\n@Client 注解也支持消费 SSE 流\nExample - 考虑如下输出 SSE 流的 Controller 方法:\n@Get(value = &#x27;/headlines&#x27;, processes = MediaType.TEXT_EVENT_STREAM) // 1Flux&lt;Event&lt;Headline&gt;&gt; streamHeadlines() &#123;    Flux.&lt;Event&lt;Headline&gt;&gt;create(   // 2        &#123; emitter -&gt;            Headline headline = new Headline(text: &quot;Latest Headline at $&#123;ZonedDateTime.now()&#125;&quot;)            emitter.next(Event.of(headline))            emitter.complete()        &#125;,        FluxSink.OverflowStrategy.BUFFER    )    .repeat(100)    // 3    .delayElements(Duration.of(1, ChronoUnit.SECONDS))  // 4&#125;\n\n1 : The controller defines a @Get annotation that produces a MediaType.TEXT_EVENT_STREAM\n2 : The method uses Reactor to emit a Headline object\n3 : The repeat method repeats the emission 100 times\n4 : With a delay of one second between each\n注意, 方法的返回值仍然是 Event, 且使用 Event.of 方法来创建流式传输给客户端的事件\n要定义一个客户端来消费事件, 定义一个 processes MediaType.TEXT_EVENT_STREAM 的方法:\nExample - SSE Client:\n@Client(&#x27;/streaming/sse&#x27;)interface HeadlineClient &#123;    @Get(value = &#x27;/headlines&#x27;, processes = TEXT_EVENT_STREAM)    Publisher&lt;Event&lt;Headline&gt;&gt; streamHeadlines()&#125;\n\nFlux 的泛型类型可以是 Event, 在这种情况下你将收到完整的事件对象, 也可以是 POJO, 在这种情况下你讲仅收到从 JSON 转换而来的事件中包含的数据\nError Response (错误响应)如果返回的 HTTP 响应的状态码是 400 或更高, 那么会创建一个 HttpClientResponseException\n这个 Exception 包含了原始的响应\nException 怎样抛出取决于方法的返回值类型:\n\n对于响应式响应类型, Exception 作为错误通过 Publisher 传递\n对于阻塞式响应类型, Exception 会被抛出, 调用者应该捕获并处理这个异常\n\n\nThe one exception to this rule is HTTP Not Found (404) responses. This exception only applies to the declarative client.\n\n这个规则的一个例外是 HTTP Not Found (404) 响应. 这个 Exception 仅适用于声明式 client\n\nHTTP Not Found (404) responses for blocking return types is not considered an error condition and the client exception will not be thrown. That behavior includes methods that return void.\n\n阻塞式响应类型的 HTTP Not Found (404) 响应不被认为是错误条件, 并且不会引发 client 异常. 这个行为包括返回 void 的方法\n如果方法的返回值是 HttpResponse, 那么原始的响应会被返回\n如果方法的返回值是 Optional, 那么一个 empty 的 Optional 会被返回\n对于所有其他类型, null 将会被返回\nCustomizing Request Headers (自定义请求头)自定义请求 Header 值得特别讨论, 因为有几种方法使用\nPopulating Headers Using Configuration (使用配置来填充请求头)\nThe @Header annotation can be declared at the type level and is repeatable such that it is possible to drive the request headers sent via configuration using annotation metadata.\n\n@Header 注解可以在类级别声明且可以重复声明, 这样就可以使用注解元数据(annotation metadata)来驱动通过配置发送的请求 Header\nExample - Defining Headers via Configuration:\n@Client(&#x27;/pets&#x27;)@Header(name = &#x27;X-Pet-Client&#x27;, value = &#x27;$&#123;pet.client.id&#125;&#x27;)interface PetClient extends PetOperations &#123;    @Override    @SingleResult    Publisher&lt;Pet&gt; save(@NotBlank String name, @Min(1L) int age)    @Get(&#x27;/&#123;name&#125;&#x27;)    @SingleResult    Publisher&lt;Pet&gt; get(String name)&#125;\n\n上面的例子中在 PetClient 接口上定义了 @Header 注解, 这个注解使用属性占位符配置读取 pet.client.id 属性\n然后在 applicaton.yml 中配置这个占位符对应的值:\npet:    client:        id: foo\n\n或者, 可以通过一个环境变量 PET_CLIENT_ID 来提供占位符值\nPopulating Headers using a Client Filter (使用一个客户端过滤器来填充请求头)或者, 为了动态填充 header, 另一个选项是使用一个 Client Filter\n查看 Client Filter 获取更多信息\nCustomizing Jackson Settings (自定义 Jackson 设置)正如上面提到的, Jackson 被用来将消息编码为 JSON\n一个默认的 Jackson ObjectMapper 会被配置, 然后被 Micronaut 的 HTTP clients 使用\n你可以使用 application.yml 中通过 JacksonConfiguration 类定义的属性覆盖用于构造 ObjectMapper 的设置\nExample- Enables indented output for Jackson:\njackson:    serialization:        indentOutput: true\n\n但是, 这个配置会应用到全局, 同时影响 HTTP server 怎样渲染 JSON 和 HTTP client 怎样发送 JSON\n因此, 有时候需要提供一个特定 client 的 Jackson 设置\n可以在一个 client 上使用 @JacksonFeatures 注解来进行特性 client 设置:\nExample - Jackson Features:\n@Client(    id = EurekaClient.SERVICE_ID,    path = &#x27;/eureka&#x27;,    configuration = EurekaConfiguration.class)@JacksonFeatures(    enabledSerializationFeatures = WRAP_ROOT_VALUE,    disabledSerializationFeatures = WRITE_SINGLE_ELEM_ARRAYS_UNWRAPPED,    enabledDeserializationFeatures = &#123;UNWRAP_ROOT_VALUE, ACCEPT_SINGLE_VALUE_AS_ARRAY&#125;)public interface EurekaClient &#123;&#125;\n\n如果 @JacksonFeatures 还不能满足自定义需求, 可以为 ObjectMapper 编写一个 BeanCreatedEventListener, 然后添加任何你需要的自定义配置\nRetry and Circuit Breaker (重试与断路器)\nRecovering from failure is critical for HTTP clients, and that is where Micronaut’s integrated Retry Advice comes in handy.\n\n从故障中恢复对于 HTTP clients 来说至关重要, 这就是 Micronaut 集成的 重试 Advice 派上用场的地方\n可以在任何 @Client 接口上声明 @Retryable 和 @CircuitBreaker 注解, 然后就会应用重试策略\nExample - Declaring @Retryable:\n@Client(&#x27;/pets&#x27;)@Retryableinterface PetClient extends PetOperations &#123;    @Override    Mono&lt;Pet&gt; save(String name, int age)&#125;\n\n查看 Retry Advice 获取自定义重试的信息\nClient Fallbacks (客户端降级)在分布式系统中, 会发生故障, 最好做好准备并优雅的处理故障\n除此之外, 在开发微服务时, 在没有项目需要的 其他可用微服务的 情况下处理单个微服务是很常见的. 就是当前微服务需要依赖的服务不可用\n\nWith that in mind, Micronaut features a native fallback mechanism that is integrated into Retry Advice that allows falling back to another implementation in the case of failure.\n\n考虑到这一点, Micronaut 提供了一个原生的集成到 重试Advice 的降级机制, 允许在失败的情况下降级到另外一个实现\n使用 @Fallback 注解, 你可以声明 client 在所有可能的重试都用尽时使用的降级实现\n实际上, 降级机制没有和重试严格绑定\n你可以声明任何一个类为 @Recoverable, 如果一个方法调用失败(或者在响应式类型中输出了一个错误), 将会搜索使用 @Fallback 修饰的类\nExample - 定义一个 PetFallback 类来在调用失败的时候被调用:\n@Fallbackclass PetFallback implements PetOperations &#123;    @Override    Mono&lt;Pet&gt; save(String name, int age) &#123;        Pet pet = new Pet(name: name, age: age)        Mono.just(pet)    &#125;&#125;\n\n如果你需要使用降级来帮助测试外部微服务, 你可以在 src/test/java 中定义降级实现, 所以这些降级实现不会被包含到产品代码. 如果不通过 hystrix 使用降级, 你还要在声明式 client 上指定 @Recoverable(api = PetOperations.class)\n正如你所看到的, 降级不会执行任何网络请求且非常简单, 因此会在一个外部系统不可用时提供成功的返回\n当然, 降级的实际行为取决于你的想法. 例如, 你可以实现一个降级实现来在真实数据不可用时从本地缓存中拉取数据, 向运营部门发送有关停机时间的警报电子邮件或其他通知。\nNetflix Hystrix Support (网飞 Hystrix 的支持)如果你使用 Micronaut CLI 创建项目, 添加 netflix-hystrix 特性来配置 Hystrix 你的项目:\nmn create-app my-app --features netflix-hystrix\n\n\nNetflix Hystrix is a fault tolerance library developed by the Netflix team and is designed to improve resilience of interprocess communication.\n\nNetflix Hystrix 是 Netflix 团队开发的容错库, 旨在提供进程间通信的弹性\nMicronaut 通过 netflix-hystrix 模块来集成 Hystrix, 这个模块可以添加到你的构建中:\nimplementation(&quot;io.micronaut.netflix:micronaut-netflix-hystrix&quot;)\n\nUsing the @HystrixCommand Annotation (使用 @HystrixCommand 注解)声明了上面的注解之后, 你可以使用 @HystrixCommand 注解修饰任何方法( 包括定义在 @Client 接口中的方法 ), 然后方法的执行就会被包装在一个 Hystrix command 中\nExample - Using @HystrixCommand:\n@HystrixCommandString hello(String name) &#123; &quot;Hello $name&quot; &#125;\n\n还可以用于响应式返回类型, 例如 Flux, 响应式类型将会被包装到 HystrixObservableCommand\n@HystrixCommand 还和 Micronaut 支持的 Retry Advice 和 Fallbacks 集成\n关于如何自定义 Hystrix 线程池, group 和 properties 的信息, 查看 HystrixCommand 的 Javadoc\nEnabling Hystrix Stream and Dashboard (开启 Hystrix 流和仪表板)可以在 application.yml 设置 hystrix.stream.enabled 为 true 来开启一个 Server Sent Event 流以发送到 Hystrix Dashboard\nExample - Enabling Hystrix Stream:\nhystrix:    stream:        enabled: true\n\n这将会暴露一个 /hystrix.stream 使用 Hystrix Dashboard期望的格式的 端点\nHTTP Clients Filters (HTTP 客户端过滤器)\nOften, you need to include the same HTTP headers or URL parameters in a set of requests against a third-party API or when calling another Microservice.\n\n通常, 你需要在针对第三方 API 或调用另一个微服务的一组请求中包含相同的 HTTP headers 或 URL 参数\n为了简化这个操作, 可以定义 HttpClientFilter 类, 用于所有匹配的 HTTP client 请求\nExample:\nclass BintraApi &#123;    public static final String URL = &#x27;https://api.bintray.com&#x27;&#125;@Singletonclass BintrayService &#123;    final HttpClient client    final String org    BintrayService(        @Client(BintrayApi.URL) HttpClient client,      // 1        @Value(&#x27;$&#123;bintray.organization&#125;&#x27;) String org    ) &#123;        this.client = client        this.org = org    &#125;    Flux&lt;HttpResponse&lt;String&gt;&gt; fetchRepositories() &#123;        client.exchange(HttpRequest.GET(&quot;/repos/$org&quot;), String) // 2    &#125;    Flux&lt;HttpResponse&lt;String&gt;&gt; fetchPackages(String repo) &#123;        client.exchange(HttpRequest.GET(&quot;/repos/$&#123;org&#125;/$&#123;repo&#125;/packages&quot;), String)    &#125;&#125;\n\n1 : An ReactorHttpClient is injected for the Bintray API\n2 : The organization is configurable via configuration\nBintray API 是加密的. 为了验证你要在每个请求中添加一个 Authorization header, 通过使用过滤器来完成:\n@Filter(&#x27;/repos/**&#x27;)    // You can match only a subset of paths with a Client filterclass BintrayFilter implements HttpClientFilter &#123;    final String username    final String token    BintrayFilter(        @Value(&#x27;$&#123;bintray.username&#125;&#x27;) String username,        @Value(&#x27;$&#123;bintray.token&#125;&#x27;) String token    ) &#123;        this.username = username        this.token = token    &#125;    @Override    Publisher&lt;? extends HttpResponse&lt;?&gt;&gt; doFilter(        MutableHttpRequest&lt;?&gt; request,        ClientFilterChain chain    ) &#123;        chain.proceed(            request.basicAuth(username, token)  // The basicAuth method includes HTTP Basic credentials        )    &#125;&#125;\n\nInjecting Another Client into a HttpClientFilter (注入另一个客户端到过滤器中)要创建 ReactorHttpClient, Micronaut 需要解析所有的 HttpClientFilter 实例, 这将会在将另一个 ReactorHttpClient 或 @Client Bean 注入 HttpClientFilter 实例时导致循环依赖\n为了解决这个问题, 使用 BeanProvider 接口来注入另外一个 ReactorHttpClient 或 @Client Bean 到一个 HttpClientFilter 实例中\nExample:\nimport io.micronaut.context.annotation.Requiresimport io.micronaut.context.env.Environmentimport io.micronaut.context.BeanProviderimport io.micronaut.http.HttpResponseimport io.micronaut.http.MutableHttpRequestimport io.micronaut.http.annotation.Filterimport io.micronaut.http.client.HttpClientimport io.micronaut.http.filter.ClientFilterChainimport io.micronaut.http.filter.HttpClientFilterimport org.reactivestreams.Publisherimport reactor.core.publisher.Fluximport reactor.core.publisher.Monoimport static io.micronaut.http.HttpRequest.GET@Requires(env = Environment.GOOGLE_COMPUTE)@Filter(patterns = &#x27;/google-auth/api/**&#x27;)class GoogleAuthFilter implements HttpClientFilter &#123;    private final BeanProvider&lt;HttpClient&gt; authClientProvider    // The BeanProvider interface is used to inject another client, avoiding a circular reference    // The `get()` method of the `Provider` interface is used to obtain the client instance    GoogleAuthFilter(BeanProvider&lt;HttpClient&gt;) httpClientProvider) &#123;        this.authClientProvider = httpClientProvider    &#125;&#125;\n\nFilter Matching By Annotation (通过注解来进行过滤匹配)\nFor cases where a filter should be applied to a client regardless of the URL, filters can be matched by the presence of an annotation applied to both the filter and the client.\n\n对于应该将过滤器应用于 client 而不考虑 URL 的情况, 过滤器可以通过同时应用于过滤器和客户端的注解来匹配\n在 client 和 filter 上使用相同的注解, 让 filter 通过注解来进行匹配\nExample:\nimport io.micronaut.http.annotation.Getimport io.micronaut.http.client.annotation.Client@BasicAuth  // 1@Client(&#x27;/message&#x27;)interface BasicAuthClient &#123;    @Get    String getMessage()&#125;\n\n1 : The @BasicAuth annotation is applied to the client\nExample - The following filter will filter the client requests:\nimport io.micronaut.http.HttpResponseimport io.micronaut.http.MutableHttpRequestimport io.micronaut.http.filter.ClientFilterChainimport io.micronaut.http.filter.HttpClientFilterimport org.reactivestreams.Publisherimport jakarta.inject.Singleton@BasicAuth  // 1@Singleton  //2class BasicAuthClientFilter implements HttpClientFilter &#123;    @Override    Publisher&lt;? extends HttpResponse&lt;?&gt;&gt; doFilter(MutableHttpRequest&lt;?&gt; request,                                                  ClientFilterChain chain) &#123;        chain.proceed(request.basicAuth(&quot;user&quot;, &quot;pass&quot;))    &#125;&#125;\n\n1 : The same annotation, @BasicAuth, is applied to the filter\n2 : Normally the @Filter annotation makes filters singletons by default. Because the @Filter annotation is not used, the desired scope must be applied\nExample - @BasicAuth 注解是一个简单的注解:\nimport io.micronaut.http.annotation.FilterMatcherimport java.lang.annotation.Documentedimport java.lang.annotation.Retentionimport java.lang.annotation.Targetimport static java.lang.annotation.ElementType.PARAMETERimport static java.lang.annotation.ElementType.TYPEimport static java.lang.annotation.RetentionPolicy.RUNTIME@FilterMatcher // 1@Documented@Retention(RUNTIME)@Target([TYPE, PARAMETER])@interface BasicAuth &#123;&#125;\n\n1 : The only requirement for custom annotations is that the @FilterMatcher annotation must be present\nHTTP&#x2F;2 Support (HTTP&#x2F;2 的支持)默认情况下, Micronaut 的 HTTP client 配置为支持 HTTP 1.1\n要开启 HTTP&#x2F;2 的支持, 在配置中设置支持的 HTTP 版本:\nExample - Enabling HTTP&#x2F;2 in Clients:\nmicronaut:    http:        client:            http-version: 2.0\n\n或者在注入 client 时指定要使用的 HTTP 版本:\nExample - Injecting an HTTP&#x2F;2 client:\n@Inject@Client(httpVersion = HttpVersion.HTTP_2_0)ReactorHttpClient client\n\nHTTP Client Sample (HTTP 客户端例子)HTTP Client Guide - Java\nHTTP Client Guide - Groovy\nHTTP Client Guide - Kotlin\n","categories":["Micronaut 中文文档"],"tags":["Micronaut","Groovy","中文"]},{"title":"Spring Boot CLI","url":"/spring/spring-boot-cli/","content":"快速开发 Spring 应用的命令行工具\n可以运行 Groovy 脚本\n可以快速启动一个新项目\n可以编写自定义命令\nUsing the CLI运行 spring help &lt;command&gt; 获取特定命令的帮助信息\n创建项目完整例子完整使用例子:\nspring init \\--build=gradle \\--dependencies=web \\--description=&#x27;你好世界&#x27; \\--java-version=11 \\--language=groovy \\--packaging=jar \\--package-name=&#x27;org.daisy&#x27; \\--group-id=&#x27;org.daisy&#x27; \\--version=&#x27;1.0.0&#x27; \\--name=wallet-server \\wallet-server\n\n\nRunning Applications with the CLI使用 run 命令可以直接编译并运行 Groovy 源代码\nExample - hello.groovy:\n@RestControllerclass WebApplication &#123;    @RequestMapping(&#x27;/&#x27;)    String home() &#123;        &#x27;Hello World!&#x27;    &#125;&#125;\n\n使用如下命令编译并运行应用: $ spring run hello.groovy\n要传递命令行参数给应用, 先使用 -- 分隔 spring 命令的参数: $ spring run hello.groovy -- --server.port=9000\n使用 JAVA_OPTS 环境变量来设置 JVM 命令行参数: $ JAVA_OPTS=-Xmx1024m spring run hello.groovy\nDeduced “grab” Dependencies使用 @Grab 来进行依赖导入\n当使用了如下元素时, CLI 将会自动进行推断并获取对应依赖\n\n\n\nItems\nGrabs\n\n\n\nJdbcTemplate,NamedParameterJdbcTemplate,DataSource\nJDBC Application.\n\n\n@EnableJms\nJMS Application.\n\n\n@EnableCaching\nCaching abstraction.\n\n\n@Test\nJUnit.\n\n\n@EnableRabbit\nRabbitMQ.\n\n\nextends Specification\nSpock test.\n\n\n@EnableBatchProcessing\nSpring Batch.\n\n\n@MessageEndpoint``@EnableIntegration\nSpring Integration.\n\n\n@Controller``@RestController``@EnableWebMvc\nSpring MVC + Embedded Tomcat.\n\n\n@EnableWebSecurity\nSpring Security.\n\n\n@EnableTransactionManagement\nSpring Transaction Management.\n\n\n查看 CompilerAutoConfiguration 获取自定义化信息\nDeduced “grab” Coordinates直接使用 @Grab(&#39;freemarker&#39;) 来获取依赖, 不需要定义 group 和 version\n通过查询 SpringBoot 默认的依赖元数据来获取指定版本的依赖\n依赖的版本和 CLI 的版本绑定, 修改 CLI 版本才会修改依赖的版本\n通过 appendix 查看指定的依赖和他们的版本\nDefault Import Statements许多 import statements 是默认包含的\n很多的 Spring 注解不需要使用 import statements. 在添加 import 前先尝试运行应用来看看是否启动失败\nAutomatic Main Method会在 Groovy 脚本中自动添加一个带有 public static void main(String[] args) 方法的 SpringApplication\nCustom Dependency Management默认情况下, 解析 @Grab 依赖时, CLI 使用定义在 spring-boot-dependencies 中的依赖管理 (dependency management)\n额外的 dependency management, 用来覆盖默认的 dependency management, 可以使用 @DependencyManagementBom 注解进行配置\n@DependencyManagementBom([    &#x27;com.example.custom-bom:1.0.0&#x27;,    &#x27;com.example.another-bom:1.0.0&#x27;])\n\n在任何可以使用 @Grab 的地方都可以使用 @DependencyManagementBom\n在应用中至多使用一次 @DependencyManagementBom\nApplications with Multiple Source Files您可以对所有接受文件输入的命令使用 shell 通配符\n这样做可以让您使用单个目录中的多个文件\n$ spring run *.groovy\n\nPackaging Your Application使用 jar 命令打包应用到一个自包含的可执行 jar 文件中:\n$ spring jar my-app.jar *.groovy\n\n使用 --include 和 --exclude 分别进行包含和排除\n默认包含如下元素:\npublic/**, resources/**, static/**, templates/**, META-INF/**, *\n\n默认排除如下元素:\n.*, repository/**, build/**, target/**, **/*.jar, **.*.groovy\n\nInitialize a New Projectinit 命令使用 start.spring.io 创建一个新项目\n$ spring init &lt;命令选项&gt; 项目目录\n将会在 项目目录 中创建项目\n$ spring help initspring init - Initialize a new project using Spring Initializr (start.spring.io)usage: spring init [options] [location]Option                       Description                                       ------                       -----------                                       -a, --artifact-id &lt;String&gt;   Project coordinates; infer archive name (for                                     example &#x27;test&#x27;)                                 -b, --boot-version &lt;String&gt;  Spring Boot version (for example &#x27;1.2.0.RELEASE&#x27;) --build &lt;String&gt;             Build system to use (for example &#x27;maven&#x27; or                                      &#x27;gradle&#x27;) (default: maven)                      -d, --dependencies &lt;String&gt;  Comma-separated list of dependency identifiers to                                include in the generated project                --description &lt;String&gt;       Project description                               -f, --force                  Force overwrite of existing files                 --format &lt;String&gt;            Format of the generated content (for example                                     &#x27;build&#x27; for a build file, &#x27;project&#x27; for a                                      project archive) (default: project)             -g, --group-id &lt;String&gt;      Project coordinates (for example &#x27;org.test&#x27;)      -j, --java-version &lt;String&gt;  Language level (for example &#x27;1.8&#x27;)                -l, --language &lt;String&gt;      Programming language  (for example &#x27;java&#x27;)        --list                       List the capabilities of the service. Use it to                                  discover the dependencies and the types that are                               available                                       -n, --name &lt;String&gt;          Project name; infer application name              -p, --packaging &lt;String&gt;     Project packaging (for example &#x27;jar&#x27;)             --package-name &lt;String&gt;      Package name                                      -t, --type &lt;String&gt;          Project type. Not normally needed if you use --                                  build and/or --format. Check the capabilities of                               the service (--list) for more details           --target &lt;String&gt;            URL of the service to use (default: https://start.                               spring.io)                                      -v, --version &lt;String&gt;       Project version (for example &#x27;0.0.1-SNAPSHOT&#x27;)    -x, --extract                Extract the project archive. Inferred if a                                       location is specified without an extension      examples:    To list all the capabilities of the service:        $ spring init --list    To creates a default project:        $ spring init    To create a web my-app.zip:        $ spring init -d=web my-app.zip    To create a web/data-jpa gradle project unpacked:        $ spring init -d=web,jpa --build=gradle my-dir\n\n\n\n\nOption\nDescription\n\n\n\n-a --artifact-id &lt;String&gt;\n指定项目坐标 (coordinates); 推断 archive name (例如 wallet-server)\n\n\n-b --boot-version &lt;String&gt;\n指定 Spring Boot 版本 (例如 1.2.0.RELEASE)\n\n\n--build &lt;String&gt;\n指定构建系统 (maven 或 gradle) (默认 maven)\n\n\n-d --dependencies &lt;String&gt;\n指定项目使用的依赖, 使用逗号进行分隔 (例如 -d=web,data-jpa)\n\n\n--description &lt;String&gt;\n指定项目描述\n\n\n-f --force\n强制覆盖已存在的文件\n\n\n--format &lt;String&gt;\n生成的内容的格式 (project 或 build) (build 即只生成构建文件 pom.xml 或 build.gradle) (默认 project)\n\n\n-g --group-id &lt;String&gt;\n设置项目的 Group Id (例如 org.daisy)\n\n\n-j --java-version &lt;String&gt;\n设置 Java 版本 (例如 1.8)\n\n\n-l --language &lt;String&gt;\n指定编程语言 (默认 java) (例如 -l=groovy)\n\n\n--list\n列出服务的功能\n\n\n-n --name &lt;String&gt;\n指定项目名称; 推断语言名称\n\n\n-p --packaging &lt;String&gt;\n项目打包类型 (例如 jar)\n\n\n--package-name &lt;String&gt;\n指定包名 (例如 org.daisy)\n\n\n-t --type &lt;String&gt;\n项目类型. 不常使用\n\n\n--target &lt;String&gt;\n指定 service 的 URL (默认 https://start.spring.io)\n\n\n-v --version &lt;String&gt;\n指定项目版本 (例如 0.0.1-SNAPSHOT)\n\n\n-x --extract\n解压缩项目. 如果坐标没有指定扩展名则进行推断\n\n\n执行 spring init list 查看 service 所有可用功能:\n$ spring init --list  .   ____          _            __ _ _ /\\\\ / ___&#x27;_ __ _ _(_)_ __  __ _ \\ \\ \\ \\( ( )\\___ | &#x27;_ | &#x27;_| | &#x27;_ \\/ _` | \\ \\ \\ \\ \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )  &#x27;  |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/:: Service capabilities ::  https://start.spring.ioSupported dependencies+--------------------------------------+--------------------------------------------------------------+-------------------------------+| Id                                   | Description                                                  | Required version              |+--------------------------------------+--------------------------------------------------------------+-------------------------------+| activemq                             | Spring JMS support with Apache ActiveMQ &#x27;Classic&#x27;.           | &gt;=2.0.0.RELEASE and &lt;3.0.0-M1 ||                                      |                                                              |                               || actuator                             | Supports built in (or custom) endpoints that let you monitor |                               ||                                      | and manage your application - such as application health,    |                               ||                                      | metrics, sessions, etc.                                      |                               ||                                      |                                                              |                               || amqp                                 | Gives your applications a common platform to send and        |                               ||                                      | receive messages, and your messages a safe place to live     |                               ||                                      | until received.                                              |                               ||                                      |                                                              |                               || artemis                              | Spring JMS support with Apache ActiveMQ Artemis.             |                               ||                                      |                                                              |                               || azure-active-directory               | Spring Security integration with Azure Active Directory for  | &gt;=2.5.0-M1 and &lt;3.0.0-M1      ||                                      | authentication.                                              |                               ||                                      |                                                              |                               || azure-cosmos-db                      | Fully managed NoSQL database service for modern app          | &gt;=2.5.0-M1 and &lt;3.0.0-M1      ||                                      | development, including Spring Data support.                  |                               ||                                      |                                                              |                               || azure-keyvault-secrets               | Manage application secrets.                                  | &gt;=2.5.0-M1 and &lt;3.0.0-M1      ||                                      |                                                              |                               || azure-storage                        | Azure Storage service integration.                           | &gt;=2.5.0-M1 and &lt;3.0.0-M1      ||                                      |                                                              |                               || azure-support                        | Auto-configuration for Azure Services (Service Bus, Storage, | &gt;=2.5.0-M1 and &lt;3.0.0-M1      ||                                      | Active Directory, Key Vault, and more).                      |                               ||                                      |                                                              |                               || batch                                | Batch applications with transactions, retry/skip and chunk   |                               ||                                      | based processing.                                            |                               ||                                      |                                                              |                               || cache                                | Provides cache-related operations, such as the ability to    |                               ||                                      | update the content of the cache, but does not provide the    |                               ||                                      | actual data store.                                           |                               ||                                      |                                                              |                               || camel                                | Apache Camel is an open source integration framework that    | &gt;=2.0.0.M1 and &lt;2.7.0-M1      ||                                      | empowers you to quickly and easily integrate various systems |                               ||                                      | consuming or producing data.                                 |                               ||                                      |                                                              |                               || cloud-bus                            | Links nodes of a distributed system with a lightweight       | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | message broker which can used to broadcast state changes or  |                               ||                                      | other management instructions (requires a binder, e.g.       |                               ||                                      | Apache Kafka or RabbitMQ).                                   |                               ||                                      |                                                              |                               || cloud-cloudfoundry-discovery         | Service discovery with Cloud Foundry.                        | &gt;=2.3.0.M1 and &lt;3.0.0-M1      ||                                      |                                                              |                               || cloud-config-client                  | Client that connects to a Spring Cloud Config Server to      | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | fetch the application&#x27;s configuration.                       |                               ||                                      |                                                              |                               || cloud-config-server                  | Central management for configuration via Git, SVN, or        | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | HashiCorp Vault.                                             |                               ||                                      |                                                              |                               || cloud-contract-stub-runner           | Stub Runner for HTTP/Messaging based communication. Allows   | &gt;=2.3.0.M1 and &lt;3.0.0-M1      ||                                      | creating WireMock stubs from RestDocs tests.                 |                               ||                                      |                                                              |                               || cloud-contract-verifier              | Moves TDD to the level of software architecture by enabling  | &gt;=2.3.0.M1 and &lt;3.0.0-M1      ||                                      | Consumer Driven Contract (CDC) development.                  |                               ||                                      |                                                              |                               || cloud-eureka                         | A REST based service for locating services for the purpose   | &gt;=2.3.0.M1 and &lt;3.0.0-M1      ||                                      | of load balancing and failover of middle-tier servers.       |                               ||                                      |                                                              |                               || cloud-eureka-server                  | spring-cloud-netflix Eureka Server.                          | &gt;=2.3.0.M1 and &lt;3.0.0-M1      ||                                      |                                                              |                               || cloud-feign                          | Declarative REST Client. OpenFeign creates a dynamic         | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | implementation of an interface decorated with JAX-RS or      |                               ||                                      | Spring MVC annotations.                                      |                               ||                                      |                                                              |                               || cloud-function                       | Promotes the implementation of business logic via functions  | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | and supports a uniform programming model across serverless   |                               ||                                      | providers, as well as the ability to run standalone (locally |                               ||                                      | or in a PaaS).                                               |                               ||                                      |                                                              |                               || cloud-gateway                        | Provides a simple, yet effective way to route to APIs and    | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | provide cross cutting concerns to them such as security,     |                               ||                                      | monitoring/metrics, and resiliency.                          |                               ||                                      |                                                              |                               || cloud-gcp                            | Contains auto-configuration support for every Spring Cloud   | &gt;=2.4.0-M1 and &lt;2.7.0-M1      ||                                      | GCP integration. Most of the auto-configuration code is only |                               ||                                      | enabled if other dependencies are added to the classpath.    |                               ||                                      |                                                              |                               || cloud-gcp-pubsub                     | Adds the GCP Support entry and all the required dependencies | &gt;=2.4.0-M1 and &lt;2.7.0-M1      ||                                      | so that the Google Cloud Pub/Sub integration work out of the |                               ||                                      | box.                                                         |                               ||                                      |                                                              |                               || cloud-gcp-storage                    | Adds the GCP Support entry and all the required dependencies | &gt;=2.4.0-M1 and &lt;2.7.0-M1      ||                                      | so that the Google Cloud Storage integration work out of the |                               ||                                      | box.                                                         |                               ||                                      |                                                              |                               || cloud-loadbalancer                   | Client-side load-balancing with Spring Cloud LoadBalancer.   | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      |                                                              |                               || cloud-resilience4j                   | Spring Cloud Circuit breaker with Resilience4j as the        | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | underlying implementation.                                   |                               ||                                      |                                                              |                               || cloud-starter                        | Non-specific Spring Cloud features, unrelated to external    | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | libraries or integrations (e.g. Bootstrap context and        |                               ||                                      | @RefreshScope).                                              |                               ||                                      |                                                              |                               || cloud-starter-consul-config          | Enable and configure the common patterns inside your         | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | application and build large distributed systems with         |                               ||                                      | Hashicorp’s Consul. The patterns provided include Service    |                               ||                                      | Discovery, Distributed Configuration and Control Bus.        |                               ||                                      |                                                              |                               || cloud-starter-consul-discovery       | Service discovery with Hashicorp Consul.                     | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      |                                                              |                               || cloud-starter-sleuth                 | Distributed tracing via logs with Spring Cloud Sleuth.       | &gt;=2.3.0.M1 and &lt;3.0.0-M1      ||                                      |                                                              |                               || cloud-starter-vault-config           | Provides client-side support for externalized configuration  | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | in a distributed system. Using HashiCorp&#x27;s Vault you have a  |                               ||                                      | central place to manage external secret properties for       |                               ||                                      | applications across all environments.                        |                               ||                                      |                                                              |                               || cloud-starter-zipkin                 | Distributed tracing with an existing Zipkin installation and | &gt;=2.3.0.M1 and &lt;3.0.0-M1      ||                                      | Spring Cloud Sleuth Zipkin.                                  |                               ||                                      |                                                              |                               || cloud-starter-zookeeper-config       | Enable and configure common patterns inside your application | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | and build large distributed systems with Apache Zookeeper    |                               ||                                      | based components. The provided patterns include Service      |                               ||                                      | Discovery and Configuration.                                 |                               ||                                      |                                                              |                               || cloud-starter-zookeeper-discovery    | Service discovery with Apache Zookeeper.                     | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      |                                                              |                               || cloud-stream                         | Framework for building highly scalable event-driven          | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | microservices connected with shared messaging systems        |                               ||                                      | (requires a binder, e.g. Apache Kafka, RabbitMQ or Solace    |                               ||                                      | PubSub+).                                                    |                               ||                                      |                                                              |                               || cloud-task                           | Allows a user to develop and run short lived microservices   | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | using Spring Cloud. Run them locally, in the cloud, and on   |                               ||                                      | Spring Cloud Data Flow.                                      |                               ||                                      |                                                              |                               || codecentric-spring-boot-admin-client | Required for your application to register with a             | &gt;=2.0.0.RELEASE and &lt;2.7.0-M1 ||                                      | Codecentric&#x27;s Spring Boot Admin Server instance.             |                               ||                                      |                                                              |                               || codecentric-spring-boot-admin-server | A community project to manage and monitor your Spring Boot   | &gt;=2.0.0.RELEASE and &lt;2.7.0-M1 ||                                      | applications. Provides a UI on top of the Spring Boot        |                               ||                                      | Actuator endpoints.                                          |                               ||                                      |                                                              |                               || configuration-processor              | Generate metadata for developers to offer contextual help    |                               ||                                      | and &quot;code completion&quot; when working with custom configuration |                               ||                                      | keys (ex.application.properties/.yml files).                 |                               ||                                      |                                                              |                               || data-cassandra                       | A free and open-source, distributed, NoSQL database          |                               ||                                      | management system that offers high-scalability and           |                               ||                                      | high-performance.                                            |                               ||                                      |                                                              |                               || data-cassandra-reactive              | Access Cassandra NoSQL Database in a reactive fashion.       |                               ||                                      |                                                              |                               || data-couchbase                       | NoSQL document-oriented database that offers in memory-first |                               ||                                      | architecture, geo-distributed deployments, and workload      |                               ||                                      | isolation.                                                   |                               ||                                      |                                                              |                               || data-couchbase-reactive              | Access Couchbase NoSQL database in a reactive fashion with   |                               ||                                      | Spring Data Couchbase.                                       |                               ||                                      |                                                              |                               || data-elasticsearch                   | A distributed, RESTful search and analytics engine with      |                               ||                                      | Spring Data Elasticsearch.                                   |                               ||                                      |                                                              |                               || data-jdbc                            | Persist data in SQL stores with plain JDBC using Spring      |                               ||                                      | Data.                                                        |                               ||                                      |                                                              |                               || data-jpa                             | Persist data in SQL stores with Java Persistence API using   |                               ||                                      | Spring Data and Hibernate.                                   |                               ||                                      |                                                              |                               || data-ldap                            | Makes it easier to build Spring based applications that use  |                               ||                                      | the Lightweight Directory Access Protocol.                   |                               ||                                      |                                                              |                               || data-mongodb                         | Store data in flexible, JSON-like documents, meaning fields  |                               ||                                      | can vary from document to document and data structure can be |                               ||                                      | changed over time.                                           |                               ||                                      |                                                              |                               || data-mongodb-reactive                | Provides asynchronous stream processing with non-blocking    |                               ||                                      | back pressure for MongoDB.                                   |                               ||                                      |                                                              |                               || data-neo4j                           | An open source NoSQL database that stores data structured as |                               ||                                      | graphs consisting of nodes, connected by relationships.      |                               ||                                      |                                                              |                               || data-r2dbc                           | Provides Reactive Relational Database Connectivity to        |                               ||                                      | persist data in SQL stores using Spring Data in reactive     |                               ||                                      | applications.                                                |                               ||                                      |                                                              |                               || data-redis                           | Advanced and thread-safe Java Redis client for synchronous,  |                               ||                                      | asynchronous, and reactive usage. Supports Cluster,          |                               ||                                      | Sentinel, Pipelining, Auto-Reconnect, Codecs and much more.  |                               ||                                      |                                                              |                               || data-redis-reactive                  | Access Redis key-value data stores in a reactive fashion     |                               ||                                      | with Spring Data Redis.                                      |                               ||                                      |                                                              |                               || data-rest                            | Exposing Spring Data repositories over REST via Spring Data  |                               ||                                      | REST.                                                        |                               ||                                      |                                                              |                               || data-rest-explorer                   | Browsing Spring Data REST repositories in your browser.      |                               ||                                      |                                                              |                               || datadog                              | Publish Micrometer metrics to Datadog, a dimensional         |                               ||                                      | time-series SaaS with built-in dashboarding and alerting.    |                               ||                                      |                                                              |                               || db2                                  | A JDBC driver that provides access to IBM DB2.               | &gt;=2.2.0.M6                    ||                                      |                                                              |                               || derby                                | An open source relational database implemented entirely in   |                               ||                                      | Java.                                                        |                               ||                                      |                                                              |                               || devtools                             | Provides fast application restarts, LiveReload, and          |                               ||                                      | configurations for enhanced development experience.          |                               ||                                      |                                                              |                               || flapdoodle-mongo                     | Provides a platform neutral way for running MongoDB in unit  | &gt;=2.0.0.RELEASE and &lt;3.0.0-M1 ||                                      | tests.                                                       |                               ||                                      |                                                              |                               || flyway                               | Version control for your database so you can migrate from    |                               ||                                      | any version (incl. an empty database) to the latest version  |                               ||                                      | of the schema.                                               |                               ||                                      |                                                              |                               || freemarker                           | Java library to generate text output (HTML web pages,        |                               ||                                      | e-mails, configuration files, source code, etc.) based on    |                               ||                                      | templates and changing data.                                 |                               ||                                      |                                                              |                               || geode                                | Apache Geode is a data management platform that helps users  | &gt;=2.3.0.M1 and &lt;3.1.0-M1      ||                                      | build real-time, highly concurrent, highly performant and    |                               ||                                      | reliable Spring Boot applications at scale that is           |                               ||                                      | compatible with Pivotal Cloud Cache.                         |                               ||                                      |                                                              |                               || graphite                             | Publish Micrometer metrics to Graphite, a hierarchical       |                               ||                                      | metrics system backed by a fixed-size database.              |                               ||                                      |                                                              |                               || graphql                              | Build GraphQL applications with Spring for GraphQL and       | &gt;=2.7.0.M1 and &lt;3.0.0-M1      ||                                      | GraphQL Java.                                                |                               ||                                      |                                                              |                               || groovy-templates                     | Groovy templating engine.                                    |                               ||                                      |                                                              |                               || h2                                   | Provides a fast in-memory database that supports JDBC API    |                               ||                                      | and R2DBC access, with a small (2mb) footprint. Supports     |                               ||                                      | embedded and server modes as well as a browser based console |                               ||                                      | application.                                                 |                               ||                                      |                                                              |                               || hateoas                              | Eases the creation of RESTful APIs that follow the HATEOAS   |                               ||                                      | principle when working with Spring / Spring MVC.             |                               ||                                      |                                                              |                               || hsql                                 | Lightweight 100% Java SQL Database Engine.                   |                               ||                                      |                                                              |                               || influx                               | Publish Micrometer metrics to InfluxDB, a dimensional        |                               ||                                      | time-series server that support real-time stream processing  |                               ||                                      | of data.                                                     |                               ||                                      |                                                              |                               || integration                          | Adds support for Enterprise Integration Patterns. Enables    |                               ||                                      | lightweight messaging and supports integration with external |                               ||                                      | systems via declarative adapters.                            |                               ||                                      |                                                              |                               || jdbc                                 | Database Connectivity API that defines how a client may      |                               ||                                      | connect and query a database.                                |                               ||                                      |                                                              |                               || jersey                               | Framework for developing RESTful Web Services in Java that   | &gt;=2.0.0.RELEASE and &lt;3.0.0-M1 ||                                      | provides support for JAX-RS APIs.                            |                               ||                                      |                                                              |                               || jooq                                 | Generate Java code from your database and build type safe    |                               ||                                      | SQL queries through a fluent API.                            |                               ||                                      |                                                              |                               || kafka                                | Publish, subscribe, store, and process streams of records.   |                               ||                                      |                                                              |                               || kafka-streams                        | Building stream processing applications with Apache Kafka    |                               ||                                      | Streams.                                                     |                               ||                                      |                                                              |                               || liquibase                            | Liquibase database migration and source control library.     |                               ||                                      |                                                              |                               || lombok                               | Java annotation library which helps to reduce boilerplate    |                               ||                                      | code.                                                        |                               ||                                      |                                                              |                               || mail                                 | Send email using Java Mail and Spring Framework&#x27;s            |                               ||                                      | JavaMailSender.                                              |                               ||                                      |                                                              |                               || mariadb                              | MariaDB JDBC and R2DBC driver.                               |                               ||                                      |                                                              |                               || mustache                             | Logic-less Templates. There are no if statements, else       |                               ||                                      | clauses, or for loops. Instead there are only tags.          |                               ||                                      |                                                              |                               || mybatis                              | Persistence framework with support for custom SQL, stored    | &gt;=2.0.0.RELEASE and &lt;3.1.0-M1 ||                                      | procedures and advanced mappings. MyBatis couples objects    |                               ||                                      | with stored procedures or SQL statements using a XML         |                               ||                                      | descriptor or annotations.                                   |                               ||                                      |                                                              |                               || mysql                                | MySQL JDBC and R2DBC driver.                                 |                               ||                                      |                                                              |                               || native                               | Incubating support for compiling Spring applications to      | &gt;=2.4.3 and &lt;3.0.0-M1         ||                                      | native executables using the GraalVM native-image compiler.  |                               ||                                      |                                                              |                               || new-relic                            | Publish Micrometer metrics to New Relic, a SaaS offering     |                               ||                                      | with a full UI and a query language called NRQL.             |                               ||                                      |                                                              |                               || oauth2-client                        | Spring Boot integration for Spring Security&#x27;s OAuth2/OpenID  |                               ||                                      | Connect client features.                                     |                               ||                                      |                                                              |                               || oauth2-resource-server               | Spring Boot integration for Spring Security&#x27;s OAuth2         | &gt;=2.1.0.M2                    ||                                      | resource server features.                                    |                               ||                                      |                                                              |                               || okta                                 | Okta specific configuration for Spring Security/Spring Boot  | &gt;=2.1.2.RELEASE and &lt;2.7.0-M1 ||                                      | OAuth2 features. Enable your Spring Boot application to work |                               ||                                      | with Okta via OAuth 2.0/OIDC.                                |                               ||                                      |                                                              |                               || open-service-broker                  | Framework for building Spring Boot apps that implement the   | &gt;=2.0.0.RELEASE and &lt;2.7.0-M1 ||                                      | Open Service Broker API, which can deliver services to       |                               ||                                      | applications running within cloud native platforms such as   |                               ||                                      | Cloud Foundry, Kubernetes and OpenShift.                     |                               ||                                      |                                                              |                               || oracle                               | A JDBC driver that provides access to Oracle.                |                               ||                                      |                                                              |                               || picocli                              | Build command line applications with picocli.                | &gt;=2.4.0.RELEASE and &lt;3.0.0-M1 ||                                      |                                                              |                               || postgresql                           | A JDBC and R2DBC driver that allows Java programs to connect |                               ||                                      | to a PostgreSQL database using standard, database            |                               ||                                      | independent Java code.                                       |                               ||                                      |                                                              |                               || prometheus                           | Expose Micrometer metrics in Prometheus format, an in-memory |                               ||                                      | dimensional time series database with a simple built-in UI,  |                               ||                                      | a custom query language, and math operations.                |                               ||                                      |                                                              |                               || quartz                               | Schedule jobs using Quartz.                                  |                               ||                                      |                                                              |                               || restdocs                             | Document RESTful services by combining hand-written with     |                               ||                                      | Asciidoctor and auto-generated snippets produced with Spring |                               ||                                      | MVC Test.                                                    |                               ||                                      |                                                              |                               || rsocket                              | RSocket.io applications with Spring Messaging and Netty.     | &gt;=2.2.0.M2                    ||                                      |                                                              |                               || scs-config-client                    | Config client on VMware Tanzu Application Service.           | &gt;=2.0.0.RELEASE and &lt;2.7.0-M1 ||                                      |                                                              |                               || scs-service-registry                 | Eureka service discovery client on VMware Tanzu Application  | &gt;=2.0.0.RELEASE and &lt;2.7.0-M1 ||                                      | Service.                                                     |                               ||                                      |                                                              |                               || security                             | Highly customizable authentication and access-control        |                               ||                                      | framework for Spring applications.                           |                               ||                                      |                                                              |                               || session                              | Provides an API and implementations for managing user        |                               ||                                      | session information.                                         |                               ||                                      |                                                              |                               || solace                               | Connect to a Solace PubSub+ Advanced Event Broker to         | &gt;=2.2.0.RELEASE and &lt;2.7.0-M1 ||                                      | publish, subscribe, request/reply and store/replay messages  |                               ||                                      |                                                              |                               || sqlserver                            | A JDBC and R2DBC driver that provides access to Microsoft    |                               ||                                      | SQL Server and Azure SQL Database from any Java application. |                               ||                                      |                                                              |                               || testcontainers                       | Provide lightweight, throwaway instances of common           |                               ||                                      | databases, Selenium web browsers, or anything else that can  |                               ||                                      | run in a Docker container.                                   |                               ||                                      |                                                              |                               || thymeleaf                            | A modern server-side Java template engine for both web and   |                               ||                                      | standalone environments. Allows HTML to be correctly         |                               ||                                      | displayed in browsers and as static prototypes.              |                               ||                                      |                                                              |                               || unboundid-ldap                       | Provides a platform neutral way for running a LDAP server in |                               ||                                      | unit tests.                                                  |                               ||                                      |                                                              |                               || vaadin                               | A web framework that allows you to write UI in pure Java     | &gt;=2.0.0.RELEASE and &lt;2.8.0-M1 ||                                      | without getting bogged down in JS, HTML, and CSS.            |                               ||                                      |                                                              |                               || validation                           | Bean Validation with Hibernate validator.                    |                               ||                                      |                                                              |                               || wavefront                            | Publish Micrometer metrics to Tanzu Observability by         | &gt;=2.3.0.M1 and &lt;2.7.0-M1      ||                                      | Wavefront, a SaaS-based metrics monitoring and analytics     |                               ||                                      | platform that lets you visualize, query, and alert over data |                               ||                                      | from across your entire stack.                               |                               ||                                      |                                                              |                               || web                                  | Build web, including RESTful, applications using Spring MVC. |                               ||                                      | Uses Apache Tomcat as the default embedded container.        |                               ||                                      |                                                              |                               || web-services                         | Facilitates contract-first SOAP development. Allows for the  |                               ||                                      | creation of flexible web services using one of the many ways |                               ||                                      | to manipulate XML payloads.                                  |                               ||                                      |                                                              |                               || webflux                              | Build reactive web applications with Spring WebFlux and      |                               ||                                      | Netty.                                                       |                               ||                                      |                                                              |                               || websocket                            | Build WebSocket applications with SockJS and STOMP.          |                               |+--------------------------------------+--------------------------------------------------------------+-------------------------------+Project types (* denotes the default)+-----------------+------------------------------------------+-----------------------------+| Id              | Description                              | Tags                        |+-----------------+------------------------------------------+-----------------------------+| gradle-build    | Generate a Gradle build file.            | build:gradle,format:build   || gradle-project  | Generate a Gradle based project archive. | build:gradle,format:project || maven-build     | Generate a Maven pom.xml.                | build:maven,format:build    || maven-project * | Generate a Maven based project archive.  | build:maven,format:project  |+-----------------+------------------------------------------+-----------------------------+Parameters+-------------+------------------------------------------+------------------------------+| Id          | Description                              | Default value                |+-------------+------------------------------------------+------------------------------+| artifactId  | project coordinates (infer archive name) | demo                         || bootVersion | spring boot version                      | 2.7.0                        || description | project description                      | Demo project for Spring Boot || groupId     | project coordinates                      | com.example                  || javaVersion | language level                           | 17                           || language    | programming language                     | java                         || name        | project name (infer application name)    | demo                         || packageName | root package                             | com.example.demo             || packaging   | project packaging                        | jar                          || type        | project type                             | maven-project                || version     | project version                          | 0.0.1-SNAPSHOT               |+-------------+------------------------------------------+------------------------------+\n\n\nUsing the Embedded ShellSpring Boot 提供了 BASH 和 zsh shell 的命令行补全脚本\n使用 shell 命令可以启动一个内置 shell:\n╭─daisy at thinkpad in ~/Desktop/wallet-server╰─○ spring shellSpring Boot (v2.7.0)Hit TAB to complete. Type &#x27;help&#x27; and hit RETURN for help, and &#x27;exit&#x27; to quit.$ help\n\nAdding Extensions to the CLI通过使用 install 命令可以添加扩展到 CLI 中\ninstall 接收一个或多个格式为 group:artifact:version 的构件坐标\n例如: $ spring install com.example:spring-boot-cli-extension:1.0.0.RELEASE\n除了通过坐标安装你提供的构件, 这个构件所有的依赖也会被安装\n使用 uninstall 命令来卸载依赖: $ spring uninstall com.example:spring-boot-cli-extension:1.0.0.RELEASE\n将会卸载这个构件和它的依赖项\n使用 --all 选项来卸载所有的依赖: spring uninstall --all\nDeveloping Applications with the Groovy Beans DSLSpring Framework 4.0 已经原生支持 beans&#123;&#125; “DSL” (从 Grails 中借鉴的), 可以使用相同的格式在 Groovy 应用脚本中嵌入 bean 定义\n有时是一个好方法来包含额外功能, 例如中间件定义:\n@Configuration(proxyBeanMethods = false)class Application implement CommandLineRunner &#123;    @Autowired    SharedService service    @Override    void run(String... args) &#123; println service.message &#125;&#125;beans &#123;    service(SharedService) &#123;        message = &quot;Hello World&quot;    &#125;&#125;\n\n可以在相同的文件中使用 beans&#123;&#125; 混合类定义, 只要它们放置在 top level\n如果你喜欢, 你可以放置 beans DSL 到不同的文件中\nConfiguring the CLI with settings.xmlSpring Boot CLI 使用 Maven 解析器, Maven 的依赖解析引擎, 来解析依赖\nCLI 使用 ~/.m2/settings.xml Maven 配置来配置 Maven 解析器\nCLI 支持一下配置:\n\nOffline\nMirrors\nServers\nProxies\nProfiles\nActivation\nRepositories\n\n\nActive profiles\n\nWhat to Read NextGroovy 脚本例子\n源代码\nBuild tool plugins\n参考Spring Boot CLI\n","categories":["SpringBoot"],"tags":["Notes","CLI"]},{"title":"在 SpringBoot 中使用 Groovy beans dsl 来定义 Bean","url":"/spring/use-groovy-beans-dsl-in-spring-boot/","content":"Example:\nimport groovy.util.logging.Slf4jimport org.springframework.beans.factory.groovy.GroovyBeanDefinitionReaderimport org.springframework.beans.factory.support.BeanDefinitionRegistryimport org.springframework.boot.SpringApplicationimport org.springframework.boot.autoconfigure.SpringBootApplicationimport org.springframework.context.ApplicationContextInitializer@SpringBootApplication@Slf4jclass WalletServerApplication &#123;        static void main(String[] args) &#123;        SpringApplication springApplication = new SpringApplication(WalletServerApplication)        springApplication.addInitializers(                &#123;                    new GroovyBeanDefinitionReader(it as BeanDefinitionRegistry).loadBeanDefinitions &#x27;classpath:beans.groovy&#x27;                &#125; as ApplicationContextInitializer        )        springApplication.run args    &#125;    &#125;\n\n使用启动类 SpringApplication 的 org.springframework.boot.SpringApplication#addInitializers 方法\n添加一个 org.springframework.context.ApplicationContextInitializer\n\nCallback interface for initializing a Spring ConfigurableApplicationContext prior to being refreshed.\n\n\nTypically used within web applications that require some programmatic initialization of the application context.\n\n添加 org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader 到 ApplicationContext 中, 即可读取解析 beans&#123;&#125; DSL 脚本\n","categories":["SpringBoot"],"tags":["Notes"]},{"title":"Groovy Arrays","url":"/groovy/groovy-arrays/","content":"Groovy ArraysGroovy 在数组中重新使用列表的定义符号[]\n但是如果要定义数组的话，必须明确声明变量的类型或使用 as 操作符进行强制类型转换\nString[] arrStr = [&#x27;Ananas&#x27;, &#x27;Banana&#x27;, &#x27;Kiwi&#x27;]assert arrStr instanceof String[]assert !(arrStr instanceof List)def numArr = [1, 2, 3] as int[]assert numArr instanceof int[]assert numArr.size() == 3\n\n\n数组的访问规则与列表一致\n\nGroovy 3 及以上的版本支持 Java 风格的数组初始化\ndef primes = new int[] &#123;2, 3, 4, 5, 6&#125;\n\n这里面的 &#123;&#125; 不会被认为是 closure 声明\n","categories":["Groovy"],"tags":["Groovy"]},{"title":"Groovy documentation 总结","url":"/groovy/groovy-documentation-summary/","content":"\n\n\nGroovy documentation 总结\nList 操作\nMap\n延迟计算 GString 的结果\nGroovy GString and String hashCodes\nSlashy string 使用反斜杠定义字符串\nDollar slashy string 使用美元符号和反斜杠定义字符串\nDecimal Literals\nNumber type suffixes\nRelational operators\nSafe navigation operator Null-safe 安全的访问符\nElvis assignment operator 默认赋值\nDirect field access operator 直接访问属性\nElvis operator 三元运算符的快捷方式\nMethod pointer operator 方法引用获取\nMethod reference operator 方法引用获取\nPattern operator 操作符 返回 Pattern 实例\nFind operator 操作符 匹配操作，返回 Matcher 实例\nMatch operator 匹配操作，返回 boolean\nSpread operator 收集集合中每个元素的指定属性\nSpreading method argument 将一个集合拆分，分别赋值给方法的每个入参\nSpread list elements 将一个集合拆分到另一个集合中\nSpread map elements 将一个 Map 拆分到另一个 Map 中\nRange operator Range 使用\nSpaceship operator 等于 compareTo 方法\nSubscript operator 等于 getAt 和 putAt 方法\nSafe index operator Null-safe 的索引访问操作符\nMembership operator 判断元素是否存在于某集合\nIdentity operator 判断引用是否相同\nCoercion operator 转义操作符\nDiamond operator 用于范型说明\nCall operator 用于隐含地调用 call 方法\nStatic import 静态导入\nStatic import aliasing 为静态导入起别名\nImport aliasing 为普通导入起一个别名\nMethods Named parameters 命名参数形式的方法入参\nMethods Default arguments 给方法的参数设置默认值\nMethods Method selection algorithm 在运行时使用最适合的入参类型执行方法\nMethods Exception declaration 自动包装检查时异常\nFields and properties 字段和属性的区分\nTraits 特性\nTraits Methods Traits 支持的方法\nTraits The meaning of this Traits 中的 this\nTraits Interfaces Traits 可以实现接口\nTraits Properties Traits 可以定义属性\nTraits Fields Traits 中的字段\nTraits Gomposition of behaviors Traits 用于实现多重继承\nTraits Overriding default methods Traits 的方法可以在实现类中重写\nTraits Extending traits Traits 可以继承其他 Traits\nTraits Multiple inheritance conflicts 继承多个 Traits 时的方法冲突解决\nTraits Runtime implementation of traits 运行时实现 Traits，使用 as 或 withTraits()\nTraits Chaining behavior Traits 中的 super 的含义\nTraits Self types 对实现 Traits 的类的限制\nTraits Limitations Traits 的限制\nClosures Parameters Closure 的参数\nClosure vs lambda expressions Closure 有委托的概念，Java 8 的 lambda 没有\nDelegate of a closure\n\n\nClosures in GStrings 在 GString 中使用 Closure\nClosures Functional programming Closure 的科里化，缓存，组合，trampoline\nMultiple assignment 多参数赋值\nConditional structures switch 支持多种比较\nObject destructuring with multiple assignment getAt 方法与多参数赋值\nSemantics Statements Overflow and Underflow 多参数赋值的范围问题\nMulti-assignment in combination with for loop 在循环语句中使用多参数赋值\nfor in loop 在 for 循环中使用 in\nPower assertion 断言增强\nLabeled statements 标签语句支持\nAssigning a closure to a SAM type 使用 Closure 快速实现一个单抽象方法的类&#x2F;接口\nClosure to arbitrary type coercion 将 Closure 转换为任意类型\nMap to type coercion Map 转成类&#x2F;接口\nString to enum coercion 字符串类型强转为枚举类型\nCustom type coercion 自定义类型转换逻辑\nClass literals vs variables and the as operator 只能在 Class 字面量情况下工作\nOptional public keyword 默认为 public 的情况\nThe Groovy Truth 判断的为 true 的规则\nList and map constructors 使用 List 和 Map 来作为实例化类\nThe @CompileStatic annotation 声明进行静态编译\nDefault imports 默认导入的包\nReading Files 读取文件\nWriting files 写入文件\nTraversing file trees 文件目录遍历\nExecuting External Processes 执行外部命令\nList 倒序访问\nList Manipulating lists 在 List 中进行查找和过滤\nList Adding or removing elements 在 List 中添加&#x2F;删除元素\nSet operations &#x3D; Set 集合操作\nSorting 集合排序\nDuplicating elements 复制元素\nIterating on maps 迭代一个 Map\nMap Adding or removing elements Map 添加&#x2F;删除元素\nMap Filtering and searching Map 过滤与搜索\nMap Grouping 将 List 转换为 Map\n集合 Slicing with the subscript operator 使用下标操作符\n时间 Property notation 时间的属性快捷访问\n时间 Ranges, upto, and downto 时间和 Range 一起工作\nCombining date and time values 将不同类型的时间组合起来\nCreating periods and durations 计算时间差\nConfigSlurper 读取配置文件信息\nExpando 动态创建对象\nCategories 给不受控制的类添加方法\nEasier cloning and externalizing 自动实现 Clone 和 Externalizable\nGrape handling Groovy 内嵌的依赖管理工具\nCode generation transformations @TupleConstructor 为字段生成许多构造方法\nGroovy Code generation transformations 各种代码生成注解\n@groovy.transform.ToString\n@groovy.transform.EqualsAndHashCode\n@groovy.transform.MapConstructor\n@groovy.transform.Canonical\n@groovy.transform.InheritConstructors\n@groovy.lang.Category\n@groovy.transform.IndexedProperty\n@groovy.lang.Lazy\n@groovy.lang.Newify\n@groovy.transform.Sortable\n@groovy.transform.builder.Builder\n@groovy.transform.AutoImplement\n@groovy.transform.NullCheck\n\n\nClass design annotations 实现类设计的一些注解，例如单例，委托\n@groovy.lang.Delegate\n@groovy.transform.Immutable\n@groovy.transform.Memoized\n@groovy.transform.TailRecursive\n@groovy.lang.Singleton\n\n\nLogging improvements 日志使用\nDeclarative concurrency 声明式异步\n@groovy.transform.Synchronized\n@groovy.transform.WithReadLock and @groovy.transform.WithWriteLock\n\n\nSafer scripting 脚本安全\n@groovy.transform.ThreadInterrupt 脚本 安全中断处理\n@groovy.transform.TimedInterrupt 脚本 可以运行多久\n\n\nCompiler directives\n@groovy.transform.Field 将脚本中的变量声明为脚本类的字段\n@groovy.transform.PackageScope 声明是 package private 的\n@groovy.transform.AutoFinal 在类或方法中自动插入 final\n\n\nSwing patterns\n@groovy.beans.Bindable\n@groovy.beans.ListenerList\n\n\nTest assistance 测试帮助类\n@groovy.test.NotYetImplemented\n\n\n@Grab 引入第三方包\nGrape Command Line Tool Grab 的命令行工具\nIterable#combinations 生成所有可能的参数组合\nIterable#eachCombination 生成所有可能的参数组合\nJsonSlurper JSON 字符串转 Groovy 对象\nJsonOutput 将 Groovy 对象转换为 JSON 字符串\nJsonBuilder与StreamingJsonBuilder 在 Groovy 中创建 JSON\nGroovy Interacting with a SQL database\nConnecting to HSQLDB\nConnecting to HSQLDB (withInstance variation)\nConnecting to HSQLDB with a DataSource\nConnecting to HSQLDB with a DataSource using Apache Commons DBCP\nConnecting using @Grab\nCreating tables\nUsing DataSets\nCreating and Inserting data\nReading rows\nUpdating rows\nDeleting rows\nWorking with transactions\nUsing batches\nBatching prepared statements\nLogging additional SQL information\nPerforming pagination\nUsing row metadata\nUsing row and metadata closures\nUsing connection metadata\nNamed parameters (colon form) 入参冒号命名方式\nNamed parameters (question mark form) 入参问号命名方式\nNamed-ordinal parameters 入参问号逗号命名方式\n\n\n\n\n\n\n\nGroovy documentation 总结List 操作\n\n\nname\nmeaning\n\n\n\n赋值\nletters[0] = &#39;c&#39;\n\n\n将值附加到列表末尾\nletters &lt;&lt; &#39;e&#39;\n\n\n使用负数下标访问倒数第一个元素\nletters[-1] == &#39;e&#39;\n\n\n使用负数下标访问倒数第二个元素\nletters[-2] == &#39;e&#39;\n\n\n使用逗号分隔同时访问多个下标的元素\nletters[1, 3] == [&#39;b&#39;, &#39;d&#39;]\n\n\n使用 Range 进行范围访问\nletters[2..4] == [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]\n\n\nMap默认的 Map 字面量是 java.util.LinkedHashMap 类型\n如果访问的 key 在 Map 中不存在，将会返回 null : assert colors.unknown == null\n延迟计算 GString 的结果在将 GString 转换成 String 的时候，closure 才会被调用，然后将新的变量值插入的字符串中。这就实现了动态插值和延迟调用插值\nGroovy GString and String hashCodesGString 和 String 有不同的 hashCodes\n因为 GString 是动态生成字符的，所以会产生新的对象；而 String 是不可变的\nSlashy string 使用反斜杠定义字符串/123/ 使用斜杠定义的字符串\n在 Slashy string 中不需要转义 \\\nDollar slashy string 使用美元符号和反斜杠定义字符串是以 $/ 开头，/$ 结尾的多行 GString\n转义字符是 $\nDecimal LiteralsGroovy 选择 java.lang.BigDecimal 作为浮点数的类型\nNumber type suffixesassert 345G             == new BigInteger(&#x27;345&#x27;)assert 123.45           == new BigDecimal(&#x27;123.45&#x27;)\n\nRelational operators=== : 相当于 Java 中的 == ，用于判断是否指向同一个对象\n!== : 相当于 Java 中的 != ，用于判断不是指向同一个对象\nSafe navigation operator Null-safe 安全的访问符Safe navigation operator ?. 会简单地返回 null 而不是抛出异常\ndef name = person?.name                     // 使用 null-safe 操作符来防止空指针异常assert name == null                         // 结果为 null\n\nElvis assignment operator 默认赋值?=\nclass Element &#123;    String name&#125;def he = new Element()assert he.name == nullhe.with &#123;    name ?= &#x27;linweiyu&#x27;          // 只有 name 为 null 的时候才赋值&#125;assert he.name == &#x27;linweiyu&#x27;he.with &#123;    name ?= &#x27;Shit&#x27;              // 只有 name 为 null 的时候才赋值&#125;assert he.name != &#x27;Shit&#x27;\n\nDirect field access operator 直接访问属性如果想直接获取到属性的值，而不是访问它的 getter 方法，那就使用 Direct field access operator .@\nassert user.@name == &#x27;Bob&#x27;\n\nElvis operator 三元运算符的快捷方式?:\n三元运算符的快捷方式\n主要用于判断为 false 时返回默认值，如果判断为 true 则返回自身\ndisplayName = user.name ? user.name : &#x27;Anonymous&#x27;displayName = user.name ?: &#x27;Anonymous&#x27;\n\nMethod pointer operator 方法引用获取.&amp;\n将一个方法的引用存储到一个变量中，稍后再进行使用\n实例对象的方法引用：\ndef str = &#x27;example of method reference&#x27;def fun = str.&amp;toUpperCase              // 2def upper = fun()                       // 3assert upper == str.toUpperCase()       // 4\n\n构造方法的应用 &amp;new：\ndef foo = BigInteger.&amp;new   // 构造方法def fortyTow = foo(&#x27;42&#x27;)assert fortyTow == 42G\n\n类的静态方法应用：\ndef instanceMethod = String.&amp;toUpperCaseassert instanceMethod(&#x27;foo&#x27;) == &#x27;FOO&#x27;\n\nMethod reference operator 方法引用获取::\n在 dynamic Groovy 中，:: 方法引用操作符就是 .&amp; 方法指针操作符的别名\n在 static Groovy 中，:: 方法引用符在字节码中和 Java 的方法引用是一样的\nPattern operator 操作符 返回 Pattern 实例~\n用来创建 java.util.regex.Pattern 实例\ndef p = ~/foo/assert p instanceof Pattern\n\np = ~&#x27;foo&#x27;p = ~&quot;foo&quot;p = ~$/dollar/slashy $ string/$p = ~&quot;$&#123;pattern&#125;&quot;\n\nFind operator 操作符 匹配操作，返回 Matcher 实例=~\n用来创建 java.util.regex.Matcher 实例\ndef text = &quot;some text to match&quot;def m = (text =~ /match/)assert m instanceof java.util.regex.Matcherif (m) println &quot;find&quot;else println &quot;not find&quot;\n\nMatch operator 匹配操作，返回 boolean==~\n直接返回 boolean\ndef text = &quot;some text to match&quot;def m = (text ==~ /match/)assert m instanceof Booleanif (m) println &quot;find&quot;else println &quot;not find&quot;\n\nSpread operator 收集集合中每个元素的指定属性*\ncars*.make 相当于 cars.collect&#123; it.make &#125;\n*. 是 null-safe 的，如果遇到 null ，则返回 null，不会抛出 NullPointerException\n*. 操作符都可以用于任何实现了 Iterable 接口的类\n作用于集合的集合的时候，可以使用 collectNested 方法来代替 *.\nSpreading method argument 将一个集合拆分，分别赋值给方法的每个入参*\n将一个集合拆分，分别赋值给方法的每个入参\nint function(int x, int y, int z) &#123;    x * y + z&#125;def args = [4, 5, 6]assert function(*args) == 26args = [4]assert function(*args, 5, 6) == 26\n\nSpread list elements 将一个集合拆分到另一个集合中*\n将一个集合拆分到另一个集合中\ndef items = [4, 5]def list = [1, 2, 3, *items, 6]assert list == [1, 2, 3, 4, 5, 6]\n\nSpread map elements 将一个 Map 拆分到另一个 Map 中*:\ndef m1 = [c:3, d:4]def map = [a:1, b:2, *:m1]assert map == [a:1, b:2, c:3, d:4]\n\nRange operator Range 使用..\ndef range = 0..5assert (0..5).collect() == [0, 1, 2, 3, 4, 5]assert (0..&lt;5).collect() == [0, 1, 2, 3, 4]assert (0..5) instanceof Listassert (0..5).size() == 6\n\n可以通过任何实现了 Comparable 接口，next() 方法，previous() 方法的对象来创建 Range\nassert (&#x27;a&#x27;..&#x27;d&#x27;).collect() == [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;]\n\nSpaceship operator 等于 compareTo 方法&lt;=&gt;\nThe spaceship operator &lt;&#x3D;&gt; delegates to the compareTo() 方法\nassert (1 &lt;=&gt; 2) == -1\nSubscript operator 等于 getAt 和 putAt 方法[]\n实现了 getAt 和 putAt 方法的类都可以使用 [] 来快速调用这两个方法\nassert list[2] == 2list[2] = 4\n\nSafe index operator Null-safe 的索引访问操作符?[]\narray = nullassert null == array?[1]    // return null for all index valuesarray?[1] = &#x27;c&#x27;             // quietly ignore attempt to set valueassert null == array?[1]personInfo = nullassert null == personInfo?[&#x27;name&#x27;]              // return null for all map valuespersonInfo?[&#x27;name&#x27;] = &#x27;sunlan&#x27;                  // quietly ignore attempt to set valueassert null == personInfo?[&#x27;name&#x27;]\n\nMembership operator 判断元素是否存在于某集合in\n等于调用 isCase 方法\n在 List 中，等于调用 contains 方法\ndef list = [&#x27;Grace&#x27;, &#x27;Rob&#x27;, &#x27;Emmy&#x27;]assert (&#x27;Emmy&#x27; in list)\n\nIdentity operator 判断引用是否相同is\n相当于 Java 中的 ==\n等同于 === 操作符\nCoercion operator 转义操作符as\n当一个对象转换为另一个，除了目标类型和原始类型一样的情况，转换都会返回一个新的对象\n当没有转换规则的时候将会转换失败\n通过实现 asType() 方法来自定义转换规则\nclass User &#123;    Long id    String name    def asType(Class target) &#123;        if (target == Identifiable) &#123;            return new Identifiable(name: name)        &#125;        throw new ClassCastException(&quot;User cannot be coerced into $target&quot;)    &#125;&#125;\n\nDiamond operator 用于范型说明&lt;&gt;\n相当于 Java 中的范型\nCall operator 用于隐含地调用 call 方法()\n任何定义了 call() 方法的对象，可以省略 .call() 的形式，使用 () 操作符来调用 call() 方法\nStatic import 静态导入import static java.lang.String.format\nStatic import aliasing 为静态导入起别名使用 as 关键字为 static import 起一个别名\nimport static Calendar.getInstance as nowassert now().class == Calendar.getInstance().class\n\nImport aliasing 为普通导入起一个别名import java.util.Dateimport java.sql.Date as SQLDate\n\nMethods Named parameters 命名参数形式的方法入参为了使用命名参数，约定方法的第一个参数是 Map\n在方法体中，通过 map.key 的形式来访问参数值\n如果方法只有一个 Map 作为入参， 所有参数都必须被命名\n第一个参数必须是 Map 才能使用方法命名参数\nMethods Default arguments 给方法的参数设置默认值def foo(String par1, Integer par2 = 1) &#123; [name: par1, age: par2] &#125;assert foo(&#x27;Marie&#x27;).age == 1\n\n在默认参数后面只能继续声明默认参数\nMethods Method selection algorithm 在运行时使用最适合的入参类型执行方法调用一个方法时，实际调用哪个方法取决于运行时方法参数类型。首先考虑的是方法名和参数数量，然后是每一个参数的类型\nGroovy 是在运行时使用类型最接近的方法来进行调用\n在继承关系中，直接实现的 Interface 比间接实现的 Interface 有更高的优先级\nObject[] 数组比 Object 有更高的优先级\nNon-vararg 比 vararg 有更高的优先级\n都是 vararg 的情况下，拥有最少数量入参的，有更高的优先级\nInterface 比 Super class 有更高的优先级\nMethods Exception declaration 自动包装检查时异常Groovy 自动地允许你将检查时异常作为运行时异常处理，所以不需要在方法中定义抛出检查时异常\nFields and properties 字段和属性的区分有访问修饰符 (public, protected, or private) 是字段 Field\n没访问修饰符 (public, protected, or private) 是属性 Property\n如果一个 Property 使用 final 声明，setter 方法不会生成, 所以手动声明构造方法来为这个 final property 赋值, Groovy 不会自动为这个 final property 生成构造方法\n通过元字段 properties 可以访问所有的 Property\n如果一个 Property 名称的前两个字母是大写的，那么不会进行大小写转换\nTraits 特性Traits 是一种语言的结构化构造，允许：\n\n行为的组合\n运行时实现接口\n行为重载\n兼容静态类型检查&#x2F;编译\n\nTraits 可以看成是有默认实现和状态的接口\n一个 Trait 使用 trait 关键字来声明：\ntrait FlyingAbility &#123;    String fly() &#123; &quot;I&#x27;m flying!&quot; &#125;&#125;\n\n像使用普通接口一样，通过 implements 关键字来使用：\nclass Bird implements FlyingAbility &#123;&#125;def b = new Bird()assert b.fly() == &quot;I&#x27;m  flying!&quot;\n\nTraits Methods Traits 支持的方法Traits 只支持 public 和 private 方法，protected 和 package private 都不支持\nTraits The meaning of this Traits 中的 thisthis 代表实现 trait 的实例\n将 trait 想成一个父类\nclass Person &#123; String name &#125;trait Speak &#123;    void speak() &#123;        println &quot;Hello, $&#123;name&#125;&quot;        println &quot;Fuck you, $&#123;this.name&#125;&quot;    &#125;&#125;def p = new Person(name: &quot;linweiyu&quot;) as Speakp.speak()\n\n输出:\n╭─daisy at thinkpad in ~/Desktop╰─○ groovy ./Test.groovyHello, linweiyuFuck you, linweiyu\n\nTraits Interfaces Traits 可以实现接口Traits 可以实现接口\nTraits Properties Traits 可以定义属性trait Named &#123;    String name&#125;class Person implements Named &#123;&#125;def p = new Person(name: &#x27;Bob&#x27;)assert p.name == &#x27;Bob&#x27;assert p.getName() == &#x27;Bob&#x27;\n\nclass Person &#123;&#125;trait Named &#123;    String name&#125;def p = new Person() as Namedp.name = &#x27;linweiyu&#x27;println p.name\n\n输出:\n╭─daisy at thinkpad in ~/Desktop╰─○ groovy ./Test.groovylinweiyu\n\nTraits Fields Traits 中的字段trait Counter &#123;    private Integer count = 0    int count() &#123; count+=1; count &#125;&#125;class Person implements Counter &#123;&#125;def p1 = new Person()assert p1.count() == 1assert p1.count() == 2def p2 = new Person()assert p2.count() == 1assert p2.count() == 2\n\n不推荐在 Traits 中使用 public fields\nTraits Gomposition of behaviors Traits 用于实现多重继承class Duck implements FlyingAbility, SpeakingAbility &#123;&#125;\nTraits Overriding default methods Traits 的方法可以在实现类中重写Traits 提供方法的默认实现，在实现类中可以重写这些方法\nTraits Extending traits Traits 可以继承其他 Traitstrait WithId &#123; Long id &#125;trait WithName &#123; String name &#125;trait Identified implements WithId, WithName &#123;&#125;\n\nTraits Multiple inheritance conflicts 继承多个 Traits 时的方法冲突解决如果多个 Trait 有相同的方法签名，那么同时继承这些 Trait 就会出现冲突\n默认的解决冲突行为是：在 implements 中最后一个声明的 Trait 胜出\n可以通过明确选择方法来调用你想要的 Trait 方法: Trait.super.方法名\ntrait A &#123; String exec() &#123; &#x27;A&#x27; &#125; &#125;trait B &#123; String exec() &#123; &#x27;B&#x27; &#125; &#125;class C implements A,B &#123;    String exec() &#123; A.super.exec() &#125;&#125;def c = new C()assert c.exec() == &#x27;A&#x27;\n\nTraits Runtime implementation of traits 运行时实现 Traits，使用 as 或 withTraits()trait Extra &#123;    String extra() &#123; &quot;I&#x27;m an extra method&quot; &#125;&#125;class Something &#123;    String doSomething() &#123; &#x27;Something&#x27; &#125;&#125;def s = new Something() as Extraprintln s.extra()println s.doSomething()\n\n实现多个 Traits，在对象上面使用 withTraits() 方法：\ntrait A &#123; void walk() &#123; println &#x27;walk&#x27; &#125; &#125;trait B &#123; void eat() &#123; println &#x27;eat&#x27; &#125; &#125;class Person &#123;&#125;def p = new Person()def pt = p.withTraits A, Bpt.walk()pt.eat()\n\nTraits Chaining behavior Traits 中的 super 的含义通过在 Traits 中使用 super 关键字来代表下一个 Trait\n就是如果 super 已经引用到继承链的最后一个时，super 就代表当前类\nTraits Self types 对实现 Traits 的类的限制为 Trait 添加类型限制，声明实现一个 Trait 的类必须实现或继承的类\n@SelfType(Device)   // implement Communicating 的类必须继承或实现 Device 类@CompileStatictrait Communicating &#123;&#125;\n\nTraits Limitations Traits 的限制在 trait 中，在更新一个字段的情况下，前置操作符和后置操作符是不允许的\n使用 +&#x3D; 作为替代\nClosures Parameters Closure 的参数可以使用默认值: def c = &#123; int a, int b = 2 -&gt; a+b &#125;\n当一个 Closure 没有使用 -&gt; 定义一个参数列表时，一个 Closure 就肯定会定义一个隐式参数，叫作 it: def greeting = &#123; &quot;Hello, $it!&quot; &#125;\n如果要定义一个严格的没有入参的 Closure ，必须明确定义一个空的入参列表：def magicNumber = &#123; -&gt; 42 &#125;\n可变长度参数:\n&#123; String... args -&gt; args.join(&#x27;&#x27;) &#125;&#123; String[] args -&gt; args.join(&#x27;&#x27;) &#125;&#123; int n, String... args -&gt; args.join(&#x27;&#x27;) * n &#125;\n\nClosure vs lambda expressions Closure 有委托的概念，Java 8 的 lambda 没有The meaning of this(getThisObject()): corresponds to the enclosing class where the closure is defined; 离 Closure 最近的类（不包括 Closure），就是 this\nThe meaning of owner(getOwner()): corresponds to the enclosing object where the closure is defined, which may be either a class or a closure; 返回的是 最近的对象，一个 closure 或者一个 class\nDelegate of a closure\nDelegate 默认等于 owner，可以手动指定\ngetDelegate()\n\ndef upperCaseName = &#123; delegate.name.toUpperCase() &#125;// Then by changing the delegate of the closure, you can see that the target object will changeupperCaseName.delegate = passert upperCaseName() == &#x27;NORMAN&#x27;  // p.name.toUpperCase()\n\nDelegation strategy: Closure.OWNER_FIRST is the default strategy. If a property&#x2F;method exists on the owner, then it will be called on the owner. If not, then the delegate is used.\nClosures in GStrings 在 GString 中使用 Closure通过使用 $&#123;-&gt; x&#125; 的形式，将 GString 变成动态求值的\nClosures Functional programming Closure 的科里化，缓存，组合，trampoline使用 Closure..curry() 和 Closure.rcurry()和 Closure.ncurry(1, 2d) 方法进行科里化\n通过使用 memoize 方法来将 Closure 的执行结果缓存: def fib; fib = &#123; long n -&gt; n &lt; 2 ? n : fib(n - 1) + fib(n - 2) &#125;.memoize()\n通过 chaining calls 将多个功能组合起来: def plus2  = &#123; it + 2 &#125;; def times3 = &#123; it * 3 &#125;; def times3plus2 = plus2 &lt;&lt; times3       // 从右往左的顺序执行\n通过 Closure 的 trampoline 功能来避免递归调用次数过多导致的 StackOverflowException\n将 Closure 封装为 TrampolineClosure，在递归调用这个 trampolined Closure 的时候，原始的 Closure 会等待返回值直到返回值是一个实际的值（而不是一个 trampolined Closure）:\ndef factorialfactorial = &#123; int n, def accu = 1G -&gt;    if (n &lt; 2) return accu    factorial.trampoline(n - 1, n * accu)&#125;factorial = factorial.trampoline()assert factorial(1)     == 1assert factorial(3)     == 1 * 2 * 3\n\nMultiple assignment 多参数赋值def (a, b, c) = [10, 20, &#x27;foo&#x27;]def (int i, String j) == [10, &#x27;foo&#x27;]def nums = [1, 3, 5]def a, b, c(a, b, c) = numsdef (_, month, year) = &quot;18th June 2009&quot;.split()\n\nConditional structures switch 支持多种比较switch (x) &#123;    case &#x27;foo&#x27;:         result = &#x27;found foo&#x27;        break    case [4, 5, 6, &#x27;inList&#x27;]:   // 查找目标是否在 List 中        result = &#x27;list&#x27;        break    case 12..30:                // 查找目标是否在 Range 中        result = &#x27;range&#x27;        break    case Integer:        result = &#x27;integer&#x27;        break    case Number:        result = &#x27;number&#x27;        break    case ~/fo*/:                // toString() representation of x matches the pattern ?        result = &#x27;foo regex&#x27;        break    case &#123; it &lt; 0 &#125;:        result = &#x27;negative&#x27;        break    default:        result = &#x27;default&#x27;&#125;\n\nObject destructuring with multiple assignment getAt 方法与多参数赋值@Immutableclass Coordinates &#123;    double latitude    double longitude        double getAt(int idx) &#123;        if (idx == 0) latitude        else if (idx == 1) longitude        else throw new Exception(&quot;Wrong coordinate index, use 0 or 1&quot;)    &#125;&#125;def coordinates = new Coordinates(latitude: 43.33, longitude: 3.67)def (la, lo) = coordinatesassert la   == 43.33assert log  == 3.67\n\nSemantics Statements Overflow and Underflow 多参数赋值的范围问题如果左边的变量过多，则多出来的变量为 null\n如果右边的赋值过多，则多出来的值被忽略\ndef (a, b, c) = [1, 2]assert a == 1 &amp;&amp; b == 2 &amp;&amp; c == nulldef (a, b) = [1, 2, 3]assert a == 1 &amp;&amp; b == 2\n\nMulti-assignment in combination with for loop 在循环语句中使用多参数赋值for (def (String u, int v) = [&#x27;bar&#x27;, 42]; v &lt; 45; u++, v++) &#123;    baNums &lt;&lt; &quot;$u $v&quot;&#125;\n\nfor in loop 在 for 循环中使用 in// iterate over a mapdef map = [&#x27;abc&#x27;: 1, &#x27;def&#x27;: 2, &#x27;xyz&#x27;: 3]x = 0for (e in map) &#123;    x += e.value&#125;assert x == 6// iterate over values in a mapx = 0for (e in map.values()) &#123;    x += v&#125;assert x == 6// iterate over the characters in a stringdef text = &#x27;abc&#x27;def list = []for (c in text) &#123;    list.add(c)&#125;assert list == [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]// iterate over the characters in a stringdef text = &#x27;abc&#x27;def list = []for (c : text) &#123;    list.add(c)&#125;assert list == [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]\n\nPower assertion 断言增强assert [left expression] == [right expression] : (optional message)\nLabeled statements 标签语句支持在默认情况下 Lable 对代码来说没有语义作用，但是 Lable 属于 AST (抽象语法树)，所以在 AST 转换的时候是可以使用这些 Label 信息的，使得结果是不同的语义\nSpock Framework 就是使用这样的操作来使得测试更加简单\ngiven:    def x = 1    def y = 2when:    def z = x+ythen:    assert z == 3\n\nAssigning a closure to a SAM type 使用 Closure 快速实现一个单抽象方法的类&#x2F;接口Predicate filter = &#123; it.contains &#x27;G&#x27; &#125; as PredicatePredicate filter = &#123; it.contains &#x27;G&#x27; &#125;  // Groovy 2.2.0 之后，as 操作符可以省略boolean doFilter(String s) &#123; s.contains(&#x27;G&#x27;) &#125;Predicate filter = this.&amp;doFilter       // 使用方法指针\n\nClosure to arbitrary type coercion 将 Closure 转换为任意类型interface FooBar &#123;    int foo()    void bar()&#125;def impl = &#123; println &#x27;ok&#x27;; 123 &#125; as FooBar  // 将会生成一个类，这个类中所有方法都使用 Closure 作为实现\n\nMap to type coercion Map 转成类&#x2F;接口Map 的 key 作为方法的名称\nMap 的 value 作为方法的实现\ndef mapmap = [        i      : 10,        hasNext: &#123; println map; map.i &gt; 0 &#125;,        next   : &#123; println map; map.i-- &#125;]def iter = map as Iterator  // 使用 as 关键字println mapif (iter.hasNext()) &#123;    println iter.next()&#125;\n\n只需要实现实际需要被调用的方法，如果一个被调用的方法不存在于 Map 中，那么一个 MissingMethodException 或 UnsupportedOperationException 异常将会抛出，取决于入参\nString to enum coercion 字符串类型强转为枚举类型enum State &#123;    up,    down&#125;\n\nState st = &#x27;up&#x27;         // 不需要明确使用 as 关键字def val = &#x27;up&#x27;State st = &quot;$&#123;val&#125;&quot;     // 使用 GString 的插值State switchState(State st) &#123;    switch(st) &#123;        case &#x27;up&#x27;:            return State.down   // 返回明确的枚举        case &#x27;down&#x27;:            return &#x27;up&#x27;         // 返回隐式转换的枚举    &#125;&#125;// 在方法调用中使用字符串转枚举时，必须明确使用 as 关键字assert switchState(&#x27;up&#x27; as State) == State.downassert switchState(State.down)    == State.up\n\nCustom type coercion 自定义类型转换逻辑在类中实现 asType 方法自定义类型转换的逻辑\n自定义类型转换通过 as 关键字来调用，并且 as 关键字不能省略\ndef asType(Class target) &#123;    if (target == Cartesian) &#123;        return new Cartesian(x: r * cos(phi), y: r * sin(phi))    &#125;&#125;def cartesian = polar as Cartesian      // 使用 as 关键字来进行类型转换，将会调用 Polar 上的 asType() 方法\n\n在 Polar 类的外面实现 asType() 方法，这在不能直接修改源码的情况下很有用：\nPolar.metaClass.asType = &#123; Class target -&gt;    if (Cartesian == target) &#123;        return new Cartesian(x: r * cos(phi), y: r * sin(phi))    &#125;&#125;\n\nClass literals vs variables and the as operator 只能在 Class 字面量情况下工作as 关键字只能在 Class 字面量的情况下工作，如果是要转换反射而来的 Class ，要使用 asType 方法:\nClass clazz = Class.forName(&#x27;Greeter&#x27;)def greeter = &#123; println &#x27;Hello, Groovy!&#x27; &#125; as clazz         // 将会报错def greeter = &#123; println &#x27;Hello, Groovy!&#x27; &#125;.asType(clazz)    // works well\n\nOptional public keyword 默认为 public 的情况Groovy 中 Class 和 Method 默认是 public 的，因此 public 可以省略\nThe Groovy Truth 判断的为 true 的规则\n非空集合 和 非空数组 ，判断为 true\n如果 Matcher 有至少一个匹配，判断为 true\nIetrators 和 Enumerations 还有元素的时候，判读为 true\n非空的 Maps ，判断为 true\n非空的字符串(不包括空字符串)，判断为 true\nif (&#39;&#39;) println &#39;yes&#39; else println &#39;no&#39; 将会输出 no\n\n\n非 0 的数字，判断为 true\n非 null 的对象引用，判断为 true\n通过自定义 asBoolean() 方法来让 Groovy 计算你的对象是 true 还是 false : Boolean asBoolean() &#123; this.name == &#39;green&#39; ? true : false &#125;\n\nList and map constructors 使用 List 和 Map 来作为实例化类@groovy.transform.TupleConstructorclass Person &#123;    String firstName    String lastName&#125;Person classic = new Person(&quot;Ada&quot;, &quot;Lovelace&quot;)\n\nPerson list = [&#x27;Ada&#x27;, &#x27;Lovelace&#x27;]\n\nPerson map = [firstName: &#x27;Ada&#x27;, lastName: &#x27;Lovelace&#x27;]\n\n在 map constructor 中，会额外检查 map 中的 keys 是否和属性的名字一致；map 中的 key 的数量不可以多于要转换的对象的属性\nThe @CompileStatic annotation 声明进行静态编译@CompileStatic 注解可以添加到 class 或者 method 上\n没有必要同时使用 @CompileStatic 和 @TypeChecked 注解，因为 @CompileStatic 做了 @TypeChecked 注解做的所有事，此外 CompileStatic 还会触发静态编译\nDefault imports 默认导入的包\njava.io.*\njava.lang.*\njava.math.BigDecimal\njava.math.BigInteger\njava.net.*\njava.util.*\ngroovy.lang.*\ngroovy.util.*\n\nReading Files 读取文件new File(baseDir, &#x27;haiku.txt&#x27;).eachLine &#123; line -&gt; println line &#125;\n\nnew File(baseDir, &#x27;haiku.txt&#x27;).eachLine &#123; line, nb -&gt; println &quot;Line $nb: $line&quot; &#125;\n\ndef count = 0, MAXSIZE = 3new File(baseDir, &quot;haiku.txt&quot;).withReader &#123; reader -&gt;    while (reader.readLine()) &#123;        if (++count &gt; MAXSIZE) &#123;            throw new RuntimeException(&#x27;Haiku should only have 3 verses&#x27;)        &#125;    &#125;&#125;\n\ndef list = new File(baseDir, &#x27;haiku.txt&#x27;).collect &#123;it&#125;List&lt;String&gt; list2 = new File(baseDir, &#x27;haiku.txt&#x27;) as List&lt;String&gt;\n\ndef array = new File(baseDir, &#x27;haiku.txt&#x27;) as String[]\n\nbyte[] contents = file.bytes\n\ndef is = new File(baseDir, &#x27;haiku.txt&#x27;).withInputStream &#123; stream -&gt;  &#125;\n\nWriting files 写入文件new File(baseDir, &#x27;haiku.txt&#x27;).withWriter(&#x27;utf-8&#x27;) &#123; writer -&gt;    writer.writeLine &#x27;Into the ancient pond&#x27;    writer.writeLine &#x27;A frog jumps&#x27;    writer.writeLine &quot;Water&#x27;s sound!&quot;&#125;\n\nUsing the &lt;&lt; operator would have been enough:\nnew File(baseDir, &#x27;haiku.txt&#x27;) &lt;&lt; &#x27;&#x27;&#x27;Into the ancient pondA frog jumpsWater&#x27;s sound!&#x27;&#x27;&#x27;\n\nDirectly write bytes:\nfile.bytes = [66, 22, 11]\n\nDirectly deal with output streams:\ndef os = new File(baseDir, &#x27;data.bin&#x27;).newOutputStream()// do somethingos.close()\n\nUse the withOutputStream idiom that will handle the exceptions and close the stream in any case:\nnew File(baseDir, &#x27;data.bin&#x27;).withOutputStream &#123; stream -&gt;    // do something&#125;\n\nTraversing file trees 文件目录遍历dir.eachFile &#123; file -&gt;    println file.name&#125;dir.eachFileMatch(~/.*\\.txt/) &#123; file -&gt;    println file.name&#125;dir.eachFileRecurse &#123; file -&gt;    println file.name&#125;dir.eachFileRecurse(FileType.FILES) &#123; file -&gt;    println file.name&#125;dir.traverse &#123; file -&gt;     if (file.directory &amp;&amp; file.name == &#x27;bin&#x27;) &#123;        FileVisitResult.TERMINATE   // 1    &#125; else &#123;        pringln file.name        FileVisitResult.CONTINUE    // 2    &#125;&#125;\n\nExecuting External Processes 执行外部命令def process = &quot;ls -l&quot;.execute()println &quot;Found text $&#123;process.text&#125;&quot;def process = &quot;ls -l&quot;.execute()process.in.eachLine &#123; line -&gt;    println line&#125;def p = &quot;rm -f foo.tmp&quot;.execute([], tmpDir)p.consumeProcessOutput()p.waitFor()// Pipes in actionproc1 = &#x27;ls&#x27;.execute()proc2 = &#x27;tr -d o&#x27;.execute()proc3 = &#x27;tr -d e&#x27;.execute()proc4 = &#x27;tr -d i&#x27;.execute()proc1 | proc2 | proc3 | proc4proc4.waitFor()if (proc4.exitValue()) &#123;    println proc4.err.text&#125; else &#123;    println proc4.text&#125;// Consuming errorsdef sout = new StringBuilder()def serr = new StringBuilder()proc2 = &#x27;tr -d o&#x27;.execute()proc3 = &#x27;tr -d e&#x27;.execute()proc4 = &#x27;tr -d i&#x27;.execute()proc4.consumeProcessOutput(sout, serr)proc2 | proc3 | proc4[proc2, proc3].each &#123; it.consumeProcessErrorStream(serr) &#125;proc2.withWriter &#123; writer -&gt;    writer &lt;&lt; &#x27;testfile.groovy&#x27;&#125;proc4.waitForOrKill(1000)println &quot;Standard output: $sout&quot;println &quot;Standard error: $serr&quot;\n\nList 倒序访问assert [1, 2, 3, 4, 5].getAt(-2) == 4   // getAt() available with negative index[1, 2, 3, 4, 5].get(-2)             // but negative index not allowed with get()\n\nList Manipulating lists 在 List 中进行查找和过滤\nfind : 查找第一个满足条件的元素\nfindAll : 查找所有满足条件的元素\nfindIndexOf : 查找第一个满足条件的元素的下标\nindexOf : 返回匹配的元素的位置\nlastIndexOf : 返回匹配的元素里面最后一个元素的位置\nevery : 判断是否所有元素都满足给定的条件\nany : 判断是否有任意一个元素满足给定的条件\nsum : 将所有元素 plus() 起来\njoin : 将所有元素连接起来\ninject : reduce 操作; assert [1,2,3].inject(&#39;counting: &#39;) &#123;str, item -&gt; str + item&#125; == &#39;counting: 123&#39;\n\nList Adding or removing elements 在 List 中添加&#x2F;删除元素使用 [] 去声明一个空 List ，使用 &lt;&lt; 增加一个元素到 List 中\nIt is however important that the + operator on a list is not mutating(可变的). Compared to &lt;&lt;, it will create a new list\n&lt;&lt; 一般不要用于添加集合类型\nlist.remove(0)                  // 删除了位置0上的元素list.removeElement(0)           // 删除了元素0assert list.removeAt(1) == 4        // remove element at index 1, and return it\n\nSet operations &#x3D; Set 集合操作intersect : 取交集\ndisjoint : 是否 不相交\nassert [1,2,4,6,8,10,12].intersect([1,3,6,9,12]) == [1,6,12]assert [1,2,3].disjoint( [4,6,9] )\n\nSorting 集合排序list.sort &#123; it.size() &#125;list2.sort &#123; a, b -&gt; a == b ? 0 : Math.abs(a) &lt; Math.abs(b) ? -1 : 1 &#125;\n\nDuplicating elements 复制元素assert [1, 2, 3] * 3 = [1, 2, 3, 1, 2, 3, 1, 2, 3]assert [1, 2, 3].multiply(2) = [1, 2, 3, 1, 2, 3]assert Collections.nCopies(3, &#x27;b&#x27;) == [&#x27;b&#x27;, &#x27;b&#x27;, &#x27;b&#x27;]// nCopies from the JDK has different semantics than multiply for listsassert Collections.nCopies(2, [1, 2]) == [[1, 2], [1, 2]] // not [1, 2, 1, 2]\n\nIterating on maps 迭代一个 Mapdef map = [        Bob  : 42,        Alice: 54,        Max  : 33]// 使用 Map.Entrymap.each &#123; entry -&gt; println &quot;Name: $entry.key Age: $entry.value&quot; &#125;// 使用 Map.Entry 和 indexmap.eachWithIndex &#123; Map.Entry&lt;String, Integer&gt; entry,                    int index    -&gt;    println &quot;$index - Name: $entry.key Age: $entry.value&quot;&#125;// 直接使用 key 和 valuemap.each &#123; key, value -&gt; println &quot;Name: $key Age: $value&quot; &#125;// 使用 key 和 value 和 indexmap.eachWithIndex &#123; key,                    value,                    index    -&gt;    println &quot;$index Name: $key Age: $value&quot;&#125;\n\nMap Adding or removing elements Map 添加&#x2F;删除元素添加元素使用 put 或者 putAll 方法\n删除全部元素使用 clear 方法\n不可以使用 GString 作为 Map 的 key ，因为 GString 的哈希值和相同的 String 的哈希值是不一样的\nMap Filtering and searching Map 过滤与搜索\nfind : 查找一个元素；返回 Map.Entry\nfindAll : 查找所有元素；返回 Map\ncollect : Map 操作\nevery : 判断所有元素；返回 Boolean\nany : 判断任一元素；返回 Boolean\n\nMap Grouping 将 List 转换为 Map使用 groupBy 方法将一个 List 转换为 Map\ndef list = [&#x27;a&#x27;, 7, &#x27;b&#x27;, [2, 3]]println list.groupBy &#123; it.class &#125;def list2 = [        [name: &#x27;Clark&#x27;, city: &#x27;London&#x27;],        [name: &#x27;Sharma&#x27;, city: &#x27;London&#x27;],        [name: &#x27;Maradona&#x27;, city: &#x27;LA&#x27;],        [name: &#x27;Zhang&#x27;, city: &#x27;HK&#x27;],        [name: &#x27;Ali&#x27;, city: &#x27;HK&#x27;],        [name: &#x27;Liu&#x27;, city: &#x27;HK&#x27;]]println list2.groupBy &#123; it.city &#125;\n\n集合 Slicing with the subscript operator 使用下标操作符在 List, Array, Map 中使用下标操作符\nString 也可以使用下标操作符\n时间 Property notation 时间的属性快捷访问使用 Groovy 的属性访问法(property notation)调用\nimport java.time.DayOfWeekimport java.time.LocalDateimport java.time.Monthimport java.time.Periodimport java.time.temporal.ChronoFieldimport java.time.temporal.ChronoUnitdef date = LocalDate.of(2018, Month.MARCH, 12)assert date[ChronoField.YEAR] == 2018assert date[ChronoField.MONTH_OF_YEAR] == Month.MARCH.valueassert date[ChronoField.DAY_OF_MONTH] == 12assert date[ChronoField.DAY_OF_WEEK] == DayOfWeek.MONDAY.valuedef period = Period.ofYears(2).withMonths(4).withDays(6)assert period[ChronoUnit.YEARS] == 2assert period[ChronoUnit.MONTHS] == 4assert period[ChronoUnit.DAYS] == 6\n\n时间 Ranges, upto, and downto 时间和 Range 一起工作import java.time.LocalDateimport java.time.Perioddef start = LocalDate.now()def end = start + Period.ofDays(6)(start..end).each &#123; println it.dayOfWeek &#125;\n\nupto() 方法完成和上面的范围操作符一样的功能，upto() 方法从 start(包含) 开始迭代，一直到 end(包含)，每一次迭代都调用一次 Clouse\ndownto() 方法完成相同的功能，方向和 upto() 方法相反\nimport java.time.LocalDateimport java.time.Perioddef start = LocalDate.now()def end = start + Period.ofDays(6)(start..end).each &#123; println it.dayOfWeek &#125;start.upto(end) &#123; println it.dayOfWeek &#125;int iterationCount = 0end.downto(start) &#123; println it; iterationCount++ &#125;assert iterationCount == 7\n\nrange 和 upto 和 downto 的迭代单位，和相加相减的单位一样：\n\nLocalDate 通过天数来迭代\nYearMonth 通过月数来迭代\nYear 通过年数来迭代\neverything else 通过秒数来迭代\n\nupto 和 downto 都支持一个额外的 TemporalUnit 参数来指定迭代的单位：\nimport java.time.LocalDateimport java.time.Monthimport java.time.temporal.ChronoUnitdef start = LocalDate.of(2018, Month.MARCH, 1)def end = start.plusDays(1)int iterationCount = 0start.upto(end, ChronoUnit.MONTHS) &#123; next    -&gt;    println next    ++iterationCount&#125;assert iterationCount == 1\n\n从参数start开始进行迭代，每次迭代的单位是一个月，在第二次迭代时，next的日期已经超过了参数end，因此只进行了一次迭代\nCombining date and time values 将不同类型的时间组合起来&lt;&lt; 操作符可以将两个 JSR 310 types 组合成一个聚合类型\n一个 LocalDate 可以 &lt;&lt; 到一个 LocalTime，组合成一个 LocalDateTime 实例\n&lt;&lt; 操作符是反射的，操作数的顺序无关的\nCreating periods and durations 计算时间差&gt;&gt; 操作符在操作数之间产生一个表示 Period 或 Duration 的值\n例如 ChronoLocalDate 和 YearMonth 和 Year，操作符产生一个 Period 实例\n如果 &gt;&gt; 左边的值早于右边的值，那么结果是正数的\n如果 &gt;&gt; 左边的值晚于右边的值，那么结果就是负数的\n总结就是，&gt;&gt; 左右的值按照时间的流逝顺序，结果就是正数\nConfigSlurper 读取配置文件信息def config = new ConfigSlurper().parse(&#x27;&#x27;&#x27;    app.date = new Date()    app.age = 42            // 1    app &#123;        name = &quot;Test$&#123;42&#125;&quot;  // 2    &#125;&#x27;&#x27;&#x27;)assert config.app.date instanceof Dateassert config.app.age == 42assert config.app.name == &#x27;Test42&#x27;\n\nparse 方法可以用来获取一个 groovy.util.ConfigObject 实例\nConfigObject 是一个特别的 java.util.Map 实现\nConfigObject 不仅返回配置值而且 ConfigObject 不会为 null\nConfigObject config = new ConfigSlurper().parse(&#x27;&#x27;&#x27;    shit.name = &#x27;lin&#x27;    shit.age = 33    shit &#123;        length = &quot;$&#123;28&#125;cm&quot;    &#125;        app.&quot;person.age&quot; = 42               // 当配置名称有 `.` 的时候，使用单引号或者双引号将这个名字扩起来&#x27;&#x27;&#x27;)assert config instanceof java.util.Map  // ConfigObject 是一个 java.util.Map 的实例assert config.shit.name == &#x27;lin&#x27;        // 通过 `.` 方式定义的值assert config.shit.length == &#x27;28cm&#x27;     // 通过 Closure 域方式定义的值assert config.app.age != null           // 没有定义的值不会为 nullassert config.app.&quot;person.age&quot; == 42    // 当配置名称有 `.` 的时候，使用单引号或者双引号将这个名字扩起来\n\ndef config = new ConfigSlurper(&#x27;development&#x27;).parse(&#x27;&#x27;&#x27;    environments &#123;        development &#123;            app.port = 8080        &#125;                test &#123;            app.port = 8082        &#125;                production &#123;            app.port = 80        &#125;    &#125;&#x27;&#x27;&#x27;)assert config.app.port = 8080\n\ndef slurper = new ConfigSlurper()slurper.registerConditionalBlock(&#x27;myProject&#x27;, &#x27;developers&#x27;) // 1def config = slurper.parse(&#x27;&#x27;&#x27;    sendMail = true        myProject &#123;        developers &#123;            sendMail = false        &#125;    &#125;&#x27;&#x27;&#x27;)assert !config.sendMail\n\npublic void registerConditionalBlock(String blockName, String blockValue)\n\nExpando 动态创建对象Expando 类用于创建动态的可扩展对象\ndef expando = new Expando()expando.name = &#x27;lin&#x27;assert expando.name == &#x27;lin&#x27;\n\ndef expando = new Expando()expando.toString = &#123; -&gt; &#x27;John&#x27; &#125;expando.say = &#123; String s -&gt; &quot;John says: $&#123;s&#125;&quot; &#125;assert expando as String == &#x27;John&#x27;assert expando.say(&#x27;fuck&#x27;) == &#x27;John says: fuck&#x27;\n\nCategories 给不受控制的类添加方法use(TimeCategory) &#123;    println 1.minute.from.now       // 1    println 10.hours.age        def someDate = new Date()       // 2    println someDate - 3.months&#125;\n\nGroovy 提供了一个 @Category 注解来将普通类在编译时转换为 Category 类\nclass Distance &#123;    def number    String toString() &#123; &quot;$&#123;number&#125;m&quot; &#125;&#125;@Category(Number)class NumberCategory &#123;    Distance getMeters() &#123;        new Distance(number: this)          // `this` 代表被增强的类的实例，在这个例子中是 Number 类的实例    &#125;&#125;use (NumberCategory) &#123;    assert 42.meters.toString() == &#x27;42m&#x27;    // `42.meters` 使用了 property notation 调用了 `getMeters()` 方法，这个方法返回了 Distance 实例，然后调用 Distance 实例上的 `toString()` 方法&#125;\n\nEasier cloning and externalizing 自动实现 Clone 和 Externalizable@groovy.transform.AutoClone : 用于实现 java.lang.Cloneable 接口，有多种策略可选，通过 style 参数指定策略\n@groovy.transform.AutoExternalize : 用于创建 java.io.Externalizable 类; 自动添加 java.io.Externalizable 接口到类中，并生成 writeExternal 和 readExternal 方法\nGrape handling Groovy 内嵌的依赖管理工具Grap is a dependency management engine embedded into Groovy, relying on serveral annotations which are described thoroughly in the section of the guide\n@groovy.lang.Grab\n@groovy.lang.Grapes\nCode generation transformations @TupleConstructor 为字段生成许多构造方法这个构造方法使用属性的定义顺序来生成\n例如 3 个字段，则会生成 3 个有参构造方法\nGroovy Code generation transformations 各种代码生成注解@groovy.transform.ToString生成可读的 toString 方法\n@groovy.transform.EqualsAndHashCode生成 equals 和 hashCode 方法\n生成的 hashcode 根据 《Effective Java》中的最佳实践来生成\n@EqualsAndHashCode 注解有许多可选的参数，具体请看 API\n@groovy.transform.MapConstructor生成一个 map 构造方法\n@groovy.transform.CanonicalCanonical : 规范，典范的\n@Canonical 注解组合了 @ToString,@EqualsAndHashCode,@TupleConstructor\n@groovy.transform.InheritConstructors生成符合父类构造方法的构造方法\n在继承异常类时非常有用\n@groovy.lang.Category简化 Groovy categories 的创建\n以前的 Groovy category 是这样写的：\n在方法中被混合的目标类可以使用 this 代替。值得注意的是在 category 类中使用实例字段会导致潜在的危险，因为 categories 是无状态的\n@groovy.transform.IndexedProperty为列表&#x2F;数组类型的属性生成索引式访问的 getter&#x2F;setter 方法\n这在使用 Java 中的类时非常有用，因为 Groovy 支持使用 GPath 去访问属性，Java 不支持\nclass SomeBean &#123;    @IndexedProperty String[] someArray = new String[2]    @IndexedProperty List someList = []&#125;def bean = new SomeBean()bean.setSomeArray(0, &#x27;value&#x27;)bean.setSomeList(0, 123)assert bean.someArray[0] == &#x27;value&#x27;assert bean.someList == [123]\n\n@groovy.lang.Lazy@Lazy 注解实现了字段的延迟初始化\n如果字段声明为 volatile 的，那么初始化就会是线程同步的，使用 double-checked locking 模式\n使用 soft=true 参数，字段将会使用 SoftReference 包装，提供一个简单的缓存机制，当垃圾回收器回收这个引用之后，初始化将会在字段下次被访问的时候进行\n@groovy.lang.Newify@Newify 注解提供创建对象的替代语法\n使用 Python 风格：\n@Newify([Tree, Leaf])class TreeBuilder &#123;    Tree tree = Tree(Leaf(&#x27;A&#x27;), Leaf(&#x27;B&#x27;), Tree(Leaf(&#x27;C&#x27;)))&#125;\n\n使用 Ruby 风格：\n@Newify([Tree, Leaf])class TreeBuilder &#123;    Tree tree = Tree.new(Leaf.new(&#x27;A&#x27;), Leaf.new(&#x27;B&#x27;), Tree.new(Leaf.new(&#x27;C&#x27;)))&#125;\n\n@groovy.transform.SortableThe @Sortable AST transformation is used to help write classes that are Comparable and easily sorted typically by numerous properties.\n@groovy.transform.builder.Builder用于生成可以使用 fluent api 调用来生成对象的代码\n@groovy.transform.AutoImplement为 继承&#x2F;实现的 还未提供实现的 抽象方法 提供假的实现\n@groovy.transform.NullCheck@NullCheck 用于在方法或者构造方法中添加 null 检查\n可以单独用于方法上，也可以用于类上，这样类中所有的方法都会添加\nClass design annotations 实现类设计的一些注解，例如单例，委托@groovy.lang.Delegate实现 delegation 设计模式\nclass Event &#123;    @Delegate Date when    String title&#125;def ev = new Event(    title: &#x27;Groovy keynote&#x27;,    when: Date.parse(&#x27;yyyy/MM/dd&#x27;, &#x27;2013/09/10&#x27;))def now = new Date()assert ev.before(now)   // Even 将 befoer() 方法的调用委托给 when 上的 before() 方法\n\n还可以将注解用于方法上，在这种情况下，这个方法被看作是 delegate 的 getter 或者工厂方法\n@groovy.transform.Immutable@Immutable 注解组合了如下注解：\n\n@ToString\n@EqualsAndHashCode\n@TupleConstructor\n@MapConstructor\n@ImmutableBase\n@ImmutableOptions\n@PropertyOptions\n@KnownImmutable\n\n@Immutable 注解用来简化不可变类的创建\nimport groovy.transform.Immutable@Immutableclass Point &#123;    int x    int y&#125;\n\n@groovy.transform.Memoized在方法上使用 @Memoized 可以实现将方法的返回值缓存\n缓存的大小可以通过两个可选参数进行配置：\n\nprotectedCacheSize : 多少数量的结果保证不会被垃圾回收器回收\nmaxCacheSize : 会被保存在内存中的最大数量\n\n默认情况下，缓存的数量没有限制，没有缓存结果会被保证不被垃圾收集器回收\n@groovy.transform.TailRecursive尾递归转换，自动将一个方法最后的递归调用转换为一个等价的迭代版本\n@TailRecursivestatic BigInteger factorial(    BigInteger i,    BigInteger product = 1) &#123;    if (i == 1) &#123;        return product    &#125;    return factorial(i-1, product*i)&#125;\n\n@groovy.lang.Singleton作用在类上，实现单例模式\nLogging improvements 日志使用\n添加一个对应的 static final 日志字段\n将所有 log.level() 调用包装成对应的 log.isLevelEnabled 判断，具体取决于依赖的日志框架\n\n需要相关类在 ClassPath 上\n\n@groovy.util.logging.Log\n@groovy.util.logging.Commons\n@groovy.util.logging.Log4j\n@groovy.util.logging.Log4j2\n\nDeclarative concurrency 声明式异步Groovy 提供一些注解使用声明式来简化通用线程同步模式\n@groovy.transform.Synchronized@Synchronzied 和关键字 synchronized 一样工作，通过锁住不同对象提供更安全的并发\n默认情况下，@Synchronized 注解创建字段 $lock （或者 $LOCK 在静态方法下）作为锁\n@groovy.transform.WithReadLock and @groovy.transform.WithWriteLock@WithReadLock 和 @WithWriteLock 结合工作，提供 读&#x2F;写 同步，使用 ReentrantReadWriteLock 作为实现\n这两个注解可以添加到 method 或者 static method 上\n这两个注解将会透明地创建一个 final $reentrantLock field（或者 final $REENTRANTLOCK 给 static method），正确的同步代码会被添加到代码中\nSafer scripting 脚本安全@groovy.transform.ThreadInterrupt 脚本 安全中断处理@ThreadInterrupt 注解简化了在线程中对于 Thread#interrupt 的处理，通过在判断的地方添加线程中断检查：\n\n循环（for, while）\n方法的入口\nClosure 的入口\n\n通过使用 @ThreadInterrupt 注解来配置执行脚本的 shell ：\ndef config = new CompilerConfiguration()config.addCompilationCustomizers(    new ASTTransformationCustomizer(ThreadInterrupt))def binding = new Binding(i:0)def shell = new GroovyShell(binding, config)\n\n@groovy.transform.TimedInterrupt 脚本 可以运行多久@TimedInterrupt 注解在线程运行过长时间时自动抛出一个异常\n@TimedInterrupt 可以指定脚本运行多久，超过时间就结束运行并抛出异常\ndef confg = new CompilerConfiguration()config.addCompilationCustomizers(    new ASTTransformationCustomizer(value: 1, TimedInterrupt))def binding = new Binding(result: 0)def shell = new GroovyShell(this.class.classLoader, binding, config)@TimedInterrupt(value = 1, unit = TimeUnit.SECONDS)class MyClass &#123;    def fib(int n) &#123;        n&lt;2?n:fib(n-1)+fib(n-2)    &#125;&#125;\n\nCompiler directives这个类别的 AST transformations 直接对代码的语义产生影响，而不是集中在代码生成\n在这方面，它们可以被视为是编译器指令，在编译时或运行时更改程序的行为\n@groovy.transform.Field 将脚本中的变量声明为脚本类的字段只在脚本中有用\n将脚本中的局部变量提升为生成的脚本类中的字段\n@groovy.transform.PackageScope 声明是 package private 的默认情况下，不使用修饰符修饰字段，这个字段是一个属性(private field+getter&#x2F;setter)\n如果要创建一个 package private 的字段，使用 @PackageScope 注解\n@PackageScope 注解可以用于 classes, methods 和 constructors\n@groovy.transform.AutoFinal 在类或方法中自动插入 final@AutoFinal 指示编译器在这个注解修饰的多个地方自动插入 final 修饰符\n如果一个方法（或者构造方法）使用了 @AutoFinal 注解，那么这个方法（或者构造方法）的入参将会被标记为 final\n如果一个类使用了 @AutoFinal 注解，同样的操作将会作用于类中所有声明的方法和构造方法\nSwing patterns@groovy.beans.Bindable@Bindable 将一个类属性转换为一个绑定属性，自动生成一些绑定属性需要的代码，如 Listener\n@groovy.beans.ListenerList为类添加一些操作监听器 List 的代码\nTest assistance 测试帮助类@groovy.test.NotYetImplemented指明某个测试方法还未实现，这个被注解的方法返回 false 时，不会导致测试失败\n@Grab 引入第三方包@Grab(group = &#x27;org.springframework&#x27;, module = &#x27;spring-orm&#x27;, version = &#x27;3.2.5.RELEASE&#x27;)import org.springframework.jdbc.core.JdbcTemplate@Grab(&#x27;org.springframework:spring-orm:3.2.5.RELEASE&#x27;)import org.springframework.jdbc.core.JdbcTemplate@GrabResolver(name = &#x27;restlet&#x27;, root = &#x27;http://maven.restlet.org/&#x27;)@Grab(group = &#x27;org.restlet&#x27;, module = &#x27;org.restlet&#x27;, version = &#x27;1.1.6&#x27;)@Grab(&#x27;net.sourceforge.htmlunit:htmlunit:2.8&#x27;)@GrabExclude(&#x27;xml-apis:xml-apis&#x27;)@GrabConfig(systemClassLoader = true)@Grab(group = &#x27;mysql&#x27;, module = &#x27;mysql-connector-java&#x27;, version = &#x27;5.1.6&#x27;)\n\n代理配置\n可以在命令行中指定系统属性：\ngroovy -Dhttp.proxyHost=yourproxy -Dhttp.proxyPort=8080 yourscript.groovy或者你可以在 JAVA_OPTS 环境变量中配置变量：\nJAVA_OPTS = -Dhttp.proxyHost=yourproxy -Dhttp.proxyPort=8080\nFrom groovysh use the method call variant:\ngroovy.grape.Grape.grab(group:&#39;org.springframework&#39;, module:&#39;spring&#39;, version:&#39;2.5.6&#39;)\nGrape Command Line Tool Grab 的命令行工具grape install [-hv] &lt;group&gt; &lt;module&gt; [&lt;version&gt;] [&lt;classifier&gt;]\n\ngrape list\n\ngrape resolve [-adhisv] (&lt;groupId&gt; &lt;artifactId&gt; &lt;version&gt;)+\n\nresolve : 这将返回表示指定模块的工件和相应的可传递依赖项的JAR的文件位置\ngrape uninstall [-hv] &lt;group&gt; &lt;module&gt; &lt;version&gt;\n\n配置仓库的目录，默认是 ~/.groovy.grapes\ngroovy -Dgrape.root=/repo/grapes yourscript.groovy\nIterable#combinations 生成所有可能的参数组合void testCombinations() &#123;    def combinations = [[2, 3], [4, 5, 6]].combinations()    assert combinations == [[2, 4], [2, 5], [2, 6], [3, 4], [3, 5], [3, 6]]&#125;\n\nIterable#eachCombination 生成所有可能的参数组合void testEachCombination() &#123;    [[2, 3], [4, 5, 6]].eachCombination &#123; println it[0] + it[1]&#125;&#125;\n\nJsonSlurper JSON 字符串转 Groovy 对象JsonSlurper 用于将 JSON 字符串转换为 Groovy 数据结构，如 Map，List，Integer，Double，Boolean，String\nJsonSlurper 有许多重载的 parse 方法和一些特殊的方法，如 parseText，parseFile\nparseText 方法解析一个 JSON String ，将其转换为一个 List 或者一个 Map\nJsonSlurper 还支持注释和日期类型\n解析器变种\n\nJsonParserCharArray\nJsonFastParser : JsonParserCharArray 的特殊变种。速度更快。尽量晚创建对象。用于 JSON buffers 低于 2MB 的情况\nJsonParserLax : JsonParserCharArray 的特殊变种。和 JsonFastParser 性能相当。支持注释，没有单引号字符串\nJsonParserUsingCharacterSource : 用于解析超大文件。超过 2MB 的文件。\n++JsonSlurper 的默认实现是 JsonParserCharArray++\n\nJsonParserType 枚举包含了所有的解析器\nimport groovy.gson.JsonSlurperimport groovy.gson.JsonParserTypedef jsonSlurper = new JsonSlurper(type: JsonParserType.INDEX_OVERLAY)def object = jsonSlurper.parseText &#x27;&#x27;&#x27;    &#123; &quot;myList&quot;: [4, 8, 15, 16, 23, 42] &#125;&#x27;&#x27;&#x27;assert object instanceof Mapassert object.myList instanceof Listassert object.myList == [4, 8, 15, 16, 23, 42]\n\nJsonOutput 将 Groovy 对象转换为 JSON 字符串JsonOutput 将 Groovy 对象转换为 JSON 字符串\nJsonOutput 提供了静态的多个重载的 toJson 方法\n使用 JsonGenerator 来控制序列化输出\nJsonGenerator.Options 创建器用来创建自定义生成器\ndef generator = new JsonGenerator.Options()                                    .excludeNulls()                                    .dateFormat(&#x27;yyyy@MM&#x27;)                                    .excludeFieldByName(&#x27;age&#x27;, &#x27;password&#x27;)                                    .excludeFieldByType(URL)                                    .build()assert generator.toJson(person) == &#x27;&#123;&quot;dob&quot;:&quot;1984@12&quot;,&quot;name&quot;:&quot;John&quot;&#125;&#x27;def generator = new JsonGenerator.Options()                                    .addConverter(URL) &#123; URL u, String key -&gt;                                        if (key == &#x27;favoriteUrl&#x27;) &#123;                                            u.getHost() // 如果 key 名称为 favoriteUrl 时，只返回 host 值                                        &#125; else &#123;                                            u                                        &#125;                                    &#125;                                    .build()\n\nJsonOutput 中的 prettyPrint 方法进行格式化输出：\ndef json = JsonOutput.toJson([name: &#x27;John Doe&#x27;, age: 42])assert JsonOutput.prettyPrint(json) == &#x27;&#x27;&#x27;&#123;    &quot;name&quot;: &quot;John Doe&quot;,    &quot;age&quot;: 42&#125;&#x27;&#x27;&#x27;\n\nJsonBuilder与StreamingJsonBuilder 在 Groovy 中创建 JSON可以通过 JsonBuilder 和 StreamingJsonBuilder 来在 Groovy 中创建 JSON\nGroovy Interacting with a SQL databaseGroovy 的 groovy-sql 模块比 Java 的 JDBC 提供了更高级别的抽象\n最常使用的 groovy-sql 类是 groovy.sql.Sql\ngroovy.sql.Sql 将 JDBC 抽象提升了一个级别\nConnecting to HSQLDBgroovy.sql.Sql 类的 newInstance 工厂方法接受这些参数来连接到数据库：\nimport groovy.sql.Sqldef url = &#x27;jdbc:hsqldb:mem:yourDB&#x27;def user = &#x27;sa&#x27;def password = &#x27;&#x27;def driver = &#x27;org.hsqldb.jdbcDriver&#x27;def sql = Sql.newInstance(url, user, password, driver)// use &#x27;sql&#x27; instancesql.close()\n\nConnecting to HSQLDB (withInstance variation)如果你不想手动处理资源（例如调用 close() 方法），可以使用 withInstance 方法： Sql.withInstance(url, user, password, driver) &#123; sql -&gt; &#125;\nConnecting to HSQLDB with a DataSourceimport groovy.sql.Sqlimport org.hsqldb.jdbc.JDBCDataSourcedef dataSource = new JDBCDataSource(    database: &#x27;jdbc:hsqldb:mem:yourDB&#x27;,     user: &#x27;sa&#x27;,     password: &#x27;&#x27;)def sql = new Sql(dataSource)// use then close &#x27;sql&#x27; instance ...\n\nConnecting to HSQLDB with a DataSource using Apache Commons DBCP使用连接池来连接数据库\n@Grab(&#x27;commons-dbcp:commons-dbcp:1.4&#x27;)import groovy.sql.Sqlimport org.apache.commons.dbcp.BasicDataSourcedef ds = new BasicDataSource(    driverClassName: &#x27;org.hsqldb.jdbcDriver&#x27;,    url: &#x27;jdbc:hsqldb:mem:yourDB&#x27;,    username: &#x27;sa&#x27;,    password: &#x27;&#x27;)def sql = new Sql(ds)   // 将 DataSource 传给 Sql\n\nConnecting using @Grab使用 @Grab 获取驱动类\n@Grab(&#x27;org.hsqldb:hsqldb:2.5.1&#x27;)@GrabConfig(systemClassLoader=true)// create, use, and then close sql instance ...\n\nThe @GrabConfig statement is necessary to make sure the system classloader is used.\nThis ensures that the driver classes and system classes like java.sql.DriverManager are in the same classloader.\nCreating tablessql.execute &#x27;&#x27;&#x27;    CREATE TABLE Author (        id          INTEGER GENERATED BY DEFAULT AS IDENTITY,        firstname   VARCHAR(64),        lastname    VARCHAR(64)    )&#x27;&#x27;&#x27;\n\nUsing DataSetsGroovy 提供了 groovy.sql.DataSet ，这个类增强了 groovy.sql.Sql，可以认为是一个迷你的 ORM 工具\n通过使用 POGO 字段和操作符去访问和查询数据库，而不是 JDBC 级别的 API 和关系型数据库的列名\n// groovy.sql.Sqldef qry = &quot;&quot;&quot;    SELECT * FROM Author    WHERE (firstname &gt; ?)    AND (lastname &lt; ?)    ORDER BY lastname DESC&quot;&quot;&quot;def params = [&#x27;Dierk&#x27;, &#x27;Pragt&#x27;]def result = sql.rows(qry, params)assert result*.firstname == [&#x27;Eric&#x27;, &#x27;Guillaume&#x27;, &#x27;Paul&#x27;]// groovy.sql.DataSet 写法def authorDS = sql.dataSet(&#x27;Author&#x27;)def result = authorDS.findAll &#123;it.firstname &gt; &#x27;Dierk&#x27;&#125;                        .findAll &#123;it.lastname &lt; &#x27;Pragt&#x27;&#125;                        .sort &#123;it.lastname&#125;                        .reverse()assert result.rows()*.firstname == [&#x27;Eric&#x27;, &#x27;Guillaume&#x27;, &#x27;Paul&#x27;]// Here we have a helper &quot;domain&quot; class:class Author &#123;    String firstname    String lastname&#125;\n\nDatabase access and manipulation involves creating or working with instances of the domain class.\nCreating and Inserting dataexecute 和 executeInsert 方法都可以在 SQL 语句中使用占位符 ?，然后传入 List 作为参数，在这种情况下，PreparedStatement 将会被使用来避免 SQL 注入问题\nexecute 和 executeInsert 方法都允许你使用 GString ，SQL 语句中的所有 &#39;$&#39; 都被认为是占位符\nReading rowssql.query(&#x27;SELECT firstname, lastname FROM Author&#x27;) &#123; resultSet -&gt;    while (resultSet.next()) &#123;        def first = resultSet.getString(1)        def last = resultSet.getString(&#x27;lastname&#x27;)        assert expected[rowNum++] == &quot;$first $last&quot;    &#125;&#125;\n\nsql.eachRow(&#x27;SELECT firstname, lastname FROM Author&#x27;) &#123; row -&gt;    def first = row[0]  // Groovy list-like notations    def last = row.lastname // Groovy map-like notations    assert expected[rowNum++] == &quot;$first $last&quot;&#125;\n\ndef first = sql.firstRow(&#x27;SELECT lastname, firstname FROM Author&#x27;)assert first.values().sort().join(&#x27;,&#x27;) == &#x27;Dierk,Koenig&#x27;\n\nList authors = sql.rows(&#x27;SELECT firstname, lastname FROM Author&#x27;)assert authors.size() == 3assert authors.collect &#123; &quot;$it.FIRSTNAME $&#123;it[-1]&#125;&quot; &#125; == expected\n\n// 读取取了别名的列值assert sql.firstRow(&#x27;SELECT COUNT(*) AS num FROM Author&#x27;).num == 3\n\nUpdating rows使用 execute 方法\nsql.execute &quot;INSERT INTO Author (lastname) VALUES (&#x27;Thorvaldsson&#x27;)&quot;sql.execute &quot;UPDATE Author SET firstname = &#x27;Erik&#x27; WHERE lastname = &#x27;Thorvaldsson&#x27;&quot;\n\nexecuteUpdate 方法返回被更新的记录的数量\ndef updateSql = &quot;UPDATE Author SET lastname=&#x27;Pragt&#x27; where lastname=&#x27;Thorvaldsson&#x27;&quot;def updateCount = sql.executeUpdate updateSqlassert updateCount == 1\n\nDeleting rows使用 execute 执行删除操作\nsql.execute &quot;DELETE FROM Author WHERE lastname = &#x27;Skeet&#x27;&quot;\n\nWorking with transactions使用 withTransactions 方法，传入一个 Closure ，在 Closure 中的逻辑就是事务控制的：\nsql.withTransaction &#123;    sql.execute &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Dierk&#x27;, &#x27;Koenig&#x27;)&quot;    sql.execute &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Jon&#x27;, &#x27;Skeet&#x27;)&quot;&#125;\n\nA failed transaction will cause a rollback:\ntry &#123;    sql.withTransaction &#123;        sql.execute &quot;INSERT INTO Author (firstname) VALUES (&#x27;Dierk&#x27;)&quot;        sql.eachRow &quot;SELECT firstname FROM Author WHERE firstname = &#x27;Dierk&#x27;&quot;,                    metaClosure,                    rowClosure        sql.execute &quot;INSERT INTO Author (firstname) VALUES (?)&quot;,                    &#x27;X&#x27; * (maxFirstnameLength + 1)    &#125;&#125; catch (ignore) &#123; println ignore.message &#125;\n\nUsing batches使用 withBatch 方法\nsql.withBatch(3) &#123; stmt -&gt;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Dierk&#x27;, &#x27;Koenig&#x27;)&quot;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Paul&#x27;, &#x27;King&#x27;)&quot;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Guillaume&#x27;, &#x27;Laforge&#x27;)&quot;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Hamlet&#x27;, &#x27;D&#x27;&#x27;Arcy&#x27;)&quot;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Cedric&#x27;, &#x27;Champeau&#x27;)&quot;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Erik&#x27;, &#x27;Pragt&#x27;)&quot;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Jon&#x27;, &#x27;Skeet&#x27;)&quot;&#125;\n\nBatching prepared statementsdef qry = &#x27;INSERT INTO Author (firstname, lastname) VALUES (?, ?)&#x27;sql.withBatch(3, qry) &#123;    ps.addBatch(&#x27;Dierk&#x27;, &#x27;Koenig&#x27;)    ps.addBatch(&#x27;Paul&#x27;, &#x27;King&#x27;)    ps.addBatch(&#x27;Guillaume&#x27;, &#x27;Laforge&#x27;)    ps.addBatch(&#x27;Hamlet&#x27;, &quot;D&#x27;Arcy&quot;)    ps.addBatch(&#x27;Cedric&#x27;, &#x27;Champeau&#x27;)    ps.addBatch(&#x27;Erik&#x27;, &#x27;Pragt&#x27;)    ps.addBatch(&#x27;Jon&#x27;, &#x27;Skeet&#x27;)&#125;\n\nLogging additional SQL informationimport java.util.logging.*// add fine loggingLogger.getLogger(&#x27;groovy.sql&#x27;).level = Level.FINE// also adjust logging.properties file in JRE_HOME/lib to hava: java.util.logging.ConsoleHandler.level = FINE\n\nPerforming paginationdef qry = &#x27;SELECT * FROM Author&#x27;assert sql.rows(qry, 1, 3)*.firstname == [&#x27;Dierk&#x27;, &#x27;Paul&#x27;, &#x27;Guillaume&#x27;]assert sql.rows(qry, 4, 3)*.firstname == [&#x27;Hamlet&#x27;, &#x27;Cedric&#x27;, &#x27;Erik&#x27;]assert sql.rows(qry, 7, 3)*.firstname == [&#x27;Jon&#x27;]\n\nUsing row metadatasql.eachRow(&quot;SELECT * FROM Author WHERE firstname = &#x27;Dierk&#x27;&quot;) &#123; row -&gt;    def md = row.getMetaData()    assert md.getTableName(1) == &#x27;AUTHOR&#x27;    assert (1..md.columnCount).collect &#123;md.getColumnName(it)&#125; == [&#x27;ID&#x27;, &#x27;FIRSTNAME&#x27;, &#x27;LASTNAME&#x27;]    assert (1..md.columnCount).collect &#123;md.getColumnTypeName(it)&#125; == [&#x27;INTEGER&#x27;, &#x27;VARCHAR&#x27;, &#x27;VARCHAR&#x27;]&#125;\n\nUsing row and metadata closuresdef metaClosure = &#123; meta -&gt; assert meta.getColumnName(1) == &#x27;FIRSTNAME&#x27; &#125;def rowClosure = &#123; row -&gt; assert row.FIRSTNAME == &#x27;Dierk&#x27; &#125;sql.eachRow(    &quot;SELECT firstname FROM Author WHERE firstname = &#x27;Dierk&#x27;&quot;,    metaClosure,    rowClosure)\n\nUsing connection metadatadef md = sql.connection.metaDataassert md.driverName == &#x27;HSQL Database Engine Driver&#x27;assert md.databaseProductVersion == &#x27;2.5.1&#x27;assert [&#x27;JDBCMajorVersion&#x27;, &#x27;JDBCMinorVersion&#x27;].collect &#123;md[it]&#125; == [4,2]assert md.stringFunctions.tokenize(&#x27;,&#x27;).contains(&#x27;CONCAT&#x27;)def rs = md.getTables(null, null, &#x27;AUTH%&#x27;, null)assert rs.next()assert rs.getString(&#x27;TABLE_NAME&#x27;) == &#x27;AUTHOR&#x27;\n\nNamed parameters (colon form) 入参冒号命名方式:参数名 的形式:\nsql.execute &quot;INSERT INTO Author (firstname, lastname) VALUES (:first, :last)&quot;,            first: &#x27;Dierk&#x27;,            last: &#x27;Koenig&#x27;\n\nNamed parameters (question mark form) 入参问号命名方式?.参数名 的形式\nsql.execute &quot;INSERT INTO Author (firstname, lastname) VALUES (?.first, ?.last)&quot;,            first: &#x27;Dierk&#x27;,            last: &#x27;Koenig&#x27;\n\nNamed-ordinal parameters 入参问号逗号命名方式?1.参数名,?2.参数名 的形式\nclass Rockstar &#123; String first, last &#125;def pogo = new Rockstar(first: &#x27;Paul&#x27;, last: &#x27;McCartney&#x27;)def map = [lion: &#x27;King&#x27;]sql.execute &quot;INSERT INTO Author (firstname, lastname) VALUES (?1.first, ?2.lion)&quot;,            pogo,            map\n\n?1.first : 1 代表第一个参数 pogo\n?2.lion : 2 代表第二个参数 map\n","categories":["Groovy"],"tags":["Groovy"]},{"title":"Groovy Lists","url":"/groovy/groovy-lists/","content":"Groovy ListsGroovy 使用中括号 [] 包围的逗号 , 分隔的值列表来表示列表\nGroovy 的列表是 java.util.List，Groovy 没有定义自己的集合类型\n默认的字面量列表类型是 java.util.ArrayList\ndef numbers = [1, 2, 3]         // 1assert numbers instanceof List  // 2assert numbers.size() == 3      // 3\n\n1 : 通过 [值, 值, 值] 的形式声明一个列表2 : 列表是 java.util.List 接口的实例3 : 调用 java.util.List 的 size() 方法\n\n可以创建一个元素类型不相同的列表：\ndef heterogeneous = [1, &quot;a&quot;, true]\n\n\n通过使用 as 操作符，或使用明确的类型声明来使用不同类型的列表：\ndef arrayList = [1, 2, 3]assert arrayList instanceof java.util.ArrayListdef linkedList = [2, 3, 4] as LinkedList        // 1assert linkedList instanceof java.util.LinkedListLinkedList otherLinked = [3, 4, 5]              // 2assert otherLinked instanceof java.util.LinkedList\n\n1 : 通过使用 as 操作符指定一个明确的 java.util.LinkedList 类型来进行类型强转2 : 使用明确的变量类型声明来指定列表的类型\n\n通过下标操作符 [] 可以进行如下操作：\n\n\n\nname\nmeaning\n\n\n\n赋值\nletters[0] = &#39;c&#39;\n\n\n将值附加到列表末尾\nletters &lt;&lt; &#39;e&#39;\n\n\n使用负数下标访问倒数第一个元素\nletters[-1] == &#39;e&#39;\n\n\n使用负数下标访问倒数第二个元素\nletters[-2] == &#39;e&#39;\n\n\n使用逗号分隔同时访问多个下标的元素\nletters[1, 3] == [&#39;b&#39;, &#39;d&#39;]\n\n\n使用 Range 进行范围访问\nletters[2..4] == [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]\n\n\n","categories":["Groovy"],"tags":["Groovy"]},{"title":"Groovy Maps","url":"/groovy/groovy-maps/","content":"Groovy Maps默认的 Map 字面量是 java.util.LinkedHashMap 类型\ndef colors = [red: &#x27;#FF0000&#x27;, green: &#x27;#00F00&#x27;, blue: &#x27;#0000FF&#x27;]     // 1assert colors[&#x27;red&#x27;] == &#x27;#FF0000&#x27;                                   // 2assert colors.green == &#x27;#00FF00&#x27;                                    // 3colors[&#x27;pink&#x27;] = &#x27;#FF00FF&#x27;                                          // 4colors.yellow = &#x27;#FFFF00&#x27;                                           // 5assert colors instanceof java.util.LinkedHashMap                    // 6\n\n1 : 定义一个 Map2 : 使用下标符号访问 key 对应的值3 : 使用属性符号访问 key 对应的值4 : 使用下标符号修改 key 对应的值5 : 使用属性符号修改 key 对应的值6 : 默认的 Map 字面量是 java.util.LinkedHashMap 类型\n\n如果访问的 key 在 Map 中不存在，将会返回 null : assert colors.unknown == null\n\n定义空 Map : def emptyMap = [:]\n\ndef key = &#x27;name&#x27;def person = [key: &#x27;Guillaume&#x27;]             // 1assert person.containsKey(&#x27;name&#x27;) == falseassert person.containsKey(&#x27;key&#x27;)  == true\n\n1 : The key associated with the &#39;Guillaume&#39; name will actually be the &quot;key&quot; string, not the value associated with the key variable\n当使用的 String 类型 key 包含特殊字符的时候，必须使用双引号将 key 包围起来: [&quot;street-name&quot;: &quot;Main street&quot;]\n如果你需要将变量值作为 key 传递给 Map 的声明，可以使用 () 将变量或表达式包住：\ndef key = &#x27;name&#x27;def person = [(key): &#x27;Guillaume&#x27;]assert person.containsKey(&#x27;name&#x27;) == trueassert person.containsKey(&#x27;key&#x27;)  == false\n\n\ndef key = &#x27;name&#x27;def person = [:]assert person.size() == 0person.key = &#x27;linweiyu&#x27;assert person.containsKey(&#x27;key&#x27;)println person                      // 输出: [key:linweiyu]person = [:]person.(key) = &#x27;Christy&#x27;            // 这样才能将变量值传递给 Mapassert person.containsKey(&#x27;name&#x27;)println person                      // 输出: [name:Christy]\n","categories":["Groovy"],"tags":["Groovy"]},{"title":"Groovy Shebang line","url":"/groovy/groovy-shebang-line/","content":"Groovy Shebang line使用 Groovy 编写类似 Bash 的脚本\n#!/usr/bin/env groovyprintln &quot;Hello from the shebang line&quot;\n\n# 运行./hello_world_from_groovy.sh\n","categories":["Groovy"],"tags":["Groovy"]},{"title":"Kubernetes 上的基于 Micronaut 的云原生项目","url":"/wingman/micronaut-istio-k8s-gitops/","content":"介绍本项目使用的是一台 Intel NUC 8 主机：\n\nCPU：i5-8260U 4C8T\nMemory：64GB\nOS：Ubuntu 22.04\n\n本项目所有应用、服务均部署于 Kubernetes 集群中，使用 Helm 或 Operator 或 Kustomize 的形式安装、部署。\nMicronautMicronaut 为 JVM 平台上新一代的 IoC 框架，同时支持 Java、Groovy、Kotlin 编程语言，使用编译时进行依赖注入的实现，实现运行时的快速启动、低内存消耗。\n本项目使用 Micronaut 作为微服务基础框架，Groovy 作为开发语言。将 Project Reactor 用于 HTTP Server 和数据库访问操作，实现全面的响应式编程。\n以 Micronaut 为中心，接入了以下服务、工具：\n\nKeycloak：认证与鉴权服务，实现统一登录\nJaeger：分布式跟踪\nPrometheus：用于应用运行监测\nFlyway：数据库模式与数据版本跟踪\nR2dbc：响应式关系数据库访问操作\nElasticsearch：全文搜索数据库与应用日志存储\n\nGitOps以 GitLab 为中心，通过 Merge Request 事件通知 Tekton。\nTekton 作为云原生的流水线工具，在 Kubernetes 中启动 Pod 来执行应用测试、打包、部署等任务，具有良好的可扩展性，健壮性等。\n通过 ArgoCD 与 Kustomize，将应用的声明式配置自动持续部署到 Kubernetes 集群中，避免了人工手动部署的不确定性，通过声明式配置，降低了持续部署的复杂性。\nIstio通过 Istio 服务网格，为应用提供云原生的微服务能力。\n为应用提供流量管理，安全管控，可观测性。\nObservability使用 Prometheus 采集应用指标。\n使用 Jaeger 分布式跟踪微服务。\n使用 Fluent-bit 采集应用日志并转发至 Elasticsearch\nFlink CDC使用 Flink CDC 读取 MySQL binlog，将数据实时处理并存储至 Elasticsearch。\n将应用中需要多表关联全文检索的操作转移到 Elasticsearch 中。\n架构图\n","categories":["Kubernetes"],"tags":["Micronaut","Kubernetes","Istio","GitOps","云原生"]},{"title":"Compose file deploy reference","url":"/docker/compose/compose-file-deploy-reference/","content":"\n\n\nDefinitions (定义)\nendpoint_mode\nlabels\nmode\nplacement\nconstraints\npreferences\n\n\nreplicas\nresources\ncpus\nmemory\npids\ndevices\n\n\nrestart_policy\nrollback_config\nupdate_config\n\n\n\n\n\n支持应用程序模型部署的 Compose 实现可能需要一些额外的元数据，因为 Compose 应用程序模型过于抽象，无法反映每个服务的实际基础架构需求或生命周期约束\nCompose 规范部署允许用户在 service 上声明额外的元数据，以便 Compose 实现获取相关数据以在平台上分配足够的资源并配置它们以满足用户的需求\nDefinitions (定义)Compose 规范被扩展以支持关于服务的可选 deploy 小节。 本节定义服务的运行时要求\nendpoint_modeendpoint_mode 为连接到服务的外部客户端指定服务发现方法。 默认值和可用值是特定于平台的，无论如何 Compose 规范定义了两个规范值:\n\nendpoint_mode: vip: 为服务分配一个虚拟 IP (VIP)，作为客户端访问网络上的服务的前端。 平台在客户端和运行服务的节点之间路由请求，而客户端不知道有多少节点参与服务或其 IP 地址或端口\nendpoint_mode: dnsrr: 平台为服务设置 DNS 条目，以便对服务名称的 DNS 查询返回 IP 地址列表（DNS 循环），客户端直接连接到其中一个\n\nservices:  frontend: awesome/webapp  ports:    - &quot;8080:80&quot;  deploy:    mode: replicated    replicas: 2    endpoint_mode: vip\n\nlabels服务的 labels 元数据。 这些 labels 必须只设置在服务上，而不是服务的任何容器上。 这假设平台有一些可以匹配 Compose 应用程序模型的本地 “service” 概念\nservices:  frontend:    image: awesome/webapp    deploy:      labels:        com.example.description: &quot;This is label will appear on the web service&quot;\n\nmodemode 定义了用于在平台上运行服务的复制模型。 global（每个物理节点只有一个容器）或 replicated（指定数量的容器）。 默认为 replicated\nservices:  frontend:    image: awesome/webapp    deploy:      mode: global\n\nplacementplacement 指定平台选择物理节点来运行服务容器的约束和偏好\nconstraintsconstraints 定义了平台节点必须满足才能运行服务容器的必需属性。 可以通过列表或带有字符串值的映射设置\nservices:  frontend:    image: awesome/webapp    deploy:      placement:        constraints:          disktype: ssd\n\nservices:  frontend:    image: awesome/webapp    deploy:      placement:        constraints:          - disktype=ssd\n\npreferencespreferences 定义了平台节点应该满足以运行服务容器的属性。 可以通过列表或带有字符串值的映射设置\nservices:  frontend:    image: awesome/webapp    deploy:      placement:        preferences:          datacenter: us-east\n\nservices:  frontend:    image: awesome/webapp    deploy:      placement:        constraints:          - datacenter=us-east\n\nreplicas如果服务是 replicated（这是默认值），replicas 指定在任何给定时间应该运行的容器数量\nservices:  frontend:    image: awesome/webapp    deploy:      mode: replicated      replicas: 6\n\nresourcesresources 配置容器在平台上运行的物理资源约束。 这些约束可以配置为:\n\nlimits: 平台必须阻止容器分配更多\nreservations: 平台必须保证容器至少可以分配配置的数量\n\nservices:  frontend:    image: awesome/webapp    deploy:      resources:        limits:          cpus: &#x27;0.50&#x27;          memory: 50M          pids: 1        reservations:          cpus: &#x27;0.25&#x27;          memory: 20M\n\ncpuscpus 为容器可以使用多少可用 CPU 资源（作为核心数）配置限制或预留\nmemorymemory 配置容器可以分配的内存量的限制或保留，设置为表示字节值的字符串\npidspids 调整容器的 PID 限制，设置为整数\ndevicesdevices 配置容器可以使用的 reservations 设备。 它包含一个 reservations 列表，每个都设置为具有以下参数的对象：capabilities、driver、count、device_ids 和 options\n使用功能列表保留设备，使 capabilities 成为唯一必填字段。 设备必须满足成功预订所需的所有功能\nrestart_policyrestart_policy 配置是否以及如何在容器退出时重新启动容器。 如果 restart_policy 未设置，Compose 实现必须考虑服务配置设置的 restart 字段\n\ncondition: none,on-failure,any 中的一个 (默认为 any)\ndelay: 尝试重新启动之间的等待时间，指定为持续时间（默认值：0）。\nmax_attempts: 在放弃之前尝试重新启动容器的次数（默认值：一直不放弃）。 如果在配置的 window 内重启没有成功，则此尝试不计入配置的 max_attempts 值。 例如，如果max_attempts 设置为 “2”，并且第一次尝试重新启动失败，则必须尝试两次以上的重新启动\nwindow: 在决定重启是否成功之前等待多长时间，指定为持续时间（默认值：立即决定）\n\nservices:  frontend:    image: awesome/webapp    deploy:      restart_policy:        condition: on-failure        delay: 5s        max_attempts: 3        window: 120s\n\nrollback_configrollback_config 配置在更新失败的情况下如何回滚服务\n\nparallelism: 一次回滚的容器数。 如果设置为 0，所有容器同时回滚\ndelay: 每个容器组回滚之间的等待时间（默认 0s）\nfailure_action: 如果回滚失败怎么办。 continue 或 pause 之一（默认为 pause）\nmonitor: 每次任务更新后监控失败的持续时间（ns|us|ms|s|m|h）（默认 0s）\nmax_failure_ratio: 回滚期间容忍的失败率（默认 0）\norder: 回滚期间的操作顺序。 stop-first（旧任务在开始新任务之前停止）或 start-first（新任务首先启动，正在运行的任务短暂重叠）之一（默认为 stop-first ）\n\nupdate_configupdate_config 配置应该如何更新服务。 用于配置滚动更新\n\nparallelism: 一次更新的容器数\ndelay: 更新一组容器之间的等待时间\nfailure_action: 如果更新失败怎么办。 continue、rollback 或 pause 之一（默认值：pause）\nmonitor: 每次任务更新后监控失败的持续时间（ns|us|ms|s|m|h&#96;）（默认 0s）\nmax_failure_ratio: 更新期间容忍的失败率\norder: 更新期间的操作顺序。 stop-first（旧任务在开始新任务之前停止）或 start-first（新任务首先启动，正在运行的任务短暂重叠）之一（默认为 stop-first ）\n\nservices:  frontend:    image: awesome/webapp    deploy:      parallelism: 2      delay: 10s      order: stop-first\n","categories":["Docker - Compose"],"tags":["Docker","Notes","Docker Compose"]},{"title":"Compose specification 总结","url":"/docker/compose/compose-specification-summary/","content":"\n\n\nservices 下常用元素\nCompose 文件\n\n\n\nservices 下常用元素\nbuild\n指定用于从源创建容器镜像的构建配置\n\n\ncommand\n覆盖容器镜像（即 Dockerfile 的 CMD）声明的默认命令\n\n\ncontainer_name\n自定义容器名称的字符串\n\n\ndepends_on\n表示服务之间的启动和关闭依赖关系\ncondition\nservice_started\nservice_healthy\nservice_completed_successfully\n\n\n\n\nentrypoint\n覆盖 Docker 映像的默认 entrypoint\n\n\nenvironment\n定义容器中设置的环境变量\n\n\nexpose\n定义 Compose 实现必须从容器公开的端口。 这些端口必须可供链接的服务访问，并且不应发布到宿主机。 只能指定内部容器端口\n\n\nextends\n在当前文件或另一个文件中继承另一个服务，可选择地覆盖配置\n\n\nextra_hosts\n将主机名映射添加到容器网络接口配置\n\n\nhealthcheck\n声明运行检查以确定该服务的容器是否 “healthy”\n\n\nhostname\n声明用于服务容器的自定义主机名\n\n\nimage\n指定启动容器的镜像\n\n\ninit\n在容器内运行一个 init 进程 (PID 1) 来转发信号并获取进程. 将此选项设置为 true 以为服务启用此功能\n\n\nlabels\n将元数据添加到容器\n\n\nlogging\n定义服务的日志配置\n\n\nnetwork_mode\n设置服务容器网络模式\n\n\nnetworks\n定义服务容器附加到的网络\n\n\nports\n暴露容器端口\n\n\nprofiles\n定义了要启用的服务的命名配置文件列表\n\n\npull_policy\n定义 Compose 实现在开始拉取镜像时将做出的决定\n\n\nread_only\n将服务容器配置为使用只读文件系统创建\n\n\nrestart\n定义了平台将在容器终止时应用的策略\n\n\ntmpfs\n在容器内挂载一个临时文件系统\n\n\ntty\n配置服务容器以使用 TTY 运行\n\n\nuser\n覆盖用于运行容器进程的用\n\n\nvolumes\n定义了服务容器必须可以访问的挂载宿主机路径或命名卷\n\n\n\nCompose 文件services:  service-one:    # 指定用于从源创建容器镜像的构建配置    build: .    # 只要声明了 `build` 部分，就可以从 Compose 文件中省略 `image`    # 指定启动容器的镜像    image: redis    image: redis:5    image: redis@sha256:0ed5d5928d4737458944eb604cc8509e245c3e19d02ad83935398bc4b991aac7    image: library/redis    image: docker.io/library/redis    image: my_private.registry:5000/redis    # 定义 Compose 实现在开始拉取镜像时将做出的决定    pull_policy: always 或 never 或 missing 或 build    # 覆盖容器镜像（即 Dockerfile 的 CMD）声明的默认命令    command: bundle exec thin -p 3000    command: [ &quot;bundle&quot;, &quot;exec&quot;, &quot;thin&quot;, &quot;-p&quot;, &quot;3000&quot; ]      # 指定自定义容器名称的字符串，而不是生成的默认名称    container_name: my-web-container    # 表示服务之间的启动和关闭依赖关系    depends_on:      - db      - redis    depends_on:      db:        condition: service_healthy      redis:        condition: service_started      cache:        condition: service_completed_successfully        # 覆盖 Docker 映像的默认 entrypoint    entrypoint: /code/entrypoint.sh    entrypoint:      - php      - -d      - zend_extension=/usr/local/lib/php/extensions/no-debug-non-zts-20100525/xdebug/so      - -d      - memory_limit=-1      - vendor/bin/phpunit        # 定义容器中设置的环境变量    environment:      RACK_ENV: development      SHOW: &quot;true&quot;      USER_INPUT:    environment:      - RACK_ENV=development      - SHOW=true      - USER_INPUT          # 定义 Compose 实现必须从容器公开的端口。 这些端口必须可供链接的服务访问，并且不应发布到宿主机。 只能指定内部容器端口    expose:      - &quot;3000&quot;      - &quot;8000&quot;    # 在当前文件或另一个文件中继承另一个服务    extends:      file: common.yml      service: webapp    # 将主机名映射添加到容器网络接口配置    extra_hosts:      - &quot;somehost:162.242.195.82&quot;      - &quot;otherhost:50.31.209.229&quot;    # 声明运行检查以确定该服务的容器是否 “healthy”    healthcheck:      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;]      interval: 1m30s      timeout: 10s      retries: 3      start_period: 40s      disable: false    # 声明用于服务容器的自定义主机名    hostname: shit    # 在容器内运行一个 init 进程 (PID 1) 来转发信号并获取进程    init: true    # 将元数据添加到容器    labels:      com.example.description: &quot;Accounting webapp&quot;      com.example.department: &quot;Finance&quot;      com.example.label-with-empty-value: &quot;&quot;    labels:      - &quot;com.example.description=Accounting webapp&quot;      - &quot;com.example.department=Finance&quot;      - &quot;com.example.label-with-empty-value&quot;    # 定义服务的日志配置    logging:      driver: syslog      options:        syslog-address: &quot;tcp://192.168.0.42:123&quot;    # 设置服务容器网络模式    network_mode: &quot;host&quot;    network_mode: &quot;none&quot;    network_mode: &quot;service: [service name]&quot;        # 定义服务容器附加到的网络    networks:      - compose-test        # 暴露容器端口. 端口映射不得与 network_mode: host 一起使用，这样做必须导致运行时错误    ports:      - &quot;3000&quot;      - &quot;3000-3005&quot;      - &quot;8000:8000&quot;      - &quot;9090-9091:8080-8081&quot;      - &quot;49100:22&quot;      - &quot;127.0.0.1:8001:8001&quot;      - &quot;127.0.0.1:5000-5010:5000-5010&quot;      - &quot;6060:6060/udp&quot;    ports:      - target: 80        host_ip: 127.0.0.1        published: 8080        protocol: tcp        mode: host      - target: 80        host_ip: 127.0.0.1        published: 8000-9000        protocol: tcp        mode: host      # 将服务容器配置为使用只读文件系统创建    read_only: true    # 定义了平台将在容器终止时应用的策略    restart: &quot;no&quot;    restart: always    restart: on-failure    restart: unless-stopped    # 在容器内挂载一个临时文件系统    tmpfs: /run    tmpfs:      - /run      - /tmp    # 配置服务容器以使用 TTY 运行    tty    # 覆盖用于运行容器进程的用户    user: linweiyu    # 定义了服务容器必须可以访问的挂载宿主机路径或命名卷    volumes:      - type: volume        source: db-data        target: /data        volume:          nocopy: true      - type: build        source: /var/run/postgres/postgres.sock        target: /var/run/postgres/postgres.sock  service-two:    image: service-two:latest    networks:      - compose-test    profiles:      - debugnetworks:  compose-test:volumes:  db-data:\n","categories":["Docker - Compose"],"tags":["Docker","Notes","Docker Compose"]},{"title":"Compose specification","url":"/docker/compose/compose-specification/","content":"\n\n\nCompose file (Compose 文件)\nProfiles (配置)\nIllustrative example (示例说明)\n\n\nVersion top-level element (顶级元素 version)\nName top-level element (顶级元素 name)\nServices top-level element (顶级元素 services)\nbuild\nblkio_config\ncpu_count\ncpu_percent\ncpu_shares\ncpu_period\ncpu_quota\ncpu_rt_runtime\ncpu_rt_period\ncpus\ncpuset\ncap_add\ncap_drop\ncgroup_parent\ncommand\nconfigs\nShort syntax\nLong syntax\n\n\ncontainer_name\ncredential_spec\nExample gMSA configuration\n\n\ndepends_on\nShort syntax\nLong syntax\n\n\ndeploy\ndevice_cgroup_rules\ndevices\ndns\ndns_opt\ndns_search\ndomainname\nentrypoint\nenv_file\nEnv_file format\n\n\nenvironment\nexpose\nextends\nRestrictions\nFinding referenced service\nMerging service definitions\nMappings\nSequences\nScalars\n\n\n\n\nexternal_links\nextra_hosts\ngroup_add\nhealthcheck\nhostname\nimage\ninit\nipc\nisolation\nlabels\nlinks\nlogging\nnetwork_mode\nnetworks\naliases\nipv4_address, ipv6_address\nlink_local_ips\npriority\n\n\nmac_address\nmem_limit\nmem_reservation\nmem_swappiness\nmemswap_limit\noom_kill_disable\noom_score_adj\npid\npids_limit\nplatform\nports\nShort syntax\nLong syntax\n\n\nprivileged\nprofiles\npull_policy\nread_only\nrestart\nruntime\nscale\nsecrets\nShort syntax\nLong syntax\n\n\nsecurity_opt\nshm_size\nstdin_open\nstop_grace_period\nstop_signal\nstorage_opt\nsysctls\ntmpfs\ntty\nulimits\nuser\nuserns_mode\nvolumes\nShort syntax\nLong syntax\n\n\nvolumes_from\nworking_dir\n\n\nNetworks top-level element (顶级元素 networks)\ndriver\nhost or none\n\n\ndriver_opts\nattachable\nenable_ipv6\nipma\ninternal\nlabels\nexternal\nname\n\n\nVolumes top-level element (顶级元素 volumes)\ndriver\ndriver_opts\nexternal\nlabels\nname\n\n\nConfigs top-level element (顶级元素 configs)\nSecrets top-level element (顶级元素 secrets)\nFragments (分段)\nExtension (扩展)\nInformative Historical Notes\nUsing extensions as fragments\nspecifying byte values\nspecifying durations\n\n\nInterpolation (插值)\n参考\n\n\n\nCompose 文件是一个为 Docker 应用程序定义服务, 网络和卷的 YAML 文件\n只有 volumes 可以配置为读写访问. secrets 和 configs 都是只读的\nsecrets 和 configs 可以使用 external: true 来声明它们不是作为应用程序生命周期的一部分来管理的\nCompose file (Compose 文件)Compose file 是一个定义 version(已弃用),services(必选),networks,volumes,configs和secrets 的 YAML 文件\n在工作目录中, Compose 文件的默认路径是 compose.yaml(推荐) 或 compose.yml\n为了向后兼容, Compose 实现要支持 docker-compose.yaml 和 docker-compose.yml\n如果两种文件都存在, 优先使用 compose.yaml\n多个 Compose 文件可以结合在一起来定义应用程序模型\nProfiles (配置)Profiles 允许为多种用途和多种环境调整 Compose 应用模型\n顶级元素 services 支持 profiles 属性来定义一个命名的 profiles 列表\n如果没有与列表中任何一个 profiles 匹配, 那么一个 service 必须被 Compose 实现忽略, 除非这个 service 在命令中明确指定了\n其他所有顶级元素不受 profiles 影响且总是激活的\nIllustrative example (示例说明)services:  foo:    image: foo  bar:    image: bar    profiles:      - test  baz:    image: baz    depends_on:      - bar    profiles:      - test  zot:    image: zot    depends_on:      - bar    profiles:      - debug\n\nVersion top-level element (顶级元素 version)顶级属性 version 由规范定义, 用于向后兼容, 仅提供信息\nName top-level element (顶级元素 name)顶级属性 name 属性由规范定义, 如果用户没有指定明确的名称, 则作为项目名称\n无论是否通过 name 设置了项目名称, 它必须要暴露给插值机制且可以作为环境变量 COMPOSE_PROJECT_NAME 进行解析\nservices:  foo:    image: busybox    environment:      - COMPOSE_PROJECT_NAME    command: echo &quot;I&#x27;m running $&#123;COMPOSE_PROJECT_NAME&#125;&quot;\n\nServices top-level element (顶级元素 services)service 是应用程序中计算资源的抽象定义, 可以独立于其他组件进行扩展&#x2F;替换\n一个 Compose 文件必须声明一个根元素 services 作为一个 map, 这个 map 的 keys 都是代表 service 名称的字符串, values 是 service 定义\nservice 定义包含应用于为该 service 启动的每个容器的配置\n每个 service 应该还要包含一个构建部分, 这个构件部分定义了怎样为 service 创建 Docker 镜像\n每个 service 定义运行时约束和要求来运行其容器. deploy 部分对这些约束进行分组, 并允许平台调整部署策略以最佳匹配容器的需求和可用资源\nbuildbuild 指定用于从源创建容器镜像的构建配置, 正如 Build support 文档中的定义\nblkio_configblkio_config 定义了一组配置选项来为 service 设置阻塞 IO 限制\nservices:  foo:    image: busybox    blkio_config:      weight: 300      weight_device:        - path: /dev/sda          weight: 400      device_read_bps:        - path: /dev/sdb          rate: &#x27;12mb&#x27;      device_read_iops:        - path: /dev/sdb          rate: 120      device_write_bps:        - path: /dev/sdb          rate: &#x27;1024k&#x27;      device_write_iops:        - path: /dev/sdb          rate: 30\n\n支持如下配置项:\n\ndevice_read_bps, device_write_bps\ndevice_read_iops, device_write_iops\nweight\nweight_device\n\ncpu_count定义服务容器的可用 CPU 数量\ncpu_percent定义可用 CPU 的可用百分比\ncpu_shares定义（作为整数值）服务容器相对于其他容器的 CPU 权重\ncpu_period当平台基于 Linux 内核时，允许 Compose 实现配置 CPU CFS（完全公平调度器）周期\ncpu_quota当平台基于 Linux 内核时，允许 Compose 实现配置 CPU CFS（完全公平调度器）配额\ncpu_rt_runtime为支持实时调度程序的平台配置 CPU 分配参数。 可以是使用微秒为单位的整数值，也可以是持续时间\ncpu_rt_runtime: &#x27;400ms&#x27;cpu_rt_runtime: 95000\n\ncpu_rt_period为支持实时调度程序的平台配置 CPU 分配参数。 可以是使用微秒为单位的整数值，也可以是持续时间\ncpu_rt_peroid: &#x27;1400us&#x27;cpu_rt_peroid: 11000\n\ncpus已废弃. 使用 deploy.reservations.cpus\ncpuset定义允许执行的指定 CPU。 可以是范围 0-3 或列表 0,1\ncap_add将其他容器功能指定为字符串\ncap_add:  - ALL\n\ncap_drop指定要作为字符串删除的容器功能\ncap_drop:  - NET_ADMIN  - SYS_ADMIN\n\ncgroup_parent为容器指定一个可选的父 cgroup\ncgroup_parent: m-executor-abcd\n\ncommand覆盖容器镜像（即 Dockerfile 的 CMD）声明的默认命令\ncommand: bundle exec thin -p 3000\n\n命令可以是一个列表, 以类似 Dockerfile 的方式:\ncommand: [ &quot;bundle&quot;, &quot;exec&quot;, &quot;thin&quot;, &quot;-p&quot;, &quot;3000&quot; ]\n\nconfigsconfigs 使用 per-service configs 配置在每个服务的基础上授予对配置的访问权限。 支持两种不同的语法变体\nShort syntax短语法变体仅指定配置名称。这将授予容器对配置的访问权限并将其安装在容器内的 /&lt;config_name&gt; 处。源名称和目标挂载点都设置为配置名称。\nservices:  redis:    image: redis:latest    configs:      - my_configconfigs:  my_config:    file: ./my_config.txt  my_other_config:    external: true\n\nLong syntax长语法为如何在服务的任务容器中创建配置提供了更多粒度\n\nsource\ntarget\nuid 和 gid\nmode\n\nservices:  redis:    image: redis:latest    configs:      - source: my_config        target: /redis_config        uid: &quot;103&quot;        gid: &quot;103&quot;        mode: 0440configs:  my_config:    external: true  my_other_config:    external: true\n\n您可以授予服务访问多个配置的权限，并且可以混合使用长语法和短语法\ncontainer_name指定自定义容器名称的字符串，而不是生成的默认名称\ncontainer_name: my-web-container\n\n如果提供了, container_name 应该遵循这样的正则表达式: [a-zA-Z0-9][a-zA-Z0-9_.-]+\ncredential_spec为托管服务帐户配置凭据规范\ncredential_spec 必须是 file://&lt;filename&gt; 或 registry://&lt;value-name&gt; 的格式\ncredential_spec:  file: my-credential-spec.json\n\ncredential_spec:  registry: my-credential-spec\n\nExample gMSA configuration为服务配置 gMSA 凭证规范时，只需使用 config 指定凭证规范\nservices:  myservice:    image: myimage:latest    credential_spec:      config: my_credential_specconfigs:  my_credentials_spec:    file: ./my-credential-spec.json|\n\ndepends_on表示服务之间的启动和关闭依赖关系\nShort syntax短语法变体仅指定依赖项的服务名称\nservices:  web:    build: .    depends_on:      - db      - redis  redis:    image: redis  db:    image: postgres\n\ndb 和 redis 在 web 之前被创建. 以容器的 “ready” 状态来判断被依赖的容器是否就绪\nweb 在 db 和 redis 之前被删除\nLong syntax启用无法以简短形式表达的附加字段的配置\n\ncondition\nservice_started\nservice_healthy\nservice_completed_successfully\n\n\n\nservices:  web:    build: .    depends_on:      db:        condition: service_healthy      redis:        condition: service_started  redis:    image: redis  db:    image: postgres\n\ndb 和 redis 在 web 之前被创建. 以容器的 “healthy” 状态来判断被依赖的容器是否就绪\nweb 在 db 和 redis 之前被删除\ndeploy指定服务的部署和生命周期的配置，如此处所定义\ndevice_cgroup_rules为此容器定义设备 cgroup 规则列表。 格式与Linux内核在Control Groups Device Whitelist Controller中指定的格式相同\ndevice_cgroup_rules:  - &#x27;c 1:3 mr&#x27;  - &#x27;a 7:* rmw&#x27;\n\ndevices以 HOST_PATH:CONTAINER_PATH[:CGROUP_PERMISSIONS]的形式为创建的容器定义设备映射列表\ndevices:  - &quot;/dev/ttyUSB0:/dev/ttyUSB0&quot;  - &quot;/dev/sda:/dev/xvda:rwm&quot;\n\ndns定义要在容器网络接口配置上设置的自定义 DNS 服务器。 可以是单个值或列表\ndns: 8.8.8.8\n\ndns:  - 8.8.8.8  - 9.9.9.9\n\ndns_opt列出要传递给容器的 DNS 解析器的自定义 DNS 选项（Linux 上的 /etc/resolv.conf 文件）\ndns_opt:  - use-vc  - no-tld-query\n\ndns_search定义自定义 DNS 搜索域以在容器网络接口配置上设置。 可以是单个值或列表\ndns_search: example.com\n\ndns_search:  - dc1.example.com  - dc2.example.com\n\ndomainname声明用于服务容器的自定义域名。 必须是有效的 RFC 1123 主机名\nentrypoint覆盖 Docker 映像的默认 entrypoint（即 Dockerfile 设置的 entrypoint）\n当 entrypoint 由 Compose 文件配置时，Compose 实现必须清除 Docker 镜像上的任何默认命令 - Dockerfile 中的 ENTRYPOINT 和 CMD 指令\n如果还设置了 command，则将其用作 entrypoint 的参数，以替代 Docker 镜像的 CMD\nentrypoint: /code/entrypoint.sh\n\nentrypoint 也可以是一个列表，方式类似于 Dockerfile:\nentrypoint:  - php  - -d  - zend_extension=/usr/local/lib/php/extensions/no-debug-non-zts-20100525/xdebug/so  - -d  - memory_limit=-1  - vendor/bin/phpunit\n\nenv_file根据文件内容向容器添加环境变量\nenv_file: .env\n\nenv_file 也可以是一个列表。 列表中的文件必须自上而下处理。 对于两个 env 文件中指定的相同变量，列表中最后一个文件的值必须保持不变\nenv_file:  - ./a.env  - ./b.env\n\n必须从 Compose 文件的父文件夹解析相对路径\n由于绝对路径会阻止 Compose 文件的可移植性，因此 Compose 实现应该在使用此类路径设置 env_file 时警告用户\n在 environment 部分中声明的环境变量必须覆盖这些值 — 即使这些值为空或未定义也是如此\nEnv_file formatenv 文件中的每一行必须是 VAR[=[VAL]] 格式\n必须忽略以 # 开头的行。 空行也必须被忽略\nVAL 的值用作原始字符串，不作任何修改。 如果值被引号包围（这通常是 shell 变量的情况），引号必须包含在传递给由 Compose 实现创建的容器的值中\nVAL 可以省略，在这种情况下，变量值是空字符串。 =VAL 可以省略，在这种情况下，变量是未设置 (unset) 的\n# Set Rails/Rack environmentRACK_ENV=developmentVAR=&quot;quoted&quot;\n\nenvironment定义容器中设置的环境变量\nenvironment 可以使用数组或 map。 任何布尔值； true, false, yes, no, 应该用引号括起来以确保它们不会被 YAML 解析器转换为 True 或 False\nenvironment 可以由单个键声明（等号没有值）。 在这种情况下，Compose 实现应该依赖一些用户交互来解析值。 如果没有，则该变量未设置 (unset) 并将从服务容器环境中删除\nMap 语法:\nenvironment:  RACK_ENV: development  SHOW: &quot;true&quot;  USER_INPUT:\n\n数组语法:\nenvironment:  - RACK_ENV=development  - SHOW=true  - USER_INPUT\n\n当为服务设置 env_file 和 environment 时，由 environment 设置的值优先\nexpose定义 Compose 实现必须从容器公开的端口。 这些端口必须可供链接的服务访问，并且不应发布到宿主机。 只能指定内部容器端口\nexpose:  - &quot;3000&quot;  - &quot;8000&quot;\n\nextends在当前文件或另一个文件中继承另一个服务，可选择地覆盖配置。 您可以在任何服务上使用 extends 以及其他配置键\nextends 值必须是使用必需 service 和可选的 file 键定义的映射\nextends:  file: common.yml  service: webapp\n\n如果支持的 Compose 实现必须以下列方式处理 extends:\n\nservice 定义作为基础引用的服务的名称，例如 web 或 database\nfile 是定义该服务的 Compose 配置文件的位置\n\nRestrictions以下限制适用于被引用的服务:\n\n依赖于其他服务的服务不能作为基础。 因此，任何引入对另一个服务的依赖的键都与 extends 不兼容; 这些键的非详尽列表是：links、volumes_from、container 模式（在ipc、pid、network_mode和net中）、service模式（在ipc中） , pid 和 network_mode), depends_on\n服务不能有带 extends 的循环引用\n\n在所有这些情况下，Compose 实现必须返回错误\nFinding referenced servicefile 值可以是:\n\n不存在。 这表明正在引用同一 Compose 文件中的另一个服务\n文件路径，可以是：\n相对路径。 此路径被认为是相对于主 Compose 文件的位置\n绝对路径\n\n\n\n由 service 表示的服务必须存在于标识的引用 Compose 文件中. Compose 实现必须返回一个错误，如果:\n\n未找到由 service 表示的服务\n找不到由file 表示的 Compose 文件\n\nMerging service definitions两个服务定义（当前 Compose 文件中的主要一个和由 extends 指定的引用一个）必须按以下方式合并:\n\n映射: 主服务定义映射中的键覆盖引用服务定义映射中的键。 未覆盖的键按原样包含在内\n序列: 项目被组合成一个新的序列。 元素的顺序被保留，引用的项目在前，主要项目在后\n标量: 主服务定义中的键优先于被引用的键\n\nMappings以下关键字必须作为映射看待: build.args,build.labels,build.extra_hosts,deploy.labels,deploy.update_config,deploy.rollback_config,deploy.restart_policy,deploy.resources.limits,environment,healthcheck,labels,logging.options,sysctls,storage_opt,extra_hosts,ulimits\n适用于 healthcheck 的一个例外是主映射不能指定 disable: true 除非引用的映射也指定 disable: true. 在这种情况下，Compose 实现必须返回错误\n例如，下面的输入:\nsercice:  common:    image: busybox    environment:      TZ: utc      PORT: 80  cli:    extends:      service: common    environment:      PORT: 8080\n\n为 cli 服务生成以下配置。 如果使用数组语法，则会产生相同的输出:\nenvironment:  PORT: 8080  TZ: utcimage: busybox\n\n在 blkio_config.device_read_bps,blkio_config.device_read_iops,blkio_config.device_write_bps,blkio_config.device_write_iops,devices,volumes 下面的 items 也被视为映射，其中 key 是容器内的目标路径\n例如，下面的输入:\nservices:  common:    image: busybox    volumes:      - common-volume:/var/lib/backup/data:rw  cli:    extends:      service: common    volumes:      - cli-volume:/var/lib/backup/data:ro\n\n如果引用的服务定义包含 extends 映射，则其下的项目将简单地复制到新的合并定义中。 然后再次启动合并过程，直到没有 extends 键剩余\n例如，下面的输入:\nservices:  base:    image: busybox    user: root  common:    image: busybox    extends:      service: base  cli:    extends:      service: common\n\n为 cli 服务生成以下配置。 在这里，cli 服务从 common 服务中获取 user 键，而后者又从 base 服务中获取键\nimage: busyboxuser: root\n\nSequences以下键应被视为序列：cap_add,cap_drop,configs,deploy.placement.constraints,deploy.placement.preferences,deploy.reservations.generic_resources,device_cgroup_rules,expose,external_links,ports,secrets,security_opt. 删除合并产生的任何重复项，以便序列仅包含唯一元素\n例如，下面的输入:\nservices:  common:    image: busybox    security_opt:      - label:role:ROLE  cli:    extends:      service: common    security_opt:      - label:user:USER\n\n为 cli 服务生成以下配置\nimage: busyboxsecurity_opt:  - label:role:ROLE  - label:user:USER\n\n如果使用列表语法，则以下键也应视为序列：dns,dns_search,env_file,tmpfs; 与上面提到的序列字段不同，合并产生的重复项不会被删除\nScalars服务定义中的任何其他允许的键都应视为标量\nexternal_links将服务容器链接到在此 Compose 应用程序之外管理的服务\nexternal_links 定义要使用平台查找机制检索的现有服务的名称。 可以指定 SERVICE:ALIAS 形式的别名\nexternal_links:  - redis  - database:mysql  - database:postgresql\n\nextra_hosts将主机名映射添加到容器网络接口配置（Linux 的 /etc/hosts）\n值必须以 HOSTNAME:IP 的形式为其他主机设置主机名和 IP 地址\nextra_hosts:  - &quot;somehost:162.242.195.82&quot;  - &quot;otherhost:50.31.209.229&quot;\n\nCompose 实现必须在容器的网络配置中创建与 IP 地址和主机名匹配的条目，这意味着对于 Linux /etc/hosts 将获得额外的行:\n162.242.195.82  somehost50.31.209.229   otherhost\n\ngroup_add指定容器内的用户必须是额外的组的成员（按名称或编号）\n这很有用的一个例子是, 当多个容器（作为不同的用户运行）需要在共享卷上读取或写入相同的文件时. 该文件可以由所有容器共享的组拥有，并在 group_add 中指定\nservices:  myservice:    image: alpine    group_add:      - mail\n\n在创建的容器中运行 id 必须显示用户属于 mail 组，如果未声明 group_add 则不会出现这种情况\nhealthcheck声明运行检查以确定该服务的容器是否 “healthy”\n这会覆盖服务的 Docker 映像设置的 HEALTHCHECK Dockerfile instruction\nhealthcheck:  test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;]  interval: 1m30s  timeout: 10s  retries: 3  start_period: 40s\n\ninterval,timeout,start_period 被定义为时间段\ntest 定义了 Compose 实现将运行以检查容器运行状况的命令。 它可以是字符串或列表。 如果是列表，第一项必须是 NONE、CMD 或 CMD-SHELL。 如果是字符串，则相当于指定 CMD-SHELL 后跟该字符串\n# Hit the local web apptest: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;]\n\n使用 CMD-SHELL 将使用容器的默认 shell（Linux 的/bin/sh）运行配置为字符串的命令。 下面两种形式是等价的:\ntest: [&quot;CMD-SHELL&quot;, &quot;curl -f http://localhost || exit 1&quot;]\n\ntest: curl -f https://localhost || exit 1\n\nNONE 禁用健康检查，主要用于禁用通过镜像设置的健康检查。 或者，可以通过设置 disable: true 来禁用镜像设置的健康检查:\nhealthcheck:  disable: true\n\nhostname声明用于服务容器的自定义主机名。 必须是有效的 RFC 1123 主机名\nimage指定启动容器的镜像。 镜像必须遵循开放容器规范 addressable image format，如 [&lt;registry&gt;/][&lt;project&gt;/]&lt;image&gt;[:|@]&#96;\nimage: redisimage: redis:5image: redis@sha256:0ed5d5928d4737458944eb604cc8509e245c3e19d02ad83935398bc4b991aac7image: library/redisimage: docker.io/library/redisimage: my_private.registry:5000/redis\n\n如果平台上不存在该镜像，Compose 实现必须尝试根据 pull_policy 拉取它\n具有构建支持的 Compose 实现可以为最终用户提供替代选项，以控制从源构建镜像的拉取优先级，但是拉取镜像必须是默认行为\n只要声明了 build 部分，就可以从 Compose 文件中省略 image。 当 Compose 文件中缺少 image 时，没有构建支持的 Compose 实现必须失败\ninit在容器内运行一个 init 进程 (PID 1) 来转发信号并获取进程. 将此选项设置为 true 以为服务启用此功能\nservices:  web:    image: alpine:latest    init: true\n\n使用的 init 二进制文件是特定于平台的\nipc配置服务容器设置的 IPC 隔离模式\n可用值是特定于平台的，但 Compose 规范定义了特定值，如果支持，则必须按照描述实现：\n\nshareable: 它为容器提供了自己的私有 IPC 命名空间，可以与其他容器共享它\nservice:&#123;name&#125;: 这使得容器加入另一个（shareable）容器的 IPC 命名空间\n\nipc: &quot;shareable&quot;ipc: &quot;service:[service name]&quot;\n\nisolation指定容器的隔离技术。 支持的值是特定于平台的\nlabels将元数据添加到容器。 您可以使用数组或 map\n建议您使用反向 DNS 表示法，以防止您的标签与其他软件使用的标签冲突\nlabels:  com.example.description: &quot;Accounting webapp&quot;  com.example.department: &quot;Finance&quot;  com.example.label-with-empty-value: &quot;&quot;\n\nlabels:  - &quot;com.example.description=Accounting webapp&quot;  - &quot;com.example.department=Finance&quot;  - &quot;com.example.label-with-empty-value&quot;\n\nCompose 实现必须创建带有规范标签的容器：\n\ncom.docker.compose.project 将 Compose 实现创建的所有资源设置为用户项目名称\ncom.docker.compose.service 使用 Compose 文件中定义的服务名称在服务容器上设置\n\ncom.docker.compose 标签前缀是保留的。 在 Compose 文件中指定带有此前缀的标签必须导致运行时错误\nlinks定义另一个服务中容器的网络链接\n要么指定服务名称和链接别名（SERVICE:ALIAS），要么只指定服务名称\nweb:  links:    - db    - db:database    - redis\n\n链接服务的容器必须可以通过与别名相同的主机名访问，或者如果没有指定别名，则使用服务名\n启用服务进行通信不需要链接 - 当没有设置特定的网络配置时，任何服务必须能够在 default 网络上以该服务的名称访问任何其他服务\n如果服务确实声明了它们所连接的网络，则 link 不应该覆盖网络配置，并且未连接到共享网络的服务不应该能够通信\nCompose 实现可能不会警告用户此配置不匹配\n链接也像 depends_on 一样表达服务之间的隐含依赖关系，因此它们决定了服务启动的顺序\nlogging定义服务的日志配置\nlogging:  driver: syslog  options:    syslog-address: &quot;tcp://192.168.0.42:123&quot;\n\ndriver 名称指定服务容器的日志记录驱动程序。 默认值和可用值是特定于平台的。 可以使用 options 作为键值对来设置驱动程序特定的选项\nnetwork_mode设置服务容器网络模式\n可用值是特定于平台的，但 Compose 规范定义了特定值，如果支持，则必须按照描述实现:\n\nnone 禁用所有容器网络\nhost 为容器提供对主机网络接口的原始访问权限\nservice:&#123;name&#125; 只允许容器访问指定的服务\n\nnetwork_mode: &quot;host&quot;network_mode: &quot;none&quot;network_mode: &quot;service: [service name]&quot;\n\nnetworks定义服务容器附加到的网络，引用 top-level 网络 key 下的条目\nservices:  some-service:    networks:      - some-network      - other-network\n\naliases在网络上声明此服务的备用主机名\n同一网络上的其他容器可以使用服务名称或此别名连接到服务的容器之一\n由于 aliases 是网络范围的，相同的服务在不同的网络上可以有不同的别名\n注意: 网络范围的别名可以被多个容器共享，甚至可以被多个服务共享。 如果是，则无法保证名称解析为哪个容器\n一般格式如下所示：\nservices:  some-service:    networks:      some-network:        aliases:          - alias1          - alias3      other-network:        aliases:          - alias2\n\n在下面的示例中，服务 frontend 将能够访问 back-tier 网络上主机名 backend 或 database 中的 backend 服务，并且服务 monitoring 将能够在 admin 网络上的 db 或 mysql 访问相同的 backend 服务\nservices:  frontent:    image: awesome/webapp    networks:      - front-tier      - back-tier  monitoring:    image: awesome/monitoring    networks:      - admin    backend:    image: awesome/backend    networks:      back-tier:        aliases:          - database      admin:        aliases:          - mysqlnetworks:  front-tier:  back-tier:  admin:          \n\nipv4_address, ipv6_address加入网络时，为此服务的容器指定静态 IP 地址\n顶级网络章节中的相应网络配置必须有一个 ipam 块，其中子网配置覆盖每个静态地址\nservices:  frontend:    image: awesome/webapp    networks:      front-tier:        ipv4_address: 172.16.238.10        ipv6_address: 2001:3984:3989::10networks:  front-tier:    ipam:      driver: default      config:        - subnet: &quot;172.16.238.0/24&quot;        - subnet: &quot;2001:3984:3989::/64&quot;\n\nlink_local_ips指定链接本地 IP 列表\nLink-local IP 是属于众所周知的子网的特殊 IP，完全由运营商管理，通常取决于它们部署在哪里的架构. 实现是特定于平台的\nservices:  app:    image: busybox    command: top    networks:      app_net:        link_local_ips:          - 57.123.22.11          - 57.123.22.13networks:  app_net:    driver: bridge\n\npriority指示 Compose 实现应该以何种顺序将服务的容器连接到其网络. 如果未指定，则默认值为 0\n在以下示例中，应用服务首先连接到 app_net_1，因为它具有最高优先级\nservices:  app:    image: busybox    command: top    networks:      app_net_1:        priority: 1000      app_net_2:      app_net_3:        priority: 100networks:  app_net_1:  app_net_2:  app_net_3:\n\nmac_address为服务容器设置 MAC 地址\nmem_limit已废弃. 使用 deploy.limits.memory\nmem_reservation已废弃. 使用 deploy.reservations.memory\nmem_swappinessmem_swappiness 定义主机内核交换容器使用的匿名内存页的百分比（0到100之间的值）\n\n值 0 关闭匿名页面交换\n值 100 将所有匿名页面设置为可交换\n\n默认值是特定于平台的\nmemswap_limitmemswap_limit 定义了容器允许的交换到磁盘的内存数量\n这是一个修饰符属性，只有在也设置了 memory 时才有意义\n使用交换允许容器在容器耗尽所有可用内存时将过量的内存需求写入磁盘\n经常将内存交换到磁盘的应用程序会降低性能\n\n如果 memswap_limit 设置为正整数，则必须同时设置 memory 和 memswap_limit. memswap_limit 表示可以使用的内存和 swap 的总量，memory 控制非 swap 内存的使用量. 所以如果 memory &#x3D;”300m”和memswap_limit&#x3D;”1g”，容器可以使用 300m 的内存和 700m（1g - 300m）的 swap\n如果 memswap_limit 设置为 0，则必须忽略该设置，并将该值视为未设置\n如果 memswap_limit 设置为与 memory 相同的值，并且 memory 设置为正整数，则容器无权访问 swap\n如果 memswap_limit 未设置，并且 memory 设置，容器可以使用与 memory 设置一样多的 swap，如果主机容器配置了 swap 内存\n例如，如果 memory &#x3D;”300m”并且没有设置 memswap_limit，容器总共可以使用 600m 的内存和 swap\n如果 memswap_limit 显式设置为 -1，则允许容器使用无限 swap，最多为主机系统上可用的数量\n\noom_kill_disable如果设置了 oom_kill_disable，则 Compose 实现必须配置平台，以便在内存不足的情况下不会杀死容器\noom_score_adjoom_score_adj 调整容器在内存不足的情况下被平台 kill 的偏好。 值必须在 [-1000,1000] 范围内\npid为 Compose 实现创建的容器设置 PID 模式。 支持的值是特定于平台的\npids_limit已废弃: 使用 deploy.reservations.pids\nplatformplatform 使用 os[/arch[/variant]] 语法定义了此服务将运行的目标平台容器\nCompose 实现必须在声明时使用此属性来确定将提取哪个版本的镜像 和&#x2F;或 将在哪个平台上执行服务的构建\nplatform: osxplatform: windows/amd64platform: linux/arm64/v8\n\nports暴露容器端口. 端口映射不得与 network_mode: host 一起使用，这样做必须导致运行时错误\nShort syntax简短语法是一个冒号分隔的字符串，用于设置主机 IP、主机端口和容器端口，形式为:\n[HOST:]CONTAINER[/PROTOCOL]:\n\nHOST 是 [IP:](port | range)\nCONTAINER 是 port | range\nPROTOCOL 将端口限制为指定的协议。 tcp 和 udp 值由规范定义，Compose 实现可以提供对特定于平台的协议名称的支持\n\nHost IP，如果未设置，必须绑定到所有网络接口\nPORT 可以是单个值或范围\n主机和容器必须使用等效范围\n要么指定两个端口（HOST:CONTAINER），要么只指定容器端口. 在后一种情况下，Compose 实现应该自动分配任何未分配的主机端口\nHOST:CONTAINER 应始终指定为（带引号的）字符串，以避免与 yaml base-60 float 冲突\n例子:\nports:  - &quot;3000&quot;  - &quot;3000-3005&quot;  - &quot;8000:8000&quot;  - &quot;9090-9091:8080-8081&quot;  - &quot;49100:22&quot;  - &quot;127.0.0.1:8001:8001&quot;  - &quot;127.0.0.1:5000-5010:5000-5010&quot;  - &quot;6060:6060/udp&quot;\n\n注意: 平台可能不支持 Host IP 映射，在这种情况下 Compose 实现应该拒绝 Compose 文件并且必须通知用户他们将忽略指定的 Host IP\nLong syntax长格式语法允许配置 无法以短格式表示的 附加字段\n\ntarget: 容器端口\npublished: 公开的端口。 可以使用语法 start-end 设置为一个范围，然后应该根据可用端口在此范围内分配实际端口\nhost_ip: Host IP 映射，未指定表示所有网络接口 (0.0.0.0)\nprotocol: 端口协议（tcp或udp），未指定表示任何协议\nmode: host 用于在每个节点上发布主机端口，或 ingress 用于要负载平衡的端口\n\nports:  - target: 80    host_ip: 127.0.0.1    published: 8080    protocol: tcp    mode: host  - target: 80    host_ip: 127.0.0.1    published: 8000-9000    protocol: tcp    mode: host\n\nprivilegedprivileged 将服务容器配置为以提升的权限运行。 支持和实际影响因平台而异\nprofilesprofiles 定义了要启用的服务的命名配置文件列表。 未设置时，服务始终启用\n如果存在，profiles 应该遵循 [a-zA-Z0-9][a-zA-Z0-9_.-]+ 的正则表达式格式\npull_policypull_policy 定义 Compose 实现在开始拉取镜像时将做出的决定. 可能的值是:\n\nalways: Compose 实现应该总是从 registry 中拉取镜像\nnever: Compose 实现不应该从 registry 中提取镜像，并且应该依赖于平台缓存的镜像。 如果没有缓存镜像，则必须报告失败\nmissing: 仅当平台缓存中不可用时，Compose 实现才应该拉取镜像。 这应该是没有构建支持的 Compose 实现的默认选项. if_not_present 应该被视为此值的别名，以实现向后兼容性\nbuild: Compose 实现应该构建镜像。 如果已经存在，Compose 实现应该重建镜像\n\n如果 pull_policy 和 build 都存在， Compose 实现应该默认构建镜像。 Compose 实现可以覆盖工具链中的这种行为\nread_onlyread_only 将服务容器配置为使用只读文件系统创建\nrestartrestart 定义了平台将在容器终止时应用的策略\n\nno: 默认重启策略。 在任何情况下都不重启容器\nalways: 该策略始终会重新启动容器，直到将其删除\non-failure: 如果退出代码指示错误，该策略会重新启动容器\nunless-stopped: 无论退出代码如何，该策略都会重新启动容器，但会在服务停止或删除时停止重新启动\n\nrestart: &quot;no&quot;restart: alwaysrestart: on-failurerestart: unless-stopped\n\nruntimeruntime 指定用于服务容器的运行时\nruntime 的值是特定于实现的. 例如, runtime 可以是 OCI Runtime Spec 的实现 的名称，例如“runc”\nweb:  image: busybox:latest  command: true  runtime: runc\n\nscale已废弃. 使用 deploy&#x2F;replicas\nsecretssecrets 授予 对基于每个服务的 secrets 定义的 敏感数据的访问权限. 支持两种不同的语法变体：短语法和长语法\n如果 secret 在平台上不存在或未在此 Compose 文件的 secrets 部分中定义，则 Compose 实现必须报告错误\nShort syntax短语法变体仅指定 secret 名称. 这将授予容器对 secret 的访问权限，并将其以只读方式挂载到容器内的 /run/secrets/&lt;secret_name&gt;. 源名称和目标挂载点都设置为 secret 名称\n以下示例使用简短语法授予 frontend 服务访问 server-certificate 密钥的权限\nservices:  frontend:    image: awesome/webapp    secrets:      - server-certificatesecrets:  servce-certificate:    file: ./server.cert\n\nLong syntax长语法为如何在服务的容器中创建 secret 提供了更多的粒度\n\nsource: 平台上存在的 secret 名称\ntarget: 要挂载在服务任务容器中的 /run/secrets/ 中的文件的名称。 如果未指定，则默认为 source\nuid 和 gid: 拥有服务任务容器中 /run/secrets/ 中文件的数字 UID 或 GID。 默认值为运行容器的 USER\nmode: 在服务的任务容器中的 /run/secrets/ 中挂载文件的权限，以八进制表示。 默认值为全局可读权限（模式 0444）。 如果设置了可写位，则必须忽略。 可执行位可以设置\n\n以下示例将容器内的 server-certificate secret 文件的名称设置为 server.crt，将模式设置为 0440（组可读）并将用户和组设置为 103s\nserver-certificate secret 的值由平台通过查找提供，并且 secret 生命周期不由 Compose 实现直接管理\nservices:  frontent:    image: awesome/webapp    secrets:      - source: server-certificate        target: server.cert        uid: &quot;103&quot;        gid: &quot;103&quot;        mode: 0440secrets:  server-certificate:    external: true\n\n服务可以被授予访问多个 secret 的权限。 可以在同一个 Compose 文件中使用 secrets 的长语法和短语法。 在顶级 secrets 中定义一个 secret 绝不能暗示授予任何服务对其的访问权限。 此类授权必须在服务规范中明确作为 secrets 服务元素\nsecurity_optsecurity_opt 覆盖每个容器的默认标签方案\nsecurity_opt:  - label:user:USER  - label:role:ROLE\n\nshm_sizeshm_size 配置服务容器允许的共享内存（Linux 上的/dev/shm 分区）的大小。 指定为字节值\nstdin_openstdin_open 将服务容器配置为使用分配的标准输入运行\nstop_grace_periodstop_grace_period 指定 Compose 实现在尝试停止容器时必须等待多长时间，如果它不处理 SIGTERM（或使用 stop_signal 指定的任何停止信号），然后再发送 SIGKILL。 指定为持续时间\nstop_grace_period: 1sstop_grace_period: 1m30s\n\n默认值是容器在发送 SIGKILL 之前退出的 10 秒\nstop_signalstop_signal 定义了 Compose 实现必须用来停止服务容器的信号。 如果未设置的容器被 Compose 实现通过发送 SIGTERM 停止\nstop_signal: SIGUSER1\n\nstorage_optstorage_opt 定义服务的存储驱动程序选项\nstorage_opt:  size: &#x27;1G&#x27;\n\nsysctlssysctls 定义要在容器中设置的内核参数。 sysctls 可以使用数组或映射\nsysctls:  net.core.somaxconn: 1024  net.ipv4.tcp_syncookies: 0\n\nsysctls:  - net.core.somaxconn=1024  - net.ipv4.tcp_syncookies=0\n\n您只能使用在内核中命名空间的 sysctl。 Docker 不支持更改容器内的 sysctls 因为这也会修改主机系统\n有关支持的 sysctls 的概述，请参阅在运行时配置命名空间内核参数 (sysctls)\ntmpfstmpfs 在容器内挂载一个临时文件系统。 可以是单个值或列表\ntmpfs: /run\n\ntmpfs:  - /run  - /tmp\n\nttytty 配置服务容器以使用 TTY 运行\nulimitsulimits 覆盖容器的默认 ulimits。 要么将单个限制指定为整数，要么将软&#x2F;硬限制指定为映射\nulimits:  nproc: 65535  nofile:    soft: 20000    hard: 40000\n\nuseruser 覆盖用于运行容器进程的用户。 默认是由镜像设置的（即 Dockerfile USER），如果未设置，则为 root\nuserns_modeuserns_mode 设置服务的用户命名空间。 支持的值是特定于平台的，可能取决于平台配置\nuserns_mode: &quot;host&quot;\n\nvolumesvolumes 定义了服务容器必须可以访问的挂载宿主机路径或命名卷\n如果挂载是宿主机路径并且仅由单个服务使用，则可以将其声明为服务定义的一部分，而不是顶级 volumes 键\n要跨多个服务重用一个卷，必须在 顶层volumes键 中声明一个命名卷\n此示例显示了 backend 服务使用的命名卷（db-data），以及为单个服务定义的绑定挂载\nservices:  backend:    image: awesome/backend    volumes:      - type: volume        source: db-data        target: /data        volume:          nocopy: true      - type: build        source: /var/run/postgres/postgres.sock        target: /var/run/postgres/postgres.sockvolumes:  db-data:\n\nShort syntax简短语法使用带有冒号分隔值的单个字符串来指定卷挂载 (VOLUME:CONTAINER_PATH) 或访问模式 (VOLUME:CONTAINER_PATH:ACCESS_MODE)\n\nVOLUME: 可以是托管容器的平台上的主机路径（绑定挂载）或卷名\nCONTAINER_PATH: 容器中挂载卷的路径\nACCESS_MODE: 是一个逗号分隔 , 的选项列表，可以设置为:\nrw: 读写访问 (默认)\nro: 只读访问\nz: SELinux 选项, 表示绑定挂载主机内容是在多个容器之间共享\nZ: SELinux 选项, 表示绑定挂载主机内容是私有的，对其他容器不共享\n\n\n\n注意: SELinux re-labeling 绑定挂载选项在没有 SELinux 的平台上被忽略\n注意: 相对主机的路径必须仅由部署到本地容器运行时的 Compose 实现支持。 这是因为相对路径是从 Compose 文件的父目录解析的，该父目录仅适用于本地情况。 部署到非本地平台的 Compose 实现必须拒绝使用相对主机路径并出现错误的 Compose 文件。为避免命名卷的歧义，相对路径应始终以 . 或 .. 开头\nLong syntax长格式语法允许配置无法以短格式表示的附加字段\n\ntype: 挂载类型 volume,bind,tmpfs,npipe\nsource: 挂载的源、主机上用于绑定挂载的路径或在顶层 volumes 键中定义的卷的名称。 不适用于 tmpfs 挂载\ntarget: 容器中挂载卷的路径\nread_only: 将卷设置为只读的标志\nbind: 配置额外的绑定选项\npropagation: 用于绑定的传播模式\ncreate_host_path: 如果没有任何内容，请在主机上的源路径创建一个目录。 如果路径上有东西，什么也不做。 为了向后兼容 docker-compose legacy 的短语法自动暗示了这一点\nselinux: SELinux re-labeling 选项 z (共享) 或 Z (私有)\n\n\nvolume: 配置额外的卷选项\nnocopy: 创建卷时停止从容器复制数据的标志\n\n\ntmpfs: 配置额外的 tmpfs 选项\nsize: tmpfs 挂载的大小（以字节为单位）（数字或字节单位）\n\n\nconsistency: 挂载的一致性要求。 可用值是特定于平台的\n\nvolumes_fromvolumes_from 挂载来自另一个服务或容器的所有卷，可选择指定只读访问 (ro) 或读写 (rw)。 如果未指定访问级别，则必须使用读写\n字符串值定义了 Compose 应用程序模型中的另一个服务来挂载卷. container: 前缀（如果支持）允许从不受 Compose 实现管理的容器中挂载卷\nvolumes_from:  - service_name  - service_name:ro  - container:container_name  - container:container_name:rw\n\nworking_dirworking_dir 覆盖了镜像指定的容器工作目录（即 Dockerfile WORKDIR）\nNetworks top-level element (顶级元素 networks)网络是允许服务相互通信的层。 向服务公开的网络模型仅限于与目标服务和外部资源的简单 IP 连接，而网络定义允许微调平台提供的实际实现\n可以通过在顶层 networks 部分下指定网络名称来创建网络。 服务可以通过在服务 networks 小节下指定网络名称来连接到网络\n在下面的示例中，在运行时，将创建网络 front-tier 和 back-tier，并将 frontend 服务连接到 front-tier 网络和 back-tier 网络\nservices:  frontend:    image: awesome/webapp    networks:      - front-tier      - back-tiernetworks:  front-tier:  back-tier\n\ndriverdriver 指定该网络应该使用哪个驱动程序。 如果驱动程序在平台上不可用，则 Compose 实现必须返回错误\ndriver: overlay\n\n默认值和可用值是特定于平台的。 Compose 规范必须支持以下特定驱动程序：none 和 host\n\nhost 使用宿主机的网络堆栈\nnone 关闭网络\n\nhost or none使用诸如 host 和 none 等内置网络的语法是不同的，因为这些网络隐含地存在于 Compose 实现的范围之外\n要使用它们，必须定义一个名为 host 或 none 的外部网络以及 Compose 实现可以使用的别名（以下示例中的 hostnet 或 nonet），然后授予服务访问该网络的权限 使用它的别名\nservices:  web:    networks:      hostnet: &#123;&#125;networks:  hostnet:    external: true    name: host\n\nservices:  web:    networks:      nonet: &#123;&#125;networks:  nonet:    external: true    name: none\n\ndriver_optsdriver_opts 指定选项列表作为键值对传递给该网络的驱动程序。 这些选项取决于驱动程序 - 请参阅驱动程序文档以获取更多信息。 可选\ndriver_opts:  foo: &quot;bar&quot;  baz: 1\n\nattachable如果 attachable 设置为 true，那么独立容器应该能够附加到这个网络，除了服务。 如果独立容器连接到网络，它可以与服务和其他也连接到网络的独立容器通信\nnetworks:  mynet1:    driver: overlay    attachable: true\n\nenable_ipv6在这个网络上开启 IPv6 网络\nipma指定自定义 IPAM 配置. 这是一个具有多个属性的对象，每个属性都是可选的：\n\ndriver: 自定义 IPAM 驱动程序，而不是默认的\nconfig: 具有零个或多个配置元素的列表，每个包含\nsubnet: 代表网段的 CIDR 格式的子网\nip_range: 分配容器 IP 的 IP 范围\ngateway: 主子网的 IPv4 或 IPv6 网关\naux_adderss: 网络驱动程序使用的辅助 IPv4 或 IPv6 地址，作为从主机名到 IP 的映射\n\n\noptions: 特定于驱动程序的选项作为键值映射\n\n完整例子:\nipam:  driver: default  config:    - subnet: 172.28.0.0/16      ip_range: 172.28.5.0/24      gateway: 172.28.5.254      aux_addresses:        host1: 172.28.1.5        host2: 172.28.1.6        host3: 172.28.1.7  options:    foo: bar    baz: &quot;0&quot;\n\ninternal默认情况下，Compose 实现必须提供到网络的外部连接。 internal 设置为 true 时允许创建外部隔离网络\nlabels使用标签将元数据添加到容器。 可以使用数组或字典\n用户应该使用反向 DNS 符号来防止标签与其他软件使用的标签冲突\nlabels:  com.example.description: &quot;Financial transaction network&quot;  com.example.department: &quot;Finance&quot;  com.example.label-with-empty-value: &quot;&quot;\n\nlabels:  - &quot;com.example.description=Financial transaction network&quot;  - &quot;com.example.department=Finance&quot;  - &quot;com.example.label-with-empty-value&quot;\n\nCompose 实现必须设置 com.docker.compose.project 和 com.docker.compose.network 标签\nexternal如果设置为 true，external 指定此网络的生命周期在应用程序之外维护。 Compose 实现不应该尝试创建这些网络，如果不存在则会引发错误\n在下面的示例中，proxy 是通往外部世界的网关。 与其尝试创建网络，Compose 实现应该询问平台以获取简单称为 outside 的现有网络，并将 proxy 服务的容器连接到它\nservices:  proxy:    image: awesome/proxy    networks:      - outside      - default  app:    image: awesome/app    networks:      - defaultnetworks:  outside:    external: true\n\nnamename 设置此网络的自定义名称。 名称字段可用于引用包含特殊字符的网络。 名称按原样使用，不受项目名称的限制\nnetworks:  network1:    name: my-app-net\n\n它也可以与 external 属性结合使用来定义 Compose 实现应该检索的平台网络，通常使用一个参数，因此 Compose 文件不需要硬编码运行时特定的值\nnetworks:  network1:    external: true    name: &quot;$&#123;NETWORK_ID&#125;&quot;\n\nVolumes top-level element (顶级元素 volumes)卷是由平台实现的持久数据存储。Compose规范为装载卷的服务和在基础架构上分配卷的配置参数提供了中立的抽象\nvolumes 部分允许配置可跨多个服务重用的命名卷。下面是一个双服务设置的示例，其中数据库的数据目录作为名为 db-data 的卷与另一个服务共享，以便可以定期备份\nservices:  backend:    image: awesome/database    volumes:      - db-data:/etc/data  backup:    image: backup-service    volumes:      - db-data:/var/lib/backup/datavolumes:  db-data:\n\n顶层 volumes 键下的条目可以为空，在这种情况下，它使用平台的默认配置来创建卷。 或者，您可以使用以下键对其进行配置\ndriver指定应为此卷使用的卷驱动程序。 默认值和可用值是特定于平台的。 如果驱动程序不可用，Compose 实现必须返回错误并停止应用程序部署\ndriver: foobar\n\ndriver_optsdriver_opts 将选项列表指定为键值对，以传递给此卷的驱动程序。 这些选项取决于驱动程序\nvolumes:  example:    driver_opts:      type: &quot;nfs&quot;      o: &quot;addr=10.40.0.199,nolock,soft,rw&quot;      device: &quot;:/docker/example&quot;\n\nexternal如果设置为 true，则 external 指定此卷已存在于平台上，并且其生命周期在应用程序之外进行管理。 Compose 实现不得尝试创建这些卷，如果它们不存在，则必须返回错误\n在下面的示例中，Compose 并没有尝试创建一个名为 &#123;project_name&#125;_db-data 的卷，而是查找一个名为 db-data 的现有卷并将其挂载到 后端 服务的容器中\nservices:   backend:    image: awesome/database    volumes:      - db-data:/etc/data      volumes:  db-data:    external: true\n\nlabelslabels 用于向卷添加元数据。 您可以使用数组或 map\n建议您使用反向 DNS 表示法，以防止您的标签与其他软件使用的标签冲突\nlabels:  com.example.description: &quot;Database volume&quot;  com.example.department: &quot;IT/Ops&quot;  com.example.label-with-empty-value: &quot;&quot;\n\nlabels:  - &quot;com.example.description=Database volume&quot;  - &quot;com.example.department: &quot;IT/Ops&quot;  - &quot;com.example.label-with-empty-value&quot;: &quot;&quot;\n\nCompose 实现必须设置 com.docker.compose.project 和 com.docker.compose.volume 标签\nnamename 为这个卷设置一个自定义名称。 名称字段可用于引用包含特殊字符的卷。 该名称按原样使用，不会与堆栈名称冲突\nvolumes:  data:    name: &quot;my-app-data&quot;\n\n它也可以与 external 属性结合使用。 这样做，用于在平台上查找实际卷的卷的名称与 Compose 文件中用于引用它的名称分开设置\nvolumes:  db-data:    external:      name: actual-name-of-volume\n\n这使得可以将此查找名称作为 Compose 文件的参数，以便卷的模型 ID 是硬编码的，但平台上的实际卷 ID 在部署期间在运行时设置\nvolumes:  db-data:    external:      name: $&#123;DATABASE_VOLUME&#125;\n\nConfigs top-level element (顶级元素 configs)Configs 允许服务调整其行为，而无需重建 Docker 映像。 从服务的角度来看，配置与卷相当，因为它们被挂载到服务的容器文件系统中。 获取平台提供的配置的实际实现细节可以从配置定义中设置\n当授予对配置的访问权限时，配置内容将作为文件挂载在容器中. 容器内挂载点的位置在 Linux 容器中默认为 /&lt;config-name&gt;，在 Windows 容器中默认为 C:\\&lt;config-name&gt;\n默认情况下，配置必须由运行容器命令的用户拥有，但可以被服务配置覆盖。 默认情况下，配置必须具有全局可读权限（模式 0444），除非服务被配置为覆盖它\n服务只能在 configs 子部分明确授予时访问配置\n顶级 configs 声明定义或引用可以授予此应用程序中的服务的配置数据。 配置的来源是 file 或 external\n\nfile: 使用指定路径中的文件内容创建配置\nexternal: 如果设置为 true，则指定此配置已创建。 Compose 实现不会尝试创建它，如果它不存在，则会发生错误\nname: 平台上要查找的配置对象的名称。 该字段可用于引用包含特殊字符的配置。 名称按原样使用，不会与项目名称冲突\n\n在这个例子中，http_config 是在应用程序部署时创建的（作为 &lt;project_name&gt;_http_config），并且 my_second_config 必须已经存在于 Platform 上并且通过查找来获取值\n在此示例中，通过将 httpd.conf 的内容注册为配置数据，在部署应用程序时将 server-http_config 创建为 &lt;project_name&gt;_http_config\nconfigs:  http_config:    file: ./httpd.conf\n\n或者，可以将 http_config 声明为外部，这样做 Compose 实现将查找 http_config 以将配置数据公开给相关服务\nconfigs:  http_config:    external: true\n\n外部配置查找也可以通过指定 name 来使用不同的键. 下面的例子修改了前面的例子，使用参数 HTTP_CONFIG_KEY 来查找配置. 这样做，实际的查找键将在部署时通过变量的 插值 设置，但作为硬编码的 ID http_config 暴露给容器\nconfigs:  http_config:    external: true    name: &quot;$&#123;HTTP_CONFIG_KEY&#125;&quot;\n\nCompose 文件需要明确授予对应用程序中相关服务的配置的访问权限\nSecrets top-level element (顶级元素 secrets)Secrets 是一种专注于敏感数据的 Configs，对这种用法有特定的限制. 由于平台实现可能与配置有很大不同，专用的 Secrets 部分允许配置相关资源\n顶层 secrets 声明定义或引用可以授予此应用程序中的服务的敏感数据. secret 的来源是 file 或 external\n\nfile: secret 是使用指定路径的文件内容创建的\nexternal: 如果设置为 true，则指定此 secret 已创建。 Compose 实现不会尝试创建它，如果它不存在，则会发生错误\nname: Docker 中 secret 对象的名称。 此字段可用于引用包含特殊字符的 secrets。 名称按原样使用，不会与项目名称冲突\n\n在此示例中，通过将 server.cert 的内容注册为平台 secret，在部署应用程序时将 server-certificate 创建为 &lt;project_name&gt;_server-certificate\nsecrets:  server-certificate:    file: ./server.cert\n\n或者，server-certificate 可以声明为外部，这样做 Compose 实现将查找 server-certificate 以向相关服务公开 secret\nsecrets:  server-certificate:    external: true\n\n外部 secrets 查找也可以通过指定 name 来使用不同的 key. 下面的例子修改了前面的例子，使用参数 CERTIFICATE_KEY 来查找 secret\n这样做，实际的查找 key 将在部署时通过变量的 interpolation 设置，但作为硬编码 ID server-certificate 暴露给容器\nsecrets:  server-certificate:    external: true    name: &quot;$&#123;CERTIFICATE_KEY&#125;&quot;\n\nCompose 文件需要明确授予对应用程序中相关服务的 secrets 的访问权限\nFragments (分段)可以使用 YAML anchors 重用配置片段\nvolumes:  db-data: &amp;default-volume    driver: default  metrics: *default-volume\n\n在前面的示例中，基于 db-data 卷规范将锚点创建为 default-volume. 它稍后被别名 *default-volume 重用以定义 metrics 卷. 相同的逻辑可以应用于 Compose 文件中的任何元素. 锚解析必须在 变量插值 之前进行，因此变量不能用于设置锚或别名\n也可以使用 YAML merge type 部分覆盖由锚引用设置的值. 在以下示例中，metrics 卷规范使用别名来避免重复，但会覆盖 name 属性:\nservices:  backend:    image: awesome/database    volumes:      - db-data      - metrics- imagevolumes:  db-data: &amp;default-volume    driver: default    name: &quot;data&quot;  metrics:    &lt;&lt;: *default-volume    name: &quot;metrics&quot;\n\nExtension (扩展)特殊扩展字段可以是任何格式，只要它们的名称以 x- 字符序列开头\n它们可以在 Compose 文件的任何结构中使用。 这是 Compose 实现自动忽略未识别字段的唯一例外\nx-custom:  foo:    - bar    - zotservices:  webapp:    image: awesome/webapp    x-foo: bar\n\nCompose 规范未指定此类字段的内容，也可用于启用自定义功能。 Compose 实现遇到未知扩展字段的实现不能失败，但可以警告未知字段\n对于平台扩展，强烈建议使用平台&#x2F;供应商名称作为扩展前缀，就像浏览器添加对自定义 CSS 功能的支持一样\nservice:  backend:    deploy:      placement:        x-aws-role: &quot;arn:aws:iam::XXXXXXXXXXXX:role/foo&quot;        x-aws-region: &quot;eu-west-3&quot;        x-azure-region: &quot;france-central&quot;\n\nInformative Historical Notes本节内容丰富。 在撰写本文时，已知存在以下前缀:\n\n\n\nprefix\nverdor&#x2F;organization\n\n\n\ndocker\nDocker\n\n\nkubernetes\nKubernetes\n\n\nUsing extensions as fragments借助扩展字段的支持，Compose 文件可以编写如下，以提高重用片段的可读性：\nx-logging: &amp;default-logging  options:    max-size: &quot;12m&quot;    max-file: &quot;5&quot;  driver: json-fileservices:  frontend:    image: awesome/webapp    logging: *default-logging  backend:    image: awesome/database    logging: *default-logging\n\nspecifying byte valuesValue 以 &#123;amount&#125;&#123;byte unit&#125; 格式将字节值表示为字符串：支持的单位为 b（字节）、k 或 kb（千字节）、m 或 mb （兆字节）和g或gb（千兆字节）\n2b1024kb2048k300m1gb\n\nspecifying durations值以 &#123;value&#125;&#123;unit&#125; 的形式将持续时间表示为字符串。 支持的单位是 us（微秒）、ms（毫秒）、s（秒）、m（分钟）和 h（小时）。 值可以组合多个值并使用不带分隔符\n10ms40s1m30s1h5m30s20ms\n\nInterpolation (插值)Compose 文件中的值可以由变量设置，并在运行时进行插值。 撰写文件使用类似 Bash 的语法 $&#123;VARIABLE&#125;\n$VARIABLE 和 $&#123;VARIABLE&#125; 语法都受支持。 可以使用典型的 shell 语法内联定义默认值：latest\n\n$&#123;VARIABLE:-default&#125; 如果 VARIABLE 在环境中未设置或为空，则评估为 default\n$&#123;VARIABLE-default&#125; 如果 VARIABLE 在环境中未设置，则评估为 default\n\n同样，以下语法允许您指定强制变量：\n\n$&#123;VARIABLE:?err&#125; 如果 VARIABLE 在环境中未设置或为空，则退出并显示包含 err 的 error 消息\n$&#123;VARIABLE?err&#125; 如果在环境中未设置 VARIABLE，则以包含错误的 err 消息退出\n\n插值也可以嵌套：\n\n$&#123;VARIABLE:-$&#123;FOO&#125;&#125;\n$&#123;VARIABLE?$&#123;FOO&#125;&#125;\n$&#123;VARIABLE:-$&#123;FOO:-default&#125;&#125;\n\nCompose 规范不支持其他扩展的 shell-style 功能，例如 $&#123;VARIABLE/foo/bar&#125;\n当您的配置需要字面量美元符号时，您可以使用 $$（双美元符号）。 这也可以防止 Compose 插入值，因此 $$ 允许您引用您不希望 Compose 处理的环境变量\nweb:  build: .  command: &quot;$$VAR_NOT_INTERPOLATED_BY_COMPOSE&quot;\n\n如果 Compose 实现无法解析替换变量并且没有定义默认值，它必须警告用户并用空字符串替换变量\n由于 Compose 文件中的任何值都可以通过变量替换进行插值，包括复杂元素的紧凑字符串表示法，因此必须在基于每个文件的合并之前应用插值\n参考Compose specification\n","categories":["Docker - Compose"],"tags":["Docker","Notes","Docker Compose"]},{"title":"Control startup and shutdown order in Compose","url":"/docker/compose/control-startup-and-shutdown-order-in-compose/","content":"可以使用 depends_on 选项来控制服务启动和关闭的顺序\nCompose 总是以依赖顺序来启动和关闭容器, 其中依赖由 depends_on,links,volumes_from,network_mode: &quot;service:...&quot; 确定\n但是, 对于启动, Compose 不会等到容器 “准备好 (ready)” (无论这对于你的特定应用程序意味着什么) - Compose 只会等到容器运行\n要由应用程序自身来保证对外部依赖连接的弹性, 可以自动发现外部依赖并拥有重试机制\n如果不需要这种级别的伸缩性, 可以使用 wrapper script 来解决这个问题\n使用类似 wait-for-it, dockerize, sh-compatible wait-for, RelayAndContainers 模板\n可以在镜像中使用这些脚本来轮询给定的主机和端口直到脚本获取到 TCP 连接\n参考Control startup and shutdown order in Compose\n","categories":["Docker - Compose"],"tags":["Docker","Notes","Docker Compose"]},{"title":"Declare default environment variables in file","url":"/docker/compose/declare-default-environment-variables-in-file/","content":"Compose 支持在项目目录中的 .env 环境文件中声明默认环境变量\n.env 默认位于项目目录根目录中\n可以通过 --env-file 选项来指定 .env 文件的位置\nCompose file and CLI variables你在环境文件中定义的环境变量用于在 Compose 文件中进行变量替换, 也可以用来定义如下CLI 变量:\n\nCOMPOSE_API_VERSION\nCOMPOSE_CONVERT_WINDOWS_PATHS\nCOMPOSE_FILE\nCOMPOSE_HTTP_TIMEOUT\nCOMPOSE_PROFILES\nCOMPOSE_PROJECT_NAME\nCOMPOSE_TLS_VERSION\nDOCKER_CERT_PATH\nDOCKER_HOST\nDOCKER_TLS_VERIFY\n\n参考Declare default environment variables in file\n","categories":["Docker - Compose"],"tags":["Docker","Notes","Docker Compose"]},{"title":"Environment variables in Compose","url":"/docker/compose/environment-variables-in-compose/","content":"可以通过 shell 环境变量传递参数给 docker-compose.yml 文件\nweb:  image: &quot;webapp:$&#123;TAG&#125;&quot;\n\n可以通过在当前项目目录的 .env 文件提供变量值; .env 文件功能只有在 docker-compose up 命令中生效, 在 docker stack deploy 命令中不生效\n如果没有变量值, Compose 使用空字符串进行变量替换\n$VARIABLE 和 $&#123;VARIABLE&#125; 语法都支持\n可以提供默认值:\n\n$&#123;VARIABLE:-default&#125; - 当 VARIABLE 没有设置或为空 (empty) 时使用 default\n$&#123;VARIABLE-default&#125; - 当 VARIABLE 没有设置时使用 default\n\n可以设置变量值必须提供:\n\n$&#123;VARIABLE:?err&#125; - 当 VARIABLE 没有设置或为空 (empty) 时使用一个包含 err 的信息进行退出 (exit)\n$&#123;VARIABLE:err&#125; - 当 VARIABLE 没有设置时使用一个包含 err 的信息进行退出 (exit)\n\n不支持 $&#123;VARIABLE/foo/bar&#125; 的形式\n使用 $$ 来表示美元符号字面量\n$$ 会阻止 Compose 解析一个值, 所以可以使用 $$ 来引用一个不想被 Compose 处理的环境变量:\nweb:  build: .    command: &quot;$$VAR_NOT_INTERPOLATED_BY_COMPOSE&quot;\n\n可以通过 --env-file 选项来指定 .env 文件, 例如: docker-compose --env-file ./config/.env.dev up\n在 docker-compose.yml 文件中设置为容器设置环境变量:\nweb:  environment:    - DEBUG=1\n\n使用外部环境变量为容器设置环境变量:\nweb:  environment:    - DEBUG\n\n使用 .env 文件为容器设置环境变量:\nweb:  env_file:    - web-variables.env\n\n使用 docker-compose run -e 命令为容器设置环境变量:\n$ docker-compose run -e DEBUG=1 web python console.py\n\n# 使用外部的环境变量 DEBUG 为容器设置环境变量$ docker-compose run -e DEBUG web python console.py\n\nCompose 选择环境变量的优先级:\n\nCompose file\nShell 环境变量\n.env 文件\nDockerfile\n变量未定义\n\n参考Environment variables in Compose\n","categories":["Docker - Compose"],"tags":["Docker","Notes","Docker Compose"]},{"title":"Get started with Docker Compose","url":"/docker/compose/get-started-with-docker-compose/","content":"docker-compose.yml 文件定义服务:\nversion: &quot;3.9&quot;services:  web:    build: .    ports:      - &quot;8080:5000&quot;  redis:    image: &quot;redis:alpine&quot;\n\ndocker compose up 用 Compose 构建并启动你的应用; 此时, 应用在前台构建并启动, 按 ctrl c 结束运行\ndocker compose down 停止服务运行\n编辑 docker-compose.yml 文件, 添加挂载绑定:\nversion: &quot;3.9&quot;services:  web:    build: .    ports:      - &quot;8000:5000&quot;    volumes:      - .:/code    environment:      FLASK_ENV: development  redis:    image: &quot;redis:alpine&quot;\n\ndocker compose up -d 以后台 (detached) 模式运行应用\ndocker compose ps 查看正在运行的容器\ndocker compose run 命令让你可以为你的服务运行一次性的命令\ndocker compose run web env 查看web 服务中可用的环境变量:\ndocker compose --help 查看帮助信息\ndocker compose down --volumes 停止所有东西, 删除整个容器; (--volumes) 同时删除容器使用的数据卷\n--file 选项或 COMPOSE_FILE 环境变量来设置 Compose 项目根目录. 默认为当前工作目录\n参考Get started with Docker Compose\n","categories":["Docker - Compose"],"tags":["Docker","Notes","Docker Compose"]},{"title":"Networking in Compose","url":"/docker/compose/networking-in-compose/","content":"默认情况下 Compose 为你的 app 设置单独一个 network\n服务的每个容器都加入默认网络, 并且可以被网络上的其他容器访问, 并且可以通过与容器名称相同的主机名被它们发现\n注意: 你的 app 的网络被赋予基于项目名称的名称, 这个网络名称基于 app 所在的目录名称. 可以通过 --project-name 标志或 COMPOSE_PROJECT_NAME 环境变量来覆盖项目名称\n例如, 假设你的 app 定义在一个被称为 myapp 的目录中, 且你的 docker-compose.yml 看起来是这样的:\nversion: &quot;3.9&quot;services:  web:    build: .    ports:      - &quot;8000:8000&quot;  db:    image: postgres    ports:      - &quot;8001:5432&quot;\n\n当运行 docker-compose up 时, 会发生如下事情:\n\n创建了一个名称为 myapp_default 的网络\n使用 web 配置创建了一个容器. 这个容器使用名称 web 加入到网络 myapp_default 中\n使用 db 配置创建了一个容器. 这个容器使用名称 db 加入到网络 myapp_default 中\n\n注意: 在 v2.1+ 中 overlay 网络总是可以 attachable 的, 且不可配置, 这意味着独立容器可以连接到 overlay 网络; 在 3.x Compose 文件中, 可以可选地设置 attachable 属性为 false\n每个容器现在可以查找主机名 web 和 db 并取回适当的容器 IP 地址\n例如, web 应用代码可以连接到 postgres://db:5432 URL 并开始使用 Postgres 数据库\n分清楚 HOST_PORT 和 CONTAINER_PORT 是很重要的\n在上面的例子中, 对于 db, HOST_PORT 是 8081 且容器端口是 5432 (postgres 默认端口)\n网络中的服务到服务通信使用 CONTAINER_PORT\n如果定义了 HOST_PORT, 那么服务也可以在 swarm 之外访问\n在 web 容器中, 连接到 db 的连接字符串看起来像这样 postgres://db:5432; 并且在宿主机上, 连接字符串看起来像这样 postgres://&#123;DOCKER_IP&#125;:8081\nUpdate containers (更新容器)如果修改了服务配置并运行 docker-compose up 来更新这个服务, 那么旧容器就会被删除, 新容器会使用不同的 IP 地址加入到网络中, 但是新容器继续使用相同的服务名称\n运行中的容器可以查找该名称并连接到新地址, 但是旧地址停止工作\n如果任何容器有到旧容器打开的连接, 这些连接将会被关闭. 这是容器的责任去检测连接, 重新查找名称并重新连接\nLinks (连接)连接允许你定义额外的别名, 通过这些别名可以从另一个服务访问服务\n它们不需要启用服务进行通信 - 默认情况下, 任何服务都可以使用该服务的名称访问任何其他服务\n在下面的例子中, 使用 db 和 database 主机名, web 可以访问到 db:\nversion: &quot;3.9&quot;services:  web:    build: .    links:      - &quot;db:database&quot;  db:    image: postgres\n\n查看 links reference 获取更多信息\nMulti-host networking (多主机网络)当使用开启 Swarm 模式 的 Docker 引擎部署一个 Compose 应用程序是, 可以使用内置的 overlay 驱动开启多主机通信\n查看 Swarm mode 章节, 查看怎样设置一个 Swarm 集群\n查看 Getting started with multi-host networking 学习多主机 overlay 网络\nSpecify custom networks (指定自定义网络)除了使用默认的 app 网络, 还可以使用顶层的 networks 键来定义自己的网络\n这让你可以创建更加复杂的拓扑并指定自定义网络驱动和选项\n你可以使用它来连接不是由 Compose 管理的外部创建网络\n每个服务可以使用服务级别的 networks 键来指定连接什么网络, 这个键是一个名称指向在顶级 networks 键下的实体的列表\n下面的 Compose 文件例子定义了两个自定义网络. proxy 服务和 db 服务是隔离的, 因为它们没有共同的网络, 只有 app 可以都和它们通信:\nversion: &quot;3.9&quot;services:  proxy:    build: ./proxy    networks:      - frontend  app:    build: ./app    networks:      - frontend      - backend  db:    image: postgres    networks:      - backendnetworks:  frontend:    # Use a custom driver    driver: custom-driver-1  backend:    # Use a custom driver which takes special options    driver: custom-driver-2    driver_opts:      foo: &quot;1&quot;      bar: &quot;2&quot;\n\n可以通过为每个连接的网络设置 ipv4_address 和&#x2F;或 ipv6_address 来为网络配置静态 IP 地址\n网络还可以指定一个自定义名称 (从 3.5 版本开始):\nversion: &quot;3.9&quot;services:  # ...networks:  frontend:    name: custom_frontend    driver: custom-driver-1\n\n查看如下手册, 获取全部可用网络配置选项的细节:\n\nTop-level networks key\nService-level networks key\n\nConfigure the default network (配置默认网络)除了指定你自己的网络, 你还可以通过在名为 default 的 networks 下定义一个条目来更改应用程序范围的默认网络的配置:\nversion: &quot;3.9&quot;services:  web:    build: .    ports:      - &quot;8000:8000&quot;  db:    image: postgresnetworks:  default:    # Use a custom driver    driver: custom-driver-1\n\nUse a pre-existing network (使用一个已存在的网络)如果你想要你的容器加入一个已存在的网络, 那么使用 external 选项:\nservices:  # ...networks:  default:    external:      name: my-pre-existing-network\n\nCompose 查找一个名为 my-pre-existing-network 的网络并将你的 app 的容器连接到这个网络, 而不是尝试创建一个名称为 [projectname]_default 的网络\n参考Networking in Compose\n","categories":["Docker - Compose"],"tags":["Docker","Notes","Docker Compose"]},{"title":"Share Compose configurations between files and projects","url":"/docker/compose/share-compose-configurations-between-files-and-projects/","content":"\n\n\nMultiple Compose files (多个 Compose 文件)\nUnderstanding multiple Compose files (理解多个 Compose 文件)\nExample use case (简单用例)\nDifferent environments\nAdministrative tasks (管理任务)\n\n\n\n\nExtending services (扩展服务)\nUnderstand the extends configuration (理解配置继承)\nExample use case\n\n\nAdding and overriding configuration (添加和覆盖配置)\n参考\n\n\n\nCompose 支持两种方式来共享通用配置:\n\n通过使用多个 Compose 文件来继承一整个 Compose 文件\n使用 extends field 来继承单独的服务 (从 2.1 版本的 Compose 文件开始)\n\nMultiple Compose files (多个 Compose 文件)使用多个 Compose 文件让你可以为不同环境或不同工作流自定义 Compose 应用程序\nUnderstanding multiple Compose files (理解多个 Compose 文件)默认地, Compose 读取两个文件, docker-compose.yml 文件 和一个可选的 docker-compose.override.yml 文件\n约定在 docker-compose.yml 中包含你的基础配置\ndocker-compose.override.yml 文件包含 用来覆盖已存在的服务 和 全新服务 的配置\n如果一个服务在两个文件中都有定义, Compose 使用 Adding and overriding configuration 中描述的规则来合并配置\n要使用多个覆盖文件, 或者一个不同名字的覆盖文件, 使用 -f 选项来指定文件列表\nCompose 以文件在命令行中指定文件的顺序来合并文件\n查看 docker-compose 命令行手册 来获取更多关于 -f 的信息\n当你使用多个配置文件时, 必须确保文件中的所有路径都是相对于基础 Compose 文件 (使用 -f 指定的第一个 Compose 文件)\n这是必须的, 因为覆盖文件不必是有效的 Compose 文件\n覆盖文件可以包含小的配置片段\n跟踪服务的哪个片段与哪个路径相关是困难且令人困惑的, 所以保持路径易于理解, 所有路径必须定义为相对于基础文件\nExample use case (简单用例)在这个章节, 有两个多 Compose 文件的常见用例:\n\n为不同环境修改一个 Compose 应用\n针对 Compose 应用运行管理任务\n\nDifferent environments一个多文件的常见用例是将开发的 Compose 应用更改为类似生产环境\n要支持这种差异性, 可以将 Compose 配置分割到不同的文件中\n从定义服务的规范配置的基础文件开始\nExample - docker-compose.yml:\nweb:  image: example/my_web_app:latest  depends_on:    - db    - cachedb:  image: postgres:latestcache:  image: redis:latest\n\n在下面的开发配置例子中, 暴露了端口给主机, 挂载代码为一个存储卷, 并构建 web 镜像:\nExample - docker-compose.overriding.yml:\nweb:  build: .  volumes:    - &#x27;.:/code&#x27;  ports:    - 8833:80  environment:    DEBUG: &#x27;true&#x27;db:  command: &#x27;-d&#x27;  ports:    - 5432:5432cache:  ports:    - 6379:6379\n\n当你运行 docker-compose up 时将自动读取上述的覆盖配置\n创建另外一个覆盖文件 (可能保存在另外一个 Git 仓库或被另外一个团队管理) 来在生产环境中使用这个 Compose 应用\nExample - docker-compose.prod.yml:\nweb:  ports:    - 80:80  environment:    PRODUCTION: &#x27;true&#x27;cache:  environment:    TTL: &#x27;500&#x27;\n\n使用上述 Compose 文件来部署:\n$ docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d\n\n这将会使用在 docker-compose.yml 和 docker-compose.prod.yml 中的配置来部署所有的三个服务\n查看 production 获取更多关于在生产中使用 Compose 的信息\nAdministrative tasks (管理任务)另一个常见用例是针对 Compose 应用中的一个或多个服务 运行 临时任务或管理任务\n这个例子演示了运行数据库备份\ndocker-compose.yml:\nweb:  image: example/my_web_app:latest  depends_on:    - dbdb:  image: postgres:latest\n\n在 docker-compose.admin.yml 中添加新的服务来执行数据库导出或备份:\ndbadmin:  build: database_admin/  depends_on:    - db\n\n要启动一个普通环境, 运行: docker-compose up -d\n要运行数据库备份, 包括 docker-compose.admin.yml:\n$ docker-compose -f docker-compose.yml -f docker-compose.admin.yml run dbadmin db-backup\n\nExtending services (扩展服务)extends 在 Compose 3.x 版本中不支持\nextends 关键字已经包含在 1.27 及更高版本的 docker-compose 文件中\nDocker Compose 的 extends 关键可以在不同文件甚至完全不同的项目之间共享通用配置\n如果你有多个服务重用一组通用的配置选项, 那么继承服务 (extending services) 就非常有用\n使用 extends 你可以定义一组通用的服务选项 (service options) 在一个地方, 并在任何地方引用它\n记得永远不要在服务之间使用 extends 共享 volumes_from 和 depends_on\n这些例外是为了避免隐式依赖; 保持在本地定义 volumes_from\n这保证了在阅读当前依赖时, 服务之间的依赖是清晰可读的\n在本地定义这些还保证了修改相关文件不会任何东西崩溃\nUnderstand the extends configuration (理解配置继承)当在 docker-compose.yml 中定义任意服务时, 你可以像这样声明继承另一个服务:\nservices:  web:    extends:      file: common-services.yml      service: webapp\n\n在上面的例子中, 你得到了和 在docker-compose.yml中直接在web下使用相同build,ports,volumes定义配置 一样的效果\n你可以更进一步地在 docker-compose.yml 本地定义 (或重新定义) 配置:\nservices:  web:    extends:      file: common-services.yml      service: webapp    environment:      - DEBUG=1    cpu_shares: 5    importnat_web:    extends: web    cpu_shares: 10\n\n你还可以编写另外一个服务并将你的 web 服务链接上它们:\nservices:  web:    extends:      file: compose      service: webapp    environment:      - DEBUG=1    cpu_shares: 5    depends_on:      - db  db:    image: postgres\n\nExample use case当你有多个服务有通用配置时, 继承一个单独的服务是很有用的\n下面的例子是一个有两个服务的 Compose 应用: 一个 web 应用和一个队列处理器\n这两个服务有相同的代码 (codebase) 且共享许多配置选项\n在 common.yml 中我们定义通用配置:\nservices:  app:    build: .    environment:      CONFIG_FILE_PATH: /code/config      API_KEY: xxxyyy    cpu_shares: 5\n\n在 docker-compose.yml 中使用通用配置定义混合服务:\nservices:  webapp:    extends:      file: common.yml      service: app    command: /code/run_web_app    ports:      - 8080:8080    depends_on:      - queue      - db  queue_worker:    extends:      file: common.yml      service: app    command: /code/run_worker    depends_on:      - queue\n\nAdding and overriding configuration (添加和覆盖配置)Compose 从原始服务复制配置到本地服务\n如果配置选项都定义在原始服务和本地服务中, 那么本地值 (local value) 代替或继承原始值 (original value)\n原始服务:\nservices:  myservice:    command: python app.py\n\n本地服务:\nservices:  myservice:    command: python otherapp.py\n\n结果:\nservices:  myservice:    command: python otherapp.py\n\n对于有多值的选项 ports,expose,external_links,dns,dns_search,tmpfs Compose 混合两组值:\n原始服务:\nservices:  myservice:    expose:      - &quot;3000&quot;\n\n本地服务:\nservices:  myservice:    expose:      - &quot;4000&quot;      - &quot;5000&quot;\n\n结果:\nservices:  myservice:    expose:      - &quot;3000&quot;      - &quot;4000&quot;      - &quot;5000&quot;\n\n在 environment,labels,volumes,devices 选项中, Compose 将实体合并在一起, 以本地定义值优先\n对于 environment,labels, 环境变量或标签名称指明了使用哪个值:\n原始服务:\nservices:  myservice:    environment:      - FOO=original      - BAR=original\n\n本地服务:\nservices:  myservice:    environment:      - BAR=local      - BAZ=local\n\n结果:\nservices:  myservice:    environment:      - FOO=original      - BAR=local      - BAZ=local\n\nvolumes 和 devices 的实体使用容器中的挂载路径合并:\n原始服务:\nservices:  myservice:    volumes:      - ./original:/foo      - ./original:/bar\n\n本地服务:\nservices:  myservice:    volumes:      - ./local:/bar      - ./local:/baz\n\n结果:\nservices:  myservice:    volumes:      - ./original:/foo      - ./local:/bar      - ./local:/baz\n\n参考Share Compose configurations between files and projects\n","categories":["Docker - Compose"],"tags":["Docker","Notes","Docker Compose"]},{"title":"Use Compose in production","url":"/docker/compose/use-compose-in-production/","content":"当你在开发中使用 Compose 定义你的应用程序时, 你可以使用这个定义来在不同环境中运行你的应用程序, 例如持续集成, 预生产, 生产环境\n部署应用程序最简单的方式是在单台服务器上运行, 就像在开发环境中运行一样. 如果你想扩展你的应用程序, 你可以在 Swarm 集群上运行 Compose 应用程序\nModify your Compose file for production (为生产环境修改你的 Compose 文件)你很有可能需要修改你的应用程序配置来使其为生产环境做好准备. 这些修改可能包括:\n\n删除所有绑定到应用代码的卷, 以使代码保持在容器中且不会被从外部修改\n绑定到主机上的不同端口\n设置不同的环境变量, 例如减少复杂的日志, 或指定设置外部服务, 例如邮件服务\n指定类似 restart: always 的重启策略来避免服务下线\n添加类似日志聚合器的额外服务\n\n因为这些原因, 考虑定义一个额外的 Compose 文件, 称为 production.yml, 这个文件指定适合生成的配置\n这个配置文件只需要包含你希望对原始 Compose 文件进行的修改\n这个额外 Compose 文件可以应用于原始的 docker-compose.yml 以创建新配置\n一旦你有第二个配置文件, 告诉 Compose 使用 -f 选项:\n$ docker-compose -f docker-compose.yml -f production.yml up -d\n\n查看 Using multiple compose files 获取完整例子\nDeploying changes (部署修改)当你修改了应用代码, 记得重新构建镜像并重新创建应用容器\n要重新部署一个称为 web 的服务, 使用:\n$ docker-compose build web$ docker-compose up --no-deps -d web\n\n首先重新构建 web 镜像, 然后停止, 销毁, 仅重新创建 web 服务\n--no-deps 标志防止 Compose 还重新创建所有 web 依赖的服务\nRunning Compose on a single server (在单台服务器上运行 Compose)通过设置适当的 DOCKER_HOST,DOCKER_TLS_VERIFY,DOCKER_CERT_PATH 环境变量来使用 Compose 部署 app 到一个远程 Docker 主机上\n一旦你设置好你的环境变量, 所有普通的 docker-compose 命令不需要额外设置来工作\n参考Use Compose in production\n","categories":["Docker - Compose"],"tags":["Docker","Notes","Docker Compose"]},{"title":"Using profiles with Compose","url":"/docker/compose/using-profiles-with-compose/","content":"profiles 允许通过选择性地启用服务来针对各种用途和环境调整 Compose 应用程序模型\n这通过为每个服务分配 0 个到多个 profiles 来实现\n如果没有分配 profiles, 那么服务总是会启动\n如果分配了 profiles, 那么服务只有在 profile 激活的时候启动\n这允许在单独一个 docker-compose.yml 文件中定义只在指定场景启动的附加服务. 例如: 用于调试或开发任务\nAssigning profiles to services (分配 profiles 给服务)服务通过接收 profile 名称数组的 profiles 属性 来分配 profiles:\nversion: &quot;3.9&quot;services:  frontend:    image: frontend    profiles: [&quot;frontend&quot;]  phpmyadmin:    image: phpmyadmin    depends_on:      - db    profiles:      - debug  backend:    image: backend  db:    image: mysql\n\n有效的 profile 名称必须满足 a-zA-Z0-9][a-zA-Z0-9_.-]+ 正则表达式\n核心服务不要分配 profiles, 因为它们一直都要开启并自动启动\nEnabling profiles (开启 profiles)使用 --profile 命令行选项或者使用 COMPOSE_PROFILES 环境变量来开启一个 profile:\n$ docker-compose --profile debug up$ COMPOSE_PROFILES=debug docker-compose up\n\n通过多个 --profile 标志或一个使用逗号分隔的列表的环境变量来开启多个 profile:\n$ docker-compose --profile frontend --profile debug up$ COMPOSE_PROFILES=frontend,debug docker-compose up\n\nAuto-enabling profiles and dependency resolution (自动配置 profiles 与依赖解析)当一个分配了 profiles 的服务在命令行中明确指定了, 那么这个服务的 profiles 将会自动开启, 所以你不需要手动开启它们\n这可以用在 one-off 服务和调试工具\n假设有如下配置:\nversion: &quot;3.9&quot;services:  backend:    image: backend    db:    image: mysql    db-migrations:    image: backend    command: myapp migrate    depends_on:      - db    profiles:      - tools\n\n# 只会启动 `backend` 和 `mysql`$ docker-compose up -d# 这将会运行 `db-migrations` (并且如果需要, 启动 `db`), 且隐含地开启 `tools` profile$ docker-compose run db-migrations\n\n但是记住 docker-compose 只会自动开启命令行中指定的服务的 profiles, 不会开启这个服务依赖的服务的 profiles\n这意味着目标服务依赖的所有服务必须要一个通用的 profile, 并永远启用这个 profile (通过去掉 profiles 属性) 或者明确开启一个匹配的 profile\nversion: &quot;3.9&quot;services:  web:    image: web  mock-backend:    image: backend    profiles: [&quot;dev&quot;]    depends_on:      - db    db:    image: mysql    profiles: [&quot;dev&quot;]    phpmyadmin:    image: phpmyadmin    profiles: [&quot;debug&quot;]    depends_on:      - db\n\n# 只会启动 `web`$ docker-compose up -d# 只会启动 `mock-backend` (如果有需要, 启动 `db`), 隐含地开启 `dev` profile$ docker-compose up -d mock-backend# 启动失败, 因为没有开启 `dev` profile# `phpadmin` 隐含地开启了 `debug` profile# 但是 `phpadmin` 依赖的 `db` 服务需要 `dev` profile# Compose 不会隐含地开启依赖的服务 (`db`) 的 profile$ docker-compose up phpadmin\n\n可以通过为 db 添加 debug profile 来解决这个问题:\ndb:  image: mysql  profiles: [&quot;dev&quot;, &quot;debug&quot;]\n\n或者明确开启 db 的一个 profile:\n# `debug` profile 通过指定 `phpadmin` 隐含地开启了$ docker-compose --profile dev up phpmyadmin$ COMPOSE_PROFILES=dev docker-compose up phpmyadmin\n\n参考Using profiles with Compose\n","categories":["Docker - Compose"],"tags":["Docker","Notes","Docker Compose"]},{"title":"Elasticsearch Aliases","url":"/elasticsearch/elasticsearch-guide/elasticsearch-aliases/","content":"\n\n\nElasticsearch Aliases\nAlias types\nAdd an alias\nRemove an alias\nMultiple actions\nAdd an alias at index creation\nView Aliases\nWrite index\nFilter an alias\nRouting\n参考\n\n\n\n\n\nElasticsearch Aliases一个 alias 是一组数据流或分片的第二个名字\n大多数 Elasticsearch API 接受一个 alias 作为数据流或索引名称的替代\nAlias types\n一个数据流别名指向一个或多个字符流\n一个索引别名指向一个或多个索引\n\n一个别名不能同时指向数据流和索引\n不能添加一个数据流的备份索引到一个索引别名中\nAdd an alias使用 aliases API 的 add 动作来添加一个已存在的数据流或索引给一个别名, 如果别名还未存在, 则请求将会新增这个别名\nPOST _aliases&#123;    &quot;actions&quot;: [        &#123;            &quot;add&quot;: &#123;                &quot;index&quot;: &quot;logs-nginx.access-prod&quot;,                &quot;alias&quot;: &quot;logs&quot;            &#125;        &#125;    ]&#125;\n\nAPI 中的 index 和 indices 参数支持通配符(*). 如果通配符模式同时匹配数据流和索引, 将会返回一个错误\nPOS _aliases&#123;    &quot;actions&quot;: [        &#123;            &quot;add&quot;: &#123;                &quot;index&quot;: &quot;logs-*&quot;,                &quot;alias&quot;: &quot;logs&quot;            &#125;        &#125;    ]&#125;\n\nRemove an aliasPOST _aliases&#123;    &quot;actions&quot;: [        &#123;            &quot;remove&quot;: &#123;                &quot;index&quot;: &quot;logs-nginx.access-prod&quot;,                &quot;alias&quot;: &quot;logs&quot;            &#125;        &#125;    ]&#125;\n\nMultiple actions可以使用别名 API 来在单个原子行为中执行多个操作\n例如, logs 别名指向单个数据流. 下面的请求中, 将会交换别名的数据流\nPOST _aliases&#123;    &quot;actions&quot;: [        &#123;            &quot;remove&quot;: &#123;                &quot;index&quot;: &quot;logs-nginx.access-prod&quot;,                &quot;alias&quot;: &quot;logs&quot;            &#125;        &#125;,        &#123;            &quot;add&quot;: &#123;                &quot;index&quot;: &quot;logs-my_app-default&quot;,                &quot;alias&quot;: &quot;logs&quot;            &#125;        &#125;    ]&#125;\n\nAdd an alias at index creation可以在索引创建的时候使用 Component 或者 Index template 来添加索引别名\n不可以使用 Component 或者 Index template 来添加一个数据流别名\n# Component template with index aliasesPUT _component_template/my-aliases&#123;    &quot;template&quot;: &#123;        &quot;aliases&quot;: &#123;            &quot;my-alias&quot;: &#123;&#125;        &#125;    &#125;&#125;# Index template with index aliasesPUT _index_template/my-index-template&#123;    &quot;index_patterns&quot;: [        &quot;my-index-*&quot;    ],    &quot;composed_of&quot;: [        &quot;my-aliases&quot;,        &quot;my-mappings&quot;,        &quot;my-settings&quot;    ],    &quot;template&quot;: &#123;        &quot;aliases&quot;: &#123;            &quot;yet-another-alias&quot;: &#123;&#125;        &#125;    &#125;&#125;\n\n还可以在创建索引 API 中指定索引别名:\nPUT %3Cmy-index-%7Bnow%2Fd%7D-000001%3E&#123;  &quot;aliases&quot;: &#123;    &quot;my-alias&quot;: &#123;&#125;  &#125;&#125;\n\nView Aliases获取集群中的所有别名:\nGET _alias\n\n查看数据流或索引的别名:\nGET my-data-stream/_alias\n\n在别名后面使用 _alias 来查看其对应的数据流或索引:\nGET _alias/logs\n\nWrite index可以使用 is_write_index 为一个别名指定是否可以写一个索引或数据流\nElasticsearch将对别名的任何写请求路由到该索引或\nPOST _aliases&#123;  &quot;actions&quot;: [    &#123;      &quot;add&quot;: &#123;        &quot;index&quot;: &quot;logs-nginx.access-prod&quot;,        &quot;alias&quot;: &quot;logs&quot;      &#125;    &#125;,    &#123;      &quot;add&quot;: &#123;        &quot;index&quot;: &quot;logs-my_app-default&quot;,        &quot;alias&quot;: &quot;logs&quot;,        &quot;is_write_index&quot;: true      &#125;    &#125;  ]&#125;\n\n如果一个别名指向多个索引或多个数据流且 is_write_index 没有配置, 那么别名将会拒绝写请求\n如果一个别名指向一个索引或一个数据流且 is_write_index 没有配置, 那么索引将自动地作为写索引. 数据流别名不会自动设置为写数据流, 即使这个别名指向了一个数据流\nFilter an aliasfilter 选项使用 Query DSL 来限制一个别名可以访问的文档数量\n数据流别名不支持 filter 选项\nPOST _aliases&#123;  &quot;actions&quot;: [    &#123;      &quot;add&quot;: &#123;        &quot;index&quot;: &quot;my-index-2099.05.06-000001&quot;,        &quot;alias&quot;: &quot;my-alias&quot;,        &quot;filter&quot;: &#123;          &quot;bool&quot;: &#123;            &quot;filter&quot;: [              &#123;                &quot;range&quot;: &#123;                  &quot;@timestamp&quot;: &#123;                    &quot;gte&quot;: &quot;now-1d/d&quot;,                    &quot;lt&quot;: &quot;now/d&quot;                  &#125;                &#125;              &#125;,              &#123;                &quot;term&quot;: &#123;                  &quot;user.id&quot;: &quot;kimchy&quot;                &#125;              &#125;            ]          &#125;        &#125;      &#125;    &#125;  ]&#125;\n\nRouting使用 routing 选项去路由一个别名的请求到一个指定的分片\n这可以让你通过 shard caches 来加速搜索\n数据流不支持这个选项\nPOST _aliases&#123;  &quot;actions&quot;: [    &#123;      &quot;add&quot;: &#123;        &quot;index&quot;: &quot;my-index-2099.05.06-000001&quot;,        &quot;alias&quot;: &quot;my-alias&quot;,        &quot;routing&quot;: &quot;1&quot;      &#125;    &#125;  ]&#125;\n\n使用 index_routing 和 search_routing 来为索引和搜索指定不同路由值\n如果配置了, 这两个选项将会在它们各自的操作中覆盖 routing 的值\nPOST _aliases&#123;  &quot;actions&quot;: [    &#123;      &quot;add&quot;: &#123;        &quot;index&quot;: &quot;my-index-2099.05.06-000001&quot;,        &quot;alias&quot;: &quot;my-alias&quot;,        &quot;search_routing&quot;: &quot;1&quot;,        &quot;index_routing&quot;: &quot;2&quot;      &#125;    &#125;  ]&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 索引 blocks","url":"/elasticsearch/elasticsearch-guide/elasticsearch-blocks/","content":"Elasticsearch 索引 blocksindex blocks 用来限制可以在一个具体索引上可以进行的操作\nblocks 可以使用动态索引设置来设置或者去除, 或者使用指定 API 进行添加\n参考link\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 在搜索请求中定义运行时字段 Define runtime fields in a search request","url":"/elasticsearch/elasticsearch-guide/elasticsearch-define-runtime-fields-in-a-search-request/","content":"Elasticsearch 在搜索请求中定义运行时字段 Define runtime fields in a search request可以在请求中使用 runtime_mappings 来定义 runtime fields\nruntime fields 的优先级比文档中同名的 fields 更高\n可以使用 runtime fields 来创建 runtime fields\n可以在 aggregations 中使用 runtime fields\n参考link\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch Delaying allocation when a node leaves","url":"/elasticsearch/elasticsearch-guide/elasticsearch-delaying-allocation-when-a-node-leaves/","content":"Elasticsearch Delaying allocation when a node leaves控制一个节点离开集群时, 等待多久才进行分片重新分配\nThis setting can be updated on a live index (or on all indices):\nPUT _all/_settings&#123;    &quot;settings&quot;: &#123;        &quot;index.unassigned.node_left.delayed_timeout&quot;: &quot;5m&quot;    &#125;&#125;\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 静态映射 Explicit mapping","url":"/elasticsearch/elasticsearch-guide/elasticsearch-explicit-mapping/","content":"Elasticsearch 静态映射 Explicit mapping使用静态映射创建索引PUT /my-index-00001&#123;    &quot;mappings&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;age&quot; : &#123;&quot;type&quot;: &quot;integer&quot;&#125;,            &quot;email&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;,            &quot;name&quot;: &#123;&quot;type&quot;: &quot;text&quot;&#125;        &#125;    &#125;&#125;\n\n添加一个字段到已存在的索引PUT /my-index-00001/_mapping&#123;    &quot;properties&quot;: &#123;        &quot;employee-id&quot;: &#123;            &quot;type&quot;: &quot;keyword&quot;,            &quot;index&quot;: false      // This means values for the employee-id field are stored but not indexed or available for search        &#125;    &#125;&#125;\n\n更新字段的映射除了使用 mapping parameters , 不能修改一个已存在的字段的映射或类型. 改变一个已存在的字段将会使已经索引好的数据失效\n可以使用 Change mappings and settings for a data stream\n创建一个新的索引, 然后将旧索引 reindex 到新索引\n使用 alias field 在原有字段上创建一个新字段\n查看一个索引的映射GET /my-index-0000001/_mapping\n\n查看一个索引的指定字段映射GET /my-index-000001/_mapping/field/employee-id\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 使用运行时字段探索你的数据 Explore your data with runtime fields","url":"/elasticsearch/elasticsearch-guide/elasticsearch-explore-your-data-with-runtime-fields/","content":"Elasticsearch 使用运行时字段探索你的数据 Explore your data with runtime fields在不预先定义 schema 的情况下探索数据\n通过使用 script 来在查询时提取已存在的字段的数据\n可以定义 组合类型 的 runtime fields\n可以在 script 中使用 grok 或者 dissect pattern 抽取数据\n参考link\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 索引运行时字段 Index a runtime field","url":"/elasticsearch/elasticsearch-guide/elasticsearch-index-a-runtime-field/","content":"Elasticsearch 索引运行时字段 Index a runtime field将 runtime field 定义到索引映射中, 有更好的性能\n在更新索引映射中, 直接使用 runtime 参数来进行定义\n参考link\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 配置运行时字段 Map a runtime field","url":"/elasticsearch/elasticsearch-guide/elasticsearch-map-a-runtime-field/","content":"Elasticsearch 配置运行时字段 Map a runtime field在定义索引时, 可以使用脚本配置 runtime field\n如果 dynamic field mapping 开启且 dynamic=&quot;runtime&quot; , 那么新字段自动作为 runtime field\n可以不使用脚本配置 runtime field\n可以通过将 runtime field 设置为 null 来将其删除\n可以设置同名的 runtime field 来更新旧的 runtime field\n参考link\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 在查询时重写字段值 Override field values at query time","url":"/elasticsearch/elasticsearch-guide/elasticsearch-override-field-values-at-query-time/","content":"Elasticsearch 在查询时重写字段值 Override field values at query time使用同名的 runtime fields 名字来覆盖文档中的字段值\n在不重新索引 index 的情况下, 来修改字段的返回值\n在 _search 端点中使用 runtime_mappings 来使用这个功能\n参考link\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 获取运行时字段 Retrieve a runtime field","url":"/elasticsearch/elasticsearch-guide/elasticsearch-retrieve-a-runtime-field/","content":"Elasticsearch 获取运行时字段 Retrieve a runtime field在 _search 端点中使用 fields 参数来获取 runtime field\n参考link\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 运行时字段 Runtime Fields","url":"/elasticsearch/elasticsearch-guide/elasticsearch-runtime-fields/","content":"Elasticsearch 运行时字段 Runtime Fields不是实际存在于索引中的字段, 类似一种视图字段\n可以用来代替 script fields\nRuntime fields 的计算会消耗性能, 所以最好使用 asynchronous search API 去执行包含 Runtime fields 的查询\n如果 search.allow_expensive_queriess=false, 那么耗时的查询将会被 Elasticsearch 拒接, Elasticsearch 也会拒绝所有包含 Runtime fields  的查询\n参考link\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 事务日志配置","url":"/elasticsearch/elasticsearch-guide/elasticsearch-%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE/","content":"Elasticsearch 事务日志配置可以配置事务日志刷新的时间间隔, 阈值, 大小\n参考link\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 慢日志配置","url":"/elasticsearch/elasticsearch-guide/elasticsearch-%E6%85%A2%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE/","content":"Elasticsearch 慢日志配置搜索慢日志可以将分片级别的搜索慢日志保存到指定的日志文件\n慢查询阈值有如下:\nindex.search.slowlog.threshold.query.warn: 10sindex.search.slowlog.threshold.query.info: 5sindex.search.slowlog.threshold.query.debug: 2sindex.search.slowlog.threshold.query.trace: 500msindex.search.slowlog.threshold.fetch.warn: 1sindex.search.slowlog.threshold.fetch.info: 800msindex.search.slowlog.threshold.fetch.debug: 500msindex.search.slowlog.threshold.fetch.trace: 200ms\n\n以上配置还可以使用 update indices settings API 来进行动态配置:\nPUT /my-index-00001/_settings&#123;    &quot;index.search.slowlog.threshold.query.warn&quot;: &quot;10s&quot;,    &quot;index.search.slowlog.threshold.query.info&quot;: &quot;5s&quot;,    &quot;index.search.slowlog.threshold.query.debug&quot;: &quot;2s&quot;,    &quot;index.search.slowlog.threshold.query.trace&quot;: &quot;500ms&quot;,    &quot;index.search.slowlog.threshold.fetch.warn&quot;: &quot;1s&quot;,    &quot;index.search.slowlog.threshold.fetch.info&quot;: &quot;800ms&quot;,    &quot;index.search.slowlog.threshold.fetch.debug&quot;: &quot;500ms&quot;,    &quot;index.search.slowlog.threshold.fetch.trace&quot;: &quot;200ms&quot;&#125;\n\n默认情况下阈值是不开启的, 设置为 -1\n索引慢日志日志文件名称为 _index_indexing_slowlog.log\n阈值配置:\nindex.indexing.slowlog.threshold.index.warn: 10sindex.indexing.slowlog.threshold.index.info: 5sindex.indexing.slowlog.threshold.index.debug: 2sindex.indexing.slowlog.threshold.index.trace: 500msindex.indexing.slowlog.source: 1000\n\n动态API设置:\nPUT /my-index-000001/_settings&#123;  &quot;index.indexing.slowlog.threshold.index.warn&quot;: &quot;10s&quot;,  &quot;index.indexing.slowlog.threshold.index.info&quot;: &quot;5s&quot;,  &quot;index.indexing.slowlog.threshold.index.debug&quot;: &quot;2s&quot;,  &quot;index.indexing.slowlog.threshold.index.trace&quot;: &quot;500ms&quot;,  &quot;index.indexing.slowlog.source&quot;: &quot;1000&quot;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 查看集群健康状态","url":"/elasticsearch/elasticsearch-guide/elasticsearch-%E6%9F%A5%E7%9C%8B%E9%9B%86%E7%BE%A4%E5%81%A5%E5%BA%B7%E7%8A%B6%E6%80%81/","content":"Elasticsearch 查看集群健康状态GET _cluster/health\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 索引恢复优先级","url":"/elasticsearch/elasticsearch-guide/elasticsearch-%E7%B4%A2%E5%BC%95%E6%81%A2%E5%A4%8D%E4%BC%98%E5%85%88%E7%BA%A7/","content":"Elasticsearch 索引恢复优先级\n根据可选的 index.priority 配置 (数值越高优先级越高)\n索引创建的时间 (越先创建优先级越高)\n索引名称排序\n\nPUT index_1PUT index_2PUT index_3&#123;    &quot;settings&quot;: &#123;        &quot;index.priority&quot;: 10    &#125;&#125;PUT index_4&#123;    &quot;settings&quot;: &#123;        &quot;index.priority&quot;: 5    &#125;&#125;\n\n恢复顺序:\n\nindex_3\nindex_4\nindex_2\nindex_1\n\n可以动态调整一个索引的恢复优先级:\nPUT index_4/_settings&#123;    &quot;index.priority&quot;: 1&#125;\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 索引排序","url":"/elasticsearch/elasticsearch-guide/elasticsearch-%E7%B4%A2%E5%BC%95%E6%8E%92%E5%BA%8F/","content":"Elasticsearch 索引排序创建索引时, 可以指定分段( Segments )中文档的排序规则:\nPUT my-index-000001&#123;  &quot;settings&quot;: &#123;    &quot;index&quot;: &#123;      &quot;sort.field&quot;: &quot;date&quot;,       &quot;sort.order&quot;: &quot;desc&quot;      &#125;  &#125;,  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;date&quot;: &#123;        &quot;type&quot;: &quot;date&quot;      &#125;    &#125;  &#125;&#125;\n\nEarly termination of search request在文档有序的情况下, 可以使得搜索扫描更少的文档并快速返回\nGET /events/_search&#123;  &quot;size&quot;: 10,  &quot;sort&quot;: [    &#123; &quot;timestamp&quot;: &quot;desc&quot; &#125;  ]&#125;\n\n上面的例子中, 还是需要通过扫描所有文档来计算文档总数. 可以使用 track_total_hits 来指定需不需要统计文档总数, 这样可以省去扫描所有文档的消耗:\nGET /events/_search&#123;  &quot;size&quot;: 10,  &quot;sort&quot;: [       &#123; &quot;timestamp&quot;: &quot;desc&quot; &#125;  ],  &quot;track_total_hits&quot;: false&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 配置合并的最大线程数","url":"/elasticsearch/elasticsearch-guide/elasticsearch-%E9%85%8D%E7%BD%AE%E5%90%88%E5%B9%B6%E7%9A%84%E6%9C%80%E5%A4%A7%E7%BA%BF%E7%A8%8B%E6%95%B0/","content":"Elasticsearch 配置合并的最大线程数index.merge.scheduler.max_thread_count\n配置一个分片上一次合并时最大的合并线程数\n默认是 Math.max(1, Math.min(4, &lt;&lt;node.processors, node.processors&gt;&gt; / 2)) , 在 SSD 上运行良好\n在普通磁盘上, 最好设置为 1\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"Elasticsearch 预加载数据到文件系统缓存","url":"/elasticsearch/elasticsearch-guide/elasticsearch-%E9%A2%84%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E5%88%B0%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98/","content":"Elasticsearch 预加载数据到文件系统缓存通过使用 index.store.preload 来指定要进行预加载的索引\nindex.store.preload 是在 config/elasticsearch.yml 中的静态配置:\nindex.store.preload: [&quot;nvd&quot;, &quot;dvd&quot;]\n\n或者在索引创建时进行指定:\nPUT /my-index-000001&#123;    &quot;settings&quot;: &#123;        &quot;index.store.preload&quot;: [&quot;nvd&quot;, &quot;dvd&quot;]    &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides"],"tags":["User Guides","Elasticsearch"]},{"title":"kubectl 命令工具","url":"/k8s/kubernetes-%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/","content":"\n\n\n获取多个 Pod 的信息\n获取多种对象的信息\n同时应用多个 YAML 文件\n使用目录下的所有文件定义\n删除所有 Pod\n在 Pod 中执行命令 (默认使用 Pod 中第一个容器)\n在 Pod 指定容器中执行命令\n在 Pod 指定容器中运行 bash\n在线编辑运行中的资源对象\n将 Pod 的开放端口映射到本地\n在 Pod 和本地之间复制文件\n检查可用的 API 资源类型列表\n查看已安装的插件列表\n\n\n\n$ kubectl [command] [TYPE] [NAME] [flags]\nTYPE: 资源对象类型, 区分大小写, 能以单数, 复数或者简写形式表示\n获取多个 Pod 的信息$ kubectl get pods pod1 pod2\n获取多种对象的信息$ kubectl get pod/pod1 rc/rc1\n同时应用多个 YAML 文件$ kubectl apply -f pod1.yaml -f pod2.yaml\n使用目录下的所有文件定义$ kubectl create -f &lt;directory&gt;\n删除所有 Pod$ kubectl delete pods --all\n在 Pod 中执行命令 (默认使用 Pod 中第一个容器)$ kubectl exec &lt;pod-name&gt; &lt;command&gt;\n在 Pod 指定容器中执行命令$ kubectl exec &lt;pod-name&gt; -c &lt;container-name&gt; &lt;command&gt;\n在 Pod 指定容器中运行 bash$ kubectl exec -ti &lt;pod-name&gt; -c &lt;container-name&gt; /bin/bash\n在线编辑运行中的资源对象$ kubectl edit deploy nginx\n将 Pod 的开放端口映射到本地$ kubectl port-forward --address 0.0.0.0 pod/nginx-2832834829-2323 8888:80\n在 Pod 和本地之间复制文件$ kubectl cp nginx-snnsowe983-wb23sd:/etc/fstab /tmp\n检查可用的 API 资源类型列表$ kubectl api-resourcecs\n查看已安装的插件列表$ kubectl plugin list\n","tags":["Notes"]},{"title":"Kubernetes 入门","url":"/k8s/kubernetes-%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97/kubernetes-%E5%85%A5%E9%97%A8/","content":"\n\n\nKubernetes 是什么\nKubernetes 的基本概念和术语\nMaster\nNode\nPod\nLabel\nReplicationController\nDeployment\nHorizontal Pod Autoscaler\nStatefulSet\nService  - 外部系统访问 Service 的问题\nJob\nVolume\nVolume 类型\nemptyDir\nhostPath\nNFS\n\n\n\n\nPersistent Volume\nNamespace\nAnnotation\nConfigMap\n\n\n\n\n\nKubernetes 是什么Kubernetes 将集群中的机器分为一个 Master 和一些 Node\n在 Master 上运行着集群管理相关的一组进程:\n\nkube-apiserver\nkube-controller-manager\nkube-scheduler\n\nNode 作为集群中的工作节点, 运行真正的应用程序\n在 Node 上 Kubernetes 管理的最小运行单元是 Pod\n在 Node 上运行着 Kubernetes 的 kubelet,kube-proxy\nKubernetes 的基本概念和术语MasterMaster 指的是集群控制节点\n所有控制命令都发给它, 它负责具体的执行过程\n在 Master 上运行着以下关键进程:\n\nKubernetes API Server (kube-apiserver)\n集群控制的入口进程\n集群资源的增删改查操作入口\n\n\nKubernetes Controller Manager (kube-controller-manager)\n所有资源对象的自动化控制中心\n\n\nKubernetes Scheduler (kube-scheduler)\n负责资源调度的进程\n\n\n\nNode在每个 Node 上运行以下关键进程:\n\nkubelet\n负责 Pod 对应的容器的创建, 启停等任务\n\n\nkube-proxy\n实现 Services 的通信与负载均衡机制\n\n\n容器运行时\n\nPod每个 Pod 都有一个特殊的”根容器” Pause容器\nPause容器 对应的镜像术语 Kubernetes 平台的一部分\n每个 Pod 还包含一个或多个紧密相关的用户业务容器\n引入业务无关的 Pause容器 作为 Pod 的根容器, 以它的状态代表整个容器组的状态\n多个业务容器共享 Pause容器 的 IP, 共享 Pause容器 挂载的 Volume. 简化了关联的容器之间的通信问题, 解决了它们之间的文件共享问题\nKubernetes 为每个 Pod 都分配了唯一的 IP 地址, 称之为 Pod IP\n一个 Pod 中的多个容器共享 Pod IP 地址\nKubernetes 要求底层网络支持集群内任意两个 Pod 之间的 TCP&#x2F;IP 直接通信\n这通常采用虚拟二层网络技术来实现\n在 Kubernetes 中, 一个 Pod 里的容器与另外主机上的 Pod 容器能够直接通信\nPod 有两种类型:\n\n普通 Pod\n静态 Pod (Static Pod)\n\nStatic Pod 没有被存储在 etcd 中, 而是被存放在某个具体的 Node 中一个具体文件上, 并且只在此 Node 上启动, 运行\n当 Pod 里的某个容器停止时, Kubernetes 会自动检测到这个问题并且重新启动这个 Pod (重启 Pod 里的所有容器)\nLabelDeployment, ReplicaSet, DaemonSet, Job 可以在 Selector 中使用基于集合的筛选条件定义:\nselector:  matchLabels:    app: myweb  matchExpressions:    - &#123;key: tier, operator: In, values: [frontend]&#125;    - &#123;key: environment, operator: NotIn, values: [dev]&#125;\n\n可用运算符包括:\n\nIn\nNotIn\nExists\nDoesNotExist\n\nLabel Selector 的重要使用场景:\n\nkube-controller-manager 通过 Label Selector 来筛选要监控的 Pod 副本数量\nkube-proxy 通过 Service 的 Label Selector 来选择对应的 Pod\nkube-scheduler 可以实现 Pod 定向调度的特性\n\nReplicationController在 Kubernetes 1.2 中, ReplicationController 升级为另外一个新概念: ReplicaSet\nReplicaSet 支持基于集合的 Label Selector\nReplicationController 只支持基于等式的 Label Selector\n很少单独使用 ReplicaSet, 它主要被 Deployment 这个更高层的资源对象所使用\nDeploymentDeployment 内部使用了 ReplicaSet\nDeployment 随时知道当前 Pod “部署”的进度\nHorizontal Pod Autoscaler横向 Pod 自动扩容\nHPA\nHPA 也是一种资源对象\nHPA 通过跟踪分析指定 ReplicaSet 控制的所有目标 Pod 的负载变化情况, 来确定是否需要有针对性地调整目标 Pod 的副本数量\nHPA 有如下 Pod 负载度量指标:\n\nCPUUtilizationPercentage\n应用程序自定义度量指标, 如 TPS, QPS\n\nCPUUtilizationPercentage 是一个算数平均值, 即目标 Pod 所有副本自身的 CPU 利用率的平均值\n一个 Pod 自身的 CPU 利用率是该 Pod 当前 CPU 的使用量除以它的 Pod Request 的值\n如果目标 Pod 没有定义 Pod Request 的值, 则无法使用 CPUUtilizationPercentage 实现 Pod 的横向自动扩容\n在 CPUUtilizationPercentage 计算过程中使用到的 Pod 的 CPU 使用量通常是 1 min 内的平均值\n可以从 Kubernetes Monitoring Architecture 来获取目标资源对象的性能数据\nHPA 定义例子:\napiVersion: autoscaling/v1kind: HorizontalPodAutoscalermetadata:  name: php-apache  namespace: defaultspec:  maxReplicas: 1  minReplicas: 10  scaleTargetRef:    kind: Deployment    name: php-apache  targetCPUUtilizationPercentage: 90\n\nStatefulSetStatefulSet 里的每个 Pod 都有稳定的, 唯一的网络标识\nStatefulSet 控制的 Pod 副本的启停顺序是受控的\nStatefulSet 里的 Pod 采用稳定的持久化存储卷, 通过 PV 或 PVC 来实现\nStatefulSet 除了要与 PV 卷捆绑使用以存储 Pod 的状态数据, 还要与 Headless Service 配合使用\n在每个 StatefulSet 定义中, 都要声明它属于哪个 Headless Service\nHeadless Service 与普通 Service 的关键区别在于, 它没有 Cluster IP\n如果解析 Headless Service 的 DNS 域名, 则返回的是该 Service 对应的全部 Pod 的 Endpoint 列表\nStatefulSet 在 Headless Service 的基础上又为 StatefulSet 控制的每个 Pod 实例都创建了一个 DNS 域名\n这个域名格式为: $&#123;podname&#125;.$&#123;headless service name&#125;\nService运行在每个 Node 上的 kube-proxy 进程负责把对 Service 的请求转发到后端的某个 Pod 实例上, 并在内部实现服务的负载均衡与会话保持机制\n每个 Service 都被分配了一个全局唯一的虚拟 IP 地址, 这个虚拟 IP 被称为 Cluster IP\n在 Service 的整个生命周期中, 它的 Cluster IP 不会发生改变\n外部系统访问 Service 的问题\nNode IP: Node 的 IP 地址\nPod IP: Pod 的 IP 地址\nCluster IP: Service 的 IP 地址\n\nNode IP 是 Kubernetes 集群中每个节点的物理网卡的 IP 地址, 是一个真实存在的物理网络\nPod IP:\n\n是每个 Pod 的 IP 地址\n根据 docker0 网桥的 IP 地址段进行分配\n通常是一个虚拟的二层网络\nKubernetes 要求位于不同 Node 上的 Pod 能够彼此直接通信, 所以 Kubernetes 里的一个 Pod 里的容器访问另一个 Pod 里的容器时, 就是通过 Pod IP 所在的虚拟二层网络进行通信的, 而真实的 TCP&#x2F;IP 流量是通过 Node IP 所在的物理网卡流出的\n\nCluster IP:\n\nCluster IP 仅作用于 Kubernetes Service 对象, 并由 Kubernetes 管理和分配 IP 地址\nCluster IP 无法被 Ping, 因为没有一个”实体网络对象”来响应\nCluster IP 只能结果 Service Port 组成一个具体的通信端口, 单独的 Cluster IP 不具备 TCP&#x2F;IP 通信的基础\n在 Kubernetes 集群内, Node IP,Pod IP,Cluster IP 之间的通信, 采用的是 Kubernetes 自己设计的一种编程方式的特殊路由规则\n\nService 的 Cluster IP 属于 Kubernetes 集群内部的地址, 无法在集群外部直接使用这个地址\n可以采用 NodePort 来解决这个问题:\napiVersion: v1kind: Servicemetadata:  name: tomcat-servicespec:  type: NodePort  ports:    - port: 8080    nodePort: 31002  selector:    tier: frontend\n\n通过 http://&lt;nodePort IP&gt;:31002 即可访问\nNodePort 的实现方式是在 Kubernetes 集群里的每个 Node 上都为需要外部访问的 Service 开启一个对应的 TCP 监听端口, 外部系统只要用任意一个 Node 的 IP 地址加上具体的 NodePort 端口号即可访问此服务\nJobJob 生成的 Pod 副本是不能自动重启的, 对应的 Pod 副本的 RestartPolicy 都被设置成 Never\nJob 所控制的 Pod 副本的工作模式能够多实例并行计算\nVolumeVolume (存储卷) 是Pod 中能够被多个容器访问的共享目录\nVolume 被定义在 Pod 上\n使用:\nspec:  volumes:    - name: datavol      emptyDir: &#123;&#125;  containers:    - name: tomcat-demo      image: tomcat      volumeMounts:        - mountPath: /mydata-data          name: datavol      imagePullPolicy: IfNotPresent\n\nVolume 类型emptyDir一个 emptyDir Volume 是在 Pod 分配到 Node 时创建的\n初始内容为空, 无须指定宿主机上对应的目录文件\n因为这是 Kubernetes 自动分配的一个目录\n当 Pod 从 Node 移除时, emptyDir 中的数据也会被永久删除\nemptyDir 的一些用途:\n\n临时空间\nCheckPoint 的临时保存目录\n多容器共享目录\n\n目前, 用户无法控制 emptyDir 使用的介质种类\nhostPathhostPath 为在 Pod 上挂载宿主机上的文件或目录\n用途:\n\n容器应用程序生成的日志文件需要永久保存时\n需要访问宿主机上 Docker 引擎内部数据结构的容器应用时, 可以通过定义 hostPath 为宿主机 /var/lib/docker 目录, 使容器内部应用可以直接访问 Docker 的文件系统\n\n注意:\n\n可能会因为宿主机上的目录和文件不同, 导致对 Volume 上目录和文件的访问结果不一致\n如果使用了资源配额管理, 则 Kubernetes 无法将 hostPath 在宿主机上使用的资源纳入管理\n\nNFS使用 NFS 网络文件系统提供的共享目录存储数据时, 需要在系统中部署一个 NFS Server\nvolumes:  - name: nfs    nfs:      server: nfs-server.localhost      path: &quot;/&quot;\n\nPersistent VolumePV 可以理解为 Kubernetes 集群中的某个网络存储对应的一块存储\n\nPV 只能是网络存储, 不属于任何 Node, 但可以在每个 Node 上访问\nPV 并不是被定义在 Pod 上的, 而是独立于 Pod 之外定义的\nPV 目前支持的类型包括\nFC (Fibre Channel)\nFlocker\nNFS\nGlusterFS\nHostPath (仅供单机测试)\n\n\n\nExample - NFS 类型的 PV 定义:\napiVersion: v1kind: PersistentVolumemetadata:  name: pv0003spec:  capacity:    storage: 5Gi  accessModes:    - ReadWriteOnce  nfs:    path: /somepath    server: 172.17.0.1\n\nPV 的 accessModes 属性:\n\nReadWriteOnce: 读写权限, 并且只能被单个 Node 挂载\nReadOnlyMany: 只读权限, 允许被多个 Node 挂载\nReadWriteMany: 读写权限, 允许被多个 Node 挂载\n\n如果某个 Pod 想申请某种类型的 PV, 则首先需要定义一个 PersistentVolumeClaim 对象:\nkind: PersistentVolumeClaimapiVersion: v1metadata:  name: myclaimspec:  accessModes:    - ReadWriteOnce  resources:    requests:      storage: 8Gi\n\n然后, 在 Pod 的 Volume 定义中引用上述 PersistentVolumeClaim 即可:\nvolumes:  - name: mypd    persistentVolumeClaim:      claimName: myclaim\n\nPV 是有状态的对象:\n\nAvailable: 空闲状态\nBound: 已经绑定到某个 PVC 上\nReleased: 对应的 PVC 已经被删除, 但资源还没有被集群回收\nFailed: PV 自动回收失败\n\nNamespace用于实现多租户的资源隔离\n默认会创建并使用一个名称为 default 的 Namespace\n使用 --namespace 参数来指定 Namespace\nAnnotation用户任意定义的附加信息\nConfigMap配置项可以作为 Map 表中的一个项, 整个 Map 的数据可以被持久化存储在 Kubernetes 的 Etcd 数据库中, 然后提供 API 以方便 Kubernetes 相关组件或客户应用 CRUD 操作这些数据\n这个专门用来保存配置参数的 Map 就是 Kubernetes ConfigMap 资源对象\nKubernetes 提供了一种内建机制, 将存储在 etcd 中的 ConfigMap 通过 Volume 映射的方式变成目标 Pod 内的配置文件\n不管目标 Pod 被调度到哪台服务器上, 都会完成自动映射\n如果 ConfigMap 中的 key-value 数据被修改, 则映射到 Pod 中的”配置文件”也会随之自动更新\n","tags":["Notes"]},{"title":"深入掌握 Pod","url":"/k8s/kubernetes-%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8F%A1-Pod/","content":"\n\n\nPod 的基本用法\n静态 Pod\nPod 容器共享 Volume\nPod 的配置管理\n直接通过 kubectl create configmap 方式创建\n在 Pod 中使用 ConfigMap\n通过 volumeMount 使用 ConfigMap\n\n\n使用 ConfigMap 的限制条件\n\n\n在容器内获取 Pod 信息 (Downward API)\nPod 健康检查和服务可用性检查\nLivenessProbe\nReadinessProb\n这两种探针都支持三种实现方式\nPod Readiness Gates 机制\n\n\n玩转 Pod 调度\nDeployment 全自动调度\nNodeSelector 定向调度\nNodeAffinity Node亲和性调度\nPodAffinity Pod 亲和与互斥调度策略\nTaints 和 Tolerations (污点和容忍)\nPod Priority Preemption (Pod 优先级调度)\nDaemonSet (在每个 Node 上都调度一个 Pod)\nJob (批处理调度)\nCronJob (定时任务)\n自定义调度器\n\n\nInit Container (初始化容器)\nPod 的升级和回滚\nDeployment 的升级\nDeployment 的回滚\n暂停和恢复 Deployment 的部署操作\n其他管理对象的更新策略\nDaemonSet 的更新策略\nOnDelete\nRollingUpdate\n\n\nStatefulSet 的更新策略\n\n\n\n\nPod 的扩缩容\n手动扩缩容机制\n自动扩缩容机制\n\n\n\n\n\nPod 的基本用法Kubernetes 系统中对长时间运行的容器的要求是: 其主程序需要一直在前台执行\n对于无法改造为前台执行的应用, 可以使用开源工具 Supervisor 辅助进行前台运行的功能\nSupervisor 提供了一种可以同时启动多个后台应用, 并保持 Supervisor 自身在前台执行的机制\n静态 Pod静态 Pod 是由 kubelet 进行管理的仅存在于特定 Node 上的 Pod\n它们不能通过 API Server 管理, 无法与 ReplicationController, Deployment 或者 DaemonSet 进行关联\nkubelet 无法对它们进行健康检查\n静态 Pod 总是由 kubelet 创建的, 并且总是在 kubelet 所在的 Node 上运行\n创建静态 Pod 有两种方式: 配置文件方式和 HTTP 方式\nPod 容器共享 Volume同一个 Pod 中的多个容器能够共享Pod 级别的存储卷 Volume\nVolume 可以被定义为各种类型, 多个容器各自进行挂载操作\nPod 的配置管理ConfigMap 供容器使用的典型用法:\n\n生成为容器内的环境变量\n设置容器启动命令的启动参数 (需设置为环境变量)\n以 Volume 的形式挂载为容器内部的文件或目录\n\nConfigMap 以键值对的形式保存配置\nvalue 可以是普通值, 也可以是一个完整的配置文件的内容\nkey 为配置文件的别名, value 为配置文件的全部文本内容:\ndata:  key-serverxml: |    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;Server&gt;    ......    &lt;/Server&gt;  key-loggingproperties: &quot;  ....  &quot;\n\n直接通过 kubectl create configmap 方式创建使用参数 --from-file 或 --from-literal 指定内容, 可以指定参数多次\n使用 --from-file 参数从文件中进行创建:\n\n$ kubectl create configmap cm-server.xml --from-file=server.xml\n\n使用 --from-file 从目录中进行创建. 该目录下的每个配置文件名都被设置为 key, 文件内容被设置为 value:\n\n$ kubectl create configmap cm-appconf --from-file=configfiles\n\n容器应用对 ConfigMap 的使用有以下两种方法:\n\n通过环境变量获取 ConfigMap 中的内容\n通过 Volume 挂载的方式将 ConfigMap 中的内容挂载为容器内部的文件目录\n\n在 Pod 中使用 ConfigMap使用字段 envFrom, 实现在 Pod 环境中将 ConfigMap 中所定义的 key=value 自动生成为环境变量:\napiVersion: v1kind: Podmetadata:  name: cm-test-podspec:  containers:  - name: cm-test    image: busybox    command: [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;env&quot;]    envFrom:    - configMapRef      name: cm-appvars\n\n通过 volumeMount 使用 ConfigMapapiVersion: v1kind: Podmetadata:  name: cm-test-appspec:  containers:  - name: cm-test-app    image: kubeguide/tomcat-app:v1    imagePullPolicy: Never    ports:    - containerPort: 8080    volumeMounts:    - name: serverxml      mountPath: /configfiles  volumes:  - name: serverxml    configMap:      name: cm-appconfigfiles\n\n配置的 key 作为文件名, 配置的 value 作为文件内容\n使用 ConfigMap 的限制条件\nConfigMap 必须在 Pod 之前创建\nConfigMap 受 Namespace 限制, 只有处于相同 Namespace 中的 Pod 才可以引用它\nConfigMap 中的配额管理还未实现\nkubelet 只支持可以被 API Server 管理的 Pod 使用 ConfigMap\n在 Pod 对 ConfigMap 进行挂载 (volumeMount) 操作时, 在容器内部只能挂载为”目录”, 无法挂载为”文件”. 容器内的该目录将被挂载的 ConfigMap 覆盖\n\n在容器内获取 Pod 信息 (Downward API)Downward API 可以通过以下两种方式将 Pod 信息注入容器内部\n\n环境变量: 用于单个变量, 可以将 Pod 信息和 Container 信息注入容器内部\nVolume 挂载: 将数组类信息生成为文件并挂载到容器内部\n\n在某些集群中, 集群中的每个节点都需要将自身的标识 (ID) 及进程绑定的 IP 地址等信息事先写入配置文件中, 进程在启动时会读取这些信息, 然后将这些信息发布到某个类似服务注册中心的地方, 以实现集群节点的自动发现功能\nPod 健康检查和服务可用性检查通过两类探针来检查 Pod 的健康状态:\n\nLivenessProbe\nReadinessProbe\n\nLivenessProbe用于判断容器是否存活 (Running状态)\n如果 LivenessProbe 探针探测到容器不健康, 则 kubelet 将杀掉该容器, 并根据容器的重启策略做相应的处理\n如果容器没有这个探针, 则 kubelet 认为这个容器的 LivenessProbe 探针返回的值永远是 Success\nReadinessProb用于判断容器是否可用 (Ready状态)\n达到 Ready状态 的 Pod 才可以接收请求\n如果在运行中 Ready状态 变为 False, 则系统自动将这个 Pod 从 Service 的后端 Endpoint 列表中隔离出去\n确保请求不会发送到 Ready状态 为 False 的 Pod\n这两种探针都支持三种实现方式\nExecAction: 在容器内部执行命令, 如果命令返回码为0, 则表明容器健康\nTCPSocketAction: 通过容器的 IP 地址和端口号执行 TCP 检查, 如果能够建立 TCP 连接, 则表明容器健康\nHTTPGetAction: 通过容器的 IP 地址, 端口号和路径, 调用 HTTP Get 方法, 如果响应的状态码大于等于 200 且小于 400, 则认为容器健康\n\nExample - HTTPGetAction:\napiVersion: v1kind: Podmetadata:  name: pod-with-healthcheckspec:  containers:  - name: nginx    image: nginx    ports:    - containerPort: 80    livenessProbe:      httpGet:        path: /_status/healthz        port: 80      initialDelaySeconds: 30      timeoutSeconds: 1\n\n对于每种实现方式, 都需要设置 initialDelaySeconds 和 timeoutSeconds 两个参数\n\ninitialDelaySeconds: 启动容器后进行首次健康检查的等待时间, 单位为秒\ntimeoutSeconds: 健康检查发送请求后等待响应的超时时间, 单位为秒\n\nPod Readiness Gates 机制通过 Pod Readiness Gates 机制, 用户可以将自定义的 ReadinessProbe 探测方式设置在 Pod 上, 辅助 Kubernetes 设置 Pod 合适达到服务可用状态 (Ready)\n为了使自定义的 ReadinessProbe 生效, 用户需要提供一个外部的控制器 (Controller) 来设置相应的 Condition 状态\nPod 的 Readiness Gates 在 Pod 定义中的 ReadinessGate 字段进行设置\n玩转 Pod 调度ReplicaSet 拥有集合式的标签选择器, 可以选择多个 Pod 标签\nReplicaSet 被设计成能控制多个不同标签的 Pod 副本:\nselector:  matchLabels:    version: v2  matchExpressions:    - &#123;key: version, operator: In, values:[v1, v2]&#125;\n\nKubernetes 的滚动升级就是巧妙运用 ReplicaSet 的这个特性来完成的\n通过给 Node 打标签, 在 Pod 模板中使用 NodeSelector 可以将这些 Pod 副本调度到标签对应的 Node 上\nDeployment 全自动调度自动部署一个容器应用的多份副本, 以及持续监控副本的状态, 在集群内始终维持用户指定的副本数量\nDeployment 会创建一个 ReplicaSet 来关联 Pod\nExample:\napiVersion: apps/v1kind: Deploymentmetadata:  name: nginx-deploymentspec:  selector:    matchLabels:      app: nginx  replicas: 3  template:    metadata:      labels:        app: nginx    spec:      containers:      - name: nginx        image: nginx:1.7.9        ports:        - containerPort: 80\n\n可以在 Pod 中使用 NodeSelector,NodeAffinity,PodAffinity,Pod 驱逐 等更加细粒度的调度策略设置\nNodeSelector 定向调度Kubernetes Master 上的 Scheduler 服务 (kube-scheduler进程) 负责实现 Pod 的调度\n通过 Node 的 Label 和 Pod 的 NodeSelector 属性, 可以将 Pod 调度到指定的 Node 上\n首先, 给 Node 添加 Label:\n$ kubectl label node &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;\n然后, 在 Pod 的定义中使用 NodeSelector 设置:\napiVersion: apps/v1kind: Deploymentmetadata:  name: nginx-deploymentspec:  selector:    matchLabels:      app: nginx  replicas: 3  template:    metadata:      labels:        app: nginx    spec:      containers:      - name: nginx        image: nginx:1.7.9        ports:        - containerPort: 80      nodeSelector:           # 将 Pod 调度到拥有 Label zonez=north 的 Node 上        zone: north\n\n如果指定了 Pod 的 NodeSelector 条件, 且在集群中不存在包含响应标签的 Node, 则即使在集群中还有其他可用的 Node, 这个 Pod 也无法被成功调度\nKubernetes 给 Node 预定义了一些标签:\n\nkubernetes.io.hostname\nkubernetes.io/os\nkubernetes.io/arch\n\n可以使用亲和性调度来改善 NodeSelector 不够灵活的缺点\nNodeAffinity Node亲和性调度Node 亲和性调度策略\n用于替换 NodeSelector 的全新调度策略\n目前有两种节点亲和性表达:\n\nRequiredDuringSchedulingIgnoredDuringExecution\nPreferredDuringSchedulingIgnoredDuringExecution\n\n末尾的 IgnoredDuringExecution 的意思是: 如果一个 Pod 所在的节点在 Pod 运行期间标签发生了变更, 不再符合该 Pod 的节点亲和性需求, 则系统将忽略 Node 上的 Label 变化, 该 Pod 能继续在该节点运行\nRequiredDuringSchedulingIgnoredDuringExecution:\n\n必须满足指定的规则才可以调度 Pod 到 Node 上\n相当于硬限制\n\nPreferredDuringSchedulingIgnoredDuringExecution:\n\n强调优先满足指定规则\n调度器会尝试调度 Pod 到 Node 上, 但并不强求\n相当于软限制\n多个优先级规则可以设置权重 (weight) 值, 以定义执行的先后顺序\n\nExample:\napiVersion: v1kind: Podmetadata:  name: with-node-affinityspec:  affinity:    nodeAffinity:      requiredDuringSchedulingIgnoredDuringExecution:        nodeSelectorTerms:        - matchExpressions:          - key: kubernetes.io/arch            operator: In            values:            - amd64      preferredDuringSchedulingIgnoredDuringExecution:      - weight: 1        preference:          matchExpressions:          - key: disk-type            operator: In            values:            - ssd  containers:  - name: with-node-affinity    image: gcr.io/google_containers/pause:2.0\n\nNodeAffinity 语法支持的操作符包括 In,NotIn,Exists,DoesNotExist,Gt,Lt\nNodeAffinity 规则设置的注意事项如下:\n\n如果同时定义了 nodeSelector 和 nodeAffinity, 那么必须两个条件都得到满足, Pod 才能最终运行在指定的 Node 上\n如果在 nodeSelectorTerms 中有多个 matchExpressions, 则一个节点必须满足所有 matchExpressions 才能运行该 Pod\n如果 nodeAffinity 指定了多个 nodeSelectorTerms, 那么其中一个能够匹配成功即可\n\nPodAffinity Pod 亲和与互斥调度策略根据在 Node 上正在运行的 Pod 的标签进行判断和调度\n要求对 Node标签 和 Pod标签 两个条件进行匹配\nNode标签 是一个集群中的节点, 机架, 区域等概念, 通过 Kubernetes 内置节点标签中的 key 来进行声明. 这个 key 的名字为 topologyKey, 意为表达节点所属的 topology 范围:\n\nkubernetes.io/hostname\nfailure-domain.beta.kubernetes.io/zone\nfailure-domain.beta.kubernetes.io/zone\n\nPod 亲和与互斥的条件设置也是 requiredDuringSchedulingIgnoredDuringExecution 和 preferredDuringSchedulingIgnoredDuringExecution\nPod 的亲和性被定义在 PodSpec 的 affinity 字段下的 podAffinity 子字段中\nPod 的互斥性被定义在 PodSpec 的 affinity 字段下的 podAntiAffinity 子字段中\nExample - Pod 的亲和性调度:\napiVersion: v1kind: Podmetadata:  name: pod-affinityspec:  affinity:    podAffinity:      requiredDuringSchedulingIgnoredDuringExecution:      - labelSelector:          matchExpressions:          - key: security            operator: In            values:            - S1        topologyKey: kubernetes.io/hostname  containers:  - name: with-pod-affinity    image: gcr.io/google_containers/pause:2.0\n\nExampel - Pod 的互斥性调度:\napiVersion: v1kind: Podmetadata:  name: anti-affinityspec:  affinity:    podAffinity:      requiredDuringSchedulingIgnoredDuringExecution:      - labelSelector:          matchExpressions:          - key: security            operator: In            values:            - S1        topologyKey: failure-domain.beta.kubernetes.io/zone    podAntiAffinity:      requiredDuringSchedulingIgnoredDuringExecution:      - labelSelector:          matchExpressions:          - key: app            operator: In            values:            - nginx        topologyKey: kubernetes.io/hostname  containers:  - name: anti-affinity    image: gcr.io/google_containers/pause:2.0\n\nTaints 和 Tolerations (污点和容忍)通过 Taint 设置让 Node 拒绝 Pod 的运行\n通过 Tolerations 在 Pod 上声明此 Pod 可以在声明了指定 Taint 的 Node 上运行\nTaint 和 Toleration 是一种处理节点并且让 Pod 进行规避或者驱逐 Pod 的弹性处理方式\n通过自动在故障 Node 上设置 Taint 来驱逐 Pod, 维持集群的正常运行\nPod Priority Preemption (Pod 优先级调度)当发生资源不足的情况时, 系统可以选择释放一些不重要的负载 (优先级最低的), 保障最重要的负载能够获取足够的资源稳定运行\n首先, 创建 kind: PriorityClass 的资源对象\n然后, 将这个资源对象在 Pod 的 spec.priorityClassName 中使用\n使用优先级抢占的调度策略可能导致某些 Pod 永远无法被成功调度\n使用优先级抢占的调度策略增加了系统的复杂性, 运维的难度\nDaemonSet (在每个 Node 上都调度一个 Pod)用于管理在集群中每个 Node 上仅运行一份 Pod 的副本实例\n适合用于 GlusterFS存储 或者 Ceph存储 的 Daemon进程\n适合用于 日志采集程序, 例如 Fluentd 或者 Logstach\n适合用于 性能监控程序, 采集该 Node 的运行性能数据, 例如 Prometheus Node Exporter\n支持设置 updateStrategy, 默认 RollingUpdate\nJob (批处理调度)通过 Kubernetes Job 资源对象来定义并启动一个批处理任务\n批处理任务可以分为以下几种模式:\n\nJob Template Expansion 模式: 一个 Job 对象对应一个待处理的 Work item, 有几个 Work item 就产生几个独立的 Job\nQueue with Pod Per Work Item 模式: 采用一个任务队列存放 Work item, 一个 Job 对象作为消费者去完成这些 Work item, Job 会启动 N 个 Pod, 每个 Pod 都对应一个 Work item\nQueue with Variable Pod Count 模式: 采用一个任务队列存放 Work item, 一个 Job 对象作为消费者去完成这些 Work item, Job 启动的 Pod 数量是可变的\n\nCronJob (定时任务)类似 Linux Cron 的定时任务\n自定义调度器一般情况下, 每个新 Pod 都会由默认的调度器进行调度\n如果 Pod 中提供了自定义的调度器名称, 那么默认的调度器会忽略该 Pod, 转由指定的调度器完成 Pod 的调度\n使用 spec.schedulerName 来指定\nInit Container (初始化容器)在启动 app contianer 之前启动一个或多个 init contianer, 完成 app container 所需的预置条件\ninit container 与 app container 本质上是一样的, 但它们是仅运行一次就结束的任务, 并且必须在成功执行完成后, 系统才能继续执行下一个容器\n使用 spec.initContainers 来声明 init container\nPod 的升级和回滚Deployment 的升级假设有名称为 nginx-deployment, 镜像为 nginx:1.7.9 的 Deployment\n通过 kubectl set image 命令为 Deployment 设置新的镜像名称: $ kubectl set image deployment/nginx-deployment nginx=:1.9.1\n或者, 使用 kubectl edit 命令: $ kubectl edit deployment/nginx-deployment\n使用 kubectl rollout status 命令查看 Deployment 的更新过程: $ kubectl rollout status deployment/nginx-deployment\n默认的 spec.strategy Pod 更新策略为 RollingUpdate\nRollingUpdate 可以设置 maxUnavailable 和 maxSurge, 分别默认为 25%\nmaxUnavailable 表示更新过程中最多不可用的 Pod 数量\nmaxSurge 表示更新过程中 Pod 总数超过 Pod 期望副本数部分的最大值\n以上两个参数均以 期望副本数 为基础进行计算\nspec.strategy 还可以设置为 Recreate, 表示先杀掉所有在运行的 Pod, 然后创建新的 Pod\n不鼓励更新 Deployment 的标签选择器\nDeployment 的回滚首先, 使用 kubectl rollout history 命令检查 Deployment 的历史记录: $ kubectl rollout history deployment/nginx-deployment\n在创建 Deployment 时使用 --record 参数, 就可以在 CHANGE-CAUSE 列看到每个版本使用的命令\nDeployment 的更新操作是在 Deployment 进行部署 (Rollout) 时被触发的, 意味着当且仅当 Deployment 的 Pod 模板 (spec.template) 被更改时才会创建新的修订版本\n这也意味着我们将 Deployment 回滚到之前的版本时, 只有 Deployment 的 Pod 模板部分会被修改\n使用 --revision=&lt;N&gt; 参数查看特定版本的详细信息: $ kubectl rollout history deployment/nginx-deployment --revision=3\n回滚到上一个版本: $ kubectl rollout undo deployment/nginx-deployment\n使用 --to-revision 参数指定回滚到的部署版本号: $ kubectl rollout undo deployment/nginx-deployment --to-revision=2\n暂停和恢复 Deployment 的部署操作使用 kubectl rollout pause 命令暂停 Deployment 的更新操作: $ kubectl rollout pause deployment/nginx-deployment\n然后可以修改 Deployment 的信息\n最后, 使用 $ kubectl rollout resume deploy nginx-deployment 恢复这个 Deployment 的部署操作\n在恢复暂停的 Deployment 之前, 无法回滚该 Deployment\n其他管理对象的更新策略DaemonSet 的更新策略OnDeleteDaemonSet 的默认升级策略\n在创建好新的 DaemonSet 配置之后, 新的 Pod 并不会被自动创建, 直到用户手动删除旧版本的 Pod, 才出发新建操作\nRollingUpdate旧版本的 Pod 将被自动杀掉, 然后自动创建新版本的 DaemonSet Pod\n目前 Kubernetes 不支持查看和管理 DaemonSet 的更新历史记录\nDaemonSet 的 Rollback 并不能如同 Deployment 一样直接通过 kubectl rollback 命令来实现, 必须通过再次提交旧版本配置的方式实现\nStatefulSet 的更新策略可以使用 RollingUpdate,Paritioned,OnDelete 的策略\nPod 的扩缩容Kubernetes 对 Pod 的扩缩容操作提供了手动和自动两种模式\n手动扩缩容机制使用 kubectl scale 命令与 --replicas 参数\n$ kubectl scale deployment &lt;deployment-name&gt; --replicas=5\n自动扩缩容机制使用 Horizontal Pod Autoscaler (HPA) 控制器\nHPA 控制器基于 Master 的 kube-controller-manager 服务启动参数 --horizontal-pod-autoscaler-sync-period 定义的探测周期 (默认值为 15s), 周期性地监测目标 Pod 的资源性能指标, 并与 HPA 资源对象中的扩缩容条件进行对比, 在满足条件时对 Pod 副本数进行调整\n","tags":["Notes"]},{"title":"深入掌握 Service","url":"/k8s/kubernetes-%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97/%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8F%A1-service/","content":"\n\n\n深入掌握 Service\n多端口服务\n外部服务 Service\n\n\nHeadless Service\n从集群外部访问 Pod 或 Service\n将容器应用的端口号映射到物理机\n将 Service 的端口号映射到物理机\n\n\nDNS 服务搭建和配置指南\nIngress (HTTP 7 层 路由机制)\n创建 Ingress Controller 和默认的 backend 服务\nIngress 的策略配置技巧\nIngress 的 TLS 安全设置\n\n\n\n\n\n深入掌握 Service通过创建 Service, 可以为一组具有相同功能的容器应用提供一个统一的入口地址, 并且将请求负载分发到后端的各个容器应用上\nspec.type Service 的类型, 指定 Service 的访问方式, 默认值为 ClusterIP:\n\nClusterIP: 虚拟的服务 IP 地址. 该地址用于 Kubernetes 集群内部的 Pod 访问, 在 Node 上 kube-proxy 通过设置的 iptables 规则进行转发\nNodePort: 使用宿主机的端口. 使得能够访问各 Node 的外部客户端通过 Node 的 IP 地址和端口号就能访问服务\nLoadBalancer: 使用外部负载均衡器完成到服务的负载分发, 需要在 spec.status.loadBalancer 字段指定外部负载均衡器的 IP 地址, 并同时定义 nodePort 和 clusterIP, 用于公有云环境\n\n可以通过 kubectl expose 命令来创建 Service: $ kubectl expose &lt;pod/svc/rc/deploy/rs&gt; &lt;对应控制器的name&gt;\n可以使用 yaml 文件来声明 Service:\napiVersion: v1kind: Servicemetadata:  name: webappspec:  ports:  - port: 8081    targetPort: 8080  selector:    app: webapp\n\nport 定义了 Service 自己的端口号\ntargetPort 定义了Pod提供服务的端口号\n目前 Kubernetes 提供了两种负载分发策略:\n\nRoundRobin: 轮询模式\nSessionAffinity: 基于客户端 IP 地址进行会话保持的模式, 之后从相同的客户端发起的请求都将被转发到相同的 Pod 上\n\n默认使用 RoundRobin\n多端口服务Service 支持设置将多个端口对应到多个应用服务\n外部服务 Service在某些环境中, 应用系统需要将一个外部数据库作为后端服务进行连接, 或将另一个集群或 namespace 中的服务作为服务的后端\n这时可以通过创建一个无 Label Selector 的 Service 来实现\napiVersion: v1kind: Servicemetadata:  name: external-servicespec:  ports:  - protocol: TCP    port: 80    targetPort: 80\n\n由于没有 Label Selector, 所以无法选择后端的 Pod, 所以系统不会自动创建 Endpoint\n因此需要手动创建一个和该 Service 同名的 Endpoint, 用于指向实际的后端访问地址:\napiVersion: v1kind: Endpointsmetadata:  name: external-servicesubsets:- addresss:  - ip: 1.2.3.4  ports:  - port: 80\n\nHeadless Service如果希望自己控制负载均衡的策略, 或者应用程序希望知道属于同组服务的其他实例\nKubernetes 提供了 Headless Service 来实现这种功能, 即不为 Service 设置 ClusterIP (入口 IP 地址), 仅通过 Label Selector 将后端的 Pod 列表返回给调用的客户端:\napiVersion: v1kind: Servicemetadata:  name: nginx  labels:    app: nginxspec:  ports:  - port: 80  clusterIP: None # 重点!  selector:    app: nginx\n\n这样, Service 就不具有一个特定的 ClusterIP 地址, 对其进行访问将获得包含 Label app: nginx 的全部 Pod 列表, 然后客户端程序自行决定如何处理这个 Pod 列表\n从集群外部访问 Pod 或 Service将容器应用的端口号映射到物理机(1) 通过设置容器级别的 hostPort, 将容器应用的端口号映射到物理机上:\napiVersion: v1kind: Podmetadata:  name: webapp  labels:    app: webappspec:  containers:  - name: webapp    image: tomcat    ports:    - containerPort: 8080      hostPort: 8081      # 重点!\n\n将容器的 8080 端口映射到物理宿主机的 8081 端口\n通过物理宿主机的 IP + 8081 即可访问到这个容器的 8080 端口\n(2) 通过设置Pod级别的 spec.hostNetwork=true, 该 Pod 中所有容器的端口号都将被直接映射到物理宿主机上; hostPort 默认等于 containerPort\n将 Service 的端口号映射到物理机(1) 设置 nodePort 映射到物理机, 同时设置 Service 的类型为 NodePort:\napiVersion: v1kind: Servicemetadata:  name: webappspec:  type: NodePort  ports:  - port: 8080    targetPort: 8080    nodePort: 8081    # 重点!  selector:    app: webapp\n\n(2) 通过设置 LoadBalancer 映射到云服务提供商提供的 LoadBalancer 地址\n这种用法仅用于在公有云服务提供商的云平台上设置 Service 的场景\nDNS 服务搭建和配置指南在集群内需要能够通过服务名对服务进行访问, 通过一个集群范围内的 DNS 服务来完成从服务名 (Service name)到ClusterIP的解析\nIngress (HTTP 7 层 路由机制)Service 的表现形式为 IP:Port, 即工作在 TCP&#x2F;IP 层\n对于基于 HTTP 的服务来说, 不同的 URL 地址经常对应到不同的后端服务 或者虚拟服务器\n这些应用层的转发机制仅通过 Service 机制是无法实现的\n使用 Ingress 资源对象, 可以将不同的 URL 的访问请求转发到后端不同的Service, 以实现 HTTP 层的业务路由机制\nKubernetes 使用了一个 Ingress 策略定义和一个具体的 Ingress Controller, 两者结合并实现了一个完整的 Ingress 负载均衡器\nIngress Controller 基于Ingress 规则将客户端请求直接转发到 Service 对应的后端 Endpoint (Pod) 上\n这样会跳过 kube-proxy 的转发功能, kube-proxy 不再起作用\n如果 Ingress Controller 提供的是对外服务, 则实际上实现的是边缘路由器的功能\n要使用 Ingress, 需要创建 Ingress Controller (带一个默认 backend 服务) 和 Ingress 策略配置\n创建 Ingress Controller 和默认的 backend 服务在 Kubernetes 中, Ingress Controller 将以 Pod 的形式运行, 监控 API Server 的 /ingress 接口后端的 backend services, 如果 Service 发生变化, 则 Ingress Controller 应自动更新其转发规则\n使用谷歌提供的 nginx-ingress-controller 镜像来创建 Ingress Controller. 该 Ingress Controller 以 daemonSet 的形式进行创建, 在每个 Node 上都将启动一个 Nginx 服务\n为这个 Nginx 容器设置 hostPort, 将容器监听的 80 和 443 端口映射到物理机上\n使得客户端可以通过 URL 地址 http://物理机IP:80 或者 https://物理机IP:443 来访问该 Ingress Controller\n这使得 Nginx 类似于通过 NodePort 映射到物理机的 Service, 成为代替 kube-proxy 的 HTTP 层的 Load Balancer\nIngress 的策略配置技巧\n转发到单个后端服务上\n同一域名下, 不同的 URL 路径被转发到不同的服务上\n不同的域名 (虚拟主机名) 被转发到不同的服务上\n不使用域名的转发规则\n\nIngress 的 TLS 安全设置可以为 Ingress 中的域名进行 TLS 安全证书的设置:\n\n创建自签名的密钥和 SSL 证书文件\n将证书保存到 Kubernetes 中的一个 Secret 资源对象中\n将该 Secret 对象设置到 Ingress 中\n\n使用 OpenSSL 工具生成密钥和证书文件\n","tags":["Notes"]},{"title":"Groovy Decimal Literals","url":"/groovy/numbers/groovy-decimal-literals/","content":"Groovy Decimal LiteralsDecimals 可以使用指数，通过使用 e 或者 E 字符\nassert 1e3  ==  1_000.0assert 2E4  ==  20_000.0assert 3e+1 ==  30.0assert 4E-2 ==  0.04assert 5e-1 ==  0.05\n\n为了方便地进行浮点数计算，Groovy 选择 java.lang.BigDecimal 作为浮点数的类型\nDecimal numbers 不能使用二进制，八进制，十六进制的形式进行声明\n","categories":["Groovy Numbers"],"tags":["Groovy","Strings"]},{"title":"Groovy Number type suffixes","url":"/groovy/numbers/groovy-number-type-suffixes/","content":"Groovy Number type suffixes我们可以通过使用后缀符号明确声明一个数字的类型（包括二进制，八进制和十六进制）。不区分大小写\n\n\n\nType\nSuffix\n\n\n\nBigInteger\nG or g\n\n\nLong\nL or l\n\n\nInteger\nI or i\n\n\nBigDecimal\nG or g\n\n\nDouble\nD or d\n\n\nFloat\nF or f\n\n\nExamples:\nassert 42I              == new Integer(&#x27;42&#x27;)assert 2147483648       == new Long(&#x27;2147483648&#x27;) // Long type used, value too large for an Integerassert 345G             == new BigInteger(&#x27;345&#x27;)assert 123.45           == new BigDecimal(&#x27;123.45&#x27;)assert 1.200065D        == new Double(&#x27;1.200065&#x27;)assert 1.23E23D         == new Double(&#x27;1.23E23&#x27;)assert 0b1111L.class    == Long // binaryassert 0xFFi.class      == Integer // hexadecimalassert 034G.class       == BigInteger // octal\n","categories":["Groovy Numbers"],"tags":["Groovy","Strings"]},{"title":"Groovy Class","url":"/groovy/object-orientation/groovy-class/","content":"Groovy ClassGroovy classes 和 Java classes 的主要区别：\n\n没有 visibility modifier 的 Classes 和 methods 自动成为 public 的\n没有 visibility modifier 的 Fields 自动转换为 properties\n\nInner classclass Computer &#123;    class Cpu &#123;        int coreNumber        Cpu(int coreNumber) &#123;            this.coreNumber = coreNumber        &#125;    &#125;&#125;assert 4 == new Computer().new Cpu(4).coreNumber\n","categories":["Groovy Object Orientation"],"tags":["Groovy","Object Orientation"]},{"title":"Groovy Constructors","url":"/groovy/object-orientation/groovy-constructors/","content":"Groovy ConstructorsPositional parametersclass PersonConstructor &#123;    String name    Integer age        PersonConstructor(name, age) &#123;        this.name = name        this.age = age    &#125;&#125;def person1 = new PersonConstructor(&#x27;Marie&#x27;, 1)def person2 = [&#x27;Marie&#x27;, 2] as PersonConstructor // using coercion with as keywordPersonConstructor person3 = [&#x27;Marie&#x27;, 3]        // using coercion in assignment\n\nNamed parameters如果没有声明（或声明了一个无参）构造方法，那么可以使用 Map 的形式传递参数来创建对象\nHaving a constructor where the first (and perhaps only) argument is a Map argument is also supported - such a constructor may also be added using the groovy.transform.MapConstructor annotation\nclass PersonWOConstructor &#123;                                      String name    Integer age&#125;def person4 = new PersonWOConstructor()                      def person5 = new PersonWOConstructor(name: &#x27;Marie&#x27;)         def person6 = new PersonWOConstructor(age: 1)                def person7 = new PersonWOConstructor(name: &#x27;Marie&#x27;, age: 2)\n\nNotes:\n\nWhile the example above supplied no constructor, you can also supply a no-arg constructor or a constructor where the first argument is a Map, most typically it’s the only argument.\nWhen no (or a no-arg) constructor is declared, Groovy replaces the named constructor call by a call to the no-arg constructor followed by calls to the setter for each supplied named property.\nWhen the first argument is a Map, Groovy combines all named parameters into a Map (regardless of ordering) and supplies the map as the first parameter. This can be a good approach if your properties are declared as final (since they will be set in the constructor rather than after the fact with setters)\nYou can support both named and positional construction by supply both positional constructors as well as a no-arg or Map constructor.\nYou can support hybrid construction by having a constructor where the first argument is a Map but there are also additional positional parameters. Use this style with caution.\n\n","categories":["Groovy Object Orientation"],"tags":["Groovy","Object Orientation"]},{"title":"Groovy Fields and properties","url":"/groovy/object-orientation/groovy-fields-and-properties/","content":"Groovy Fields and propertiesFieldsfield 是 Class 或 Trait 的成员\n一个 field 拥有：\n\n一个 强制 的访问修饰符 (public, protected, or private)\n一个或多个 可选 的修饰符 (static, final, synchronized)\n一个 可选 的类型声明\n一个 强制 的名字\n\nProperties定义一个 Property:\n\n不使用访问修饰符 (no public, protected or private)\n一个或多个 可选 的修饰符 (static, final, synchronized)\n一个 可选 的类型声明\n一个 强制 的名字\n\nGroovy 将会生成对应的 getters&#x2F;setters 方法\nclass Person &#123;    String name&#125;\n\n\n生成 private String name 字段(field)\n生成 getName() 方法\n生成 setName() 方法\n\n如果一个 Property 使用 final 声明，setter 方法不会生成\np.name : 调用 p.getName()&#x2F;p.setName()\np.name(&#39;Maria&#39;) : 调用 name(String n)\n通过元字段 properties 可以访问所有的 Property:\nclass Person &#123;    String name    Integer age&#125;def p = new Person()assert p.properties.keySet().containsAll([&#x27;name&#x27;, &#x27;age&#x27;])\n\n即使没有声明对应的 Field，而声明了 getter/setter 方法，也可以通过 Property 的方式来访问:\nclass Person &#123;    void setName(String name) &#123;        println &quot;setName invoke&quot;    &#125;        String getName() &#123;        &quot;getName invoke&quot;    &#125;&#125;def person = new Person()person.name = &#x27;lin&#x27;println person.name\n\nProperty naming conventions如果一个 Property 名称的前两个字母是大写的，那么不会进行大小写转换\ngetURL 是 URL 的 getter 方法\ngetaProp 是 aProp 的 getter 方法\ngetAProp 是 AProp 的 getter 方法\n","categories":["Groovy Object Orientation"],"tags":["Groovy","Object Orientation"]},{"title":"Groovy Interface","url":"/groovy/object-orientation/groovy-interface/","content":"Groovy InterfaceIt is however possible to make an instance of an object implement an interface at runtime, using the as coercion operator:\ndef greeter = new DefaultGreeter()def coerced = greeter as Greeterassert coerced instanceof Greeter\n","categories":["Groovy Object Orientation"],"tags":["Groovy","Object Orientation"]},{"title":"Groovy Methods","url":"/groovy/object-orientation/groovy-methods/","content":"Groovy Methods如果方法是 no visibility 的，那么方法就是 public\nMethods in Groovy always return some value. If no return statement is provided, the value evaluated in the last line executed will be return.\nNamed parameters为了使用命名参数，约定方法的第一个参数是 Map\n在方法体中，通过 map.key 的形式来访问参数值\n如果方法只有一个 Map 作为入参， 所有参数都必须被命名\n第一个参数必须是 Map 才能使用方法命名参数\nMixing named and positional parametersdef foo(Map args, Integer number) &#123; &quot;$&#123;args.name&#125;: $&#123;args.age&#125;, and the number is $&#123;number&#125;&quot; &#125;foo(name: &#x27;Marie&#x27;, age: 1, 23)  // works wellfoo(23, name: &#x27;Marie&#x27;, age: 1)  // works well\n\n如果 Map 不是第一个参数，那么 Map 不能通过 named parameter 的形式提供，必须使用明确的 Map 类型参数，否则，将会抛出 groovy.lang.MissingMethodException\ndef foo(Integer number, Map args) &#123; &quot;$&#123;args.name&#125;: $&#123;args.age&#125;, and the number is $&#123;number&#125;&quot; &#125;foo(name: &#x27;Marie&#x27;, age: 1, 23)      // throws groovy.lang.MissingMethodExceptionfoo(23, [name: &#x27;Marie&#x27;, age: 1])    // 使用明确的 Map 参数来调用方法\n\nDefault arguments给参数设置默认值\ndef foo(String par1, Integer par2 = 1) &#123; [name: par1, age: par2] &#125;assert foo(&#x27;Marie&#x27;).age == 1\n\n在默认参数后面只能继续声明默认参数\nVarargs不定数量参数\ndef foo(Object... args) &#123; args.length &#125;// 等价于def foo(Object[] args) &#123; args.length &#125;// 传入 null 将会作为 null 处理，而不是包含 null 的数组def foo(Object... args) &#123; args &#125;assert foo(null) == null\n\n传入数组作为参数，则直接使用这个数组\ndef foo(Object... args) &#123; args &#125;Integer[] ints = [1, 2]assert foo(ints) == [1, 2]\n\nGroovy 的 method overloading 将会使用最明确的方法\ndef foo(Object... args) &#123; 1 &#125;def foo(Object x) &#123; 2 &#125;assert foo() == 1assert foo(1) == 2assert foo(1, 2) == 1\n\nMethod selection algorithm调用一个方法时，实际调用哪个方法取决于运行时方法参数类型。首先考虑的是方法名和参数数量，然后是每一个参数的类型\ndef method(Object o1, Object o2) &#123; &#x27;o/o&#x27; &#125;def method(Integer i, String  s) &#123; &#x27;i/s&#x27; &#125;def method(String  s, Integer i) &#123; &#x27;s/i&#x27; &#125;assert method(&#x27;foo&#x27;, 43) == &#x27;s/i&#x27;\n\nGroovy 是在运行时使用类型最接近的方法来进行调用\n在继承关系中，直接实现的 Interface 比间接实现的 Interface 有更高的优先级\nObject[] 数组比 Object 有更高的优先级\nNon-vararg 比 vararg 有更高的优先级\n都是 vararg 的情况下，拥有最少数量入参的，有更高的优先级\nInterface 比 Super class 有更高的优先级\nException declarationGroovy 自动地允许你将检查时异常作为运行时异常处理，所以不需要在方法中定义抛出检查时异常\n","categories":["Groovy Object Orientation"],"tags":["Groovy","Object Orientation"]},{"title":"Groovy Bit shift operators","url":"/groovy/operators/groovy-bit-shift-operators/","content":"Groovy Bit shift operatorsGroovy 提供三个移位运算符:\n\n&lt;&lt; : left shift\n&gt;&gt; : right shift\n&gt;&gt;&gt; : right shift unsigned\n\n运算符左边的参数类型是 type, short, int, or long 的话可以使用这三个移位运算符\n运算符左边的参数类型是 BigInteger 的话可以使用 &lt;&lt; 和 &gt;&gt; 移位运算符\n如果左边运算参数的类型是 BigInteger ，那么运算结果的类型就是 BigInteger 类型\n如果左边运算参数的类型是 long ，那么运算结果的类型就是 long 类型\n如果左边运算参数的类型是 int ，那么运算结果的类型就是 int 类型\n在 Groovy 中，移位运算符是可以重载的，这意味着你可以为了任何类型的对象去重新定义运算符的行为\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Bitwise operators","url":"/groovy/operators/groovy-bitwise-operators/","content":"Groovy Bitwise operatorsGroovy 提供了四个位运算符\n\n&amp; : 与运算\n| : 或运算\n^ : 异或运算\n~ : 非运算\n\n位运算符可以用在 type, short, int, long, or BigInteger 类型\n如果运算参数中一个参数的类型是 BigInteger ，那么运算结果的类型就是 BigInteger 类型\n如果运算参数中一个参数的类型是 long ，那么运算结果的类型就是 long 类型\n如果运算参数中一个参数的类型是 int ，那么运算结果的类型就是 int 类型\n在 Groovy 中，位运算符是可以重载的，这意味着你可以为了任何类型的对象去重新定义运算符的行为\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Call operator","url":"/groovy/operators/groovy-call-operator/","content":"Groovy Call operator ()用于隐含地调用 call() 方法\n任何定义了 call() 方法的对象，可以省略 .call() 的形式，使用 () 操作符来调用 call() 方法\nclass MyCallable &#123;    int call(int x) &#123;        2 * x    &#125;&#125;def mc = new MyCallable()assert mc.call(2) == 4assert mc(2) == 4\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Coercion operator","url":"/groovy/operators/groovy-coercion-operator/","content":"Groovy Coercion operator asA variant of casting\nCoercion converts object from one type to another ++without them being compatible for assignment++\nInteger x = 123String s = (String) x       // Integer is not assignable to a String, so it will produce a ClassCastException at runtime\n\nInteger x = 123String s = x as String      // Integer is not assignable to a String, but use of as will coerce it to a String\n\n当一个对象转换为另一个，除了目标类型和原始类型一样的情况，转换都会返回一个新的对象\n当没有转换规则的时候将会转换失败\n通过实现 asType() 方法来自定义转换规则\nclass Identifiable &#123;    String name&#125;class User &#123;    Long id    String name    def asType(Class target) &#123;        if (target == Identifiable) &#123;            return new Identifiable(name: name)        &#125;        throw new ClassCastException(&quot;User cannot be coerced into $target&quot;)    &#125;&#125;def u = new User(name: &#x27;Xavier&#x27;)def p = u as Identifiableassert p instanceof Identifiableassert !(p instanceof User)\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Diamond operator","url":"/groovy/operators/groovy-diamond-operator/","content":"Groovy Diamond operator &lt;&gt;用于范型说明\n在动态 Groovy 没有用\n在静态 Groovy 中可以帮助类型检查器进行检查\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Direct field access operator","url":"/groovy/operators/groovy-direct-field-access-operator/","content":"Groovy Direct field access operator .@class User &#123;    public final String name                // 1    User(String name) &#123; this.name = name &#125;    String getName() &#123; &quot;Name: $name&quot; &#125;      // 2&#125;def user = new User(&#x27;Bob&#x27;)assert user.name == &#x27;Name: Bob&#x27;             // 3\n\n1 : public field name2 : a getter of name that returns a custom string3 : calls the getter\nuser.name 会触发调用 name 的 getter 方法 getName，即使 name 被修饰为 public\n如果想直接获取到属性的值，而不是访问它的 getter 方法，那就使用 Direct field access operator .@\nassert user.@name == &#39;Bob&#39;\n\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Elvis assignment operator","url":"/groovy/operators/groovy-elvis-assignment-operator/","content":"Groovy Elvis assignment operator ?=Groovy 3.0.0 开始支持这个操作符\nimport groovy.transform.ToString@ToStringclass Element &#123;    String name    int atomicNumber&#125;def he = new Element(name: &#x27;Helium&#x27;)he.with &#123;    name = name ?: &#x27;Hydrogen&#x27;    atomicNumber ?= 2           // 1 new Elvis assignment shorthand&#125;assert he.toString() == &#x27;Element(Helium, 2)&#x27;\n\n1 : atomicNumber 为空的情况下赋值为2\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Elvis operator","url":"/groovy/operators/groovy-elvis-operator/","content":"Groovy Elvis operator ?:三元运算符的快捷方式\n主要用于判断为 false 时返回默认值，如果判断为 true 则返回自身\ndisplayName = user.name ? user.name : &#x27;Anonymous&#x27;displayName = user.name ?: &#x27;Anonymous&#x27;\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Identity operator","url":"/groovy/operators/groovy-identity-operator/","content":"Groovy Identity operator is进行引用比较，使用 is\ndef list1 = [&#x27;Groovy 1.8&#x27;,&#x27;Groovy 2.0&#x27;,&#x27;Groovy 2.3&#x27;]        def list2 = [&#x27;Groovy 1.8&#x27;,&#x27;Groovy 2.0&#x27;,&#x27;Groovy 2.3&#x27;]assert list1 == list2       // 调用 equals() 方法assert !list1.is(list2)     // 进行引用比较\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Logical operators","url":"/groovy/operators/groovy-logical-operators/","content":"Groovy Logical operatorsPrecedence 优先级! 比 and 有更高的优先级\n&amp; 比 | 有更高的优先级\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Membership operator","url":"/groovy/operators/groovy-membership-operator/","content":"Groovy Membership operator inThe membership operator(in) is equivalent to calling the isCase method\nIn the context of a List, it is equivalent to calling contains, like in the following example:\ndef list = [&#x27;Grace&#x27;, &#x27;Rob&#x27;, &#x27;Emmy&#x27;]assert (&#x27;Emmy&#x27; in list)\n\nequivalent to calling list.contains(&#39;Emmy&#39;) or list.isCase(&#39;Emmy&#39;)\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Method pointer operator","url":"/groovy/operators/groovy-method-pointer-operator/","content":"Groovy Method pointer operator .&amp;将一个方法的引用存储到一个变量中，稍后在进行使用\ndef str = &#x27;example of method reference&#x27;def fun = str.&amp;toUpperCase              // 2def upper = fun()                       // 3assert upper == str.toUpperCase()       // 4\n\n2 : 将 str 实例上的 toUpperCase 方法引用存储到变量 fun 上面3 : fun 可以像调用普通方法一样被调用4 : 检查 fun 执行的结果\n\nMethod pointers 由接收者和方法名联系起来\n由于参数在运行时才处理，意味着如果你有多个相同名字的方法，这在语法调用上是相同的，只有在运行时才会决定那个最适合的方法进行调用：\ndef doSomething(String str) &#123; str.toUpperCase() &#125;   // adef doSomething(Integer x) &#123; 2*x &#125;                  // bdef reference this.&amp;doSomethingassert reference(&#x27;foo&#x27;) == &#x27;FOO&#x27;                    // 调用 a 方法assert reference(123)   == 246                      // 调用 b 方法\n\n\n在 Groovy 3 及其以上版本，可以使用 new 方法名来获取一个构造器的 method pointer\ndef foo = BigInteger.&amp;new   // 构造方法def fortyTow = foo(&#x27;42&#x27;)assert fortyTow == 42G\n\n\n在 Groovy 3 及其以上版本，你可以获取到一个类的实例方法作为 method pointer\ndef instanceMethod = String.&amp;toUpperCaseassert instanceMethod(&#x27;foo&#x27;) == &#x27;FOO&#x27;\n\n为了底层的兼容性，任何拥有正确入参的静态方法相比实例方法拥有更高的优先级\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Method reference operator","url":"/groovy/operators/groovy-method-reference-operator/","content":"Groovy Method reference operator :::: 方法引用操作符可以在需要函数式接口的上下文中引用一个方法或者一个构造方法\n在 dynamic Groovy 中，:: 方法引用操作符就是 .&amp; 方法指针操作符的别名\n在 static Groovy 中，:: 方法引用符在字节码中和 Java 的方法引用是一样的\nimport groovy.transform.CompileStaticimport static java.util.stream.Collectors.toList@CompileStaticvoid methodRefs() &#123;    assert 6G == [1G, 2G, 3G].stream().reduce(0G, BigInteger::add)        assert [4G, 5G, 6G] == [1G, 2G, 3G].stream().map(3G::add).collect(toList())        assert [1G, 2G, 3G] == [1L, 2L, 3L].stream().map(BigInteger::valueOf).collect(toList())        assert [1G, 2G, 3G] == [1L, 2L, 3L].stream().map(3G::valueOf).collect(toList())&#125;methodRefs()\n\n@CompileStaticvoid constructorRefs() &#123;    assert [1, 2, 3] == [&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;].stream().map(Integer::new).collect(toList())        def result = [1, 2, 3].stream().toArray(Integer[]::new)        assert result instanceof Integer[]    assert result.toString() == &#x27;[1, 2, 3]&#x27;&#125;\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Not operator","url":"/groovy/operators/groovy-not-operator/","content":"Groovy Not operatorassert (!true) == false     // 1assert (!&#x27;foo&#x27;) == false    // 2assert (!&#x27;&#x27;) == true        // 3\n\n2 : ‘foo’ 不是一个空的字符串，判断为 true ,所以取非之后返回 false3 : ‘’ 是一个空的字符串，判断为 false ,所以取非之后返回 true\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Range operator","url":"/groovy/operators/groovy-range-operator/","content":"Groovy Range operator ..def range = 0..5assert (0..5).collect() == [0, 1, 2, 3, 4, 5]assert (0..&lt;5).collect() == [0, 1, 2, 3, 4]assert (0..5) instanceof Listassert (0..5).size() == 6\n\n可以通过任何实现了 Comparable 接口，next() 方法，previous() 方法的对象来创建 Range\nassert (&#x27;a&#x27;..&#x27;d&#x27;).collect() == [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;]\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Regular expression operators","url":"/groovy/operators/groovy-regular-expression-operators/","content":"Groovy Regular expression operatorsPattern operator ~ 操作符用来创建 java.util.regex.Pattern 实例\ndef p = ~/foo/assert p instanceof Pattern\n\n可以和任意的 String 一起使用：\np = ~&#x27;foo&#x27;p = ~&quot;foo&quot;p = ~$/dollar/slashy $ string/$p = ~&quot;$&#123;pattern&#125;&quot;\n\nFind operator =~ 操作符用来创建 java.util.regex.Matcher 实例\ndef text = &quot;some text to match&quot;def m = (text =~ /match/)assert m instanceof java.util.regex.Matcherif (m) println &quot;find&quot;else println &quot;not find&quot;\n\nMatch operator ==~直接返回 boolean\ndef text = &quot;some text to match&quot;def m = (text ==~ /match/)assert m instanceof Booleanif (m) println &quot;find&quot;else println &quot;not find&quot;\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Relational operators","url":"/groovy/operators/groovy-relational-operators/","content":"Groovy Relational operators\n\n\nOperator\nPurpose\n\n\n\n===\nidentical(Since Groovy 3.0.0)\n\n\n!==\nnot identical(Since Groovy 3.0.0)\n\n\nBoth === and !== are supported which are the same as calling the is() method, and negating a call to the is() method respectively\nimport groovy.transform.EqualsAndHashCode@EqualsAndHashCodeclass Creature &#123; String type &#125;def cat = new Creature(type: &#x27;cat&#x27;)def copyCat = catdef lion = new Creature(type: &#x27;lion&#x27;)assert cat.equals(lion) // 通过 type 字段判断是否相等assert cat == lion // 通过 type 字段判断是否相等assert cat.is(copyCat) // 判断是否指向同一个对象assert cat === copyCat // 判断是否指向同一个对象assert cat !== lion // 判断不是指向同一个对象\n\n=== : 相当于 Java 中的 == ，用于判断是否指向同一个对象\n!== : 相当于 Java 中的 != ，用于判断不是指向同一个对象\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Safe index operator","url":"/groovy/operators/groovy-safe-index-operator/","content":"Groovy Safe index operator ?[]String[] array = [&#x27;a&#x27;, &#x27;b&#x27;]assert &#x27;b&#x27; == array?[1]     // get using normal array indexarray?[1] == &#x27;c&#x27;            // set using normal array indexarray = nullassert null == array?[1]    // return null for all index valuesarray?[1] = &#x27;c&#x27;             // quietly ignore attempt to set valueassert null == array?[1]def personInfo = [name: &#x27;Daniel.Sun&#x27;, location: &#x27;Shanghai&#x27;]assert &#x27;Daniel.Sun&#x27; == personInfo?[&#x27;name&#x27;]      // get using normal map indexpersonInfo?[&#x27;name&#x27;] = &#x27;sunlan&#x27;                  // set using normal map indexassert &#x27;sunlan&#x27; == personInfo?[&#x27;name&#x27;]personInfo = nullassert null == personInfo?[&#x27;name&#x27;]              // return null for all map valuespersonInfo?[&#x27;name&#x27;] = &#x27;sunlan&#x27;                  // quietly ignore attempt to set valueassert null == personInfo?[&#x27;name&#x27;]\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Safe navigation operator","url":"/groovy/operators/groovy-safe-navigation-operator/","content":"Groovy Safe navigation operator ?.Groovy Safe navigation operator 用来避免 空指针异常NullPointerException\nGroovy Safe navigation operator 会简单地返回 null 而不是抛出异常\ndef person = Person.find &#123; it.id == 123 &#125;   // find 方法将会返回 nulldef name = person?.name                     // 使用 null-safe 操作符来防止空指针异常assert name == null                         // 结果为 null\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Spaceship operator","url":"/groovy/operators/groovy-spaceship-operator/","content":"Groovy Spaceship operator &lt;=&gt;The spaceship operator &lt;=&gt; delegates to the compareTo() 方法\nassert (1 &lt;=&gt; 1) == 0assert (1 &lt;=&gt; 2) == -1assert (2 &lt;=&gt; 1) == 1assert (&#x27;a&#x27; &lt;=&gt; &#x27;z&#x27;) == -1\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Spread operator","url":"/groovy/operators/groovy-spread-operator/","content":"Groovy Spread operatorSpread operator *is used to invoke an action on all items of an aggregate object\nIt is equivalent to calling the action on each item and collecting the result into a list\nclass Car &#123;    String make    String model&#125;def cars = [       new Car(make: &#x27;Peugeot&#x27;, model: &#x27;508&#x27;),       new Car(make: &#x27;Renault&#x27;, model: &#x27;Clio&#x27;)    ]def makes = cars*.makeassert makes == [&#x27;Peugeot&#x27;, &#x27;Renault&#x27;]\n\ncars*.make 相当于 cars.collect&#123; it.make &#125;\n*. 是 null-safe 的，如果遇到 null ，则返回 null，不会抛出 NullPointerException\nclass Car &#123;    String make    String model&#125;def cars = [       new Car(make: &#x27;Peugeot&#x27;, model: &#x27;508&#x27;),       null,       new Car(make: &#x27;Renault&#x27;, model: &#x27;Clio&#x27;)    ]def makes = cars*.makeassert makes == [&#x27;Peugeot&#x27;, null, &#x27;Renault&#x27;]\n\n*. 操作符都可以用于任何实现了 Iterable 接口的类\n作用于集合的集合的时候，可以使用 collectNested 方法来代替 *.\nclass Car &#123;    String make    String model&#125;def cars = [   [       new Car(make: &#x27;Peugeot&#x27;, model: &#x27;408&#x27;),       new Car(make: &#x27;Peugeot&#x27;, model: &#x27;508&#x27;)   ],   [       new Car(make: &#x27;Renault&#x27;, model: &#x27;Clio&#x27;),       new Car(make: &#x27;Renault&#x27;, model: &#x27;Captur&#x27;)   ]]def models = cars.collectNested&#123; it.model &#125;assert models == [[&#x27;408&#x27;, &#x27;508&#x27;], [&#x27;Clio&#x27;, &#x27;Captur&#x27;]]\n\nSpreading method argument *int function(int x, int y, int z) &#123;    x * y + z&#125;def args = [4, 5, 6]assert function(*args) == 26args = [4]assert function(*args, 5, 6) == 26\n\nSpread list elements *def items = [4, 5]def list = [1, 2, 3, *items, 6]assert list == [1, 2, 3, 4, 5, 6]\n\nSpread map elements *:def m1 = [c:3, d:4]def map = [a:1, b:2, *:m1]assert map == [a:1, b:2, c:3, d:4]\n\ndef m1 = [c:3, d:4]def map = [a:1, b:2, *:m1, d: 8]assert map == [a:1, b:2, c:3, d: 8]\n\n*:m1 后面还有一个 d: 8 进行赋值，所以进行了覆盖\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Subscript operator","url":"/groovy/operators/groovy-subscript-operator/","content":"Groovy Subscript operator []The subscript operator is a short hand notation for getAt or putAt\ndef list = [0, 1, 2, 3, 4]assert list[2] == 2list[2] = 4assert list[0..2] == [0, 1, 4]list[0..2] = [6, 6, 6]assert list == [6, 6, 6, 3, 4]\n\n实现了 getAt 和 putAt 方法的类都可以使用 [] 来快速调用这两个方法\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Ternary operator","url":"/groovy/operators/groovy-ternary-operator/","content":"Groovy Ternary operator ?:三元运算符\n三元运算符是 if&#x2F;else 判断并赋值的快捷表达式\nif (string != null &amp;&amp; string.length() &gt;0) &#123;    result = &#x27;Found&#x27;&#125; else &#123;    result = &#x27;Not found&#x27;&#125;\n\nresult = (string != null &amp;&amp; string.length() &gt;0) ? &#x27;Found&#x27; : &#x27;Not Found&#x27;\n\nresult = string ? &#x27;Found&#x27; : &#x27;Not found&#x27;\n","categories":["Groovy Operators"],"tags":["Groovy","Operators"]},{"title":"Groovy Import aliasing","url":"/groovy/program-structure/groovy-import-aliasing/","content":"Groovy Import aliasing为普通 import 起别名\nimport java.util.Dateimport java.sql.Date as SQLDateDate utilDate = new Date(1000L)SQLDate sqlDate = new SQLDate(1000L)assert utilDate instanceof java.util.Dateassert sqlDate instanceof java.sql.Date\n","categories":["Groovy Program Structure"],"tags":["Groovy","Program Structure"]},{"title":"Groovy Script class","url":"/groovy/program-structure/groovy-script-class/","content":"Groovy Script classGroovy 编译器会将脚本里的代码复制到一个 run 方法中，然后在生成的 main 方法中调用这个 run 方法\nimport org.codehaus.groovy.runtime.InvokerHelperclass Main extends Script &#123;                         def run() &#123;                                         println &#x27;Groovy world!&#x27;                     &#125;    static void main(String[] args) &#123;                   InvokerHelper.runScript(Main, args)         &#125;&#125;\n\nMethods脚本中定义的方法，编译后作为生成类的普通方法\nVariables如果一个变量已经声明了，那么这个变量就是生成的 run 方法中的普通变量\n如果一个变量还没声明，那这个变量将在 script binding 中，可以在方法间可见\n可以使用 @Field 注解来修饰变量，将变量变成类的 field\n","categories":["Groovy Program Structure"],"tags":["Groovy","Program Structure"]},{"title":"Groovy Static import aliasing","url":"/groovy/program-structure/groovy-static-import-aliasing/","content":"Groovy Static import aliasing使用 as 关键字为 static import 起一个别名\nimport static Calendar.getInstance as nowassert now().class == Calendar.getInstance().class\n","categories":["Groovy Program Structure"],"tags":["Groovy","Program Structure"]},{"title":"Groovy Static import","url":"/groovy/program-structure/groovy-static-import/","content":"Groovy Static importIt allows you to define methods with the same name as an imported method as long as you have different types:\nimport static java.lang.String.formatclass SomeClass &#123;        String format(Integer i) &#123;                  // 和 static import method 相同名字的方法，但是参数类型不同        i.toString()    &#125;        static void main(String[] args) &#123;        assert format(&#x27;String&#x27;) == &#x27;String&#x27;     // compiler error in java, but is valid groovy code        assert new SomeClass().format(Integer.valueOf(1)) == &#x27;1&#x27;    &#125;    &#125;\n","categories":["Groovy Program Structure"],"tags":["Groovy","Program Structure"]},{"title":"Groovy Characters","url":"/groovy/strings/groovy-characters/","content":"Groovy CharactersGroovy 不能使用字符字面量来定义字符\nGroovy 中通过三种方式来明确定义字符：\nchar c1 = &#x27;A&#x27; // 1assert c1 instanceof Characterdef c2 = &#x27;B&#x27; as char // 2assert c2 instanceof Characterdef c3 = (char) &#x27;C&#x27; // 3assert c3 instanceof Character\n\n1 : 通过明确指定变量类型为 char 来声明字符\n2 : 使用 as 操作符将字符串转换为字符\n3 : 使用类型强制转换\n","categories":["Groovy Strings"],"tags":["Groovy","Strings"]},{"title":"Groovy Dollar slashy string","url":"/groovy/strings/groovy-dollar-slashy-string/","content":"Groovy Dollar slashy stringDollar slashy string 是以 $/ 开头，/$ 结尾的多行 GString\n转义字符是 $ ，它可以转义其他 $ 字符，也可以转义一个 /\n只有当 $ 和 / 字符在需要被使用时才进行转义\n例如 $foo 中的 $ 会被解析为使用插值，如果需要显示这四个字符 $foo 那就进行转义: $$foo，这样将会输出 $foo\ndef name = &quot;Guillaume&quot;def date = &quot;April, 1st&quot;def dollarSlashy = $/    Hello $name,    today we&#x27;re $&#123;date&#125;.    $ dollar sign    $$ escaped dollar sign    \\ backslash    / forward slash    $/ escaped forward slash    $$$/ escaped opening dollar slashy    $/$$ escaped closing dollar slashy/$println dollarSlashy\n\n输出：\nHello Guillaume,                    // Hello $nametoday we&#x27;re April, 1st.             // today we&#x27;re $&#123;date&#125;$ dollar sign                       // $ dollar sign$ escaped dollar sign               // $$ escaped dollar sign\\ backslash                         // \\ backslash/ forward slash                     // / forward slash/ escaped forward slash             // $/ escaped forward slash$/ escaped opening dollar slashy    // $$$/ escaped opening dollar slashy/$ escaped closing dollar slashy    // $/$$ escaped closing dollar slashy\n","categories":["Groovy Strings"],"tags":["Groovy","Strings"]},{"title":"Groovy Double-quoted string","url":"/groovy/strings/groovy-double-quoted-string/","content":"Groovy Double-quoted string如果没有插值表达式在双引号字符串中，那么这个双引号字符串是 java.lang.String 类型的\n如果有有插值表达式在双引号字符串中，那么这个双引号字符串是 groovy.lang.GString 类型的\n\n不仅表达式可以使用在占位符 $&#123;&#125; 中，语句也可以用于 $&#123;&#125;\ndef sum = &quot;The sum of 1 and 2 equals $&#123; def a=1; def b=2; a+b &#125;&quot;\n\n最好还是使用简单的占位符\n","categories":["Groovy Strings"],"tags":["Groovy","Strings"]},{"title":"Groovy GString and String hashCodes","url":"/groovy/strings/groovy-gstring-and-string-hashCodes/","content":"Groovy GString and String hashCodes使用双引号包围，且有插值表达式的字符串是 GString\nGString 和 String 有不同的 hashCodes\n即使 GString 和 String 包含相同的字符，它们的 hashCodes 也不同\n因为 GString 是动态生成字符的，所以会产生新的对象；而 String 是不可变的\n","categories":["Groovy Strings"],"tags":["Groovy","Strings"]},{"title":"Groovy Single-quoted string","url":"/groovy/strings/groovy-single-quoted-string/","content":"Groovy Single-quoted string单引号字符串是 java.lang.String 类型的\n不支持字符串插值\n","categories":["Groovy Strings"],"tags":["Groovy","Strings"]},{"title":"Groovy Slashy string","url":"/groovy/strings/groovy-slashy-string/","content":"Groovy Slashy stringSlashy strings 可以被认为是另一种定义 GString 的方式，不过使用了不同转义规则\nSlashy strings 因此也支持字符串插值: /a $&#123;color&#125; car/\n在 Slashy string 中不需要转义 /\ndef fooPattern = /.*foo.*/ // 1assert fooPattern == &#x27;.*foo.*&#x27;\n\n1 : 是一个 Slashy string\n只有 / 需要使用 \\ 来进行转义:\ndef escapeSlash = /The character \\/ is a forward slash/assert escapeSlash == &#x27;The character / is a forward slash&#x27;\n\n多行定义1:\ndef multilineSlashy = /one    two    three/println multilineSlashy\n\n输出1：\none    two    three\n\n定义2:\ndef multilineSlashy = /onetwo    three/println multilineSlashy\n\n输出2：\nonetwo    three\n\n定义3:\ndef multilineSlashy = /onetwothree/println multilineSlashy\n\n输出3：\nonetwothree\n\n定义4:\ndef multilineSlashy = /\\onetwothree\\/println multilineSlashy\n\n输出4：\nonetwothree\n\n特殊的地方空的 Slashy string // 会被解析器认为是注释符\n像 $() 或 $5 这些在 GString 中是错误的字符是可以正常工作在 Slashy string 中的，因为 Slashy string 是被设计用来更容易地创建正则表达式\n在 Slashy string 中转义其实是不支持的，例如 println /\\t/ 的输出结果是 \\t ，转义只有在遇到 / 时才会生效，例如 /\\/folder/ 的输出结果是 /folder\nSlashy string 中不能使用 \\ 作为一个字符串的结尾，因为这个最后的字符 \\ 将会转义最后一个 /；如果必须要使用 \\ 作为一个字符串的结尾，那么可以这样做: /ends with slash $&#123;&#39;\\&#39;&#125;/；不过最好还是避免这样用 Slashy string\n","categories":["Groovy Strings"],"tags":["Groovy","Strings"]},{"title":"Groovy Special case of interpolating closure expressions","url":"/groovy/strings/groovy-special-case-of-interpolating-closure-expressions/","content":"Groovy Special case of interpolating closure expressions通过 $&#123;-&gt;&#125; 的方式可以在字符串插值中使用 Closure\ndef sParameterLessClosure = &quot;1 + 2 == $&#123;-&gt; 3&#125;&quot; // 1assert sParameterLessClosure == &#x27;1 + 2 == 3&#x27;def sOneParameterClosure = &quot;1 + 2 == $&#123; w -&gt; w &lt;&lt; 3 &#125;&quot; // 2assert sOneParameterClosure == &#x27;1 + 2 == 3&#x27;\n\n1 : 一个没有参数的 Closure\n2 : 接受一个 java.io.StringWriter 作为 参数w 的 Closure，然后使用 &lt;&lt; 将 3 附加到这个 StringWriter 中；在其他情况，所有的占位符都是嵌入的 Closure\n如果一个嵌入式的 closure 表达式使用超过一个参数将会产生一个运行时异常。一个 closure 只允许有零个或一个参数\nlazy evaluationdef number = 1def eagerGString = &quot;value == $&#123;number&#125;&quot;def lazyGString = &quot;value == $&#123;-&gt; number&#125;&quot;assert eagerGString == &quot;value == 1&quot;assert lazyGString == &quot;value == 1&quot;number = 2 // 4assert eagerGString == &quot;value == 1&quot; // 5assert lazyGString == &quot;value == 2&quot; // 6\n\n4 : 将变量值修改为 2\n5 : 使用一个普通的插值表达式，字符串值还是创建 GString 时被绑定的值\n6 : But with a closure expression, the closure is called upon each coercion of the GString int String, resulting in an updated string containing the new number value. 在将 GString 转换成 String 的时候，closure 才会被调用，然后将新的变量值插入的字符串中。这就实现了动态插值和延迟调用插值\n","categories":["Groovy Strings"],"tags":["Groovy","Strings"]},{"title":"Groovy Triple-double-quoted string","url":"/groovy/strings/groovy-triple-double-quoted-string/","content":"Groovy Triple-double-quoted stringdef name = &quot;Christy&quot;def template = &quot;&quot;&quot;    Dear Mrs $&#123;name&#125;,    You&#x27;re the winner of the lottery!    Yours sincerly,    Daisy&quot;&quot;&quot;println template\n\n输出：\nDear Mrs Christy,You&#x27;re the winner of the lottery!Yours sincerly,Daisy\n\n第一行前边有一个空行\n最后一行后边有一个空行\n\ndef name = &quot;Christy&quot;def template = &quot;&quot;&quot;\\    Dear Mrs $&#123;name&#125;,    You&#x27;re the winner of the lottery!    Yours sincerly,    Daisy\\&quot;&quot;&quot;println template\n\n输出：\nDear Mrs Christy,You&#x27;re the winner of the lottery!Yours sincerly,Daisy\n\n第一行前边和最后一行后边都没有空行，因为使用了 \\\n","categories":["Groovy Strings"],"tags":["Groovy","Strings"]},{"title":"Groovy Triple-single-quoted string","url":"/groovy/strings/groovy-triple-single-quoted-string/","content":"Groovy Triple-single-quoted stringprintln &#x27;---&#x27;println &#x27;&#x27;&#x27;line 1line 2line 3&#x27;&#x27;&#x27;println &#x27;---&#x27;\n\n这样的字符串，会在 line 1 前 和 line 3 后有一个空格\n这是因为在第一个 &#39;&#39;&#39; 后有一个回车符；在 line 3 后面有一个回车符\n输出：\n---line 1line 2line 3---\n\n要去掉回车符，就使用转义符 \\\nprintln &#x27;---&#x27;println &#x27;&#x27;&#x27;\\line 1line 2line 3\\&#x27;&#x27;&#x27;println &#x27;---&#x27;\n\n输出：\n---line 1line 2line 3---\n","categories":["Groovy Strings"],"tags":["Groovy","Strings"]},{"title":"Groovy Unicode escape sequence","url":"/groovy/strings/groovy-unicode-escape-sequence/","content":"Groovy Unicode escape sequence使用 Unicode 符号\n: ```\\``` + `u` + 4个十六进制数字```groovyprintln &#x27;The Euro currency symbol: \\u20AC&#x27;\n","categories":["Groovy Strings"],"tags":["Groovy","Strings"]},{"title":"Groovy Joint compilation","url":"/groovy/tools/groovy-joint-compilation/","content":"Groovy Joint compilationJoint compilation means that the Groovy compiler will parse the Groovy source files, create stubs for all of them, invoke the Java compiler to compile the stubs along with Java sources, and then continue compilation in the normal Groovy compiler way.\nThis allows mixing of Java and Groovy files without constraint.\nJoint compilation can be enabled using the -j flag with the command-line compiler, or using using a nested tag and all the attributes and further nested tags as required for the Ant task.\nIt is important to know that if you don’t enable joint compilation and try to compile Java source files with the Groovy compiler, the Java source files will be compiled as if they were Groovy sources.\nIn some situations, this might work since most of the Java syntax is compatible with Groovy, but there are a number of places where semantics could be different.\n","categories":["Groovy Tools"],"tags":["Groovy","Tools"]},{"title":"Create a base image","url":"/docker/develop-with-docker/build-images/create-a-base-image/","content":"Create a base image基础镜像分为两种:\n\nparent image - FROM 指令后面声明的镜像, FROM 指令之后的指令在基于这个镜像进行修改\nbase image - Dockerfile 中以 FROM scratch 开头的镜像\n\nCreate a simple parent image using scratchscratch 是 Docker 保留的, 最小的镜像, 作为构建容器的起始点\n使用 scratch 镜像向构建过程发出信号，您希望 Dockerfile 中的下一个命令成为镜像中的第一个文件系统层\n即使 scratch 出现在 Docker Hub 仓库中, 但是你不能拉取它, 或者使用 scratch 来为任何镜像打标签\n相反, 你可以在你的 Dockerfile 中引用 scratch\nExample - 使用 scratch 创建一个最小化的容器:\n# syntax=docker/dockerfile:1FROM scratchADD hello /CMD [&quot;/hello&quot;]\n\n从 scratch 中构建的镜像直接使用宿主机的 Linux 内核功能, 因此 hello 必须是一个可执行文件, 且必须是可以直接在 Linux 宿主机内核上不需要依赖来运行的可执行文件\n参考Create a base image\n","categories":["Docker - Develop with Docker - Build images"],"tags":["Docker","Notes"]},{"title":"Use multi-stage builds","url":"/docker/develop-with-docker/build-images/use-multi-stage-builds/","content":"Use multi-stage builds可以在一个 Dockerfile 中使用多个 FROM 指令, 每个 FROM 指令可以使用不同的 base, 每个 FROM 开启一个新的构建阶段 (stage)\n可以从一个构建复制 artifacts 到另一个构建中\n# syntax=docker/dockerfile:1FROM golang:1.16WORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/htmlCOPY app.go ./RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latestRUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=0 /go/src/github.com/alexellis/href-counter/app ./CMD [&quot;./app&quot;]\n\n第二个 FROM 指令使用 alpine:latest 镜像作为基础开启了一个新的构建阶段\nCOPY --from=0 从第 0 个构建阶段复制 artifacts 到这个新构建阶段中\n只有最后一个构建阶段会生成最终镜像, 其他之前的构建阶段的产物都会被清除\nName your build stages默认情况下, 使用整数数字来引用构建阶段, 第一个 FROM 指令使用 0 作为开始\n通过添加 AS &lt;NAME&gt; 到 FROM 指令中来为构建阶段添加名称\nFROM golang:1.16 AS builder...COPY --from=builder /go/src/github.com/alexellis/href-counter/app ./\n\nStop at a specific build stage可以不需要构建 Dockerfile 中包含所有构建阶段\n通过使用 --target 标志, 可以指定一个目标构建阶段来进行构建:\n$ docker build --target builder -t alexellis2/href-counter: latest .\n\n使用这个功能, 可以在单个 Dockerfile 中声明多个阶段, 然后按需进行构建, 例如分为开发构建阶段, 测试构建阶段, 生产构建阶段\nUse an external image as a “stage”可以使用 COPY --from 指令来从任何地方使用镜像, 本地或者 Docker registry 等\nCOPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf\n\nUse a previous stage as a new stage可以在使用 FROM 指令时引用前面的构建阶段:\n# syntax=docker/dockerfile:1FROM alpine:latest AS builderRUN apk --no-cache add build-baseFROM builder AS build1COPY source1.cpp source.cppFROM builder AS build2COPY source2.cpp source.cppRUN g++ -o /binary source.app\n\n参考Use multi-stage builds\n","categories":["Docker - Develop with Docker - Build images"],"tags":["Docker","Notes"]},{"title":"Run your tests","url":"/docker/language-specific-guides/java/run-your-tests/","content":"Refactor Dockerfile to run tests使用临时容器, 并传递测试命令来启动容器:\n$ docker run --rm --name springboot-test java-docker ./mvnw test\n\nMulti-stage Dockerfile for testing使用多阶段构建 Dockerfile 来进行测试\n以下 Dockerfile 将会构建生产镜像和测试镜像和开发镜像:\n# syntax=docker/dockerfile:1# 构建基础镜像FROM openjdk:16-alpine3.13 as baseWORKDIR /appCOPY .mvn/ .mvnCOPY mvnw pom.xml ./RUN ./mvnw dependency:go-offlineCOPY src ./src# 构建测试镜像 testFROM base as testCMD [&quot;./mvnw&quot;, &quot;test&quot;]# 构建开发镜像 developmentFROM base as developmentCMD [&quot;./mvnw&quot;, &quot;spring-boot:run&quot;, &quot;-Dspring-boot.run.profiles=mysql&quot;, &quot;-Dspring-boot.run.jvmArguments=&#x27;-agentlib:jdwp=transport=dt_socket,server,suspend=n,address=*:8000&#x27;&quot;]# 构建打包镜像FROM base as buildRUN ./mvnw package# 构建生产镜像FROM openjdk:11-jre-slim as productionEXPOSE 8080COPY --from=build /app/target/spring-petclinic-*.jar /spring-petclinic.jarCMD [&quot;java&quot;, &quot;-Djava.security.egd=file:/dev/./urandom&quot;, &quot;-jar&quot;, &quot;/spring-petclinic.jar&quot;]\n\n使用这个 Dockerfile 进行测试需要先运行 test 构建阶段构建测试镜像:\n$ docker build -t java-docker --target test .\n\n\n使用 --target 来指定要运行的构建阶段\n\n完成测试镜像构建之后, 要运行一个容器来运行镜像中的 CMD 指令来进行测试:\n$ docker run --rm --name springboot-test java-docker\n\n可以通过将 test 构建阶段中的 CMD 指令替换成 RUN 指令, 这样可以在镜像构建时运行测试命令, 而不需要先构建测试镜像再运行容器:\n# 构建测试镜像 testFROM base as testRUN [&quot;./mvnw&quot;, &quot;test&quot;]\n\n然后 build 这个 test 构建阶段来运行测试:\n$ docker build -t java-docker --target test .\n\n如果 [&quot;./mvnw&quot;, &quot;test&quot;] 命令的 exit code 不为 0, 则构建失败\nMulti-stage Dockerfile for developmentDockerfile 已经有如下 development 构建阶段:\n# 构建开发镜像 developmentFROM base as developmentCMD [&quot;./mvnw&quot;, &quot;spring-boot:run&quot;, &quot;-Dspring-boot.run.profiles=mysql&quot;, &quot;-Dspring-boot.run.jvmArguments=&#x27;-agentlib:jdwp=transport=dt_socket,server,suspend=n,address=*:8000&#x27;&quot;]\n\n所以可以更新 docker-compose.dev.yaml 让 petclinic service 使用指定的构建阶段, 并可以移除 command 元素:\nservices:  petclinic:    build:      context: .      target: development # 指定构建阶段    ports:      - 8000:8000      - 8080:8080    environment:      - SERVER_PORT=8080      - MYSQL_URL=jdbc:mysql://mysqlserver/petclinic    volumes:      - ./:/app\n\n然后可以正常运行 docker compose up 来运行应用:\n$ docker-compose -f docker-compose.dev.yaml up --build\n\n使用这个特性可以用来进行集成测试\n参考Run your tests\n","categories":["Docker - Language-specific guides"],"tags":["Docker","Notes","Language-specific guides"]},{"title":"Use containers for development","url":"/docker/language-specific-guides/java/use-containers-for-development/","content":"Run a database in a container创建两个 volume 来持久化数据和配置:\n$ docker volume create mysql_data$ docker volume create mysql_config\n\n创建一个 network 来进行通信. 这个 network 称为用户定义的桥接网络, 且提供一个 DNS 查找服务, 可以使用这个 DNS 查找服务来进行容器之间的通信:\n$ docker network create mysqlnet\n\n在容器中运行 MySQL 并将其挂载到 volume 中, attach 到 network 中:\n$ docker run \\--rm \\-d \\-v mysql_data:/var/lib/mysql \\-v mysql_config:/etc/mysql/conf.d \\--network mysqlnet \\--name mysqlserver \\-e MYSQL_USER=petclinic -e MYSQL_PASSWORD=petclinic \\-e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=petclinic \\-p 3306:3306 \\mysql:8.0.23\n\n\n使用 -v 进行存储卷挂载\n使用 --network 指定使用的网络\n使用 --name 指定容器的名称, 用于 DNS 查找\n使用 -e 来定义环境变量, 这里指定了 MySQL 的相关配置\n\n启动应用容器, 指定使用上面和 MySQL 相同的 network:\n$ docker run \\--rm \\-d \\--name springboot-server \\--network mysqlnet \\-e MYSQL_URL=jdbc:mysql://mysqlserver/petclinic \\-p 8080:8080 \\java-docker\n\n\n-e MYSQL_URL=jdbc:mysql://mysqlserver/petclinic 使用环境变量设置传入了 MySQL 的连接地址, 使用容器名称 mysqlserver 在 mysqlnet network 中进行 DNS 查找以连接上数据库\n\nUse Compose to develop locallydocker-compose.dev.yml:\nservices:  petclinic:    build:      context: .    ports:      - 8000:8000      - 8080:8080    environment:      - SERVER_PORT=8080      - MYSQL_URL=jdbc:mysql://mysqlserver/petclinic    volumes:      - ./:/app    command: ./mvnw spring-boot:run -Dspring-boot.run.profiles=mysql -Dspring-boot.run.jvmArguments=&quot;-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:8000&quot;  mysqlserver:    image: mysql:8.0.23    ports:      - 3306:3306    environment:      - MYSQL_ROOT_PASSWORD=      - MYSQL_ALLOW_EMPTY_PASSWORD=true      - MYSQL_USER=petclinic      - MYSQL_PASSWORD=petclinic      - MYSQL_DATABASE=petclinic    volumes:      - mysql_data:/var/lib/mysql      - mysql_config:/etc/mysql/conf.dvolumes:  mysql_data:  mysql_config:\n\n暴露了 8000 端口并配置 JVM 调试参数, 以使得可以 attach 一个调试器\n由于使用了 Compose, 所以可以直接在 MYSQL_URL=jdbc:mysql://mysqlserver/petclinic 中使用 mysqlserver 来连接另一个 service mysqlserver\n启动应用:\n$ docker-compose -f docker-compose.dev.yml up --build\n\n\n-f 指定使用的 Compose 文件\n--build 指定启动容器前构建镜像\n\n参考Use containers for development\n","categories":["Docker - Language-specific guides"],"tags":["Docker","Notes","Language-specific guides"]},{"title":"Elasticsearch Change mappings and settings for a data stream","url":"/elasticsearch/elasticsearch-guide/data-streams/elasticsearch-change-mappings-and-settings-for-a-data-stream/","content":"Elasticsearch Change mappings and settings for a data stream修改数据流的映射和设置\n\nAdd a new field mapping to a data stream(添加一个新的字段映射到数据流中)\nChange an existing field mapping in a data stream(修改数据流中的一个已存在的字段映射)\nChange a dynamic index setting for a data stream(修改一个数据流中一个动态索引配置)\nChange a static index setting for a data stream(修改一个数据流中一个静态索引配置)\n\n参考link\n","categories":["Elasticsearch - User Guides - Data streams"],"tags":["User Guides","Elasticsearch","Data streams"]},{"title":"Elasticsearch Data streams","url":"/elasticsearch/elasticsearch-guide/data-streams/elasticsearch-data-streams/","content":"Elasticsearch Data streams一个数据流让你可以存储跨多个分片的只增(append-only)的时间序列数据, 让你可以只使用一个命名的资源来进行请求\n数据流很适合日志, 事件, 度量和其他持续产生的的数据\n你可以直接提交索引或者搜索请求给一个数据流\n数据流会自动路由请求到一个备份的存储流数据的分片\n你可以使用 index lifecycle management (ILM) 去自动管理这些备份的分片\nBacking indices一个数据流包含一个或多个隐藏的, 自动生成的备份分片\n一个数据流需要一个匹配的索引模板. 这个模板包含用来配置备份分片的映射和设置\n每个文档被索引到一个数据流必须包含一个 @timestamp 字段, 映射为 data 或者 date_nanos 类型字段\n如果索引模板没有定义一个 @timestamp 字段, Elasticsearch 默认映射 @timestamp 为一个 date 字段\n相同的索引模板可以用于多个数据流\n不可以删除一个已经被数据流使用的索引模板\nRead requests当你提交一个读请求到一个数据流, 数据流路由这个请求到备份的分片\nWrite index最近被创建的备份分片作为数据流的写分片. 数据流只会添加新文档到这个索引\nRolloverrollover 创建了一个新的索引来作为写索引\n建议使用 ILM 来自动管理数据流的滚动\nGeneration使用六位的, 零填充的增加的整数作为数据流跟踪的标识, 从 000001 开始\nAppend-only数据流不可以或者很少被更新\n不能直接发送更新或者删除文档请求到一个数据流\n可以直接发送更新或者删除文档请求到备份的分片\n参考link\n","categories":["Elasticsearch - User Guides - Data streams"],"tags":["User Guides","Elasticsearch","Data streams"]},{"title":"Elasticsearch Set up a data stream","url":"/elasticsearch/elasticsearch-guide/data-streams/elasticsearch-set-up-a-data-stream/","content":"Elasticsearch Set up a data stream使用如下步骤来配置一个数据流:\n\n创建一个索引生命周期策略\n创建 Component templates\n创建一个 Index template\n创建数据流\n保护数据流\n\n还可以转换一个索引别名为数据流\n如果你使用 Fleet 或者 Elastic Agent , 它们将会为你设置好数据流\nConvert an index alias to a data streamPOST _data_stream/_migrate/my-time-series-data\nGet information about a data streamGET _data_stream/my-data-stream\nDelete a data streamDELETE _data_stream/my-data-stream\n参考link\n","categories":["Elasticsearch - User Guides - Data streams"],"tags":["User Guides","Elasticsearch","Data streams"]},{"title":"Elasticsearch Use a data stream","url":"/elasticsearch/elasticsearch-guide/data-streams/elasticsearch-use-a-data-stream/","content":"Elasticsearch Use a data stream在配置好一个数据流之后, 可以进行如下操作:\n\nAdd documents to a data stream(添加一个文档到数据流中)\nSearch a data stream(搜索一个数据流)\nGet statistics for a data stream(获取数据流的统计信息)\nManually roll over a data stream(手动滚动一个数据流)\nOpen closed backing indices(打开已经关闭的数据流)\nReindex with a data stream(重新索引一个数据流)\nUpdate documents in a data stream by query(通过查询更新一个数据流中的文档)\nDelete documents in a data stream by query(通过查询删除一个数据流中的文档)\nUpdate or delete documents in a backing index(更新或者删除备份索引中的文档)\n\n参考link\n","categories":["Elasticsearch - User Guides - Data streams"],"tags":["User Guides","Elasticsearch","Data streams"]},{"title":"Elasticsearch Index templates","url":"/elasticsearch/elasticsearch-guide/index-templates/elasticsearch-index-templates/","content":"Elasticsearch Index templatesindex template 是用来告诉 Elasticsearch 在创建索引时怎样进行配置的一种方式\n对于数据流, index template 对数据流背后创建的分片进行配置\nTemplates 是在索引创建前进行设置的\n无论是手动还是通过索引文档的方式来创建索引, template settings 都会用作创建索引的基础\n有两种类型的 templates:\n\nindex templates\ncomponent templates\n\nComponent templates 是可重复使用的, 用来配置映射, 设置和别名的创建模块\n但是使用 Component templates 去构建 Index templates, Component templates 不会直接作用于一组索引\nIndex templates 可以包含一组 Component templates, 也可以直接包含指定设置, 映射和别名\n以下状况适用于 Index templates:\n\nComposable templates 的优先级比 legacy templates 高. 如果没有 Composable templates 匹配一个索引, 那么一个匹配的 legacy template 将会被使用\n如果一个索引创建时使用了明确的参数配置, 同时也匹配了索引模板, 创建索引中指定的参数配置将会比索引模板中的参数有更高的优先级\n如果一个新的数据流或索引匹配多个索引模板, 有更高优先级的索引模板将会被使用\n\nAvoid index pattern collisionElasticsearch 有一些内置的 index template , 优先级为 100 :\n\nlogs-*-*\nmetrics-*-*\nsynthetics-*-*\n\nElastic Agent 使用这些模板来创建数据流\n由 Fleet integrations 创建的索引模板使用类似的有重叠的索引模式, 优先级高达 200\n如果你使用 Fleet 或者 Elastic Agent , 为你的索引模板设置小于 100 的优先级来避免重写这些模板. 否则, 为了避免意外地使用这些模板, 做如下操作:\n\n关闭所有内置的 Index template 和 Component template, 使用 cluster update settings API 设置 stack.templates.enabled=false\n使用一个没有重叠的索引模式\n配置一个有重叠的索引模板的优先级大于 200\n\nCreate index template创建 Component Template\nPUT _component_template/component_template1&#123;    &quot;template&quot;: &#123;        &quot;mappings&quot;: &#123;            &quot;properties&quot;: &#123;                &quot;@timestamp&quot;: &#123;                    &quot;type&quot;: &quot;date&quot;                &#125;            &#125;        &#125;    &#125;&#125;PUT _component_template/runtime_component_template&#123;    &quot;template&quot;: &#123;        &quot;mappings&quot;: &#123;            &quot;runtime&quot;: &#123;                &quot;day_of_week&quot;: &#123;                    &quot;type&quot;: &quot;keyword&quot;,                    &quot;script&quot;: &#123;                        &quot;source&quot;: &quot;emit(doc[&#x27;@timestamp&#x27;].value.dayOfWeekEnum.getDisplayName(TextStyle.FULL, Locale.ROOT))&quot;                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;\n\n使用 Component Template 创建 Index Template:\nPUT _index_template/template_1&#123;  &quot;index_patterns&quot;: [&quot;te*&quot;, &quot;bar*&quot;],  &quot;template&quot;: &#123;    &quot;settings&quot;: &#123;      &quot;number_of_shards&quot;: 1    &#125;,    &quot;mappings&quot;: &#123;      &quot;_source&quot;: &#123;        &quot;enabled&quot;: true      &#125;,      &quot;properties&quot;: &#123;        &quot;host_name&quot;: &#123;          &quot;type&quot;: &quot;keyword&quot;        &#125;,        &quot;created_at&quot;: &#123;          &quot;type&quot;: &quot;date&quot;,          &quot;format&quot;: &quot;EEE MMM dd HH:mm:ss Z yyyy&quot;        &#125;      &#125;    &#125;,    &quot;aliases&quot;: &#123;      &quot;mydata&quot;: &#123; &#125;    &#125;  &#125;,  &quot;priority&quot;: 500,  &quot;composed_of&quot;: [&quot;component_template1&quot;, &quot;runtime_component_template&quot;],   &quot;version&quot;: 3,  &quot;_meta&quot;: &#123;    &quot;description&quot;: &quot;my custom&quot;  &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Index templates"],"tags":["User Guides","Elasticsearch","Index templates"]},{"title":"Elasticsearch Simulate multi-component templates","url":"/elasticsearch/elasticsearch-guide/index-templates/elasticsearch-simulate-multi-component-templates/","content":"Elasticsearch Simulate multi-component templates由于模板不仅可以由多个 Component Template 组成, 还可以由索引模板本身组成, 因此有两个模拟 API 来确定最终索引设置是什么\nPOST /_index_template/_simulate_index/my-index-000001\nPOST /_index_template/_simulate/template_1\n参考link\n","categories":["Elasticsearch - User Guides - Index templates"],"tags":["User Guides","Elasticsearch","Index templates"]},{"title":"Elasticsearch Enrich your data","url":"/elasticsearch/elasticsearch-guide/ingest-pipelines/elasticsearch-enrich-your-data/","content":"Elasticsearch Enrich your data在 ingest 过程中可以使用 enrich processor 将已存在的索引中的数据添加到输入的文档中\n例如:\n\n使用已知的 IP 地址来标识 Web 服务器\n使用产品 ID 来获取产品信息\n使用邮箱地址来提供联系信息\n\n参考link\n","categories":["Elasticsearch - User Guides - Ingest pipelines"],"tags":["User Guides","Elasticsearch","Ingest pipelines"]},{"title":"Elasticsearch Ingest pipelines","url":"/elasticsearch/elasticsearch-guide/ingest-pipelines/elasticsearch-ingest-pipelines/","content":"Elasticsearch Ingest pipelinesIngest pipelines 让你可以在索引数据之前对数据进行通用转换\n例如, 你可以使用 pipelines 去删除字段, 从文本中抽取信息, 或丰富你的数据\n一个 pipeline 包含一系列可配置的称为 processors 的任务\n每个 processor 按顺序运行, 对传入的文档做指定的修改\n在 processors 执行完, Elasticsearch 添加转换好的文档到你的数据流或者索引中\n可以使用 Kibana 的 Ingest Node Pipelines 特性或 ingest APIs 来创建和管理 ingest pipelines\nElasticsearch 存储 pipelines 在集群状态中\n先决条件\n拥有 ingest 节点规则的节点负责管道处理. 为了使用 ingest pipeline , 你的集群必须有至少一个节点拥有 ingest 规则. 建议创建专用的 ingest nodes 来处理高 ingest 负载\n如果 Elasticsearch 安全特性开启, 你必须拥有 manage_pipeline 集群权限去管理 ingest pipelines . 要使用 Kibana 的 Ingest Node Pipeline 功能, 你还需要有 cluster:monitor/nodes/info 集群权限\n包含 enrich 处理器的管道需要额外的配置\n\nPipelines for Fleet and Elastic AgentFleet 自动添加 ingest pipelines 到它的集成中\n参考link\n","categories":["Elasticsearch - User Guides - Ingest pipelines"],"tags":["User Guides","Elasticsearch","Ingest pipelines"]},{"title":"Elasticsearch Ingest processor reference","url":"/elasticsearch/elasticsearch-guide/ingest-pipelines/elasticsearch-ingest-processor-reference/","content":"Elasticsearch Ingest processor referenceElasticsearch 包含了一些可配置的处理器\n使用这个 API 来获取所有可用的处理器: GET _nodes/ingest?filter_path=nodes.*.ingest.processors\n内置的处理器\n\n\nName\nMeaning\n\n\n\nAppend\n添加一些值到 array 数组中\n\n\nBytes\n将一个人类可读的字节值 (e.g. 1kb) 转换为它的字节数 (e.g. 1024)\n\n\nCircle\n将圆形的形状定义转换为近似它的正多边形\n\n\nCommunity ID\n为网络流数据计算定义在 Community ID Specification 中的 Community ID\n\n\nConvert\n进行类型转换, 如 String -&gt; Integer\n\n\nCSV\n从一个文档中单个文本字段 CSV 行中提取字段\n\n\nDate\n从字段中解析日期, 然后使用日期或时间戳作为文档的 timestamp\n\n\nDate index name\n这个处理器的目的是通过文档中的一个使用 date math index name support 日期或时间戳字段, 将文档指向正确的基于时间的索引\n\n\nDissect\n从文档的一个文本字段中提取结构化字段信息\n\n\nDot expander\n展开一个有 . 号的字段成为一个对象字段\n\n\nDrop\n不抛任何异常地丢弃一个文档\n\n\nEnrich\n可以使用另一个索引的数据来 enrich 文档\n\n\nFail\n抛出一个异常\n\n\nFingerprint\n为文档内容计算一个哈希值\n\n\nForeach\n处理一个不知道长度的数组中的元素\n\n\nGeoIP\n为 IPv4 或 IPv6 地址添加地理信息\n\n\nGrok\n从一个文档的单个文本字段中提取结构字段\n\n\nGsub\n使用一个正则表达式和一个替代品来转换一个字符字段\n\n\nHTML strip\n将字段中的 HTML 标签删除\n\n\nInference\n使用预先训练的数据帧分析模型来推断管道中正在加载的数据\n\n\nJoin\n使用一个分隔符将数组中的元素连接成单个字符串\n\n\nJSON\n将一个 JSON 字符串转换成 JSON 对象\n\n\nKV\n自动解析键值对信息或者特定事件\n\n\nLowercase\n将字符串转换为小写形式\n\n\nNetwork direction\n计算两个 IP 地址之间的距离\n\n\nPipeline\n执行另外一个 Pipeline\n\n\nRegistered domain\n从一个全限定名称中提取注册域名, 子域名, 和顶级域名\n\n\nRemove\n删除一个已存在的字段\n\n\nRename\n重命名一个已存在的字段\n\n\nScript\n在输入的文档上运行脚本\n\n\nSet\n设置一个字段并将其关联到一个指定的值\n\n\nSet security user\n将当前已验证的用户信息设置到当前文档\n\n\nSort\n对数组的元素进行排序\n\n\nSplit\n使用一个分隔字符分割一个字段为数组\n\n\nTrim\n去除字段前后的空格\n\n\nUppercase\n将一个字符串转换为大写形式\n\n\nURL decode\n解码一个字符串\n\n\nURI parts\n解析一个 URI 字符串并提取它的成员作为一个对象\n\n\nUser agent\n提取一个 Web 请求中浏览器发送的 user agent 信息\n\n\nProcessor plugins可以使用插件的方式来安装额外的处理器\n必须在所有的集群节点上都安装同样的处理器\n参考link\n","categories":["Elasticsearch - User Guides - Ingest pipelines"],"tags":["User Guides","Elasticsearch","Ingest pipelines"]},{"title":"Elasticsearch Set up an enrich processor","url":"/elasticsearch/elasticsearch-guide/ingest-pipelines/elasticsearch-set-up-an-enrich-processor/","content":"Elasticsearch Set up an enrich processor\nCheck the prerequisites\nAdd enrich data\nCreate an enrich policy\nExecute the enrich policy\nAdd a enrich processor to an ingest pipeline\nIngest and enrich documents\n\n参考link\n","categories":["Elasticsearch - User Guides - Ingest pipelines"],"tags":["User Guides","Elasticsearch","Ingest pipelines"]},{"title":"Elasticsearch analyzer","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-analyzer/","content":"Elasticsearch analyzer只有 text 类型字段才可以配置这个参数\n这个参数用来配置索引和搜索时使用的文本分析器\nPUT my-index-000001&#123;   &quot;settings&quot;:&#123;      &quot;analysis&quot;:&#123;         &quot;analyzer&quot;:&#123;            &quot;my_analyzer&quot;:&#123;                &quot;type&quot;:&quot;custom&quot;,               &quot;tokenizer&quot;:&quot;standard&quot;,               &quot;filter&quot;:[                  &quot;lowercase&quot;               ]            &#125;,            &quot;my_stop_analyzer&quot;:&#123;                &quot;type&quot;:&quot;custom&quot;,               &quot;tokenizer&quot;:&quot;standard&quot;,               &quot;filter&quot;:[                  &quot;lowercase&quot;,                  &quot;english_stop&quot;               ]            &#125;         &#125;,         &quot;filter&quot;:&#123;            &quot;english_stop&quot;:&#123;               &quot;type&quot;:&quot;stop&quot;,               &quot;stopwords&quot;:&quot;_english_&quot;            &#125;         &#125;      &#125;   &#125;,   &quot;mappings&quot;:&#123;       &quot;properties&quot;:&#123;          &quot;title&quot;: &#123;             &quot;type&quot;:&quot;text&quot;,             &quot;analyzer&quot;:&quot;my_analyzer&quot;,              &quot;search_analyzer&quot;:&quot;my_stop_analyzer&quot;,              &quot;search_quote_analyzer&quot;:&quot;my_analyzer&quot;          &#125;      &#125;   &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch boost","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-boost/","content":"Elasticsearch boost用来计算更多的相关性得分\n就是用来手动提升某个字段的得分\n建议在查询时使用 boost:\nPOST _search&#123;    &quot;query&quot;: &#123;        &quot;match&quot;: &#123;            &quot;title&quot;: &#123;                &quot;query&quot;: &quot;quick brown fox&quot;,                &quot;boost&quot;: 2            &#125;        &#125;    &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch coerce","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-coerce/","content":"Elasticsearch coerce用来配置是否自动进行类型转换, 默认为 true , 进行转换\n例如, 字符串会转换为数值\nPUT my-index-000001&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;number_one&quot;: &#123;        &quot;type&quot;: &quot;integer&quot;      &#125;,      &quot;number_two&quot;: &#123;        &quot;type&quot;: &quot;integer&quot;,        &quot;coerce&quot;: false      &#125;    &#125;  &#125;&#125;PUT my-index-000001/_doc/1&#123;  &quot;number_one&quot;: &quot;10&quot;            // 1&#125;PUT my-index-000001/_doc/2&#123;  &quot;number_two&quot;: &quot;10&quot;            // 2&#125;\n\n1 : 字符串 &quot;10&quot; 自动转换为数字\n2 : 因为 coerce 配置为 false , 所以这个 PUT 请求被拒绝\n还可以在索引级别配置 coerce:\nPUT my-index-000001&#123;  &quot;settings&quot;: &#123;    &quot;index.mapping.coerce&quot;: false  &#125;,  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;number_one&quot;: &#123;        &quot;type&quot;: &quot;integer&quot;,        &quot;coerce&quot;: true      &#125;,      &quot;number_two&quot;: &#123;        &quot;type&quot;: &quot;integer&quot;      &#125;    &#125;  &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch copy_to","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-copy-to/","content":"Elasticsearch copy_tocopy_to 参数允许你将多个字段的值拷贝到一个组字段, 然后这个组字段可以当做一个单独字段来进行查询\n如果你经常搜索多个字段, 你可以通过使用 copy_to 去搜索更少的字段来提升搜索速度\n例如, first_name 和 last_name 字段可以拷贝到 full_name 字段:\nPUT my-index-000001&#123;    &quot;mappings&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;first_name&quot;: &#123;                &quot;type&quot;: &quot;text&quot;,                &quot;copy_to&quot;: &quot;full_name&quot;            &#125;,            &quot;last_name&quot;: &#123;                &quot;type&quot;: &quot;text&quot;,                &quot;copy_to&quot;: &quot;full_name&quot;            &#125;,            &quot;full_name&quot;: &#123;                &quot;type&quot;: &quot;text&quot;            &#125;        &#125;    &#125;&#125;\n\nPUT my-index-000001/_doc/1&#123;  &quot;first_name&quot;: &quot;John&quot;,  &quot;last_name&quot;: &quot;Smith&quot;&#125;\n\nGET my-index-000001/_search&#123;  &quot;query&quot;: &#123;    &quot;match&quot;: &#123;      &quot;full_name&quot;: &#123;         &quot;query&quot;: &quot;John Smith&quot;,        &quot;operator&quot;: &quot;and&quot;      &#125;    &#125;  &#125;&#125;\n\nfirst_name 和 last_name 仍然可以分别被搜索\nfull_name 字段可以同时查询 first_name 和 last_name 中的值\n一些重要的点:\n\n是字段的值被拷贝, 不是分析后的词\n_source 中没有拷贝的值\n可以将一个字段拷贝到多个字段中: &quot;copy_to&quot;: [&quot;field_1&quot;, &quot;field_2&quot;]\n不能进行递归拷贝\ncopy_to 不支持对象类型的字段, 例如: date_range\n\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch doc_values","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-doc_values/","content":"Elasticsearch doc_valuesdoc_values 是在索引时与倒排索引同时生成的\ndoc_values 和倒排索引一样序列化到磁盘\ndoc_values 通过序列化把数据结构持久化到磁盘, 这样可以充分利用操作系统的内存, 而不是 JVM 的 Heap\n从广义上来说, doc_values 本质上是一个序列化的列式存储\n列式存储适合于聚合, 排序, 脚本等操作\ndoc_values 默认对所有字段启动, 除了 analyzed strings. 也就是说所有的数字, 地理坐标, 日期, IP和 not_analyzed 字符类型都会默认开启\n要禁用 doc_values , 在字段的 mapping 设置中设置 doc_values: false\n搜索需要用到倒排索引, 而排序和聚合则需要使用正排索引\n倒排索引的优势在于查找包含某个项的文档, 而反过来确定哪些项在单个文档里并不高效\ndoc_values 和 fielddata 是用来给文档建立正排索引的\ndoc_values 的主要工作地盘是磁盘\nfielddata 的主要工作地盘是内存\n\n\n\n维度\ndoc_values\nfielddata\n\n\n\n创建时间\nindex 时创建\n使用时动态创建\n\n\n创建位置\n磁盘\n内存( JVM Heap )\n\n\n优点\n不占用内存空间\n不占用磁盘空间\n\n\n缺点\n索引速度稍低\n文档很多时, 动态创建开销比较大, 而且占内存\n\n\n虽然速度稍慢, 但是 doc_values 的优势在于不会随着文档数的增多引起 OOM 问题\n在 ES2.x 之后, 支持聚合的字段属性默认都使用 doc_values , 而不是 fielddata\ndoc_values 其实是 Lucene 在构建倒排索引时, 会额外建立一个有序的正排索引( 基于 document &#x3D;&gt; field value 的映射列表 )\n参考link\nlink\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch dynamic","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-dynamic/","content":"Elasticsearch dynamic用来配置是否自动索引新字段, 默认开启\n内部对象默认继承外部对象的配置, 如果外部对象关闭了 dynamic, 要在内部对象中手动开启 dynamic:\nPUT my-index-0000001&#123;    &quot;mappings&quot;: &#123;        &quot;dynamic&quot;: false,        &quot;properties&quot;: &#123;            &quot;user&quot;: &#123;                &quot;properties&quot;: &#123;                    &quot;name&quot;: &#123;                        &#x27;type&#x27;: &quot;text&quot;                    &#125;,                    &quot;social_networks&quot;: &#123;                        &quot;dynamic&quot;: true,                        &quot;properties&quot;: &#123;]                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;\n\n\n\n\nParameters for dynamic\nMeaning\n\n\n\ntrue\n默认值. 新字段会添加到映射中\n\n\nruntime\n新字段会作为 runtime fields 添加到映射中. 这些字段不会被索引, 会在查询时从 _source 中加载\n\n\nfalse\n新字段会被忽略. 这些字段不会被索引和不可搜索, 不过还是会在 _source 字段中出现. 这些字段不会添加到映射中, 新字段必须显示添加\n\n\nstrict\n如果有新字段被检测到, 那么将会抛出异常\n\n\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch eager_global_ordinals","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-eager-global-ordinals/","content":"\n\n\nElasticsearch eager_global_ordinals\nglobal ordinals\nwhat’s this\ndetail\n\n\neager_global_ordinals\nwhat’s this\n使用场景\n使用\n\n\nexecution_hint\nwhat’s this\nhow to use\n\n\n参考\n\n\n\n\n\nElasticsearch eager_global_ordinalsglobal ordinalswhat’s this当我们使用 doc values 或者 fielddata 存储时，在磁盘中存储的值不是真正的字段值，而是一个字典值( ordinal)\n当我们进行聚合查询的时候，es 会把这个 字典值 跟真正字段值的映射字典加载到内存中，并对结果集做映射，转化为真正的值\n这份映射关系是 shard 级别的，为这个 shard 里面是所有 segment 服务，这也是 global 的体现\ndetail字典关系是 lazy init 的，只有第一次使用的时候才会加载到内存中\n字典关系在 shard 被触发 refresh 以后就会失效。下次使用的时候需要再重新构建。所以可以提高 refresh_interval 的值，减少 fresh 频率提高字典的生存时间\neager_global_ordinalswhat’s this当在 global ordinals 的时候，refresh 以后下一次查询字典就需要重新构建，在追求查询的场景下很影响查询性能\n可以使用 eager_global_ordinals ，即在每次 refresh 以后马上更新字典，字典常驻内存，减少了查询的时候构建字典的耗时\n使用场景因为这份字典需要常驻内存，并且每次 refresh 以后就会重构，所以增大了内存以及cpu的消耗\n推荐在低写高查、数据量不大的 index 中使用\n使用PUT my_index/_mapping&#123;    &quot;properties&quot;: &#123;        &quot;tags&quot;: &#123;            &quot;type&quot;: &quot;keyword&quot;,            &quot;eager_global_ordinals&quot;: true        &#125;    &#125;&#125;\n\nexecution_hintwhat’s thisglobal ordinal 的使用场景，是 doc_values 以及 fileddata 的默认数据架构\n除了这种模式，还可以选择 map 模式\n即不再使用字典而是直接把值加载到内存中计算，减去了构建字典的耗时\n当查询的结果集很小的情况下，可以使用map的模式不去构建字典\n使用 map 还是 global_ordinals 的取决于构建字典的开销与加载原始字典的开销。当结果集大到一定程序，map 的内存开销的代价可能抵消了构建字典的开销\nhow to useGET /_search&#123;    &quot;aggs&quot;: &#123;        &quot;tags&quot;: &#123;            &quot;terms&quot;: &#123;                &quot;field&quot;: &quot;tags&quot;,                &quot;execution_hint&quot;: &quot;map&quot;            &#125;        &#125;    &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch enabled","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-enabled/","content":"Elasticsearch enabled用来控制一个字段是否要启用\n设置为 false 的字段不会被索引\n但是可以通过 _source 字段来获取\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch fields","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-fields/","content":"Elasticsearch fields为了不同的目的用不同的方式索引同一个索引\n就是给字段增加子字段, 子字段可以有不同的属性\nPUT my-index-000001&#123;    &quot;mappings&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;city&quot;: &#123;                &quot;type&quot;: &quot;text&quot;,                &quot;fields&quot;: &#123;                    &quot;raw&quot;: &#123;                        &quot;type&quot;: &quot;keyword&quot;                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;\n\ncity 的类型为 text , 可以用于全文搜索\ncity.raw 的类型为 keyword , 可以用于排序和聚合\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch format","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-format/","content":"Elasticsearch format用来定义日期类型字段的格式\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch ignore_above","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-ignore-above/","content":"Elasticsearch ignore_above字符串中大于这个参数值的字符将不会被索引和存储\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch ignore_malformed","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-ignore-malformed/","content":"Elasticsearch ignore_malformed是否忽略畸形的数据\n如果设置为 true , 不符合要求的字段将会被忽略, 这个文档仍然可以存储到 Elasticsearch 中\n默认为 false\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch index_options","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-index-options/","content":"Elasticsearch index_optionsindex_options 选项用来控制哪些用于搜索和高亮目的的信息添加到反向索引中\n默认是 positions\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch index_phrases","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-index-phrases/","content":"Elasticsearch index_phrases默认为 false\n如果设置为 true , 两个单词组成的词组将会被索引成一个单独字段, 这会使得精确词组查找运行速度更快\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch index_prefixes","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-index-prefixes/","content":"Elasticsearch index_prefixes这个参数启用单词前缀索引, 用来加速前缀搜索\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch index","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-index/","content":"Elasticsearch indexindex 选项控制一个字段是否可索引的\n默认为 true\n如果设置为 false , 字段将不会被索引, 不可搜索\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch meta","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-meta/","content":"Elasticsearch meta元数据和字段关联\n这个元数据对 Elasticsearch 是不透明的\n这个字段只是用于多个在相同索引上工作, 共享关于字段的元数据的应用程序\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch normalizer","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-normalizer/","content":"Elasticsearch normalizer用来对数据进行标准化处理\n在索引, 查询前将文本进行前置处理\n可以用于数据清洗, 数据标准化\nPUT index&#123;  &quot;settings&quot;: &#123;    &quot;analysis&quot;: &#123;      &quot;normalizer&quot;: &#123;        &quot;my_normalizer&quot;: &#123;          &quot;type&quot;: &quot;custom&quot;,          &quot;char_filter&quot;: [],          &quot;filter&quot;: [&quot;lowercase&quot;, &quot;asciifolding&quot;]        &#125;      &#125;    &#125;  &#125;,  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;foo&quot;: &#123;        &quot;type&quot;: &quot;keyword&quot;,        &quot;normalizer&quot;: &quot;my_normalizer&quot;      &#125;    &#125;  &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch norms","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-norms/","content":"Elasticsearch normsnorms 里面存储的是各种各样的归一化因子, 用来在查询时计算一个文档的得分\n如果在一个字段上不需要计算得分, 可以配置 norms 为 false\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch null_value","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-null_value/","content":"Elasticsearch null_valuenull 值不能被索引和搜索\n使用 null_value 来代替 null , 这个字段可以被当做是 null 值来看待, 但其是有值的\nnull_value 参数允许使用具体值你明确代替 null 值, 然后这个值可以被索引和搜索:\nPUT my-index-000001&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;status_code&quot;: &#123;        &quot;type&quot;:       &quot;keyword&quot;,        &quot;null_value&quot;: &quot;NULL&quot;       &#125;    &#125;  &#125;&#125;PUT my-index-000001/_doc/1&#123;  &quot;status_code&quot;: null&#125;PUT my-index-000001/_doc/2&#123;  &quot;status_code&quot;: [] &#125;GET my-index-000001/_search&#123;  &quot;query&quot;: &#123;    &quot;term&quot;: &#123;      &quot;status_code&quot;: &quot;NULL&quot;     // 返回文档 1    &#125;  &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch position_increment_gap","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-position_increment_gap/","content":"Elasticsearch position_increment_gapposition_increment_gap 设置告诉 Elasticsearch 应该为数组中每个新元素增加当前词条 position 的指定值\n默认为 100\nPUT my-index-000001/_doc/1&#123;  &quot;names&quot;: [ &quot;John Abraham&quot;, &quot;Lincoln Smith&quot;]&#125;GET my-index-000001/_search&#123;  &quot;query&quot;: &#123;    &quot;match_phrase&quot;: &#123;      &quot;names&quot;: &quot;Abraham Lincoln&quot;        // 不会匹配到文档    &#125;  &#125;&#125;GET my-index-000001/_search&#123;  &quot;query&quot;: &#123;    &quot;match_phrase&quot;: &#123;      &quot;names&quot;: &quot;Abraham Lincoln&quot;,      &quot;slop&quot;; 101                       // 将会匹配到文档. 因为 slop 大于 position_increment_gap    &#125;  &#125;&#125;\n\n分析之后, 会产生如下结果\nPosition 1: john\nPosition 2: abraham\nPosition 103: lincoln\nPosition 104: smith\n如果设置 position_increment_gap 为 0:\nPUT my-index-000001&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;names&quot;: &#123;        &quot;type&quot;: &quot;text&quot;,        &quot;position_increment_gap&quot;: 0       &#125;    &#125;  &#125;&#125;PUT my-index-000001/_doc/1&#123;  &quot;names&quot;: [ &quot;John Abraham&quot;, &quot;Lincoln Smith&quot;]&#125;GET my-index-000001/_search&#123;  &quot;query&quot;: &#123;    &quot;match_phrase&quot;: &#123;      &quot;names&quot;: &quot;Abraham Lincoln&quot;            // 将会匹配到文档    &#125;  &#125;&#125;\n\nPosition 1: john\nPosition 2: abraham\nPosition 4: lincoln\nPosition 4: smith\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch properties","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-properties/","content":"Elasticsearch properties用来定义子字段\nPUT my-index-000001&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;       &quot;manager&quot;: &#123;        &quot;properties&quot;: &#123;           &quot;age&quot;:  &#123; &quot;type&quot;: &quot;integer&quot; &#125;,          &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot;  &#125;        &#125;      &#125;,      &quot;employees&quot;: &#123;        &quot;type&quot;: &quot;nested&quot;,        &quot;properties&quot;: &#123;           &quot;age&quot;:  &#123; &quot;type&quot;: &quot;integer&quot; &#125;,          &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot;  &#125;        &#125;      &#125;    &#125;  &#125;&#125;PUT my-index-000001/_doc/1 &#123;  &quot;region&quot;: &quot;US&quot;,  &quot;manager&quot;: &#123;    &quot;name&quot;: &quot;Alice White&quot;,    &quot;age&quot;: 30  &#125;,  &quot;employees&quot;: [    &#123;      &quot;name&quot;: &quot;John Smith&quot;,      &quot;age&quot;: 34    &#125;,    &#123;      &quot;name&quot;: &quot;Peter Brown&quot;,      &quot;age&quot;: 26    &#125;  ]&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch search_analyzer","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-search_analyzer/","content":"Elasticsearch search_analyzer默认情况下, 搜索和索引使用相同的分析器\n可以通过 search_analyzer 来指定搜索时使用的分析器\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch similarity","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-similarity/","content":"Elasticsearch similaritysimilarity 参数用来指定计算分数用的算法\nPUT my-index-000001&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;default_field&quot;: &#123;         &quot;type&quot;: &quot;text&quot;      &#125;,      &quot;boolean_sim_field&quot;: &#123;        &quot;type&quot;: &quot;text&quot;,        &quot;similarity&quot;: &quot;boolean&quot;       &#125;    &#125;  &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch store","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-store/","content":"Elasticsearch store默认情况下, 字段值会被索引, 使得字段值可以被搜索, 但是字段值不会被单独存储\n所有的字段值都存储在 _source 字段中, 不能单独获取某个字段的值, 必须从 _source 中获取\n可以配置 store 为 true 来将一个字段配置成单独存储, 这样就要可以单独获取某个字段的值, 而不需要从 _source 中获取\nPUT my-index-000001&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;title&quot;: &#123;        &quot;type&quot;: &quot;text&quot;,        &quot;store&quot;: true       &#125;,      &quot;date&quot;: &#123;        &quot;type&quot;: &quot;date&quot;,        &quot;store&quot;: true       &#125;,      &quot;content&quot;: &#123;        &quot;type&quot;: &quot;text&quot;      &#125;    &#125;  &#125;&#125;PUT my-index-000001/_doc/1&#123;  &quot;title&quot;:   &quot;Some short title&quot;,  &quot;date&quot;:    &quot;2015-01-01&quot;,  &quot;content&quot;: &quot;A very long content field...&quot;&#125;GET my-index-000001/_search&#123;  &quot;stored_fields&quot;: [ &quot;title&quot;, &quot;date&quot; ] &#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch term_vector","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-term-vector/","content":"Elasticsearch term_vectorTerm vector 包含了分析过程产生的关于词语的信息\nterm_vector 默认为 no , 不保存这些信息\nPUT my-index-000001&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;text&quot;: &#123;        &quot;type&quot;:        &quot;text&quot;,        &quot;term_vector&quot;: &quot;with_positions_offsets&quot;      &#125;    &#125;  &#125;&#125;PUT my-index-000001/_doc/1&#123;  &quot;text&quot;: &quot;Quick brown fox&quot;&#125;GET my-index-000001/_search&#123;  &quot;query&quot;: &#123;    &quot;match&quot;: &#123;      &quot;text&quot;: &quot;brown fox&quot;    &#125;  &#125;,  &quot;highlight&quot;: &#123;    &quot;fields&quot;: &#123;      &quot;text&quot;: &#123;&#125;     &#125;  &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch Typeless APIs in 7.0","url":"/elasticsearch/elasticsearch-guide/mapping-parameters/elasticsearch-typeless-apis-in-7-0/","content":"Elasticsearch Typeless APIs in 7.0Document APIs创建文档&#123;index&#125;/_doc 或 &#123;index&#125;/_doc/1 来创建文档\n++创建++文档必须包含 _doc 作为端点\n获取&#x2F;删除文档&#123;index&#125;/_doc/id 来 get 或 delete 文档\n++获取++和++删除++文档必须包含 _doc 作为端点\n更新&#x2F;新增文档_update 的请求 url 不需要 _doc\n_bulk 的请求 url 不需要 _doc\nPOST /my-index-0000001/_update/1&#123;    &quot;doc&quot;: &#123;        &quot;foo&quot;: &quot;qux&quot;    &#125;&#125;POST _bulk&#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;my-index-000001&quot;, &quot;_id&quot; : &quot;3&quot; &#125; &#125;&#123; &quot;foo&quot; : &quot;baz&quot; &#125;&#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;my-index-000001&quot;, &quot;_id&quot; : &quot;4&quot; &#125; &#125;&#123; &quot;foo&quot; : &quot;qux&quot; &#125;\n\nSearch APIs当调用 _search,_msearch,_explain 这些搜索 API 时, 不需要在 URL 中指定 _doc 或类型\n在查询,聚合,脚本中都不需要使用 _type 字段\n参考link\n","categories":["Elasticsearch - User Guides - Mapping parameters"],"tags":["User Guides","Elasticsearch","Mapping parameters"]},{"title":"Elasticsearch Match all query","url":"/elasticsearch/elasticsearch-guide/query-dsl/elasticsearch-match-all-query/","content":"Elasticsearch Match all query最简单的查询, 匹配所有文档, 所有文档的相关性得分 _score 为 1.0\nGET /_search&#123;    &quot;query&quot;: &#123;        &quot;match_all&quot;: &#123;&#125;    &#125;&#125;\n\n可以使用 boost 参数修改 _score 的值:\nGET /_search&#123;    &quot;query&quot;: &#123;        &quot;match_all&quot;: &#123;            &quot;boost&quot;: 1.2        &#125;    &#125;&#125;\n\nMatch None Querymatch_all 查询的相反, 不会匹配任何文档\nGET /_search&#123;    &quot;query&quot;: &#123;        &quot;match_none&quot;: &#123;&#125;    &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Query DSL"],"tags":["User Guides","Elasticsearch","Query DSL"]},{"title":"Elasticsearch Query and filter context","url":"/elasticsearch/elasticsearch-guide/query-dsl/elasticsearch-query-and-filter-context/","content":"Elasticsearch Query and filter contextRelevance scores默认情况下, Elasticsearch 根据相关性得分对文档进行排序\nQuery context查询上下文\n回答了这个问题: How well does this document match this query clause\n这个文档有多匹配查询条件\n不仅决定一个文档是否匹配, 还会计算相关性得分\n查询上下文在 query 参数下起作用\nFilter context回答了这个问题: Does this document match this query clause\n一个文档是否匹配查询条件, 不会计算相关性得分\n回答是否的问题\nfilter 参数下起作用, 例如 filter, 或者 bool 中的 must_not, 或者 constant_score 中的 filter, 或者 filter 聚合\nExample of query and filter contextGET /_search&#123;    &quot;query&quot;: &#123;                  // 1        &quot;bool&quot;: &#123;               // 2            &quot;must&quot;: [                &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;search&quot;&#125;&#125;,                &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;Elasticsearch&quot;&#125;&#125;            ],            &quot;filter&quot;: [         // 3                &#123; &quot;term&quot;: &#123; &quot;status&quot;: &quot;publish&quot;&#125;&#125;,                &#123; &quot;range&quot;: &#123; &quot;publish_date&quot;: &#123; &quot;gte&quot;: &quot;2015-01-01&quot;&#125;&#125;&#125;            ]        &#125;    &#125;&#125;\n\n1 : query 参数指明了是 查询上下文 (query context)\n2 : bool 和 两个 match 查询条件用在了查询上下文中, 意味着它们将会被用于计算每一个匹配的文档的相关性得分\n3 : filter 参数指明了是 过滤器上下文 (filter context). term 和 range 查询条件用于过滤器上下文. 它们将会过滤掉不匹配的文档, 不会计算匹配的文档的相关性得分\n参考link\n","categories":["Elasticsearch - User Guides - Query DSL"],"tags":["User Guides","Elasticsearch","Query DSL"]},{"title":"Elasticsearch Query DSL","url":"/elasticsearch/elasticsearch-guide/query-dsl/query-dsl/","content":"Query DSLElasticsearch provides a full Query DSL (Domain Specific Language) based on JSON to define queries\nThink of the Query DSL as an AST (Abstract Syntax Tree) of queries, consisting of two types of clauses:\n\nLeaf query clauses\nCompound query caluses\n\nQuery clauses behave differently depending on whether they are used in query context or filter context\nLeaf query clausesLeaf query clauses look for a particular value in a particular field\nSuch as the match, term or range queries\nThese queries can be used by themselves\n这种查询可以单独使用, 针对指定的字段查询指定的值\nCompound query clausesCompound query clauses wrap other leaf or compound queries and are used to combine multiple queries in a logical fashion (such as the bool or dis_max query)\nor to alter their behaviour (such as the constant_score query).\n复杂查询可以包含叶子或者其他的复杂查询语句, 用于组合成复杂的查询语句, 比如 not,boo 等\n参考link\n","categories":["Elasticsearch - User Guides - Query DSL"],"tags":["User Guides","Elasticsearch","Query DSL"]},{"title":"Elasticsearch Collapse search results","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-collapse-search-results/","content":"Elasticsearch Collapse search results可以通过指定字段来折叠返回的结果, 可以用来进行去重, 有点类似根据指定字段进行分组\n参考link\nlink\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Filter search results","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-filter-search-results/","content":"Elasticsearch Filter search results有两种方法来过滤搜索结果\n\n在 boolean query 中使用 filter 条件. 搜索请求对搜索结果和聚合应用布尔过滤器\n使用搜索 API 中的 post_filter 参数. 搜索请求只对搜索结果应用 post filters. 可以使用一个 post filter来根据更广泛的结果集计算聚合, 然后缩小结果\n\n你还可以在 post filter 后面 rescore 结果来增加相关性和重排序结果\nPost filterGET /shirts/_search&#123;  &quot;query&quot;: &#123;    &quot;bool&quot;: &#123;      &quot;filter&quot;: &#123;        &quot;term&quot;: &#123; &quot;brand&quot;: &quot;gucci&quot; &#125;       &#125;    &#125;  &#125;,  &quot;aggs&quot;: &#123;    &quot;colors&quot;: &#123;      &quot;terms&quot;: &#123; &quot;field&quot;: &quot;color&quot; &#125;     &#125;,    &quot;color_red&quot;: &#123;      &quot;filter&quot;: &#123;        &quot;term&quot;: &#123; &quot;color&quot;: &quot;red&quot; &#125;       &#125;,      &quot;aggs&quot;: &#123;        &quot;models&quot;: &#123;          &quot;terms&quot;: &#123; &quot;field&quot;: &quot;model&quot; &#125;         &#125;      &#125;    &#125;  &#125;,  &quot;post_filter&quot;: &#123;                  // 使用 post_filter    &quot;term&quot;: &#123; &quot;color&quot;: &quot;red&quot; &#125;  &#125;&#125;\n\nRescore filtered search results重新计算得分可以重排序的准确性\nQuery rescorePOST /_search&#123;   &quot;query&quot; : &#123;      &quot;match&quot; : &#123;         &quot;message&quot; : &#123;            &quot;operator&quot; : &quot;or&quot;,            &quot;query&quot; : &quot;the quick brown&quot;         &#125;      &#125;   &#125;,   &quot;rescore&quot; : &#123;                                // 使用 rescore      &quot;window_size&quot; : 50,      &quot;query&quot; : &#123;         &quot;rescore_query&quot; : &#123;            &quot;match_phrase&quot; : &#123;               &quot;message&quot; : &#123;                  &quot;query&quot; : &quot;the quick brown&quot;,                  &quot;slop&quot; : 2               &#125;            &#125;         &#125;,         &quot;query_weight&quot; : 0.7,         &quot;rescore_query_weight&quot; : 1.2      &#125;   &#125;&#125;\n\n每个分片中要被检查的文档数量通过 window_size 参数来控制, 默认为 10\nMultiple rescores执行多个 rescore\nPOST /_search&#123;   &quot;query&quot; : &#123;      &quot;match&quot; : &#123;         &quot;message&quot; : &#123;            &quot;operator&quot; : &quot;or&quot;,            &quot;query&quot; : &quot;the quick brown&quot;         &#125;      &#125;   &#125;,   &quot;rescore&quot; : [ &#123;      &quot;window_size&quot; : 100,      &quot;query&quot; : &#123;         &quot;rescore_query&quot; : &#123;            &quot;match_phrase&quot; : &#123;               &quot;message&quot; : &#123;                  &quot;query&quot; : &quot;the quick brown&quot;,                  &quot;slop&quot; : 2               &#125;            &#125;         &#125;,         &quot;query_weight&quot; : 0.7,         &quot;rescore_query_weight&quot; : 1.2      &#125;   &#125;, &#123;      &quot;window_size&quot; : 10,      &quot;query&quot; : &#123;         &quot;score_mode&quot;: &quot;multiply&quot;,         &quot;rescore_query&quot; : &#123;            &quot;function_score&quot; : &#123;               &quot;script_score&quot;: &#123;                  &quot;script&quot;: &#123;                    &quot;source&quot;: &quot;Math.log10(doc.count.value + 2)&quot;                  &#125;               &#125;            &#125;         &#125;      &#125;   &#125; ]&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Highlighting","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-highlighting/","content":"Elasticsearch Highlighting例如, 为了获取每个搜索命中的 content 字段的默认高亮器, 包含一个 highlight 对象在请求体中来定义 content 字段:\nGET /_search&#123;    &quot;query&quot;: &#123;        &quot;match&quot;: &#123; &quot;content&quot;: &quot;kimchy&quot; &#125;    &#125;,    &quot;highlight&quot;: &#123;        &quot;fields&quot;: &#123;            &quot;content&quot;: &#123;&#125;        &#125;    &#125;&#125;\n\nElasticsearch 支持三种高亮器:\n\nunified\nplain\nfvh (fast vector highlighter)\n\n可以通过指定高亮器的 type 来为每个字段配置想要使用的高亮器\nUnified highlighter将文本拆分成句子, 然后使用 BM25 算法单独计算每个句子的评分, 就像它们是语料库中的文档一样\n默认的高亮器\nPlain highlighter它试图从理解词的重要性和短语查询中的任何词的定位标准方面反映查询匹配逻辑\nplain 高亮器最适合高亮单个字段中的简单查询匹配\nFast vector highlighter这个高亮器可以用在配置了 with_positions_offsets 的 term_vector 类型字段上\nOffsets strategy要从查询的术语创建有意义的搜索片段，高亮器显示需要知道原始文本中每个单词的开始和结束字符偏移量\n这些偏移量可以从这些地方获取:\n\nThe postings list\nTerm vectors\nPlain highlighting\n\nHighlight examples\nOverride global settings\nSpecify a highlight query\nSet highlighter type\nConfigure highlighting tags\nHighlight source\nHighlight all fields\nCombine matches on multiple fields\nExplicitly order highlighted fields\nControl highlighted fragments\nHighlight using the postings list\nSpecify a fragmenter for the plain highlighter\n\n参考link\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Long-running searches","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-long-running-searches/","content":"Elasticsearch Long-running searches异步搜索让你提交一个异步执行的搜索请求, 监控请求的执行进度, 然后在稍后获取结果\n你还可以在搜索执行结束之前获取部分已经可用的结果\n可以使用 submit async search API 来提交一个异步搜索请求\n使用 get async search API 来监听一个异步搜索请求的进度并获取它的结果\n一个执行中的异步请求可以通过 delete async search API 来进行删除\n参考link\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Near real-time search","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-near-real-time-search/","content":"Elasticsearch Near real-time search文档的修改不会马上对搜索可见, 但是将会在时间窗口之后变得可见\n参考link\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Paginate search results","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-paginate-search-results/","content":"Elasticsearch Paginate search results搜索许多的也或大量的结果, 将会显著增加内存和 CPU 的使用, 导致性能问题或节点崩溃. 原理类似 MySQL\n默认情况下, 你不能使用 from 和 size 参数去分页查询超过 10000 个命中结果\n这个限制是一个由 index.max_result_window 索引配置设置的保护措施\n如果你需要分页查询超过 10000 命中结果, 使用 search_after 参数\nSearch after你可以通过使用一组上一个分页中的排序值来使用 search_after 参数去获取下一页的结果\n使用 search_after 要求多个搜索请求有相同的 query 和 sort 值\n如果一个刷新发生在两个分页查询中, 你的结果的顺序可能会该表, 导致不同页中的结果不连续\n为了防止这种情况, 你可以创建一个 point in time (PIT) 来在你的搜索中保护当前索引状态: POST /my-index/_pit?keep_alive=1m, 这样将会返回:\n&#123;    &quot;id&quot;: &quot;46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA&quot;&#125;\n\n这是一个 PID\n为了获取第一页的结果, 提交一个使用 sort 参数的搜索请求\n如果使用一个 PIT , 通过 pit.id 参数来指定 PID 值且省去请求路径中的目标数据流或索引\nExampleGET /_search&#123;  &quot;size&quot;: 10000,  &quot;query&quot;: &#123;    &quot;match&quot; : &#123;      &quot;user.id&quot; : &quot;elkbee&quot;    &#125;  &#125;,  &quot;pit&quot;: &#123;    &quot;id&quot;:  &quot;46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==&quot;,      // 1    &quot;keep_alive&quot;: &quot;1m&quot;  &#125;,  &quot;sort&quot;: [                             // 2    &#123;&quot;@timestamp&quot;: &#123;&quot;order&quot;: &quot;asc&quot;, &quot;format&quot;: &quot;strict_date_optional_time_nanos&quot;&#125;&#125;,    &#123;&quot;_shard_doc&quot;: &quot;desc&quot;&#125;  ]&#125;\n\n1 : PIT ID for the search\n2 : Sorts hits for the search with an explicit tiebreak on _shard_doc descending\n返回:\n&#123;  &quot;pit_id&quot; : &quot;46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==&quot;,        // 1  &quot;took&quot; : 17,  &quot;timed_out&quot; : false,  &quot;_shards&quot; : ...,  &quot;hits&quot; : &#123;    &quot;total&quot; : ...,    &quot;max_score&quot; : null,    &quot;hits&quot; : [      ...      &#123;        &quot;_index&quot; : &quot;my-index-000001&quot;,        &quot;_id&quot; : &quot;FaslK3QBySSL_rrj9zM5&quot;,        &quot;_score&quot; : null,        &quot;_source&quot; : ...,        &quot;sort&quot; : [                                // 2          &quot;2021-05-20T05:30:04.832Z&quot;,          4294967298                              // 3        ]      &#125;    ]  &#125;&#125;\n\n1 : Updated id for the point in time.\n2 : Sort values for the last returned hit\n3 : The tieBreaker value, unique per document within the pid_id\nTo get the next page of resultsrerun the previous search using the last hit’s sort values (including the tiebreaker) as the search_after argument\nIf using a PIT, use the latest PIT ID in the pit.id parameter\nThe search’s query and sort arguments must remain unchanged\nIf provided, the from argument must be 0 (default) or -1\nGET /_search&#123;  &quot;size&quot;: 10000,  &quot;query&quot;: &#123;    &quot;match&quot; : &#123;      &quot;user.id&quot; : &quot;elkbee&quot;    &#125;  &#125;,  &quot;pit&quot;: &#123;    &quot;id&quot;:  &quot;46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==&quot;,  // 1    &quot;keep_alive&quot;: &quot;1m&quot;  &#125;,  &quot;sort&quot;: [    &#123;&quot;@timestamp&quot;: &#123;&quot;order&quot;: &quot;asc&quot;, &quot;format&quot;: &quot;strict_date_optional_time_nanos&quot;&#125;&#125;  ],  &quot;search_after&quot;: [                                // 2    &quot;2021-05-20T05:30:04.832Z&quot;,    4294967298  ],  &quot;track_total_hits&quot;: false                        // 3&#125;\n\n1 : PIT ID returned by the previous search\n2 : Sort values from the previous search’s hit\n3 : Disable the tracking of total hits to speed up pagination\nYou can repeat this process to get additional pages of results\nIf using a PIT, you can extend the PIT’s retention period using the keep_alive parameter of each search request\nWhen you’re finished, you should delete your PIT:\nDELETE /_pit&#123;    &quot;id&quot;: &quot;46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA&quot;&#125;\n\nScroll search results不推荐使用\n参考link\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Retrieve inner hits","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-retrieve-inner-hits/","content":"Elasticsearch Retrieve inner hits主要用于 parent-join 和 nested 特性\n返回嵌套的匹配记录\ninner hits (内部命中) 还支持如下每文档特性:\n\nHighlighting\nExplain\nSearch fields\nSource filtering\nScript fields\nDoc value fields\nInclude versions\nInclude Sequence Numbers and Primary Terms\n\n参考link\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Retrieve selected fields from a search","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-retrieve-selected-fields-from-a-search/","content":"Elasticsearch Retrieve selected fields from a search推荐使用 fields option 和 _source option 来获取指定字段\nfields 选项在请求中使用 fields 来指定字段\nPOST my-index-000001/_search&#123;  &quot;query&quot;: &#123;    &quot;match&quot;: &#123;      &quot;user.id&quot;: &quot;kimchy&quot;    &#125;  &#125;,  &quot;fields&quot;: [    &quot;user.id&quot;,    &quot;http.response.*&quot;,             &#123;      &quot;field&quot;: &quot;@timestamp&quot;,      &quot;format&quot;: &quot;epoch_millis&quot;     &#125;  ],  &quot;_source&quot;: false&#125;\n\n请求的响应永远返回指定的字段的数组, 其中包含查询出来的字段\n可以通过路径导航获取内嵌字段:\nPOST my-index/_search&#123;    &quot;fields&quot;: [&quot;user.first&quot;],    &quot;_source&quot;: false&#125;\n\n可以通过 include_unmapped 选项从 _source 中获取不映射的字段\n可以获取诸如 _id 和 _index 的元数据字段\n使用 _source 字段从 _source 中获取指定的数据:\nGET /_search&#123;  &quot;_source&quot;: [ &quot;obj1.*&quot;, &quot;obj2.*&quot; ],  &quot;query&quot;: &#123;    &quot;match&quot;: &#123;      &quot;user.id&quot;: &quot;kimchy&quot;    &#125;  &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Search across clusters","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-search-across-clusters/","content":"Elasticsearch Search across clusters跨集群搜索让你可以在一个或多个远程集群上运行一个搜索请求\n支持的 APIs\n\nSearch\nAsync search\nMulti search\nSearch template\nMulti search template\nField capabilities\nSQL search\nEQL search\nVector tile search\n\n参考link\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Search multiple data streams and indices","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-search-multiple-data-streams-and-indices/","content":"Elasticsearch Search multiple data streams and indices搜索多个数据流和分片, 在 Search API 的请求路径中使用逗号分隔的值\nExample - 搜索 my-index-01 和 my-index-02 两个分片:\nGET /my-index-01,my-index-02/_search&#123;    &quot;query&quot;: &#123;        &quot;match&quot;: &#123;            &quot;user.id&quot;: &quot;kimchy&quot;        &#125;    &#125;&#125;\n\n可以使用类似 my-index-* 的模式来搜索任何匹配的数据流或分片:\nGET /my-index-*/_search&#123;    &quot;query&quot;: &#123;        &quot;match&quot;: &#123;            &quot;user.id&quot;: &quot;kimchy&quot;        &#125;    &#125;&#125;\n\n搜索集群中所有的数据流和分片:\nGET /_search&#123;    &quot;query&quot;: &#123;        &quot;match&quot;: &#123;            &quot;user.id&quot;: &quot;kimchy&quot;        &#125;    &#125;&#125;GET /_all/_search&#123;    &quot;query&quot;: &#123;        &quot;match&quot;: &#123;            &quot;user.id&quot;: &quot;kimchy&quot;        &#125;    &#125;&#125;GET /*/_search&#123;    &quot;query&quot;: &#123;        &quot;match&quot;: &#123;            &quot;user.id&quot;: &quot;kimchy&quot;        &#125;    &#125;&#125;\n\nIndex boost当搜索多个分片时, 你可以使用 indices_boost 参数来提升整个索引的权重:\nGET /_search&#123;    &quot;indices_boost&quot;: [        &#123; &quot;my-index-000001&quot;: 1.4 &#125;,        &#123; &quot;my-index-000002&quot;: 1.3 &#125;    ]&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Search shard routing","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-search-shard-routing/","content":"Elasticsearch Search shard routing运行一个搜索请求时, Elasticsearch 选择一个包含分片数据的节点来处理请求\nAdaptive replica selection默认情况下, Elasticsearch 使用 自适应分片选择 来路由搜索请求\n通过如下规则:\n\n响应时间\n运行搜索花费的时间\n搜索线程池长度\n\n通过在 Cluster settings API 中设置 cluster.routing.use_adaptive_replica_selection=false 来关闭 自适应分片选择\nSet a preference发送请求到指定的节点\n在搜索请求 API 中使用 preference 请求参数来指定:\nGET /my-index-01/_search?preference=_local&#123;    &quot;query&quot;: &#123;        &quot;match&quot;: &#123;            &quot;user.id&quot;: &quot;kimchy&quot;        &#125;    &#125;&#125;\n\n_local : 将请求发送到本地的节点\n可以传递一个自定义的字符串给 preference 参数来作为路由值, 固定使用这个值可以使得多次请求可以路由到相同的地方\n这个字符串不能以 _ 开头\n可以用固定路由值来使得结果可以缓存\nUse a routing value通过指定 routing 参数值来将一个文档索引到指定的分片上:\nPOST /my-index/_doc?routing=my-routing-value&#123;  &quot;@timestamp&quot;: &quot;2099-11-15T13:12:00&quot;,  &quot;message&quot;: &quot;GET /search HTTP/1.1 200 1070000&quot;,  &quot;user&quot;: &#123;    &quot;id&quot;: &quot;kimchy&quot;  &#125;&#125;\n\n可以在搜索请求中使用同样的 routing 参数值, 使得可以在同一个分片上进行搜索:\nGET /my-index/_search?routing=my-routing-value&#123;    &quot;query&quot;: &#123;        &quot;match&quot;: &#123;            &quot;user.id&quot;: &quot;kimchy&quot;        &#125;    &#125;&#125;\n\nrouting 可以使用逗号分隔来指定多个值\nSearch concurrency and parallelism使用 max_concurrent_shard_requests 请求参数来控制一个节点上面最多有多少个同步运行搜索的分片. 这个参数值默认为 5\nGET /my-index/_search?max_concurrent_shard_requests=3&#123;    &quot;query&quot;: &#123;        &quot;match&quot;: &#123;            &quot;user.id&quot;: &quot;kimchy&quot;        &#125;    &#125;&#125;\n\n可以使用 action.search.shard_count.limit 参数来在 Cluster settings API 中配置最大请求分片数\n参考link\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Search templates","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-search-templates/","content":"Elasticsearch Search templates一个 Search template 是一个你可以使用不同参数来运行的存储起来的搜索\nSearch template 为上层隐藏了 Elasticsearch 的语法\nSearch template 可以避免修改程序代码来改变搜索\nCreate a search template使用 Create stored script API 来创建或更新一个 Search template\n创建一个 id 为 my-search-template 的 Search template:\nPUT _scripts/my-search-template&#123;    &quot;script&quot;: &#123;        &quot;lang&quot;: &quot;mustache&quot;,        &quot;source&quot;: &#123;            &quot;query&quot;: &#123;                &quot;match&quot;: &#123;                    &quot;message&quot;: &quot;&#123;&#123;query_string&#125;&#125;&quot;                &#125;            &#125;,            &quot;from&quot;: &quot;&#123;&#123;from&#125;&#125;&quot;,            &quot;size&quot;: &quot;&#123;&#123;size&#125;&#125;&quot;        &#125;,        &quot;params&quot;: &#123;            &quot;query_string&quot;: &quot;My query string&quot;        &#125;    &#125;&#125;\n\nValidate a search template使用 Render search template API 来使用不同参数测试一个模板:\nPOST _render/template&#123;    &quot;id&quot;: &quot;my-search-template&quot;,    &quot;params&quot;: &#123;        &quot;query_string&quot;: &quot;hello world&quot;,        &quot;from&quot;: 20,        &quot;size&quot;: 10    &#125;&#125;\n\n将会一个搜索请求体:\n&#123;  &quot;template_output&quot;: &#123;    &quot;query&quot;: &#123;      &quot;match&quot;: &#123;        &quot;message&quot;: &quot;hello world&quot;      &#125;    &#125;,    &quot;from&quot;: &quot;20&quot;,    &quot;size&quot;: &quot;10&quot;  &#125;&#125;\n\n还可以在 Render API 中使用内嵌的 Search template\nRun a templated search通过 Search template API 运行一个搜索模板\n可以在每个请求中指定不同的 params 参数\nGET my-index/_search/template&#123;    &quot;id&quot;: &quot;my-search-template&quot;,    &quot;params&quot;: &#123;        &quot;query_string&quot;: &quot;hello world&quot;,        &quot;from&quot;: 0,        &quot;size&quot;: 10    &#125;&#125;\n\nRun multiple templated searches使用 Multi search template API 来在同一个请求中运行多个模板搜索:\nGET my-index/_msearch/template&#123; &#125;&#123; &quot;id&quot;: &quot;my-search-template&quot;, &quot;params&quot;: &#123; &quot;query_string&quot;: &quot;hello world&quot;, &quot;from&quot;: 0, &quot;size&quot;: 10 &#125;&#125;&#123; &#125;&#123; &quot;id&quot;: &quot;my-other-search-template&quot;, &quot;params&quot;: &#123; &quot;query_type&quot;: &quot;match_all&quot; &#125;&#125;\n\nGet search templatesGET _scripts/my-search-template\n获取多个搜索模板: GET _cluster/state/metadata?pretty&amp;filter_path=metadata.stored_scripts\nDelete a search templateDELETE _scripts/my-search-template\nSet default values使用如下语法设置参数默认值:\n&#123;&#123;my-var&#125;&#125;&#123;&#123;^my-var&#125;&#125;default value&#123;&#123;/my-var&#125;&#125;\n\nPOST _render/template&#123;  &quot;source&quot;: &#123;    &quot;query&quot;: &#123;      &quot;match&quot;: &#123;        &quot;message&quot;: &quot;&#123;&#123;query_string&#125;&#125;&quot;      &#125;    &#125;,    &quot;from&quot;: &quot;&#123;&#123;from&#125;&#125;&#123;&#123;^from&#125;&#125;0&#123;&#123;/from&#125;&#125;&quot;,    &quot;size&quot;: &quot;&#123;&#123;size&#125;&#125;&#123;&#123;^size&#125;&#125;10&#123;&#123;/size&#125;&#125;&quot;  &#125;,  &quot;params&quot;: &#123;    &quot;query_string&quot;: &quot;hello world&quot;  &#125;&#125;\n\nURL encode strings使用 &#123;&#123;#url&#125;&#125; 函数来进行 URL 编码:\nPOST _render/template&#123;  &quot;source&quot;: &#123;    &quot;query&quot;: &#123;      &quot;term&quot;: &#123;        &quot;url.full&quot;: &quot;&#123;&#123;#url&#125;&#125;&#123;&#123;host&#125;&#125;/&#123;&#123;page&#125;&#125;&#123;&#123;/url&#125;&#125;&quot;      &#125;    &#125;  &#125;,  &quot;params&quot;: &#123;    &quot;host&quot;: &quot;http://example.com&quot;,    &quot;page&quot;: &quot;hello-world&quot;  &#125;&#125;\n\nConcatenate values使用 &#123;&#123;#join&#125;&#125; 函数来将一个数组连接成逗号分隔的字符串\nPOST _render/template&#123;  &quot;source&quot;: &#123;    &quot;query&quot;: &#123;      &quot;match&quot;: &#123;        &quot;user.group.emails&quot;: &quot;&#123;&#123;#join&#125;&#125;emails&#123;&#123;/join&#125;&#125;&quot;      &#125;    &#125;  &#125;,  &quot;params&quot;: &#123;    &quot;emails&quot;: [ &quot;user1@example.com&quot;, &quot;user_one@example.com&quot; ]  &#125;&#125;\n\n还可以指定分隔符: &#123;&#123;#join delimiter='||'&#125;&#125;date.formats&#123;&#123;/join delimiter='||'&#125;&#125;\nConvert to JSON使用 &#123;&#123;#json&#125;&#125; 函数来将一个变量值转换成 JSON 的形式\nUse conditions使用 &#123;&#123;#condition&#125;&#125;content&#123;&#123;/condition&#125;&#125; 来进行条件判断\n只有当变量 condition 为 true 时, content 才会被显示\n参考link\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Search your data","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-search-your-data/","content":"\n\n\nElasticsearch Search your data\nDefine fields that exist only in a query\nCommon search options\nQuery DSL\nAggregations\nSearch multiple data streams and indices\nPaginate search results\nRetrieve selected fields\nSort search results\nRun an async search\n\n\nSearch timeout\nSearch cancellation\nTrack total hits\nQuick check for matching docs\n参考\n\n\n\n\n\nElasticsearch Search your dataDefine fields that exist only in a query除了索引数据然后搜索数据, 还可以定义只作为搜索请求的一部分存在的 runtime fields\n你可以在你的搜索请求中定义一个 runtime_mappings 块来定义 runtime field, runtime field 可选地包含一个 Painless 脚本\nGET /my-index/_search&#123;    &quot;runtime_mappings&quot;: &#123;        &quot;day_of_week&quot;: &#123;            &quot;type&quot;: &quot;keyword&quot;,            &quot;script&quot;: &#123;                &quot;source&quot;:                &quot;&quot;&quot;emit(doc[&#x27;@timestamp&#x27;].value.dayOfWeekEnum.getDisplayName(TextStyle.FULL, Locale.ROOT))&quot;&quot;&quot;            &#125;        &#125;    &#125;,    &quot;aggs&quot;: &#123;        &quot;day_of_week&quot;: &#123;            &quot;terms&quot;: &#123;                &quot;field&quot;: &quot;day_of_week&quot;      // 可以在 runtime field 上进行 terms aggregation            &#125;        &#125;    &#125;&#125;\n\nCommon search options可以使用如下选项来自定义搜索\nQuery DSLQuery DSL 支持各种各样的可以用来混合和匹配你想要的结果的查询类型\nQuery 类型包括:\n\nBoolean 和其他复合查询, 让你可以组合查询和基于多个条件匹配查询结果\nTerm-level queries 用来过滤和查找准确匹配\nFull text queries 搜索引擎中常用的全文搜索\n地理位置和空间的查询\n\nAggregations可以使用 search aggregations(搜索聚合) 在你的搜索结果上获取统计数据和其他分析数据\n聚合可以帮助你回答类似这样的问题:\n\n服务器的平均响应时间\n网络上访问量最大的 IP 地址是哪个\n按客户计算的总交易收入是多少\n\nSearch multiple data streams and indices可以在同一个请求中使用逗号分隔的值或索引匹配符来搜索多个数据流和索引\n还可以通过指定索引来加速搜索结果\nPaginate search results默认情况下, 搜索只返回前十个匹配的值\n为了获得更多或更少的文档, 可使用分页查询\nRetrieve selected fields获取指定要获取的字段\nSort search results默认情况下, 搜索结果通过 _score 进行排序, 一个相关性得分用来衡量每个文档与搜索有多相关\n自定义计算的结果, 可以使用 script_score 查询\n可以对结果使用指定的字段值进行排序\nRun an async search一个 async search 让你可以在一个长时间运行的查询上马上获取部分结果和在稍后获取完整的结果\nSearch timeout默认情况下, 搜索请求不会超时. 请求会在返回响应前等待每个分片上完整的结果\n因为 async search 被设计用来进行长时间运行的搜索, 你通过 timeout 参数来指定一个你想等待每个分片完成搜索的时间\n每个分片在指定的时间范围内收集匹配的结果\n如果收集没有在时间范围内完成, Elasticsearch 将会只收集在那时候已经匹配的结果\nGET /my-index/_search&#123;    &quot;timeout&quot;: &quot;2s&quot;,    &quot;query&quot;: &#123;        &quot;match&quot;: &#123;            &quot;user.id&quot;: &quot;kimchy&quot;        &#125;    &#125;&#125;\n\n在 cluster settings API 中使用 search.default_search_timeout 来为所有搜索请求配置一个集群级别的默认超时时间\n这个全局超时时间配置将会在每个请求中 timeout 参数没有配置的时候生效\n如果一个请求超过了全局超时时间配置, 那么这个请求将会使用 task cancellation 来进行取消\nsearch.default_search_timeout 默认设置为 -1 (没有限制)\nSearch cancellation你可以使用 task management API 来取消一个搜索请求\nElasticsearch 也会在你的客户端 HTTP 连接关闭时取消一个搜索请求\n建议在一个搜索请求被拒接或超时的时候关闭客户端上的 HTTP 连接\nTrack total hits通常, 在不访问所有匹配结果的情况下无法准确计算总命中数, 因为这对于匹配大量文档的查询来说代价很高\ntrack_total_hits 参数允许你控制总共多少个命中结果应该被跟踪\n考虑到通常有一个点击次数的下限就足够了, 比如 “至少10000次点击”, 默认设置为 10000\n这意味着请求将准确计算总命中数, 最多到 10000\n如果在某个阈值之后不需要准确的点击率, 那么这是一个很好的权衡去加速搜索\ntrack_total_hits 设置为 true 将会告诉 Elasticsearch 计算准确的命中记录数, 同时返回的 total.relation 将会为 eq\nGET my-index/_search&#123;    &quot;track_total_hits&quot;: true,    &quot;query&quot;: &#123;        &quot;match&quot;: &#123;            &quot;user.id&quot;: &quot;elkbee&quot;        &#125;    &#125;&#125;\n\n将 track_total_hits 设置为一个整数, Elasticsearch 将会最多计算准确的数量到这个参数配置的值\n如果匹配的值大于这个参数配置的整数, 那么 relation 将会为 gte\n&#123;  &quot;_shards&quot;: ...  &quot;hits&quot;: &#123;    &quot;max_score&quot;: 1.0,    &quot;total&quot;: &#123;      &quot;value&quot;: 100,               &quot;relation&quot;: &quot;gte&quot;         &#125;,    &quot;hits&quot;: ...  &#125;&#125;\n\n如果不想跟踪命中数, 那么可以将 track_total_hits 设置为 false\nQuick check for matching docs如果你只是想知道是否有文档匹配一个指定查询, 你可以设置 size=0来指明我们对返回的结果没有兴趣\n还可以设置 terminate_after=1 来指明查询可以在每个分片上第一个匹配的文档找到后任何时候进行中断\nterminate_after 总是在后置过滤之后应用, 并在分片上收集到足够的命中时停止查询和聚合\n文档数量在聚合中可能无法反映命中数, 因为聚合是在后置过滤之前进行的\n由于 size=0 所以请求的相应将不会包含任何命中文档\nhits.total=0 意味着没有匹配的文档\nhits.total 大于 0 意味着在请求中断前有至少这么多匹配的文档\n如果请求被提前中断, 那么 terminated_early 将会被设置为 true\n&#123;  &quot;took&quot;: 3,  &quot;timed_out&quot;: false,  &quot;terminated_early&quot;: true,  &quot;_shards&quot;: &#123;    &quot;total&quot;: 1,    &quot;successful&quot;: 1,    &quot;skipped&quot; : 0,    &quot;failed&quot;: 0  &#125;,  &quot;hits&quot;: &#123;    &quot;total&quot; : &#123;        &quot;value&quot;: 1,        &quot;relation&quot;: &quot;eq&quot;    &#125;,    &quot;max_score&quot;: null,    &quot;hits&quot;: []  &#125;&#125;\n\n响应体中的 time 时间是一个毫秒值, 说明这个用来处理这个请求的时间\n从节点接收到这个请求开始, 直到所有请求相关的工作结束, 在响应体 JSON 返回给客户端的这段时间\n这意味着 time 包括了请求在线程池中等待的时间, 执行一个跨越整个集群的分布式搜索和获取所有结果的时间\n参考link\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Sort search results","url":"/elasticsearch/elasticsearch-guide/search-your-data/elasticsearch-sort-search-results/","content":"Elasticsearch Sort search results排序是定义在字段级别上的\nSort mode Option可以根据如下 mode 选项来控制排序\n\nmin\nmax\nsum\navg\nmedian\n\n默认的 mode 是 min\n在 DESC 排序中默认的 mode 是 max\nExample:\nPOST /_search&#123;   &quot;query&quot; : &#123;      &quot;term&quot; : &#123; &quot;product&quot; : &quot;chocolate&quot; &#125;   &#125;,   &quot;sort&quot; : [      &#123;&quot;price&quot; : &#123;&quot;order&quot; : &quot;asc&quot;, &quot;mode&quot; : &quot;avg&quot;&#125;&#125;   ]&#125;\n\nSorting numeric fields可以使用 numeric_type 来指定被排序的字段转换成的类型, 可用于跨索引搜索中, 不同类型字段的排序, 将不同类型的字段转换成相同类型的字段\nPOST /index_long,index_double/_search&#123;   &quot;sort&quot; : [      &#123;        &quot;field&quot; : &#123;            &quot;numeric_type&quot; : &quot;double&quot;        &#125;      &#125;   ]&#125;\n\nSorting within nested objectsElasticsearch 支持在内嵌对象的字段上进行排序\nPOST /_search&#123;   &quot;query&quot; : &#123;      &quot;term&quot; : &#123; &quot;product&quot; : &quot;chocolate&quot; &#125;   &#125;,   &quot;sort&quot; : [       &#123;          &quot;offer.price&quot; : &#123;             &quot;mode&quot; :  &quot;avg&quot;,             &quot;order&quot; : &quot;asc&quot;,             &quot;nested&quot;: &#123;                &quot;path&quot;: &quot;offer&quot;,                &quot;filter&quot;: &#123;                   &quot;term&quot; : &#123; &quot;offer.color&quot; : &quot;blue&quot; &#125;                &#125;             &#125;          &#125;       &#125;    ]&#125;\n\nMissing Values通过 missing 参数来指定一个字段没有排序值时处理方式\n可以设置为 _last 或 _first , 或者一个自定义值\n默认是 _last\nGET /_search&#123;  &quot;sort&quot; : [    &#123; &quot;price&quot; : &#123;&quot;missing&quot; : &quot;_last&quot;&#125; &#125;  ],  &quot;query&quot; : &#123;    &quot;term&quot; : &#123; &quot;product&quot; : &quot;chocolate&quot; &#125;  &#125;&#125;\n\nIgnoring Unmapped Fields排序没有 mapping 的字段, 让 Elasticsearch 怎样去处理\nGET /_search&#123;    &quot;sort&quot;: [        &#123;            &quot;price&quot; : &#123;                &quot;unmapped_type&quot;: &quot;long&quot;            &#125;        &#125;    ],    &quot;query&quot;: &#123;        &quot;term&quot;: &#123;            &quot;user&quot;: &quot;kimchy&quot;        &#125;    &#125;&#125;\n\nElasticsearch 会自动创建一个 type 为 long 的 field price\nGeo Distance Sorting可以使用 _geo_distance 对 geo_point 类型字段进行排序\nGET /_search&#123;  &quot;sort&quot; : [    &#123;      &quot;_geo_distance&quot; : &#123;          &quot;pin.location&quot; : [-70, 40],          &quot;order&quot; : &quot;asc&quot;,          &quot;unit&quot; : &quot;km&quot;,          &quot;mode&quot; : &quot;min&quot;,          &quot;distance_type&quot; : &quot;arc&quot;,          &quot;ignore_unmapped&quot;: true      &#125;    &#125;  ],  &quot;query&quot; : &#123;    &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;  &#125;&#125;\n\nMultiple reference points通过一个包含多个 geo_format 的位置数组进行排序\nGET /_search&#123;  &quot;sort&quot;: [    &#123;      &quot;_geo_distance&quot;: &#123;        &quot;pin.location&quot;: [ [ -70, 40 ], [ -71, 42 ] ],        &quot;order&quot;: &quot;asc&quot;,        &quot;unit&quot;: &quot;km&quot;      &#125;    &#125;  ],  &quot;query&quot;: &#123;    &quot;term&quot;: &#123; &quot;user&quot;: &quot;kimchy&quot; &#125;  &#125;&#125;\n\nScript Based Sorting通知自定义的脚本来指定排序规则\nGET /_search&#123;    &quot;query&quot;: &#123;        &quot;term&quot;: &#123; &quot;user&quot;: &quot;kimchy&quot;&#125;    &#125;,    &quot;sort&quot;: &#123;        &quot;_search&quot; : &#123;            &quot;type&quot;: &quot;number&quot;,            &quot;script&quot;: &#123;                &quot;lang&quot;: &quot;painless&quot;,                &quot;source&quot;: &quot;doc[&#x27;field_name&#x27;].value * params.factor&quot;,                &quot;params&quot;: &#123;                    &quot;factor&quot;: 1.1                &#125;            &#125;,            &quot;order&quot;: &quot;asc&quot;        &#125;    &#125;&#125;\n\nTrack Scores通过 track_scores 来指定要在排序时进行得分计算和跟踪\nGET /_search&#123;  &quot;track_scores&quot;: true,  &quot;sort&quot; : [    &#123; &quot;post_date&quot; : &#123;&quot;order&quot; : &quot;desc&quot;&#125; &#125;,    &#123; &quot;name&quot; : &quot;desc&quot; &#125;,    &#123; &quot;age&quot; : &quot;desc&quot; &#125;  ],  &quot;query&quot; : &#123;    &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;  &#125;&#125;\n\nMemory Considerations排序时, 相关的排序字段值会被存储到内存中\n对于字符串类型的排序, 排序的字段不应该是分词的\n对于数值类型的排序, 最好明确使用狭窄的类型 short,integer,float\n参考link\n","categories":["Elasticsearch - User Guides - Search your data"],"tags":["User Guides","Elasticsearch","Search your data"]},{"title":"Elasticsearch Anatomy of an analyzer","url":"/elasticsearch/elasticsearch-guide/text-analysis/elasticsearch-anatomy-of-an-analyzer/","content":"Elasticsearch Anatomy of an analyzer分析器解析, 一个分析器包含如下东西\nCharacter filters : 可以有 0 个或多个, 会修改字符流, 将字符进行转换, 例如将拉丁文数字转换为阿拉伯数字\nTokenizer : 有且只能有一个, 进行分词操作\nToken filters : 可以有 0 个或多个, 会修改字符流, 进行例如小写转换, 删除停用词, 同义词转换等操作\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis"],"tags":["User Guides","Elasticsearch","Text analysis"]},{"title":"Elasticsearch Built-in analyzer reference","url":"/elasticsearch/elasticsearch-guide/text-analysis/elasticsearch-built-in-analyzer-reference/","content":"Elasticsearch Built-in analyzer referenceElasticsearch 有如下内建的分析器:\n\nStandard Analyzer : 使用 Unicode Text Segmentation algorithm 来进行分词. 删除大多数标点符号, 小写单词, 并支持删除停用词\nSimple Analyzer : 当遇到一个字符不是字母的时候进行分词. 会进行小写转换\nWhitespace Analyzer : 当遇到空格符时进行分词. 不进行小写转换\nStop Analyzer : 和 Simple Analyzer 一样, 但是会删除停用词\nKeyword Analyzer : 不会进行任何操作\nPattern Analyzer : 使用指定的正则表达式进行分词. 支持小写转换和停用词\nLanguage Analyzer : 指定语言的分析器. 例如 english,french\nFingerprint Analyzer : 创建指纹来进行重复性检测\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis"],"tags":["User Guides","Elasticsearch","Text analysis"]},{"title":"Elasticsearch built-in analyzers","url":"/elasticsearch/elasticsearch-guide/text-analysis/elasticsearch-built-in-analyzers/","content":"Elasticsearch built-in analyzers可以对内建的分析器进行参数配置\nPUT my-index-000001&#123;  &quot;settings&quot;: &#123;    &quot;analysis&quot;: &#123;      &quot;analyzer&quot;: &#123;        &quot;std_english&quot;: &#123;           &quot;type&quot;:      &quot;standard&quot;,          &quot;stopwords&quot;: &quot;_english_&quot;      // 配置 standard 分析器的停用词为 _english_        &#125;      &#125;    &#125;  &#125;,  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;my_text&quot;: &#123;        &quot;type&quot;:     &quot;text&quot;,        &quot;analyzer&quot;: &quot;standard&quot;,         &quot;fields&quot;: &#123;          &quot;english&quot;: &#123;            &quot;type&quot;:     &quot;text&quot;,            &quot;analyzer&quot;: &quot;std_english&quot;           &#125;        &#125;      &#125;    &#125;  &#125;&#125;POST my-index-000001/_analyze&#123;  &quot;field&quot;: &quot;my_text&quot;,   &quot;text&quot;: &quot;The old brown cow&quot;&#125;POST my-index-000001/_analyze&#123;  &quot;field&quot;: &quot;my_text.english&quot;,   &quot;text&quot;: &quot;The old brown cow&quot;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis"],"tags":["User Guides","Elasticsearch","Text analysis"]},{"title":"Elasticsearch Create a custom analyzer","url":"/elasticsearch/elasticsearch-guide/text-analysis/elasticsearch-create-a-custom-analyzer/","content":"Elasticsearch Create a custom analyzer创建自定义的分析器\n必须包含如下组成部分:\n\n0 个或多个字符过滤器\n一个分词器\n0 个或多个分词过滤器\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis"],"tags":["User Guides","Elasticsearch","Text analysis"]},{"title":"Elasticsearch Index and search analysis","url":"/elasticsearch/elasticsearch-guide/text-analysis/elasticsearch-index-and-search-analysis/","content":"Elasticsearch Index and search analysis文本分析发生在对于一个 text 字段的 索引阶段 和 搜索阶段\n索引阶段The QUICK brown foxes jumped over the dog! -&gt; [ quick, brown, fox, jump, over, dog ]\n经过小写转换, 删除停用词, 同义词转换等操作\n搜索阶段Quick fox -&gt; [ quick, fox ]\n使用和索引阶段相同的分析器, 经过小写转换, 删除停用词, 同义词转换等操作\n索引阶段和搜索阶段使用不同的分析器在有些情况下需要在两个阶段使用不同的分析器\n例如, 需要对单词进行前缀匹配\n索引阶段Apple -&gt; [ a, ap, app, appl, apple]\n搜索阶段使用相同的分析器appli -&gt; [ a, ap, app, appl, appli ]\n预期是匹配 appli 开头的结果, 但是却错误地匹配到 Apple\n搜索阶段使用不同的分析器appli -&gt; [ appli ]\n分词后还是保持 appli 单词, 因此可以匹配到 appli 开头的结果\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis"],"tags":["User Guides","Elasticsearch","Text analysis"]},{"title":"Elasticsearch Normalizers","url":"/elasticsearch/elasticsearch-guide/text-analysis/elasticsearch-normalizers/","content":"Elasticsearch Normalizers规范化器, 用来将分词进行统一化处理, 例如同一进行小写转换\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis"],"tags":["User Guides","Elasticsearch","Text analysis"]},{"title":"Elasticsearch Specify an analyzer","url":"/elasticsearch/elasticsearch-guide/text-analysis/elasticsearch-specify-an-analyzer/","content":"Elasticsearch Specify an analyzer可以通过多种方式来指定某个分析器\nHow Elasticsearch determine the index analyzer\n字段的 analyzer 映射参数\n索引配置参数 analysis.analyzer.default\n\n如果上面两个都没有配置, 就使用 standard analyzer 分析器\nSpecify the analyzer for a field可以在创建索引时, 给 text 类型字段指定要使用的分析器\nPUT my-index-00000001&#123;    &quot;mappings&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;title&quot;: &#123;                &quot;type&quot;: &quot;text&quot;,                &quot;analyzer&quot;: &quot;whitespace&quot;            &#125;        &#125;    &#125;&#125;\n\nSpecify the default analyzer for an index使用 analysis.analyzer.default 配置参数来为索引设置默认的分析器\nPUT my-index-000001&#123;  &quot;settings&quot;: &#123;    &quot;analysis&quot;: &#123;      &quot;analyzer&quot;: &#123;        &quot;default&quot;: &#123;          &quot;type&quot;: &quot;simple&quot;        &#125;      &#125;    &#125;  &#125;&#125;\n\nHow Elasticsearch determines the search analyzer在搜索时, Elasticsearch 通过如下顺序来决定使用哪个分析器:\n\n搜索查询中的 analyzer 参数\n字段的映射参数 search_analyzer\n索引的映射参数 analysis.analyzer.default_search\n字段的映射参数 analyzer\nstandard analyzer\n\nSpecify the search analyzer for a query进行全文搜索时, 可以通过 analyzer 参数指定要使用的搜索分析器\nGET my-index-000001/_search&#123;  &quot;query&quot;: &#123;    &quot;match&quot;: &#123;      &quot;message&quot;: &#123;        &quot;query&quot;: &quot;Quick foxes&quot;,        &quot;analyzer&quot;: &quot;stop&quot;      &#125;    &#125;  &#125;&#125;\n\nSpecify the search analyzer for a field创建索引时可以通过 search_analyzer 参数为 text 类型字段指定搜索分析器\n如果提供了搜索分析器, 那么还要通过 analyzer 参数指定索引分析器\nPUT my-index-000001&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;title&quot;: &#123;        &quot;type&quot;: &quot;text&quot;,        &quot;analyzer&quot;: &quot;whitespace&quot;,        &quot;search_analyzer&quot;: &quot;simple&quot;      &#125;    &#125;  &#125;&#125;\n\nSpecify the default search analyzer for an index可以为一个索引指定要使用的搜索分析器, 使用 analysis.analyzer.default_search\n如果配置了搜索分析器, 那还要通过 analysis.analyzer.default 参数配置一个默认索引分析器\nPUT my-index-000001&#123;  &quot;settings&quot;: &#123;    &quot;analysis&quot;: &#123;      &quot;analyzer&quot;: &#123;        &quot;default&quot;: &#123;          &quot;type&quot;: &quot;simple&quot;        &#125;,        &quot;default_search&quot;: &#123;          &quot;type&quot;: &quot;whitespace&quot;        &#125;      &#125;    &#125;  &#125;&#125;\n","categories":["Elasticsearch - User Guides - Text analysis"],"tags":["User Guides","Elasticsearch","Text analysis"]},{"title":"Elasticsearch Stemming","url":"/elasticsearch/elasticsearch-guide/text-analysis/elasticsearch-stemming/","content":"Elasticsearch StemmingStemming 是将一个词还原到词根的过程\nwakling 和 walked -&gt; walk\n词根不一定是一个真实存在的词, 例如 jumping 和 jumpiness -&gt; jumpi\nAlgorithmic stemmers使用特定算法规则来进行词根转换\n例如删除复数英文单词结尾的 -s 和 -es\n速度比词典 Stemmers 快\n节省内存\n开箱即用\n基于单词的字符内容来进行计算, 对于同义但不同字符序列的单词运行得不好\n或者字符序列相似, 但是意思完全不同的单词运行得不好\nDictionary stemmers使用定义好的词根规则词典来进行词根转换\n字符序列相似, 但是意思完全不同的单词运行得很好\n词典的质量直接影响词根转换的质量\n占用更多的内存\n更慢的执行速度\n可以不用就不用\nControl stemming控制词根转换\n\nstemmer_override\nkeyword_marker\nconditional\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis"],"tags":["User Guides","Elasticsearch","Text analysis"]},{"title":"Elasticsearch Test an analyzer","url":"/elasticsearch/elasticsearch-guide/text-analysis/elasticsearch-test-an-analyzer/","content":"Elasticsearch Test an analyzer使用一个分析器进行测试\n通过使用 _analyze 端口来实现\nPOST _analyze&#123;  &quot;analyzer&quot;: &quot;whitespace&quot;,  &quot;text&quot;:     &quot;The quick brown fox.&quot;&#125;\n\nPOST _analyze&#123;  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;:  [ &quot;lowercase&quot;, &quot;asciifolding&quot; ],  &quot;text&quot;:      &quot;Is this déja vu?&quot;&#125;\n\nGET my-index-000001/_analyze &#123;  &quot;analyzer&quot;: &quot;std_folded&quot;,   &quot;text&quot;:     &quot;Is this déjà vu?&quot;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis"],"tags":["User Guides","Elasticsearch","Text analysis"]},{"title":"Elasticsearch Text analysis","url":"/elasticsearch/elasticsearch-guide/text-analysis/elasticsearch-text-analysis/","content":"Elasticsearch Text analysisElasticsearch 在索引和搜索 text 字段的时候执行文本分析\n","categories":["Elasticsearch - User Guides - Text analysis"],"tags":["User Guides","Elasticsearch","Text analysis"]},{"title":"Elasticsearch Token graphs","url":"/elasticsearch/elasticsearch-guide/text-analysis/elasticsearch-token-graphs/","content":"Elasticsearch Token graphs当一个分词器将一个文本转换为一个分词序列时, 分词通常会记录如下信息:\n\n每个分词在分词序列中的位置( position )\n每个分词的长度( positionLength )\n\n可以通过上面的信息创建一个有向无环图\n分词的 position 作为节点, 分词作为边\n[0] - quick -&gt; [1] - brown -&gt; [2] - fox -&gt; [3]\n同义词有些分词器可以为分词添加同义词\n同义词和原分词共享相同的 position\n[0] - quick -&gt; [1] - brown -&gt; [2] - fox -&gt; [3]-——fast –&gt;  [1]\n多位置分词( Multi-position tokens )一些分词器可以添加跨多个 position 的分词\n这样可以跨多分词的同义词, 例如 domain name system 的同义词 dns\n只有一些图分词器, 才会为 multi-position tokens 精确记录 positionLength , 如这些分词器:\n\nsynonym_graph\nword_delimiter_graph\n\n一些分词器, 例如 nori_tokenizer , 准确地将复合标记分解为多位置标记\n[0] - domain -&gt; [1] - name -&gt; [2] - system -&gt; [3] - is -&gt; [4] - fragile -&gt; [5]\n[0] - dns -&gt; [3]\n在搜索中使用分词图索引过程会忽略 positionLength 属性, 也不支持包含多位置分词的分词图\n在 match 和 match_phrase 查询中, 可以使用这些分词图从一个查询字符串中生成多个子查询\n搜索 domain name system is fragile\n将会生成 domain name system 的同义词 dns\ndns 分词拥有属性 positionLength=3\nmatch_phrase 查询使用这个图来生成子查询, 这个子查询是这些:\ndns is fragiledomain name system is fragile\n\n所以将会查询匹配如上两个字符串\nInvalid token graphs下面这些分词器可以添加跨位置的分词, 但是只记录一个默认的 positionLength=1:\n\nsynonym\nword_delimiter\n\n这意味着过滤器会为包含这些分词的字符流产生无效分词图\n避免在搜索中使用无效分词图\n无效分词图会导致意外的搜索结果\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis"],"tags":["User Guides","Elasticsearch","Text analysis"]},{"title":"Elasticsearch _doc_count field","url":"/elasticsearch/elasticsearch-guide/%E5%85%83%E4%BF%A1%E6%81%AF%E5%AD%97%E6%AE%B5/elasticsearch-doc-count-field/","content":"Elasticsearch _doc_count fieldBucket aggregation 总是返回一个名为 doc_count 的字段, 展示在每个 bucket 中被聚合和划分的文档\n为了与聚合数据可以准确计算文档的数量, 提供了名为 _doc_count 的元数据字段类型\n_doc_count 必须永远是一个正整数, 代表着聚合的文档数量的一个统计字段\n参考link\n","categories":["Elasticsearch - User Guides - 元信息字段"],"tags":["User Guides","Elasticsearch","元信息字段"]},{"title":"Elasticsearch _field_names field","url":"/elasticsearch/elasticsearch-guide/%E5%85%83%E4%BF%A1%E6%81%AF%E5%AD%97%E6%AE%B5/elasticsearch-field-names-field/","content":"Elasticsearch _field_names field_field_names 字段用来索引个每个文档中其字段值不为 null 的字段的名称\n这个字段用来在 exists 查询中查找一个特定字段是否为非空的文档\n参考link\n","categories":["Elasticsearch - User Guides - 元信息字段"],"tags":["User Guides","Elasticsearch","元信息字段"]},{"title":"Elasticsearch _id field","url":"/elasticsearch/elasticsearch-guide/%E5%85%83%E4%BF%A1%E6%81%AF%E5%AD%97%E6%AE%B5/elasticsearch-id-field/","content":"Elasticsearch _id field每个文档有一个唯一标识它的 _id 字段, 因此文档可以在 GET API 或者 ids query 中被查找\n_id 可以在索引时被赋值, 也通过 Elasticsearch 来生成一个唯一 _id 值\n这个字段在映射配置中是不可配置的\n_id 字段的值可以在例如 term,terms,match,query_string 的查询中被获取\n_id 字段在聚合, 排序和脚本的使用中是受限制的\n如果在 _id 字段上的聚合或者排序是必须的, 建议将 _id 字段的值复制一份存储到其他字段中, 同时 doc_values 开启\n_id 字段的大小限制为 512 字节, 大于这个值的字段会被拒接\n参考link\n","categories":["Elasticsearch - User Guides - 元信息字段"],"tags":["User Guides","Elasticsearch","元信息字段"]},{"title":"Elasticsearch _ignored field","url":"/elasticsearch/elasticsearch-guide/%E5%85%83%E4%BF%A1%E6%81%AF%E5%AD%97%E6%AE%B5/elasticsearch-ignored-field/","content":"Elasticsearch _ignored field_ignored 字段索引和存储一个文档中所有的在文档索引时被忽略的字段的名称\n参考link\n","categories":["Elasticsearch - User Guides - 元信息字段"],"tags":["User Guides","Elasticsearch","元信息字段"]},{"title":"Elasticsearch _index field","url":"/elasticsearch/elasticsearch-guide/%E5%85%83%E4%BF%A1%E6%81%AF%E5%AD%97%E6%AE%B5/elasticsearch-index-field/","content":"Elasticsearch _index field当执行跨多个索引的查询时, 有时候希望添加关联了文档的指定索引的查询条件\n_index 字段允许匹配一个包含了索引了文档的索引\n_index 的值在指定的查询, 聚合, 排序或者脚本中是可访问的\nGET index_1,index_2/_search&#123;  &quot;query&quot;: &#123;    &quot;terms&quot;: &#123;      &quot;_index&quot;: [&quot;index_1&quot;, &quot;index_2&quot;]      // 1    &#125;  &#125;,  &quot;aggs&quot;: &#123;    &quot;indices&quot;: &#123;      &quot;terms&quot;: &#123;        &quot;field&quot;: &quot;_index&quot;,                  // 2        &quot;size&quot;: 10      &#125;    &#125;  &#125;,  &quot;sort&quot;: [    &#123;      &quot;_index&quot;: &#123;                           // 3        &quot;order&quot;: &quot;asc&quot;      &#125;    &#125;  ],  &quot;script_fields&quot;: &#123;    &quot;index_name&quot;: &#123;      &quot;script&quot;: &#123;        &quot;lang&quot;: &quot;painless&quot;,        &quot;source&quot;: &quot;doc[&#x27;_index&#x27;]&quot;           // 4      &#125;    &#125;  &#125;&#125;\n\n1 : 在 _index 字段上进行查询\n2 : 在 _index 字段上进行聚合\n3 : 在 _index 字段上进行排序\n4 : 在脚本中访问 _index 字段值\n如果要访问一个远程索引( cluster_1:index_3 ), 要在查询中包含分隔字符 : , 例如 cluster_*:index_3\ncluster*index_1 只会匹配本地分片\n参考link\n","categories":["Elasticsearch - User Guides - 元信息字段"],"tags":["User Guides","Elasticsearch","元信息字段"]},{"title":"Elasticsearch _meta field","url":"/elasticsearch/elasticsearch-guide/%E5%85%83%E4%BF%A1%E6%81%AF%E5%AD%97%E6%AE%B5/elasticsearch-meta-field/","content":"Elasticsearch _meta field一个用来保存应用自定义元数据的字段, Elasticsearch 不使用这个字段\nPUT my-index-000001&#123;    &quot;mappings&quot;: &#123;        &quot;_meta&quot;: &#123;            &quot;class&quot;: &quot;MyApp:User&quot;,            &quot;version&quot;: &#123;                &quot;min&quot;: &quot;1.0&quot;,                &quot;max&quot;: &quot;1.3&quot;            &#125;        &#125;    &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - 元信息字段"],"tags":["User Guides","Elasticsearch","元信息字段"]},{"title":"Elasticsearch _routing field","url":"/elasticsearch/elasticsearch-guide/%E5%85%83%E4%BF%A1%E6%81%AF%E5%AD%97%E6%AE%B5/elasticsearch-routing-field/","content":"Elasticsearch _routing field通过 _routing 字段的值来计算一个文档要被索引到哪个分片中\n计算公式为:\nrouting_factor = num_routing_shards / num_primary_shardsshard_num      = (hash(_routing) % num_routing_shards) / routing_factor\n\nnum_routing_shards &#x3D; index.number_of_routing_shards index setting\nnum_primary_shards &#x3D; index.number_of_shards index setting\n_routing 的默认值是文档的 _id 值\n在新增文档通过 routing 参数来指定路由值:\nPUT my-index-000001/_doc/1?routing=user1&amp;refresh=true&#123;    &quot;title&quot;: &quot;This is a document&quot;&#125;\n\n在 getting,deleting,updating 这个新增的文档时, 必须使用同样的 routing 值\n可以在查询中获取到 _routing 的值:\nGET my-index-00000001/_search&#123;    &quot;query&quot;: &#123;        &quot;terms&quot;: &#123;            &quot;_routing&quot;: [&quot;user1&quot;]        &#125;    &#125;&#125;\n\nSearching with custom routing自定义路由可以减少搜索的碰撞\n不像要将搜索请求到所有的分片, 使用自定义路由的请求仅仅需要发送到匹配路由值的分片:\nGET my-index-000001/_search?routing=user1,user2&#123;    &quot;query&quot;: &#123;        &quot;match&quot;: &#123;            &quot;title&quot;: &quot;document&quot;        &#125;    &#125;&#125;\n\nMaking a routing value required使用了自定义路由之后, 必须在所有的索引, 获取, 删除, 更新文档时都使用自定义路由\n可以将自定义路由值 _routing 配置为必传:\nPUT my-index-000001&#123;    &quot;mappings&quot;: &#123;        &quot;_routing&quot;: &#123;            &quot;required&quot;: true        &#125;    &#125;&#125;\n\nUnique IDs with custom routing使用了自定义路由之后, 跨索引分片的文档 id 的唯一性需要由用户自己来保证\n事实上, 一个拥有相同 _id 当拥有不同路由值的文档是可能索引到不同的分片的\nRouting to an index partition通过在创建索引时设置 index.routing_partition_size 来将文档路由到某个路由组\n一个路由组由多个分片组成\n通过 _id 来决定文档在路由组中分配给哪个分片\nindex.routing_partition_size 的值应该大于 1 小于 index.number_of_shards\n\njoin field 关系不能使用路由组\n所有的索引映射配置必须将 _routing 字段设置为必选\n\n参考link\n","categories":["Elasticsearch - User Guides - 元信息字段"],"tags":["User Guides","Elasticsearch","元信息字段"]},{"title":"Elasticsearch _source field","url":"/elasticsearch/elasticsearch-guide/%E5%85%83%E4%BF%A1%E6%81%AF%E5%AD%97%E6%AE%B5/elasticsearch-source-field/","content":"Elasticsearch _source field_source 字段包含文档的原始 JSON 值\n_source 是不可搜索的\n_source 可以通过 get 或者 search 来获取\n可以停止使用 _source 字段值, 但非常不建议\n可以指定 _source 包含&#x2F;不包含 哪些字段\n参考link\n","categories":["Elasticsearch - User Guides - 元信息字段"],"tags":["User Guides","Elasticsearch","元信息字段"]},{"title":"Elasticsearch _tier field","url":"/elasticsearch/elasticsearch-guide/%E5%85%83%E4%BF%A1%E6%81%AF%E5%AD%97%E6%AE%B5/elasticsearch-tier-field/","content":"Elasticsearch _tier fieldPUT index_1/_doc/1&#123;  &quot;text&quot;: &quot;Document in index 1&quot;&#125;PUT index_2/_doc/2?refresh=true&#123;  &quot;text&quot;: &quot;Document in index 2&quot;&#125;GET index_1,index_2/_search&#123;    &quot;query&quot;: &#123;        &quot;terms&quot;: &#123;            &quot;_tier&quot;: [&quot;data_hot&quot;, &quot;data_warm&quot;]        &#125;    &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - 元信息字段"],"tags":["User Guides","Elasticsearch","元信息字段"]},{"title":"Elasticsearch 聚合统计字段类型 Aggregate metric field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-aggregate-metric-field-type/","content":"Elasticsearch 聚合统计字段类型 Aggregate metric field type存储预聚合的数字值, 用于统计聚合\n一个 aggregate_metric_double 字段是一个包含一个或多个以下 min,max,sum,value_count 子字段的对象\n当你在一个 aggregate_metric_double 字段上运行指定的统计聚合时, 聚合运算会使用对应的子字段值\n例如, 一个运行在 aggregate_metric_double 字段上的 min 聚合返回子字段中的 min 子字段\n定义 aggregate_metric_doublePUT my-index&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;my-agg-metric-field&quot;: &#123;        &quot;type&quot;: &quot;aggregate_metric_double&quot;,        &quot;metrics&quot;: [ &quot;min&quot;, &quot;max&quot;, &quot;sum&quot;, &quot;value_count&quot; ],        &quot;default_metric&quot;: &quot;max&quot;      &#125;    &#125;  &#125;&#125;\n\n向 aggregate_metric_double 字段中存入数据PUT stats-index/_doc/1&#123;  &quot;agg_metric&quot;: &#123;    &quot;min&quot;: -302.50,    &quot;max&quot;: 702.30,    &quot;sum&quot;: 200.0,    &quot;value_count&quot;: 25  &#125;&#125;\n\n在 aggregate_metric_double 字段中进行聚合运算POST stats-index/_search?size=0&#123;  &quot;aggs&quot;: &#123;    &quot;metric_min&quot;: &#123; &quot;min&quot;: &#123; &quot;field&quot;: &quot;agg_metric&quot; &#125; &#125;,    &quot;metric_max&quot;: &#123; &quot;max&quot;: &#123; &quot;field&quot;: &quot;agg_metric&quot; &#125; &#125;,    &quot;metric_value_count&quot;: &#123; &quot;value_count&quot;: &#123; &quot;field&quot;: &quot;agg_metric&quot; &#125; &#125;,    &quot;metric_sum&quot;: &#123; &quot;sum&quot;: &#123; &quot;field&quot;: &quot;agg_metric&quot; &#125; &#125;,    &quot;metric_avg&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;agg_metric&quot; &#125; &#125;  &#125;&#125;\n\nGET stats-index/_search&#123;  &quot;query&quot;: &#123;    &quot;term&quot;: &#123;      &quot;agg_metric&quot;: &#123;        &quot;value&quot;: 702.30      &#125;    &#125;  &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch 别名字段类型 Alias field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-alias-field-type/","content":"Elasticsearch 别名字段类型 Alias field type为索引中的字段取别名\n可以在搜索请求中使用别名\n通配符搜索中也会对别名进行查询\n不能在 _source 中使用别名\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch 数组类型 Arrays","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-arrays/","content":"Elasticsearch 数组类型 Arrays在 Elasticsearch 中没有专用的 数组 数据类型\n任何字段默认都包含0个或多个值\n数组中的所有元素必须是相同的数据类型\n[1, [2, 3]] 等同于 [1, 2, 3]\n对象类型数组: [ &#123; &quot;name&quot;: &quot;Mary&quot;, &quot;age&quot;: 12 &#125;, &#123; &quot;name&quot;: &quot;John&quot;, &quot;age&quot;: 10 &#125;]\n在动态索引中, 数组的第一个元素的类型为整个数据的数据类型\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch 二进制字段类型 Binary field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-binary-field-type/","content":"Elasticsearch 二进制字段类型 Binary field type使用 Base64 编码的字符串作为存储\n默认不存储到 _source 中\n默认不可搜索\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch 布尔字段类型 Boolean field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-boolean-field-type/","content":"Elasticsearch 布尔字段类型 Boolean field typetrue 或者 false\n&quot;false&quot; 字符串解释为 false\n&quot;&quot; 空字符串解释为 false\n&quot;true&quot; 字符串解释为 true\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch 日期字段类型 Date field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-date-field-type/","content":"Elasticsearch 日期字段类型 Date field type在 Elasticsearch 中日期存储为 long 类型的毫秒值, 从 1970 年开始的毫秒值\nElasticsearch 自动将符合格式的日期字符串转换为毫秒值进行存储, 或者返回\n毫秒值不能为空, 早于 1970 年的日期使用日期字符串表示\n配置 Date 类型的字段PUT my-index-000001&#123;    &quot;mapping&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;date&quot;: &#123;                &quot;type&quot;: &quot;date&quot;            &#125;        &#125;    &#125;&#125;\n\n日期字符串的默认格式默认的 format 字段配置为 &quot;strict_date_optional_time||epoch_millis&quot;\n2022-02-22\nstrict_date_optional_time 对应 2021-01-01T12:00:21Z\n毫秒值: 1420070400001\n指定要使用的日期格式PUT my-index-00001&#123;    &quot;mapping&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;date&quot;: &#123;                &quot;type&quot;: &quot;date&quot;,                &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_mills&quot;            &#125;        &#125;    &#125;&#125;\n\n使用秒数进行保存PUT my-index-00001&#123;    &quot;mapping&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;date&quot;: &#123;                &quot;type&quot;: &quot;date&quot;,                &quot;format&quot;: &quot;strict_date_optional_time||epoch_second&quot;            &#125;        &#125;    &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch 纳秒日期字段类型 Date nanoseconds field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-date-nanoseconds-field-type/","content":"Elasticsearch 纳秒日期字段类型 Date nanoseconds field type使用 long 类型来保存纳秒值\n只能保存 1970 到 2262 年的数据\n默认 format 使用 &quot;strict_date_optional_time_nanos&quot;||epoch_mills 的时间格式\n分别对应:\n\n&quot;2021-01-01&quot;\n&quot;2015-01-01T12:10:30.123456789Z&quot;\n1420070400000\n\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch 密集向量数据类型 Dense vector field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-dense-vector-field-type/","content":"Elasticsearch 密集向量数据类型 Dense vector field type一个 dense_vector 字段存储浮点类型的密集向量\n就是通过 dims 属性来定义可以存储多个元素的数组, dims 不能操作 2048\ndense_vector 不能用于查询, 排序, 聚集\n只能在脚本中使用专用的 vector functions\nPUT my-index-00001&#123;    &quot;mappings&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;my_vector&quot;: &#123;                &quot;type&quot;: &quot;dense_vector&quot;,                &quot;dims&quot;: 3            &#125;,            &quot;my_text&quot;: &#123;                &quot;type&quot;: &quot;keyword&quot;            &#125;        &#125;    &#125;&#125;PUT my-index-000001/_doc/1&#123;    &quot;my_text&quot;: &quot;text1&quot;,    &quot;my_vector&quot;: [0.5, 10, 6]&#125;PUT my-index-000001/_doc/2&#123;    &quot;my_text&quot;: &quot;text2&quot;,    &quot;my_vector&quot;: [-0.5, 10, 10]&#125;\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Flattened field type 扁平字段类型","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-flattened-field-type/","content":"Elasticsearch Flattened field type 扁平字段类型默认情况下, 每个对象的子字段都是分开映射和索引的\n如果不能明确子字段的名称和类型, 可以使用 flattened field type, 然后他们会自动映射\n扁平字段类型是解决字段过多问题的另一种方法，它把整个对象映射为单个字段\n给定对象, flattened field type 解析出每个子字段值作为 keyword 类型\n对象中的内容可以通过单个查询进行搜索或聚集\n对于唯一字段类型未知的情况非常有用, 对于整个 JSON 对象仅创建一个映射字段, 可以有效防止映射太多字段, 从而导致映射爆炸\nPUT bug_reports&#123;    &quot;mappings&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;title&quot;: &#123;                &quot;type&quot;: &quot;text&quot;            &#125;,            &quot;labels&quot;: &#123;                &quot;type&quot;: &quot;flattened&quot;            &#125;        &#125;    &#125;&#125;POST bug_reports/_doc/1&#123;  &quot;title&quot;: &quot;Results are not sorted correctly.&quot;,  &quot;labels&quot;: &#123;    &quot;priority&quot;: &quot;urgent&quot;,    &quot;release&quot;: [&quot;v1.2.5&quot;, &quot;v1.3.0&quot;],    &quot;timestamp&quot;: &#123;      &quot;created&quot;: 1541458026,      &quot;closed&quot;: 1541457010    &#125;  &#125;&#125;POST bug_reports/_search&#123;  &quot;query&quot;: &#123;    &quot;term&quot;: &#123;&quot;labels&quot;: &quot;urgent&quot;&#125;  &#125;&#125;POST bug_reports/_search&#123;  &quot;query&quot;: &#123;    &quot;term&quot;: &#123;&quot;labels.release&quot;: &quot;v1.3.0&quot;&#125;  &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch 地理坐标字段类型 Geopoint field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-geopoint-field-type/","content":"Elasticsearch 地理坐标字段类型 Geopoint field type字段类型 geo_point 接受 经纬度\n有五种方法来定义 地理坐标\n&#123;  &quot;text&quot;: &quot;Geopoint as an object&quot;,  &quot;location&quot;: &#123;     &quot;lat&quot;: 41.12,    &quot;lon&quot;: -71.34  &#125;&#125;\n\n&#123;  &quot;text&quot;: &quot;Geopoint as a string&quot;,  &quot;location&quot;: &quot;41.12,-71.34&quot; &#125;\n\n&#123;  &quot;text&quot;: &quot;Geopoint as a geohash&quot;,  &quot;location&quot;: &quot;drm3btev3e86&quot; &#125;\n\n&#123;  &quot;text&quot;: &quot;Geopoint as an array&quot;,  &quot;location&quot;: [ -71.34, 41.12 ] &#125;\n\n&#123;  &quot;text&quot;: &quot;Geopoint as a WKT POINT primitive&quot;,  &quot;location&quot; : &quot;POINT (-71.34 41.12)&quot; &#125;\n\nstring geopoints are ordered as lat,lon\narray geopoints are ordered as the reverse: lon,lat\nGeohashes are base32 encoded strings of the bits of the latitude and longitude interleaved.\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch 地理形状字段类型 Geoshape field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-geoshape-field-type/","content":"Elasticsearch 地理形状字段类型 Geoshape field type用来查询落在某个多边形内的点\n进行空间查询\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch 直方图字段类型 Histogram field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-histogram-field-type/","content":"Elasticsearch 直方图字段类型 Histogram field type存储预聚合的数值型直方图\n创建PUT my-index-000001&#123;    &quot;mappings&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;my_histogram&quot;: &#123;                &quot;type&quot;: &quot;histogram&quot;            &#125;,            &quot;my_text&quot;: &#123;                &quot;type&quot;: &quot;keyword&quot;            &#125;        &#125;    &#125;&#125;\n\n插入数据PUT my-index-000001/_doc/1&#123;    &quot;my_text&quot;: &quot;histogram_1&quot;,    &quot;my_histogram&quot;: &#123;        &quot;values&quot;: [0.1, 0.2, 0.3, 0.4, 0.5],        &quot;counts&quot;: [3, 7, 23, 12, 6]    &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch IP字段类型 IP field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-ip-field-type/","content":"Elasticsearch IP字段类型 IP field type用来存储 IPv4或者 IPv6 地址\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Join field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-join-field-type/","content":"Elasticsearch Join field type在同一个索引中建立父子关系文档\n使用 relations 块来定义\nPUT my-index-000001&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;my_id&quot;: &#123;        &quot;type&quot;: &quot;keyword&quot;      &#125;,      &quot;my_join_field&quot;: &#123;            // 关系名称        &quot;type&quot;: &quot;join&quot;,             // 指明是 Join field type        &quot;relations&quot;: &#123;          &quot;question&quot;: &quot;answer&quot;      // 定义一个关系, `questions` 是 `answer` 的父亲        &#125;      &#125;    &#125;  &#125;&#125;\n\n插入父亲文档PUT my-index-000001/_doc/1?refresh&#123;  &quot;my_id&quot;: &quot;1&quot;,  &quot;text&quot;: &quot;This is a question&quot;,  &quot;my_join_field&quot;: &#123;    &quot;name&quot;: &quot;question&quot;   &#125;&#125;\n\n插入子文档PUT my-index-000001/_doc/4?routing=1&amp;refresh    // `routing` 参数是必须的, 因为父文档与子文档必须索引在同一个分片上&#123;  &quot;my_id&quot;: &quot;4&quot;,  &quot;text&quot;: &quot;This is another answer&quot;,  &quot;my_join_field&quot;: &#123;    &quot;name&quot;: &quot;answer&quot;,                           // 指明是子文档    &quot;parent&quot;: &quot;1&quot;                               // 指明父文档的id  &#125;&#125;\n\n性能Join field 不应该像关系数据库的 joins 那样来使用\n只有在你的数据包含一对多, 且一个文档对应大量子文档的情况下才使用\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Keyword type family","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-keyword-type-family/","content":"Elasticsearch Keyword type familyKeyword type family 包含以下字段类型\n\nkeyword : 用于结构化内容, 例如 IDs, 邮箱地址, 主机名, 状态码\nconstant_keyword : 用于永远包含相同值的 keyword 字段\nwildcard: 用于机器生成的非结构化内容; wildcard 类型为超大值或高基数的字段进行了优化\n\n避免将 Keyword fields 用于全文搜索, 全文搜索使用 text fields\nKeyword fields 通常用于 sorting, aggregations, term-level-queries\ntext 和 keyword 的区别text:\n\n支持分词, 全文索引, 支持模糊, 精确查询\n不支持聚合, 排序操作\n支持的字符长度没有限制, 适合大字段存储\n\nkeyword:\n\n不进行分词, 直接索引, 支持模糊, 支持精确匹配, 支持聚合, 排序操作\n最大支持 32766 个 UTF-8 类型的字符\n\nKeyword field typeMapping numeric identifiers不是所有的数值数据都应该映射为一个 数值类型字段\nElasticsearch 为 range queries 优化 integer,long 等数值类型字段\nterm 或 term-level 查询, 使用 Keyword fields 更好\nidentifiers , 例如 ISBN, 产品ID, 很少用于 range 查询, 通常在 term-level 查询中进行获取\n在以下情况中将一个数值标识符定义为 keyword 类型:\n\n不打算在 range 查询中搜索标识符\n需要更快的获取速度. term 查询在 keyword 字段上的速度比 term 搜索在数值字段上的速度更快\n\n如果不确定使用哪个字段类型, 可以使用 multi-field 来将数据映射为 keyword 和 数值类型字段\nConstant keyword field type一个特殊的 keyword 字段类型, 索引中所有文档的这个字段的值都相等\n这个字段的值一旦设置就不可再更改\nWildcard field type特殊的 keyword 字段类型\n用于机器生成的非机构化内容\n用于通配符查询, grep-like 查询\nwildcard 类型为超大值和高基数的字段进行了优化\nMapping unstructured content可以将非结构化数据映射到 text 或者 keyword family\n哪个字段类型更好取决于存储的内容和你打算如何搜索字段\nUse the text field type if内容是人类可读的, 例如邮件主题或者产品信息\n计划通过单独的单词或词组来搜索字段, 例如 the brown fox jumped , 使用 全文搜索\nElasticsearch 分析 text 字段来返回最相关的结果\nUse a keyword family field type if内容是机器生成的, 例如日志信息, HTTP 请求信息\n计划通过准确全值来搜索字段, 例如 org.foo.bar , 或者字符串的一部分, 例如 org.foo.* , 使用 term-level queries\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Nested field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-nested-field-type/","content":"Elasticsearch Nested field type内嵌字段类型, 将一个内部对象作为一个文档进行单独存储\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Numeric field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-numeric-field-type/","content":"Elasticsearch Numeric field typehalf_float : A half-precision 16-bit IEEE 754 floating point number, restricted to finite values; 一个半精度16位IEEE 754浮点数，限制为有限值\nscaled_float : A floating point number that is backed by a long, scaled by a fixed double scaling factor\nunsigned_long : An unsigned 64-bit integer with a minimum value of 0 and a maximum value of 264-1\nThe double, float and half_float types consider that -0.0 and +0.0 are different values.\n需要精确的浮点数, 使用 scaled_float\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Percolator field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-percolator-field-type/","content":"Elasticsearch Percolator field type简单的说:\n\n就是将搜索条件存储在文档中\n在查询时, 传入文档, 判断是否满足搜索条件\n如果满足, 则返回存储了搜索条件的文档\n\nElasticsearch 的正常工作流程是将文档存储在索引中, 然后在执行搜索时通过索引查询这些文档的信息\nPercolate 可以实现逆转这种流程, 先有查询条件, 再有文档\n其使用流程是先存储 search 条件, 之后使用文档询问是否可以命中这些搜索条件\nPercolation 功能围绕 percolator 字段类型展开\n先在 mappings 中定义, 再进行写入\n不同的是, 它将搜索条件作为文档进行存储\nPercolate query 执行的时候, 接受一个或多个文档, 并返回预先存储的拥有搜索条件的文档\n示例建立一个索引, 该索引含有 玩具名字和玩具价格搜索条件\n其背后的思路是, 用户输入搜索词和最高价格, 然后在 玩具名匹配且商品价格低于用户指定的价格 时, 立即得到通知, 用户还可以开启或关闭这些通知\n\n与保存的搜索条件本身相关的字段位于 search 对象中\n与原始玩具相关的字段位于映射的根级别\n\nPUT toys&#123;    &quot;mappings&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;search&quot;: &#123;                 // 搜索条件本身相关                &quot;properties&quot;: &#123;                    &quot;query&quot;: &#123;                        &quot;type&quot;: &quot;percolator&quot;                    &#125;,                    &quot;user_id&quot;: &#123;                        &quot;type&quot;: &quot;integer&quot;                    &#125;,                    &quot;enabled&quot;: &#123;                        &quot;type&quot;: &quot;boolean&quot;                    &#125;                &#125;            &#125;,            &quot;price&quot;: &#123;                  // 原始玩具相关                &quot;type&quot;: &quot;float&quot;            &#125;,            &quot;description&quot;: &#123;            // 原始玩具相关                &quot;type&quot;: &quot;text&quot;            &#125;        &#125;    &#125;&#125;\n\n插入一个包含查询条件的文档:\nPUT toys/_doc/1&#123;    &quot;search&quot;: &#123;        &quot;query&quot;: &#123;            &quot;bool&quot;: &#123;                &quot;filter&quot;: [                    &#123;                        &quot;match&quot;: &#123;                            &quot;description&quot;: &#123;                                &quot;query&quot;: &quot;nintendo switch&quot;      // 设置具体查询条件                            &#125;                        &#125;                    &#125;,                    &#123;                        &quot;range&quot;: &#123;                            &quot;price&quot;: &#123;                                &quot;lte&quot;: 300                      // 设置具体查询条件                            &#125;                        &#125;                    &#125;                ]            &#125;        &#125;,        &quot;user_id&quot;: 5,        &quot;enabled&quot;: true    &#125;&#125;\n\n查询:\nGET toys/_search&#123;    &quot;query&quot;: &#123;        &quot;bool&quot;: &#123;            &quot;filter&quot;: [                &#123;                    &quot;percolate&quot;: &#123;                              // 使用 percolate 过滤器                        &quot;field&quot;: &quot;search.query&quot;                 // 指明 查询条件 保存在哪个字段中                        &quot;document&quot;: &#123;                            &quot;description&quot;: &quot;Nintendo Switch&quot;,   // 为 查询条件 传入用到的参数, 字段名+字段值                            &quot;price&quot;: 250                        // 为 查询条件 传入用到的参数, 字段名+字段值                        &#125;                    &#125;                &#125;,                &#123;                    &quot;term&quot;: &#123;                        &quot;search.user_id&quot;: 5                     // 其他匹配条件                    &#125;                &#125;,                &#123;                    &quot;term&quot;: &#123;                        &quot;search.enabled&quot;: true                  // 其他匹配条件                    &#125;                &#125;            ]        &#125;    &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Point field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-point-field-type/","content":"Elasticsearch Point field type用来存储二维坐标系\n可以使用 shape Query 来查询这种类型的文档\n限制不能排序 Point 类型\n不能直接通过 字段值 获取 Point 类型\n只能通过 _source 字段来获取\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Range field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-range-field-type/","content":"Elasticsearch Range field type用来存储范围值\n支持查询\n只支持 histogram,cardinality 的 aggregations\n支持 date_range,ip_range\n定义PUT range_index&#123;  &quot;settings&quot;: &#123;    &quot;number_of_shards&quot;: 2  &#125;,  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;expected_attendees&quot;: &#123;        &quot;type&quot;: &quot;integer_range&quot;      &#125;,      &quot;time_frame&quot;: &#123;        &quot;type&quot;: &quot;date_range&quot;,         &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;      &#125;    &#125;  &#125;&#125;\n\n插入数据PUT range_index/_doc/1?refresh&#123;  &quot;expected_attendees&quot; : &#123;     &quot;gte&quot; : 10,    &quot;lt&quot; : 20  &#125;,  &quot;time_frame&quot; : &#123;    &quot;gte&quot; : &quot;2015-10-31 12:00:00&quot;,     &quot;lte&quot; : &quot;2015-11-01&quot;  &#125;&#125;\n\n查询GET range_index/_search&#123;  &quot;query&quot; : &#123;    &quot;term&quot; : &#123;      &quot;expected_attendees&quot; : &#123;        &quot;value&quot;: 12      &#125;    &#125;  &#125;&#125;\n\nGET range_index/_search&#123;  &quot;query&quot; : &#123;    &quot;range&quot; : &#123;      &quot;time_frame&quot; : &#123;         &quot;gte&quot; : &quot;2015-10-31&quot;,        &quot;lte&quot; : &quot;2015-11-01&quot;,        &quot;relation&quot; : &quot;within&quot;       &#125;    &#125;  &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Rank feature field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-rank-feature-field-type/","content":"Elasticsearch Rank feature field typeA rank_feature field can index numbers so that they can later be used to boost documents in queries with a rank_feature query\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Rank features field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-rank-features-field-type/","content":"Elasticsearch Rank features field typeA rank_features field can index numeric feature vectors, so that they can later be used to boost documents in queries with a rank_feature query\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Search-as-you-type field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-search-as-you-type-field-type/","content":"Elasticsearch Search-as-you-type field type搜索框的字段补全，当用户在输入框输入一段文本的前几个词时，下面会出现很多相关的候选词提示\n为用户提供了一种开箱即用的搜索即可见的解决方案，内部会自动拆分为多个子字段索引以支持高效查询，目前 search_as_you_type 实现前缀，中缀查询\n创建PUT my_index&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;my_field&quot;: &#123;        &quot;type&quot;: &quot;search_as_you_type&quot;      &#125;    &#125;  &#125;&#125;\n\n插入数据PUT my_index/_doc/1?refresh&#123;  &quot;my_field&quot;: &quot;quick brown fox jump lazy dog&quot;&#125;\n\n查询数据实现 search_as_you_type 最高效的查询是使用类型为 bool_prefix的 multi_match query\nGET my_index/_search&#123;  &quot;query&quot;: &#123;    &quot;multi_match&quot;: &#123;      &quot;query&quot;: &quot;brown f&quot;,      &quot;type&quot;: &quot;bool_prefix&quot;,      &quot;fields&quot;: [        &quot;my_field&quot;,        &quot;my_field._2gram&quot;,        &quot;my_field._3gram&quot;      ]    &#125;  &#125;&#125;\n\n参考link\nlink\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Shape field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-shape-field-type/","content":"Elasticsearch Shape field typeThe shape data type facilitates the indexing of and searching with arbitrary x, y cartesian shapes such as rectangles and polygons. It can be used to index and query geometries whose coordinates fall in a 2-dimensional planar coordinate system.\n形状数据类型有助于对任意x、y笛卡尔形状(如矩形和多边形)进行索引和搜索。它可以用于索引和查询坐标属于二维平面坐标系的几何图形。\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Text type family","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-text-type-family/","content":"Elasticsearch Text type family\ntext : 用于全文搜索\nmatch_only_text : 空间优化的 text , 关闭得分计算\n\nText field typetext 类型的字段, 会被分析器进行分词等处理, 再存储\ntext 字段最适合用于非结构化的人类可读的内容\n如果需要索引非结构化机器生成的内容, 使用 Mapping unstructed content\n如果需要索引结构化内容, 例如邮箱地址, 最好使用 keyword 类型字段\n可以通过 multi-fields 来同时使用 text 和 keyword 类型\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Token count field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-token-count-field-type/","content":"Elasticsearch Token count field typetoken_count 类型字段是一个 整型 字段, 接受字符串值, 分析字符串, 然后保存这个字符串的分词数量\nPUT my-index-000001&#123;    &quot;mappings&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;name&quot;: &#123;                &quot;type&quot;: &quot;text&quot;,                &quot;fields&quot;: &#123;                    &quot;length&quot;: &#123;                        &quot;type&quot;: &quot;token_count&quot;,                        &quot;analyzer&quot;: &quot;standard&quot;                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Unsigned long field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-unsigned-long-field-type/","content":"Elasticsearch Unsigned long field type无符号 64位 整型\n范围: 0 ~ 18446744073709551615\nPUT my_index&#123;    &quot;mappings&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;my_counter&quot;: &#123;                &quot;type&quot;: &quot;unsigned_long&quot;            &#125;        &#125;    &#125;&#125;\n\nGET /my_index/_search&#123;    &quot;query&quot;: &#123;        &quot;range&quot; : &#123;            &quot;my_counter&quot; : &#123;                &quot;gte&quot; : &quot;9223372036854775808.5&quot;,                &quot;lte&quot; : &quot;18446744073709551615&quot;            &#125;        &#125;    &#125;&#125;\n\n在范围查询中使用字符串来传递值, 避免精度丢失\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Elasticsearch Version field type","url":"/elasticsearch/elasticsearch-guide/%E5%AD%97%E6%AE%B5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/elasticsearch-version-field-type/","content":"Elasticsearch Version field typeversion 字段类型是专用的 keyword 字段, 用来处理软件版本值\n支持专用的版本优先级规则\ni.e. “2.1.0” &lt; “2.4.1” &lt; “2.11.2”\ni.e. “1.0.0-alpha” &lt; “1.0.0”\nPUT my-index-0000001&#123;    &quot;mappings&quot;: &#123;        &quot;properties&quot;: &#123;            &quot;my_version&quot;: &#123;                &quot;type&quot;: &quot;version&quot;            &#125;        &#125;    &#125;&#125;\n\n这个字段提供了与 keyword 类型字段相同的搜索功能\n参考link\n","categories":["Elasticsearch - User Guides - 字段数据类型"],"tags":["User Guides","Elasticsearch","字段数据类型"]},{"title":"Groovy Annotation definition","url":"/groovy/object-orientation/annotation/groovy-annotation-definition/","content":"Groovy Annotation definitionAn annotation may define members in the form of methods without bodies and an optional default value.\nThe possible member type are limited to:\n\nprimitive types\nStrings\nClasses\nan enumeration\nanother annotation type\nor any array of the above\n\nFor example:\n@interface SomeAnnotation &#123;    String value()&#125;@interface SomeAnnotation &#123;    String value() default &#x27;something&#x27;&#125;@interface SomeAnnotation &#123;    int step()&#125;@interface SomeAnnotation &#123;    Class appliesTo()&#125;@interface SomeAnnotation &#123;&#125;@interface SomeAnnotation &#123;    SomeAnnotation[] value()&#125;enum DayOfWeek &#123; mon, tue, wed, thu, fri, sat, sun &#125;@interface Scheduled &#123;    DayOfWeek dayOfWeek()&#125;\n\nUnlike in the Java language, in Groovy, an annotation can be used to alter the semantics of the language.\nIt is especially true of AST transformations which will generate code based on annotations.\n","categories":["Groovy Object Orientation - Annotation"],"tags":["Groovy","Object Orientation","Annotation"]},{"title":"Groovy Annotation member values","url":"/groovy/object-orientation/annotation/groovy-annotation-member-values/","content":"Groovy Annotation member values使用一个 Annotation 时，没有默认值的 values 都必须进行设置\n","categories":["Groovy Object Orientation - Annotation"],"tags":["Groovy","Object Orientation","Annotation"]},{"title":"Groovy Annotation placement","url":"/groovy/object-orientation/annotation/groovy-annotation-placement/","content":"Groovy Annotation placement通过 @Target 注解来限制 Annotation 可以使用地方\nimport java.lang.annotation.ElementTypeimport java.lang.annotation.Target@Target([ElementType.METHOD, ElementType.TYPE])@interface SomeAnnotation &#123;&#125;\n","categories":["Groovy Object Orientation - Annotation"],"tags":["Groovy","Object Orientation","Annotation"]},{"title":"Groovy Closure annotation parameters","url":"/groovy/object-orientation/annotation/groovy-closure-annotation-parameters/","content":"Groovy Closure annotation parameters可以使用 Closure 作为 Annotation 的 value\nFor example:\nclass Tasks &#123;    Set result = []        void alwaysExecuted() &#123; result &lt;&lt; 1 &#125;        @OnlyIf(&#123; jdk &gt;= 6 &#125;)    void supportedOnlyInJDK6() &#123; result &lt;&lt; &#x27;JDK 6&#x27; &#125;        @OnlyIf(&#123; jdk &gt;= 7 &amp;&amp; windows &#125;)    void requiresJDK7AndWindows() &#123; result &lt;&lt; &#x27;JDK 7 Windows&#x27; &#125;&#125;\n\n要让 @OnyIf Annotation 接收一个 Closure 作为参数，只需定义一个 Class 类型的 value 成员:\n@Retention(RetentionPolicy.RUNTIME)@interface OnlyIf &#123;    Class value()&#125;\n\nclass Runner &#123;    static &lt;T&gt; T run(Class&lt;T&gt; taskClass) &#123;        def tasks = taskClass.newInstance()                      def params = [jdk:6, windows: false]                  tasks.class.declaredMethods.each &#123; m -&gt;                                                 if (Modifier.isPublic(m.modifiers) &amp;&amp; m.parameterTypes.length == 0) &#123;                               def onlyIf = m.getAnnotation(OnlyIf)                                                if (onlyIf) &#123;                    Closure cl = onlyIf.value().newInstance(tasks,tasks)                                cl.delegate = params                                                                if (cl()) &#123;                                                                             m.invoke(tasks)                                                                 &#125;                &#125; else &#123;                    m.invoke(tasks)                                                                 &#125;                            &#125;        &#125;        tasks                                                                           &#125;&#125;def tasks = Runner.run(Tasks)assert tasks.result == [1, &#x27;JDK 6&#x27;] as Set\n","categories":["Groovy Object Orientation - Annotation"],"tags":["Groovy","Object Orientation","Annotation"]},{"title":"Groovy Retention policy","url":"/groovy/object-orientation/annotation/groovy-retention-policy/","content":"Groovy Retention policy一个 Annotation 的可见性取决于它的 retention(保留) policy\nRetention policy 通过 @Retention 注解来进行定义\nimport java.lang.annotation.Retentionimport java.lang.annotation.RetentionPolicy@Retention(RetentionPolicy.SOURCE)@interface SomeAnnotation &#123;&#125;\n","categories":["Groovy Object Orientation - Annotation"],"tags":["Groovy","Object Orientation","Annotation"]},{"title":"Groovy Closures Delegation strategy","url":"/groovy/object-orientation/closures/groovy-closures-delegation-strategy/","content":"\n\n\nGroovy Closures Delegation strategy\nGroovy closure vs lambda expressions\nOwner, delegate and this\nThe meaning of this\nOwner of a closure\nDelegate of a closure\nDelegation strategy\n\n\n\n\n\n\n\nGroovy Closures Delegation strategyGroovy closure vs lambda expressionsGroovy 将 closures 定义为 Closure 类的实例，这使得 Closure 和 Java 8 中的 lambda expressions 非常地不同\n在 Groovy 的 Closure 中委托是一个关键概念，而 lambdas 中并没有委托\n依托修改委托或者委托策略的能力，在 Groovy 中非常容易实现漂亮的领域定义语言\nOwner, delegate and this一个 Closure 定义了 3 个明确的东西：\n\nthis : corresponds to the ++enclosing class++ where the closure is defined\nowner : corresponds to the ++enclosing object++ where the closure is defined, which may be either a class or a closure\ndelegate : corresponds to ++a third party object++ where methods calls or properties are resolved whenever the receiver of the message is not defined\n\nThe meaning of this离 Closure 最近的类（不包括 Closure），就是 this\nIn a closure, calling getThisObject will return the enclosing class where the closure is defined.\nIt is equivalent to using an explict this :\nclass Enclosing &#123;    void run() &#123;        def whatIsThisObject = &#123; getThisObject() &#125;        assert whatIsThisObject() == this                def whatIsThis = &#123; this &#125;        assert whatIsThis == this    &#125;&#125;\n\nclass EnclosedInInnerClass &#123;    class Inner &#123;        Closure c1 = &#123; this &#125;    &#125;        void run() &#123;        def inner = new Inner()                assert inner.c1() == inner          // `this` in the closure will return the inner class, not the top-level one    &#125;&#125;\n\nclass NestedClosures &#123;    void run() &#123;        def nestedClosures = &#123;            def c1 = &#123; this &#125;            c1()        &#125;                assert nestedClosures() == this     // then `this` corresponds to the closest outer class, not the enclosing closure!    &#125;&#125;\n\nIt is of course possible to call methods from the enclosing class this way:\nclass Person &#123;    String name    Integer age        String toString() &#123; &quot;$name is $age years old&quot; &#125;        String dump() &#123;        def cl = &#123;            String msg = this.toString()    // 调用的是距离最近的 Person 类的实例的 toString() 方法            println msg            msg        &#125;                cl()    &#125;&#125;def p = new Person(name: &quot;lin&quot;, age: 28)assert p.dump() == &#x27;lin is 28 years old&#x27;\n\nOwner of a closure和 this 很类似，不同的是它返回的是 最近的对象，一个 closure 或者一个 class\nThe owner of a closure is very similar to the definition of this in a closure with a subtle difference: it will return the direct enclosing object, be it a ++closure++ or a class:\nclass Enclosing &#123;    void run() &#123;        def whatIsOwnerMethod = &#123; getOwner() &#125;        assert whatIsOwnerMethod == this                def whatIsOwner = &#123; owner &#125;        assert whatIsOwner == this    &#125;&#125;\n\nclass EnclosedInInnerClass &#123;    class Inner &#123;        Closure cl = &#123; owner &#125;        Closure cl2 = &#123; this &#125;    &#125;    void run() &#123;        def inner = new Inner()        assert inner.cl() == inner                  // `owner` in the closure will return the inner class, not the top-level one        assert inner.cl() == inner.cl2()    &#125;&#125;\n\nclass NestedClosures &#123;    void run() &#123;        def nestedClosures = &#123;            def cl = &#123; owner &#125;            cl()        &#125;                assert nestedClosures() == nestedClosures   // then `owner` corresponds to the enclosing closure, hence a different object from `this`!    &#125;&#125;\n\nDelegate of a closureDelegate 默认等于 owner，可以手动指定\nThe delegate of a closure can be accessed by using the delegate property or calling the getDelegate method.\nIt is a powerful concept for building domain specific languages in Groovy.\nWhile closure-this and closure-owner refer to the lexical(语法上) scope of a closure, the delegate is a user defined object that a closure will use.\nBy default, the delegate is set to owner:\nclass Enclosing &#123;    void run() &#123;        def cl = &#123; getDelegate() &#125;        def cl2 = &#123; delegate &#125;        assert cl() ==  cl2()        assert cl() == this                def enclosed = &#123;            &#123; -&gt; delegate &#125;.call()        &#125;        assert enclosed() == enclosed       // `delegate` will correspond to the `owner`    &#125;&#125;\n\nThe delegate of a closure can be changed to any object:\nclass Person &#123;    String name&#125;class Thing &#123;    String name&#125;def p = new Person(name: &quot;Norman&quot;)def t = new Thing(name: &#x27;Teapot&#x27;)def upperCaseName = &#123; delegate.name.toUpperCase() &#125;// Then by changing the delegate of the closure, you can see that the target object will changeupperCaseName.delegate = passert upperCaseName() == &#x27;NORMAN&#x27;upperCaseName.delegate = tassert upperCaseName() == &#x27;TEAPOT&#x27;\n\nDelegation strategyWhenever, in a closure, a property is accessed without explicitly setting a receiver object, then a delegation strategy is involved:\nclass Person &#123;    String name&#125;def p = new Person(name: &#x27;Igor&#x27;)def cl = &#123; name.toUpperCase() &#125;     // `name` is not referencing a variable in the lexical scope of the closurecl.delegate = passert cl() == &#x27;IGOR&#x27;\n\nThe reason this code works is that ++the name property will be resolved transparently on the delegate object++!\nThere’s no need to set an explicit delegate. receiver: the call will be made because the default delegation strategy of the closure makes it so.\nA closure actually defines multiple resolution strategies that you can choose:\n\nClosure.OWNER_FIRST is the ++default strategy++. If a property&#x2F;method exists on the owner, then it will be called on the owner. If not, then the ++delegate++ is used.\nClosure.DELEGATE_FIRST reverses the logic: the ++delegate++ is used first, then the owner\nClosure.OWNER_ONLY will only resolve the property&#x2F;method lookup on the owner: the delegate will be ignored\nClosure.DELEGATE_ONLY will only resolve the property&#x2F;method lookup on the delegate: the owner will be ignored\nClosure.TO_SELF can be used by developers who need advanced meta-programming techniques and wish to implement a custom resolution strategy: the resolution will not be made on the owner or the delegate but only on the closure class itself. It makes only sense to use this if you implement your own subclass of Closure\n\nclass Person &#123;    String name    def    pretty = &#123; &quot;My name is $name&quot; &#125;    String toString() &#123; pretty() &#125;&#125;class Thing &#123;    String name&#125;def p = new Person(name: &#x27;Sarah&#x27;)def t = new Thing(name: &#x27;Teapot&#x27;)assert p.toString() == &#x27;My name is Sarah&#x27;p.pretty.delegate = tassert p.toString() == &#x27;My name is Sarah&#x27;           // there is no change in the result: `name` is first resolved on the `owner` of the closure. 因为默认是 OWNER_FIRST 策略p.pretty.resolveStrategy = Closure.DELEGATE_FIRST   // `name` will first be looked in the delegate, then if not found, on the owner. Since `name` is defined in the delegate, an instance of `Thing`, then this value is usedassert p.toString() == &#x27;My name is Teapot&#x27;\n","categories":["Groovy Object Orientation - Closures"],"tags":["Groovy","Object Orientation","Closures"]},{"title":"Groovy Closures Functional programming","url":"/groovy/object-orientation/closures/groovy-closures-functional-programming/","content":"\n\n\nGroovy Closures Functional programming\nCurrying\nLeft currying\nRight Currying\nIndex based currying\n\n\nMemoization\nComposition\nTrampoline\nMethod pointers\n\n\n\n\n\nGroovy Closures Functional programmingCurryingCurrying in Groovy will let you set the value of one parameter of a closure, and it will return a new closure accepting one less argument\nLeft curryingdef nCopies = &#123; int n, String str -&gt; str * n &#125;def twice = nCopies.curry(2)assert twice(&#x27;bla&#x27;) == &#x27;blabla&#x27;assert twice(&#x27;bla&#x27;) == nCopies(2, &#x27;bla&#x27;)\n\nRight Curryingdef nCopies = &#123; int n, String str -&gt; str * n &#125;def blah = nCopies.rcurry(&#x27;bla&#x27;)assert blah(2) == &#x27;blabla&#x27;assert blah(2) == nCopies(2, &#x27;bla&#x27;)\n\nIndex based curryingdef volume = &#123; double l, double w, double h -&gt; l * w * h &#125;def fixedWidthVolume = volume.ncurry(1, 2d)             // `ncurry` will set the second parameter (index = 1) to `2d`assert fixedWidthVolume(3d, 4d) == volume(3d, 2d, 4d)def fixedWidthAndHeight = volume.ncurry(1, 2d, 4d)      // it is possible to set multiple parameters, starting from the specified indexassert fixedWidthAndHeight(3d) == volume(3d, 2d, 4d)\n\nMemoization用于将 Closure 的计算结果进行缓存\n当一个 Closure 执行很缓慢当又被使用相同的入参经常执行，使用缓存就很有用\ndef fibfib = &#123; long n -&gt; n &lt; 2 ? n : fib(n-1)+fib(n-2) &#125;assert fib(15) == 610       // will be slow\n\n通过使用 memoize 方法来将 Closure 的执行结果缓存\ndef fibfib = &#123; long n -&gt; n &lt; 2 ? n : fib(n - 1) + fib(n - 2) &#125;.memoize()println fib(100)\n\nThe cache works using the actual values of the arguments\nThis means that you should be very careful if you use memoization with something else than primitive or boxed primitive types\nThe behavior of the cache can be tweaked using alternate methods:\n\nmemoizeAtMost will generate a new closure which caches ++at most++ n values\nmemoizeAtLeast will generate a new closure which caches ++at least++ n values\nmemoizeBetween will generate a new closure which caches ++at least++ n values and ++at most++ n values\n\nThe cache used in all memoize variants is a LRU cache\nComposition通过 chaining calls 将多个功能组合起来\ndef plus2  = &#123; it + 2 &#125;def times3 = &#123; it * 3 &#125;def times3plus2 = plus2 &lt;&lt; times3       // 从右往左的顺序执行assert times3plus2(3) == 11assert times3plus2(4) == plus2(times3(4))def plus2times3 = times3 &lt;&lt; plus2       // 从右往左的顺序执行assert plus2times3(3) == 15assert plus2times3(5) == times3(plus2(5))times3plus2 = times3 &gt;&gt; plus2           // 从左往右的顺序执行assert times3plus2(3) == 11\n\nTrampolinetrampoline : 蹦床, 弹床\n通过 Closure 的 trampoline 功能来避免递归调用次数过多导致的 StackOverflowException\n将 Closure 封装为 TrampolineClosure，在递归调用这个 trampolined Closure 的时候，原始的 Closure 会等待返回值直到返回值是一个实际的值（而不是一个 trampolined Closure）\ndef factorialfactorial = &#123; int n, def accu = 1G -&gt;    if (n &lt; 2) return accu    factorial.trampoline(n - 1, n * accu)&#125;factorial = factorial.trampoline()assert factorial(1)     == 1assert factorial(3)     == 1 * 2 * 3assert factorial(1000)  == ...\n\nMethod pointers通过 .&amp; 操作符来将一个普通方法创建成 Closure\n","categories":["Groovy Object Orientation - Closures"],"tags":["Groovy","Object Orientation","Closures"]},{"title":"Groovy Closures in GStrings","url":"/groovy/object-orientation/closures/groovy-closures-in-gstrings/","content":"Groovy Closures in GStringsA GString only evaluates lazily the toString representation of values\nThe syntax $&#123;x&#125; in a GString ++does not represent a closure++ but an expression to $&#123;x&#125; , evaluated when the GString is created\nIf you need a real closure in a GString and for example enforce lazy evaluation of variables, you need to use the alternate syntax $&#123;-&gt; x&#125; like in the fixed example:\ndef x = 1def gs = &quot;x = $&#123;-&gt; x&#125;&quot;assert gs == &#x27;x = 1&#x27;x = 2assert gs == &#x27;x = 2&#x27;\n\n通过使用 $&#123;-&gt; x&#125; 的形式，将 GString 变成动态求值的\n","categories":["Groovy Object Orientation - Closures"],"tags":["Groovy","Object Orientation","Closures"]},{"title":"Groovy Closures Parameters","url":"/groovy/object-orientation/closures/groovy-closures-parameters/","content":"Groovy Closures ParametersNormal parameters可以使用默认值:\ndef c = &#123; int a, int b = 2 -&gt; a+b &#125;assert c(1) == 3\n\nImplicit parameter当一个 Closure 没有使用 -&gt; 定义一个参数列表时，一个 Closure 就肯定会定义一个隐式参数，叫作 it\ndef greeting = &#123; &quot;Hello, $it!&quot; &#125;assert greeting(&#x27;lin&#x27;) == &#x27;Hello, lin!&#x27;\n\n如果要定义一个严格的没有入参的 Closure ，必须明确定义一个空的入参列表：\n使用 &#123; -&gt; &#125; 的形式\ndef magicNumber = &#123; -&gt; 42 &#125;magicNumber(1) // this call will fail\n\nVarargs可变长度参数\ndef concat = &#123; String... args -&gt; args.join(&#x27;&#x27;) &#125;assert concat1(&#x27;abc&#x27;, &#x27;def&#x27;) == &#x27;abcdef&#x27;def concat2 = &#123; String[] args -&gt; args.join(&#x27;&#x27;) &#125;assert concat2(&#x27;abc&#x27;, &#x27;def&#x27;) == &#x27;abcdef&#x27;def multiConcat = &#123; int n, String... args -&gt; args.join(&#x27;&#x27;) * n &#125;assert multiConcat(2, &#x27;abc&#x27;, &#x27;def&#x27;) == &#x27;abcdefabcdef&#x27;\n","categories":["Groovy Object Orientation - Closures"],"tags":["Groovy","Object Orientation","Closures"]},{"title":"Groovy Closures Syntax","url":"/groovy/object-orientation/closures/groovy-closures-syntax/","content":"Groovy Closures SyntaxDefining a closure&#123; [closureParameters -&gt;] statements &#125;\n\nClosures as an objectdef listener = &#123; e -&gt; println &quot;Clicked on $e.source&quot; &#125;assert listener instanceof ClosureClosure callback = &#123; println &#x27;Done!&#x27; &#125;Closure&lt;Boolean&gt; isTextFile = &#123;    File it -&gt; it.name.endsWith(&#x27;.txt&#x27;)&#125;\n\nCalling a closuredef code = &#123; 123 &#125;assert code() == 123assert code.call() == 123\n\nUnlike a method, a closure always returns a value when called:\ndef code = &#123;&#125;assert code() == null\n","categories":["Groovy Object Orientation - Closures"],"tags":["Groovy","Object Orientation","Closures"]},{"title":"Groovy GPath expressions","url":"/groovy/object-orientation/semantics/groovy-gpath-expressions/","content":"Groovy GPath expressionsGPath 是一个集成在 Groovy 的路径表达式语言(path expression language)，它允许辨识部分嵌入的结构化数据\nGPath 使用 dot-object 的符号来进行对象访问\na.b.c : for XML, yields all the c elements inside b inside a\na.b.c : for POJOS, yields the c properties for all the b properties of a (sort of like a.getB().getC() in JavaBeans)\n在使用 XmlParser 或 XmlSlurper 时，可以通过 @ 符号来访问 attributes：\n\na[&quot;@href&quot;]  : map-like notation, the href attribute of all the elemetns\na.&#39;@href&#39;   : property notation, an alternative way of expressing this\na.@href     : direct notation, yet another alternative way of expressing this\n\nObject navigation使用反射进行\nvoid aMethodFoo() &#123; println &quot;This is aMethodFoo.&quot; &#125;assert [&#x27;aMethodFoo&#x27;] == this.class.methods.name.grep(~/.*Foo/)\n\nvoid aMethodBar() &#123; println &quot;This is aMethodBar.&quot; &#125; void anotherFooMethod() &#123; println &quot;This is anotherFooMethod.&quot; &#125; void aSecondMethodBar() &#123; println &quot;This is aSecondMethodBar.&quot; &#125; assert [&#x27;aMethodBar&#x27;, &#x27;aSecondMethodBar&#x27;] as Set == this.class.methods.name.grep(~/.*Bar/) as Set\n\nExpression Deconstruction对 this.class.methods.name.grep(~/.*Bar/) 进行解构\nthis.class\nproperty accessor\nequivalent to this.getClass() in Java\nyield a Class object\n\nthis.class.methods\nproperty accessor\nequivalent to this.getClass().getMethods()\nyield ++an array++ of Method objects\n\nthis.class.methods.name\napply a property accessor on each element of an array\nproduce ++a list++ of the results\n\nthis.class.methods.name.grep(...)\ncall method grep on each element of the list\nproduce ++a list++ of the results\n\n一个很强大的特性是 GPath 表达式可以将一个集合类型的属性访问转换为对这个集合上所有元素的访问，并将结果保存到一个集合中\nOne powerful feature of GPath expression is that property access on a collection is converted to a property access on each element of the collection with the results collected into a collection.\n因此 this.class.methods.name 对应这样的 Java 代码：\nList&lt;String&gt; methodNames = new ArrayList&lt;String&gt;();for (Method method : this.getClass().getMethods()) &#123;    methodNames.add(method.getName());&#125;return methodNames;\n\n数组访问也可以用在 GPath 表达式中，当遇到一个集合的时候：\nassert &#x27;aSecondMethodBar&#x27; == this.class.methods.name.grep(~/.*Bar/).sort()[1]\n\n数组下标从 0 开始\n","categories":["Groovy Object Orientation - Semantics"],"tags":["Groovy","Object Orientation","Semantics"]},{"title":"Groovy Inheritance of state gotchas","url":"/groovy/object-orientation/traits/groovy-inheritance-of-state-gotchas/","content":"Groovy Inheritance of state gotchastrait IntCouple &#123;    int x = 1    int y = 2    int sum() &#123; x + y &#125;&#125;class BaseElem implements IntCouple &#123;    int f() &#123; sum() &#125;&#125;def base = new BaseElem()assert base.f() == 3assert base.sum() == 3\n\ntrait IntCouple &#123;    int x = 1    int y = 2    int sum() &#123; x + y &#125;&#125;class Elem implements IntCouple &#123;    int x = 3    int y = 4    int f() &#123; sum() &#125;&#125;def elem = new Elem()assert elem.f() == 3    // 使用 trait 中的 x 与 yassert elem.sum() == 3  // 使用 trait 中的 x 与 yassert elem.f() != 7    // 使用 trait 中的 x 与 yassert elem.sum() != 7  // 使用 trait 中的 x 与 y\n\ntrait IntCouple2 &#123;    int x = 1    int y = 2    int sum() &#123; getX() + getY() &#125;&#125;class Elem2 implements IntCouple2 &#123;    int x = 3    int y = 4    int f() &#123; sum() &#125;&#125;def elem2 = new Elem2()assert elem2.f() != 3       // 因为 getX() 和 getY() ，所以使用了 Elem2 中的 x 与 yassert elem2.sum() != 3     // 因为 getX() 和 getY() ，所以使用了 Elem2 中的 x 与 yassert elem2.f() == 7       // 因为 getX() 和 getY() ，所以使用了 Elem2 中的 x 与 yassert elem2.sum() == 7     // 因为 getX() 和 getY() ，所以使用了 Elem2 中的 x 与 y\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Self types","url":"/groovy/object-orientation/traits/groovy-self-types/","content":"Groovy Self typesThe @SelfType annotation为 Trait 添加类型限制，声明实现一个 Trait 的类必须实现或继承的类\n在编译时检查中不满足类型限制，将会抛出异常\nIn order to make this contract explict, and to make the type checker aware of the type of itself, Groovy provides a @SelfType annotation that will:\n\nlet you declare the types that a class that implements this trait must inherit or implement\nthrow a compile time error if those type constraints are not satisfied\n\n@SelfType(Device)   // implement Communicating 的类必须继承或实现 Device 类@CompileStatictrait Communicating &#123;    void sendMessage(Device to, String message) &#123;        SecurityService.check(this)        CommunicationService.sendMessage(id, to.id, message)    &#125;&#125;\n\nNow if you try to implement this trait on a class that is not a device, a compile-time error will occur:\nclass MyDevice implements Communicating &#123;&#125; // forgot to extend Device\n\nThe error will be:\nclass &#x27;MyDevice&#x27; implements trait &#x27;Communicating&#x27; but does not extend self type class &#x27;Device&#x27;\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy The meaning of this","url":"/groovy/object-orientation/traits/groovy-the-meaning-of-this/","content":"Groovy The meaning of thisthis 代表实现 trait 的实例\n将 trait 想成一个父类\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Advanced features","url":"/groovy/object-orientation/traits/groovy-traits-advanced-features/","content":"Groovy Traits Advanced featuresSAM type coercion如果 Trait 只有一个抽象方法，则可以直接通过 Closure 转换来实现抽象方法\ntrait Greeter &#123;    String greet() &#123; &quot;Hello $name&quot; &#125;    abstract String getName()&#125;Greeter g = &#123; &#x27;linweiyu&#x27; &#125;println g.greet()\n\ntrait Greeter &#123;    String greet() &#123; &quot;Hello $name&quot; &#125;    abstract String getName()&#125;def greetMethod(Greeter g) &#123; g.greet() &#125;def r = greetMethod &#123; &#x27;lin&#x27; &#125;println r\n\nDifferences with Java 8 default methodsclass Test &#123;    public static void main(String[] args) &#123;        Lin l = new Lin();        l.talk();    &#125;    public static class Person &#123;        void talk() &#123;System.out.println(&quot;Person talk&quot;);&#125;    &#125;    public static interface Talk &#123;        default void talk() &#123;System.out.println(&quot;Interface default Talk&quot;);&#125;    &#125;    public static class Lin extends Person implements Talk &#123;&#125;&#125;\n\n在以上的 Java 例子中，父类 Person 和 接口 Talk 都声明了 talk() 方法\n接口 Talk 中的 talk() 方法为默认方法，提供了实现\n类 Lin 继承了 类 Person ，实现了 接口 Talk\n类 Lin 无法通过编译：\nTest.java:15: 错误: Person中的talk()无法实现Talk中的talk()    public static class Lin extends Person implements Talk &#123;&#125;                  ^  正在尝试分配更低的访问权限; 以前为public1 个错误\n\n在 Groovy 中，可以使用 Trait 来绕过 父类 Person 的限制：\nabstract class Person &#123;    void talk() &#123; println &quot;Person talk&quot; &#125;&#125;trait Talk &#123;    void talk() &#123; println &quot;Interface default Talk&quot; &#125;&#125;class Lin extends Person implements Talk &#123;&#125;def l = new Lin()l.talk()\n\n输出：\nInterface default Talk\n\n经测试，将 Trait 替换为 Interface with default method ，也是可以的\nIn runtime traits, the methods from the trait are always preferred to those of the proxied objectclass Person &#123;    String name&#125;trait Bob &#123;    String getName() &#123; &#x27;Bob&#x27; &#125;&#125;def p = new Person(name: &#x27;Alice&#x27;)assert p.name == &#x27;Alice&#x27;def p2 = p as Bob           // p2 coercoes p into Bob at runtimeassert p2.name == &#x27;Bob&#x27;     // getName returns Bob because getName is taken from the trait\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Chaining behavior","url":"/groovy/object-orientation/traits/groovy-traits-chaining-behavior/","content":"Groovy Traits Chaining behavior通过在 Traits 中使用 super 关键字来代表下一个 Trait\ninterface MessageHandler &#123;    void on(String message, Map payload)&#125;trait DefaultHandler implements MessageHandler &#123;    void on(String message, Map payload) &#123;        println &quot;In DefaultHandler&quot;        println &quot;Received $message with payload $payload&quot;    &#125;&#125;trait LoggingHandler implements MessageHandler &#123;    void on(String message, Map payload) &#123;        println &quot;In LoggingHandler&quot;        super.on(message, payload)  // 调用下一个 Trait 的 on() 方法    &#125;&#125;class HandlerWithLogger implements DefaultHandler, LoggingHandler &#123;&#125;def loggingHander = new HandlerWithLogger()loggingHander.on(&#x27;test logging&#x27;, [name: &#x27;lin&#x27;])\n\nSemantics of super inside a traitIf a class implements multiple traits and a call to an unqualified super is found, then:\n\nif the class implements another trait, the call delegates to the next trait in the chain\nif there isn’t any trait left in the chain, super refers to the super class of the implementing class (this)\n\n就是如果 super 已经引用到继承链的最后一个时，super 就代表当前类\ntrait Filtering &#123;    StringBuilder append(String str) &#123;        def subst = str.replace(&#x27;o&#x27;, &#x27;&#x27;)        super.append(subst) // 在这个例子中，super 代表了 StringBuilder    &#125;    String toString() &#123; super.toString() &#125; // 在这个例子中，super 代表了 StringBuilder&#125;def sb = new StringBuilder().withTraits Filteringsb.append(&#x27;Groovy&#x27;)assert sb.toString() == &#x27;Grvy&#x27;\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Differences with mixins","url":"/groovy/object-orientation/traits/groovy-traits-differences-with-mixins/","content":"Groovy Traits Differences with mixinsTrait 中的方法在字节码中是可以见的\n在内部，Trait 是作为 Interface 处理的（不使用默认方法和静态方法的 Interface）\n这意味着 implement 一个 Trait 相当于 implement 一个 Interface\n这些 Trait 方法对 Java 可见\nMixin 的方法只有在运行时可见，并且不是以 implement 的形式获取到这些方法：\nclass A &#123;    String methodFromA() &#123; &#x27;A&#x27; &#125;&#125;class B &#123;    String methodFromB() &#123; &#x27;B&#x27; &#125;&#125;A.metaClass.mixin Bdef o = new A()assert o.methodFromA() == &#x27;A&#x27;assert o.methodFromB() == &#x27;B&#x27;assert o instanceof Aassert !(o instanceof B) // o 不是 B 的实例，虽然 o 有 B 的方法\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Duck typing and traits","url":"/groovy/object-orientation/traits/groovy-traits-duck-typing-and-traits/","content":"Groovy Traits Duck typing and traitsDynamic codeTraits 可以调用任何动态代码，像一个普通的 Groovy 类一样\n这意味着你可以在方法体中，调用一个应该存在于实现类的的方法，而不要用在接口中明确声明这个方法\ntrait SpeakingDuck &#123;    String speak() &#123; quack() &#125;&#125;class Duck implements SpeakingDuck &#123;    String methodMissing(String name, args) &#123;        &quot;$&#123;name.capitalize()&#125;!&quot;    &#125;&#125;def d = new Duck()assert d.speak() == &#x27;Quack!&#x27;\n\nDynamic methods in a trait可以在 Traits 中实现诸如 methodMissing，propertyMissing 的 MOP 方法\n实现类会从 Traits 中继承这些行为\ntrait DynamicObject &#123;    private Map props = [:]        def methodMissing(String name, args) &#123; name.toUpperCase() &#125;        def propertyMissing(String prop) &#123; props[prop] &#125;        void setProperty(String prop, Object value) &#123; props[prop] = value &#125;&#125;class Dynamic implements DynamicObject &#123;    String existingProperty = &#x27;ok&#x27;    String existingMethod() &#123; &#x27;ok&#x27; &#125;&#125;def d = new Dynamic()assert d.existingProperty == &#x27;ok&#x27;assert d.foo == nulld.foo = &#x27;bar&#x27;assert d.foo == &#x27;bar&#x27;assert d.existingMethod() == &#x27;ok&#x27;assert d.someMethod() == &#x27;SOMEMETHOD&#x27;\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Extending traits","url":"/groovy/object-orientation/traits/groovy-traits-extending-traits/","content":"Groovy Traits Extending traitsSimple inheritanceTraits 使用 extends 关键字来继承其他 trait\ntrait Named &#123;    String name&#125;trait Polite extends Named &#123;    String introduce() &#123; &quot;Hello, I am $name&quot; &#125;&#125;class Person implements Polite &#123;&#125;def p = new Person(name: &#x27;Alice&#x27;)assert p.introduce() == &#x27;Hello, I am Alice&#x27;\n\nMultiple inheritancetrait WithId &#123; Long id &#125;trait WithName &#123; String name &#125;trait Identified implements WithId, WithName &#123;&#125;\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Fields","url":"/groovy/object-orientation/traits/groovy-traits-fields/","content":"Groovy Traits FieldsPrivate fieldstrait Counter &#123;    private Integer count = 0    int count() &#123; count+=1; count &#125;&#125;class Person implements Counter &#123;&#125;def p1 = new Person()assert p1.count() == 1assert p1.count() == 2def p2 = new Person()assert p2.count() == 1assert p2.count() == 2\n\nPublic fieldsPublic fields work the same way as private fields\n为了避免 diamond problem ,字段名在实现类中被重映射\ntrait Named &#123;    public String name&#125;class Person implements Named &#123;&#125;def p = new Person()p.Named__name = &#x27;Bob&#x27;\n\n字段名取决于 trait 的全限定名\n包名中所有的 . 被替换为 _\n最后的名字包含一个 __\n如果字段类型为 String ，包名为 my.package ，trait 名为 Foo ，字段名为 bar，则在实现类中，这个 public field 的名称是: String my_package_Foo__bar\n不推荐在 Traits 中使用 public fields\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Gomposition of behaviors","url":"/groovy/object-orientation/traits/groovy-traits-gomposition-of-behaviors/","content":"Groovy Traits Gomposition of behaviorsTraits 可以用于实现多重继承\nclass Duck implements FlyingAbility, SpeakingAbility &#123;&#125;\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Interfaces","url":"/groovy/object-orientation/traits/groovy-traits-interfaces/","content":"Groovy Traits InterfacesTraits 可以实现接口\ninterface Named &#123;    String name()&#125;trait Greetable implements Named &#123;    String greeting() &#123; &quot;Hello, $&#123;name()&#125;!&quot; &#125;&#125;class Person implements Greetable &#123;    String name() &#123; &#x27;Bob&#x27; &#125;&#125;def p = new Person()assert p.greeting() == &#x27;Hello, Bob!&#x27;assert p instanceof Namedassert p instanceof Greetable\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Limitations","url":"/groovy/object-orientation/traits/groovy-traits-limitations/","content":"Groovy Traits LimitationsCompatibility with AST transformationsTraits 不是官方兼容 AST 转换\n像 @CompileStatic 会作用在 trait 本身，而不是作用在实现 trait 的类上\n但是有一些其他的 AST transformations 同时作用在 实现类 和 trait 上\nPrefix and postfix operations在 trait 中，在更新一个字段的情况下，前置操作符和后置操作符是不允许的\n使用 += 作为替代\ntrait Counting &#123;    int x    void inc() &#123;        x++         // x is defined within the trait, postfix increment is not allowed    &#125;    void dec() &#123;        --x         // x is defined within the trait, prefix decrement is not allowed    &#125;&#125;class Counter implements Counting &#123;&#125;def c = new Counter()c.inc()\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Methods","url":"/groovy/object-orientation/traits/groovy-traits-methods/","content":"Groovy Traits MethodsTraits 只支持 public 和 private 方法，protected 和 package private 都不支持\nPublic methodstrait FlyingAbility &#123;    String fly() &#123; &quot;I&#x27;m flying!&quot; &#125;&#125;\n\nAbstract methodstrait Greetable &#123;    abstract String name()    String greeting() &#123; &quot;Hello, $&#123;name()&#125;!&quot; &#125;&#125;class Person implements Greetable &#123;    String name() &#123; &quot;Bob&quot; &#125;&#125;def p = new Person()assert p.greeting() == &#x27;Hello, Bob!&#x27;\n\nPrivate methodstrait Greeter &#123;    private String greetingMessage() &#123;        &#x27;Hello from a private method!&#x27;    &#125;        String greet() &#123;        def m = greetingMessage()        println m        m    &#125;&#125;\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Multiple inheritance conflicts","url":"/groovy/object-orientation/traits/groovy-traits-multiple-inheritance-conflicts/","content":"Groovy Traits Multiple inheritance conflictsDefault conflict resolution如果多个 Trait 有相同的方法签名，那么同时继承这些 Trait 就会出现冲突\n默认的解决冲突行为是：在 implements 中最后一个声明的 Trait 胜出\nUser conflict resolution可以通过明确选择方法来调用你想要的 Trait 方法\nTrait.super.方法名\ntrait A &#123;    String exec() &#123; &#x27;A&#x27; &#125;               &#125;trait B &#123;    String exec() &#123; &#x27;B&#x27; &#125;               &#125;class C implements A,B &#123;    String exec() &#123; A.super.exec() &#125;&#125;def c = new C()assert c.exec() == &#x27;A&#x27;\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Overriding default methods","url":"/groovy/object-orientation/traits/groovy-traits-overriding-default-methods/","content":"Groovy Traits Overriding default methodsTraits 提供方法的默认实现，在实现类中可以重写这些方法\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Properties","url":"/groovy/object-orientation/traits/groovy-traits-properties/","content":"Groovy Traits PropertiesTraits 可以定义 Properties\ntrait Named &#123;    String name&#125;class Person implements Named &#123;&#125;def p = new Person(name: &#x27;Bob&#x27;)assert p.name == &#x27;Bob&#x27;assert p.getName() == &#x27;Bob&#x27;\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits Runtime implementation of traits","url":"/groovy/object-orientation/traits/groovy-traits-runtime-implementation-of-traits/","content":"Groovy Traits Runtime implementation of traitsImplementing a trait at runtimetrait Extra &#123;    String extra() &#123; &quot;I&#x27;m an extra method&quot; &#125;&#125;class Something &#123;    String doSomething() &#123; &#x27;Something&#x27; &#125;&#125;def s = new Something() as Extraprintln s.extra()println s.doSomething()\n\nImplementing multiple traits at once在对象上面使用 withTraits() 方法\ntrait A &#123; void walk() &#123; println &#x27;walk&#x27; &#125; &#125;trait B &#123; void eat() &#123; println &#x27;eat&#x27; &#125; &#125;class Person &#123;&#125;def p = new Person()def pt = p.withTraits A, Bpt.walk()pt.eat()\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Traits","url":"/groovy/object-orientation/traits/groovy-traits/","content":"Groovy TraitsTraits 是一种语言的结构化构造，允许：\n\n行为的组合\n运行时实现接口\n行为重载\n兼容静态类型检查&#x2F;编译\n\nTraits 可以看成是有默认实现和状态的接口\n一个 Trait 使用 trait 关键字来声明：\ntrait FlyingAbility &#123;    String fly() &#123; &quot;I&#x27;m flying!&quot; &#125;&#125;\n\n像使用普通接口一样，通过 implements 关键字来使用：\nclass Bird implements FlyingAbility &#123;&#125;def b = new Bird()assert b.fly() == &quot;I&#x27;m  flying!&quot;\n","categories":["Groovy Object Orientation - Traits"],"tags":["Groovy","Object Orientation","Traits"]},{"title":"Groovy Grape Advanced configuration","url":"/groovy/user-guides/dependency-management-with-grape/groovy-grape-advanced-configuration/","content":"Groovy Grape Advanced configurationRepository Directory配置仓库的目录，默认是 ~/.groovy.grapes\ngroovy -Dgrape.root=/repo/grapes yourscript.groovy\n\nCustomize Ivy settings配置 Ivy 的配置，通过创建 ~/.groovy/grapeConfig.xml 来指定配置\n如果这个文件不存在，则使用默认配置\n","categories":["Groovy User Guides - Dependency management with Grape"],"tags":["User Guides","Groovy","Dependency management with Grape"]},{"title":"Groovy Grape Command Line Tool","url":"/groovy/user-guides/dependency-management-with-grape/groovy-grape-command-line-tool/","content":"Groovy Grape Command Line Toolgrape install [-hv] &lt;group&gt; &lt;module&gt; [&lt;version&gt;] [&lt;classifier&gt;]\n\ngrape list\n\ngrape resolve [-adhisv] (&lt;groupId&gt; &lt;artifactId&gt; &lt;version&gt;)+\n\nresolve : 这将返回表示指定模块的工件和相应的可传递依赖项的JAR的文件位置\ngrape uninstall [-hv] &lt;group&gt; &lt;module&gt; &lt;version&gt;\n","categories":["Groovy User Guides - Dependency management with Grape"],"tags":["User Guides","Groovy","Dependency management with Grape"]},{"title":"Groovy Grape Detail","url":"/groovy/user-guides/dependency-management-with-grape/groovy-grape-detail/","content":"Groovy Grape DetailGrape follows the Ivy conventions for module version identification, with naming change.\n底层使用的是 Ivy\n\ngroup : 相当于 Maven 的 groupId\nmodule : 相当于 Maven 的 artifactId\nversion : 相当于 Maven 的 version\nclassifier : The optional classifier to use (for example, jdk15)\n\n下载好的依赖保存在 ~/.groovy/grapes 中\n","categories":["Groovy User Guides - Dependency management with Grape"],"tags":["User Guides","Groovy","Dependency management with Grape"]},{"title":"Groovy Grape Example","url":"/groovy/user-guides/dependency-management-with-grape/groovy-grape-example/","content":"Groovy Grape Example使用 Groovy templates 启动一个 Jetty 服务器\n@Grab(&#x27;org.eclipse.jetty.aggregate:jetty-server:8.1.19.v20160209&#x27;)@Grab(&#x27;org.eclipse.jetty.aggregate:jetty-servlet:8.1.19.v20160209&#x27;)@Grab(&#x27;javax.servlet:javax.servlet-api:3.0.1&#x27;)import org.eclipse.jetty.server.Serverimport org.eclipse.jetty.servlet.ServletContextHandlerimport groovy.servlet.TemplateServletdef runServer(duration) &#123;    def server = new Server(8080)    def context = new ServletContextHandler(        server,        &quot;/&quot;,        ServletContextHandler.SESSIONS    )    context.resourceBase = &quot;.&quot;    context.addServlet(TemplateServlet, &quot;*.gsp&quot;)    server.start()    sleep duration    server.stop()&#125;runServer(10000)\n\nEach time someone will hit http://localhost:8080/somepage.gsp, it will display the somepage.gsp template to the user — those template pages should be situated ++in the same directory as this server script++.\n","categories":["Groovy User Guides - Dependency management with Grape"],"tags":["User Guides","Groovy","Dependency management with Grape"]},{"title":"Groovy Grape Quick start","url":"/groovy/user-guides/dependency-management-with-grape/groovy-grape-quick-start/","content":"Groovy Grape Quick startAdd a DependencyGape 是一个内嵌在 Groovy 中的 JAR 依赖管理器\nGape 允许你快速添加 maven 仓库依赖到你的 classpath 上\n@Grab(group = &#x27;org.springframework&#x27;, module = &#x27;spring-orm&#x27;, version = &#x27;3.2.5.RELEASE&#x27;)import org.springframework.jdbc.core.JdbcTemplate\n\n简短的写法：\n@Grab(&#x27;org.springframework:spring-orm:3.2.5.RELEASE&#x27;)import org.springframework.jdbc.core.JdbcTemplate\n\n推荐在 import 上面使用 @Grab\nSpecify Additional Repositories指定 Maven 仓库\n@GrabResolver(name = &#x27;restlet&#x27;, root = &#x27;http://maven.restlet.org/&#x27;)@Grab(group = &#x27;org.restlet&#x27;, module = &#x27;org.restlet&#x27;, version = &#x27;1.1.6&#x27;)\n\nMavne Classifiers添加 classifiers\n@Grab(    group = &#x27;net.sf.json-lib&#x27;,    module = &#x27;json-lib&#x27;,    version = &#x27;2.2.3&#x27;,    classifier = &#x27;jdk15&#x27;)\n\nExcluding Transitive Dependencies排除可传递依赖项\n@Grab(&#x27;net.sourceforge.htmlunit:htmlunit:2.8&#x27;)@GrabExclude(&#x27;xml-apis:xml-apis&#x27;)\n\nJDBC Drivers必须配置 Grape 将 JDBC 驱动依赖绑定到系统 classloader 上\n@GrabConfig(systemClassLoader = true)@Grab(group = &#x27;mysql&#x27;, module = &#x27;mysql-connector-java&#x27;, version = &#x27;5.1.6&#x27;)\n\nUsing Grape From the Groovy ShellFrom groovysh use the method call variant:\ngroovy.grape.Grape.grab(group:&#x27;org.springframework&#x27;, module:&#x27;spring&#x27;, version:&#x27;2.5.6&#x27;)\n\nProxy settings代理配置\n可以在命令行中指定系统属性：\ngroovy -Dhttp.proxyHost=yourproxy -Dhttp.proxyPort=8080 yourscript.groovy\n\n或者你可以在 JAVA_OPTS 环境变量中配置变量：\nJAVA_OPTS = -Dhttp.proxyHost=yourproxy -Dhttp.proxyPort=8080\n\nLogging观察 Grape 在干什么，设置系统属性：\ngroovy.grape.report.downloads = true 或者 命令行参数&#x2F;JAVA_OPTS -Dgroovy.grape.report.downloads = true\nGrape 将会打印以下信息到 System.error 中：\n\nStarting resolve of a dependency\nStarting download of an artifact\nRetrying download of an artifact\nDownload size and time for downloaded artifacts\n\nTo log with even more verbosity, increase the Ivy log level (defaults to -1). For example -Divy.message.logger.level=4.\n","categories":["Groovy User Guides - Dependency management with Grape"],"tags":["User Guides","Groovy","Dependency management with Grape"]},{"title":"Groovy Grape Usage","url":"/groovy/user-guides/dependency-management-with-grape/groovy-grape-usage/","content":"Groovy Grape UsageAnnotationOne or more groovy.lang.Grab annotations can be added at any place that annotations are accepted to tell the compiler that this code relies on the specific library.\nMethod call通常，对grab的调用会在脚本或类初始化的早期发生\nimport groovy.grape.Grape// random maven libraryGrape.grab(group:&#x27;com.jidesoft&#x27;, module:&#x27;jide-oss&#x27;, version:&#x27;[2.2.0,)&#x27;)Grape.grab(    [        group: &#x27;org.apache.ivy&#x27;,        module: &#x27;ivy&#x27;,        version: &#x27;2.0.0-beta1&#x27;,        conf: [            &#x27;default&#x27;,            &#x27;optional&#x27;        ]    ],    [        group:&#x27;org.apache.ant&#x27;,        module:&#x27;ant&#x27;,        version:&#x27;1.7.0&#x27;    ])\n\ngrab(HashMap) Parameters\ngroup : 相当于 Maven 的 groupId\nmodule : 相当于 Maven 的 artifactId\nversion : 相当于 Maven 的 version\nclassifier : Maven 的 classifier\nconf : - &lt;String&gt;, default default’ - The configuration or scope of the module to download. The default conf is &#96;default: which maps to the maven runtime and master scopes.\nforce : &lt;boolean&gt;, defaults true - Used to indicate that this revision must be used in case of conflicts\nchanging : &lt;boolean&gt;, default false - Whether the artifact can change without its version designation changing\ntransitive : &lt;boolean&gt;, default true - Whether to resolve other dependencies this module has or not\n\nArguments Map arguments\nclassLoader: - &lt;GroovyClassLaoder&gt; or &lt;RootClassLoader&gt; - The ClassLoader to add resolved Jars to\n\nrefObject: - &lt;Object&gt; - The closest parent ClassLoader for the object’s class will be treated as though it were passed in as classLoader:\n\nvalidate: - &lt;boolean&gt;, default false - Should poms or ivy files be validated (true), or should we trust the cache (false).\n\nnoExceptions: - &lt;boolean&gt;, default false - If ClassLoader resolution or repository querying fails, should we throw an exception (false) or fail silently (true).\n\n\n","categories":["Groovy User Guides - Dependency management with Grape"],"tags":["User Guides","Groovy","Dependency management with Grape"]},{"title":"Groovy Default imports","url":"/groovy/user-guides/differences-with-java/groovy-default-imports/","content":"Groovy Default imports\njava.io.*\njava.lang.*\njava.math.BigDecimal\njava.math.BigInteger\njava.net.*\njava.util.*\ngroovy.lang.*\ngroovy.util.*\n\n","categories":["Groovy User Guides - Differences with Java"],"tags":["User Guides","Groovy","Differences with Java"]},{"title":"Groovy Multi-methods","url":"/groovy/user-guides/differences-with-java/groovy-multi-methods/","content":"Groovy Multi-methodsIn Groovy, the methods which will be invoked are chosen at runtime.\nThis is called runtime dispatch or multi-methods.\nIt means that the method will be chosen based on the types of the arguments at runtime.\nIn Java, this is the opposite: methods are chosen at compile time, based on the declared types.\nint method(String arg) &#123; return 1; &#125;int method(Object arg) &#123; return 2; &#125;Object o = &quot;Object&quot;;int result = method(o);\n\n在 Java 中，assertEquals(2, result);\n在 Groovy 中，assertEquals(1, result);\n","categories":["Groovy User Guides - Differences with Java"],"tags":["User Guides","Groovy","Differences with Java"]},{"title":"Groovy Packages scope visibility","url":"/groovy/user-guides/differences-with-java/groovy-packages-scope-visibility/","content":"Groovy Packages scope visibility在 Groovy 中，省略一个字段的修饰符不会使得这个字段编程 包私有 的（像 Java 中一样）\nclass Person &#123;    String name&#125;\n\n相反，这样将会创建一个属性（property），意味着一个 private field，一个对应的 getter，一个对应的 setter\n可以通过使用 @PackageScope 注解来创建一个 包私有 的字段：\nclass Person &#123;    @PackageScope String name&#125;\n","categories":["Groovy User Guides - Differences with Java"],"tags":["User Guides","Groovy","Differences with Java"]},{"title":"Groovy Builders CliBuilder","url":"/groovy/user-guides/domain-specific-languages/groovy-builders-clibuilder/","content":"\n\n\nGroovy Builders CliBuilder\nUsing Annotations and an interface\nUsing Annotations and an instance\nUsing Annotations and a script\nOptions with arguments\nSpecifying a type\nCustom parsing of the argument String\nOptions with multiple arguments\nTypes and multiple arguments\nSetting a default value\nUse with TypeChecked\n\n\n\n\n\nGroovy Builders CliBuilderdef cli = new CliBuilder(usage: &#x27;groovy Greeter [option]&#x27;)// specify parameterscli.a(longOpt: &#x27;audience&#x27;, args: 1, &#x27;greeting audience&#x27;)    // 1cli.h(longOpt: &#x27;help&#x27;, &#x27;display usage&#x27;)                     // 2// parse and process parametersdef options = cli.parse(args)if (options.h) cli.usage()else println &quot;Hello $&#123;options.a ? options.a : &#x27;World&#x27;&#125;&quot;\n\n1 : specify a -a option taking a single argument with an optional long variant --audience\n2 : specify a -h option taking no arguments with an optional long variant --help\nimport groovy.cli.commons.CliBuilderimport groovy.cli.commons.OptionAccessordef cli = new CliBuilder(usage: &quot;groovy Test [option]&quot;)cli.n(longOpt: &#x27;name&#x27;, args: 1, &#x27;你的名字&#x27;)cli.h(longOpt: &#x27;help&#x27;, &#x27;帮助&#x27;)OptionAccessor options = cli.parse(args)if (options.h) cli.usage()else println &quot;fuck you $&#123;options.n ? options.n : &#x27;ALL&#x27;&#125;&quot;\n\ngroovy Test helpusage: groovy Test [option] -h,--help         帮助 -n,--name &lt;arg&gt;   你的名字\n\ngroovy Test --name linweiyufuck you linweiyu\n\nThe following additonal properties are supported when specifying an allowed commandline option:\n\n\n\nName\nDescription\nType\n\n\n\nargName\nthe name of the argument for this option used in output\nString\n\n\nlongOpt\nthe long representation or long name of the option\nString\n\n\nargs\nthe number of argument values\nint or String\n\n\noptionalArg\nwhether the argument value is optional\nboolean\n\n\nrequired\nwhether the option is mandatory\nboolean\n\n\ntype\nthe type of this option\nClass\n\n\nvalueSeparator\nthe character that is the value separator\nchar\n\n\ndefaultValue\na default value\nString\n\n\nconvert\nconverts the incoming String to the required type\nClosure\n\n\nIf you have an option with only a longOpt variant, you can use the special shortname of _ to specify the option, e.g.: cli._(longOpt: &#39;verbose&#39;, &#39;enable verbose logging&#39;)\nUsing Annotations and an interfaceYou can provide an interface specification of the allowable options where annotations are used to indicate and provide details for those options and for how unprocessed parameters are handled.\nTwo annotations are used: groovy.cli.Option and groovy.cli.Unparsed\ninterface GreeterI &#123;    @Option(        shortName = &#x27;h&#x27;,        description = &#x27;display usage&#x27;    )    Boolean help()      // 1    @Option(        shortName = &#x27;a&#x27;,        description = &#x27;greeting audience&#x27;    )    String audience()   // 2    @Unparsed(        description = &quot;positional parameters&quot;    )    List remaining()&#125;\n\n1 : Specify a Boolean option set using -h or -help\n2 : Specify a String option set using a or --audience\ndef cli = new CliBuilder(usage: &#x27;groovy Greeter&#x27;)def argz = &#x27;--audience Groovylogist&#x27;.split()def options = cli.parseFromSpec(GreeterI, argz)assert options.audience() == &#x27;Groovylogist&#x27;argz = &#x27;-h Some Other Args&#x27;.split()options = cli.parseFromSpec(GreeterI, argz)assert options.help()assert options.remaining() == [&#x27;Some&#x27;, &#x27;Other&#x27;, &#x27;Args&#x27;]\n\nWhen parseFromSpec is called, CliBuilder automatically creates an instance implementing the interface and populates it.\nYou simply call the interface methods to interrogate(审讯) the option values\nUsing Annotations and an instanceclass GreeterC &#123;    @Option(        shortName = &#x27;h&#x27;,        description = &#x27;display usage&#x27;    )    Boolean help    private String audience    @Option(        shortName = &#x27;a&#x27;,        description = &#x27;greeting audience&#x27;    )    void setAudience(String audience) &#123;        this.audience = audience    &#125;    String getAudience() &#123; audience &#125;    @Unparsed(        description = &quot;positional parameters&quot;    )    List remaining()&#125;def cli = new CliBuilder(usage: &#x27;groovy Test [option]&#x27;)def options = new GreeterC()def argz = &#x27;--audience Groovologist foo&#x27;.split()cli.parseFromInstance(options, argz)assert options.audience == &#x27;Groovologist&#x27;assert options.remaining == [&#x27;foo&#x27;]\n\nUsing Annotations and a scriptHere is an example using those annotations in a self-contained script that would be called with the same arguments as shown for the instance example earlier:\n\ngroovy.transform.Field\ngroovy.cli.OptionField\ngroovy.cli.UnparsedField\n\nimport groovy.cli.OptionFieldimport groovy.cli.UnparsedField@OptionField String audience@OptionField Boolean help@UnparsedField List remainingnew CliBuilder().parseFromInstance(this, args)assert audience == &#x27;Groovologist&#x27;assert remaining == [&#x27;foo&#x27;]\n\nOptions with argumentsdef cli = new CliBuilder()cli.a(args: 0, &#x27;a arg&#x27;)cli.b(args: 1, &#x27;b arg&#x27;)cli.c(args: 1, optionalArg: true, &#x27;c arg&#x27;)def options = cli.parse(&#x27;-a -b foo -c bar baz&#x27;.split())assert options.a == true    // a 接受 0 个参数，是一个 flagassert options.b == &#x27;foo&#x27;   // b 就是一个普通的参数assert options.c == &#x27;bar&#x27;   // c 后面有一个参数，那么 c 就是接受一个参数的options = cli.parse(&#x27;-a -c -b foo bar baz&#x27;.split())assert options.a == trueassert options.c == true    // c 后面没有参数，所以作为一个 flagassert options.b == &#x27;foo&#x27;\n\ninterface WithArgI &#123;    @Option boolean a()    @Option String b()    @Options(optionalArg=true) String[] c()    @Unparsed List remaining()&#125;def cli = new CliBuilder()def options = cli.parseFromSpec(WithArgI, &#x27;-a -b foo -c bar baz&#x27;.split())assert options.a()assert options.b() == &#x27;foo&#x27;assert options.c() == [&#x27;bar&#x27;]assert options.remaining() == [&#x27;baz&#x27;]options = cli.parseFromSpec(WithArgsI, &#x27;-a -c -b foo bar baz&#x27;.split())assert options.a()assert options.c() == []assert options.b() == &#x27;foo&#x27;assert options.remaining() == [&#x27;bar&#x27;, &#x27;baz&#x27;]\n\nSpecifying a typedef argz = &#x27;&#x27;&#x27;-a John -b -d 21 -e 1980 -f 3.5 -g 3.14159 -h cv.txt -i DOWN and some more&#x27;&#x27;&#x27;.split()def cli = new CliBuilder()cli.a(type: String, &#x27;a-arg&#x27;)cli.b(type: boolean, &#x27;b-arg&#x27;)cli.c(type: Boolean, &#x27;c-arg&#x27;)cli.d(type: int, &#x27;d-arg&#x27;)cli.e(type: Long, &#x27;e-arg&#x27;)cli.f(type: Float, &#x27;f-arg&#x27;)cli.g(type: BigDecimal, &#x27;g-arg&#x27;)cli.h(type: File, &#x27;h-arg&#x27;)cli.i(type: RoundingMode, &#x27;i-arg&#x27;)def options = cli.parse(argz)assert options.a == &#x27;John&#x27;assert options.bassert !options.cassert options.d == 32assert options.e == 1980Lassert options.f == 3.5Fassert options.g == 3.14159assert options.h == new File(&#x27;cv.txt&#x27;)assert options.i == RoundingMode.DOWNassert options.arguments() == [&#x27;and&#x27;, &#x27;some&#x27;, &#x27;more&#x27;]\n\nThey are converted using StringGroovyMethods#asType(String, Class)\nCustom parsing of the argument Stringdef argz = &#x27;&#x27;&#x27;-a John -b Mary -d 2016-01-01 and some more&#x27;&#x27;&#x27;.split()def cli = new CliBuilder()def lower = &#123; it.toLowerCase() &#125;cli.a(convert: lower, &#x27;a-arg&#x27;)cli.b(convert: &#123;it.toUpperCase()&#125;, &#x27;b-arg&#x27;)cli.d(convert: &#123;Date.parse(&#x27;yyyy-MM-dd&#x27;, it)&#125;, &#x27;d-arg&#x27;)def options = cli.parse(argz)assert options.a == &#x27;john&#x27;assert options.b == &#x27;MARY&#x27;assert options.d.format(&#x27;dd-MM-yyyy&#x27;) == &#x27;01-01-2016&#x27;assert options.arguments() == [&#x27;and&#x27;, &#x27;some&#x27;, &#x27;more&#x27;]\n\ninterface WithConvertI &#123;    @Option(convert=&#123;it.toLowerCase()&#125;) String a()    @Option(convert=&#123;it.toUpperCase()&#125;) String b()    @Option(convert=&#123;Date.parse(&#x27;yyyy-MM-dd&#x27;, it)&#125;) Date d()    @Unparsed List remaining()&#125;Date newYears = Date.parse(&quot;yyyy-MM-dd&quot;, &quot;2016-01-01&quot;)def argz = &#x27;&#x27;&#x27;-a John -b Mary -d 2016-01-01 and some more&#x27;&#x27;&#x27;.split()def cli = new CliBuilder()def options = cli.parseFromSpec(WithConvertI, argz)assert options.a() == &#x27;john&#x27;assert options.b() == &#x27;MARY&#x27;assert options.d() == newYearsassert options.remaining() == [&#x27;and&#x27;, &#x27;some&#x27;, &#x27;more&#x27;]\n\nOptions with multiple argumentsdef cli = new CliBuilder()cli.a(args: 2, &#x27;a-arg&#x27;)cli.b(args: &#x27;2&#x27;, valueSeparator: &#x27;,&#x27;, &#x27;b-arg&#x27;)  // 1cli.c(args: &#x27;+&#x27;, valueSeparator: &#x27;,&#x27;, &#x27;c-arg&#x27;)  // 2def options = cli.parse(&#x27;-a 1 2 3 4&#x27;.split())   // 3assert options.a == &#x27;1&#x27;                         // 4assert options.as == [&#x27;1&#x27;, &#x27;2&#x27;]                 // 5assert options.arguments() == [&#x27;3&#x27;, &#x27;4&#x27;]options = cli.parse(&#x27;-a1 -a2 3&#x27;.split())        // 6assert options.as == [&#x27;1&#x27;, &#x27;2&#x27;]assert options.arguments() == [&#x27;3&#x27;]options = cli.parse([&#x27;-b1,2&#x27;])                  // 7assert options.bs == [&#x27;1&#x27;, &#x27;2&#x27;]options = cli.parse([&#x27;-c&#x27;, &#x27;1&#x27;])assert options.cs == [&#x27;1&#x27;]options = cli.parse([&#x27;-c1&#x27;])assert options.cs == [&#x27;1&#x27;]options = cli.parse([&#x27;-c1,2,3&#x27;])assert options.cs == [&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;]\n\n1 : Args value supplied as a String and comma value separator specified\n2 : One or more arguments are allowed\n3 : Two commandline parameters will be supplied as the ‘b’ option’s list of arguments\n4 : Access the ‘a’ option’s first argument\n5 : Access the ‘a’ option’s list of arguments\n6 : An alternative syntax for specifying two arguments for the ‘a’ option\n7 : The arguments to the ‘b’ option supplied as a comman-separated value\ninterface ValSepI &#123;    @Option(numberOfArguments=2) String[] a()    @Option(numberOfArgumentsString=&#x27;2&#x27;, valueSeparator=&#x27;,&#x27;) String[] b()    @Option(numberOfArgumentsString=&#x27;+&#x27;, valueSeparator=&#x27;,&#x27;) String[] c()    @Unparsed remaining()&#125;def cli = new CliBuilder()def options = cli.parseFromSpec(ValSepI, &#x27;-a 1 2 3 4&#x27;.split())assert options.a() == [&#x27;1&#x27;, &#x27;2&#x27;]assert options.remaining() == [&#x27;3&#x27;, &#x27;4&#x27;]options = cli.parseFromSpec(ValSepI, &#x27;-a1 -a2 3&#x27;.split())assert options.a() == [&#x27;1&#x27;, &#x27;2&#x27;]assert options.remaining() == [&#x27;3&#x27;]options = cli.parseFromSpec(ValSepI, [&#x27;-b1,2&#x27;] as String[])assert options.b() == [&#x27;1&#x27;, &#x27;2&#x27;]options = cli.parseFromSpec(ValSepI, [&#x27;-c&#x27;, &#x27;1&#x27;] as String[])assert options.c() == [&#x27;1&#x27;]options = cli.parseFromSpec(ValSepI, [&#x27;-c1&#x27;] as String[])assert options.c() == [&#x27;1&#x27;]options = cli.parseFromSpec(ValSepI, [&#x27;-c1,2,3&#x27;] as String[])assert options.c() == [&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;]\n\nTypes and multiple argumentsdef argz = &#x27;&#x27;&#x27;-j 3 4 5 -k1.5,2.5,3.5 and some more&#x27;&#x27;&#x27;.split()def cli = new CliBuilder()cli.j(args: 3, type: int[], &#x27;j-arg&#x27;)cli.k(args: &#x27;+&#x27;, valueSeparator: &#x27;,&#x27;, type: BigDecimal[], &#x27;k-arg&#x27;)def options = cli.parse(argz)assert options.js == [3, 4, 5] assert options.j == [3, 4, 5]  assert options.k == [1.5, 2.5, 3.5]assert options.arguments() == [&#x27;and&#x27;, &#x27;some&#x27;, &#x27;more&#x27;]\n\nSetting a default valuedef cli = new CliBuilder()cli.f longOpt: &#x27;from&#x27;, type: String, args: 1, defaultValue: &#x27;one&#x27;, &#x27;f option&#x27;cli.t longOpt: &#x27;to&#x27;, type: int, defaultValue: &#x27;35&#x27;, &#x27;t option&#x27;def options = cli.parse(&#x27;-f two&#x27;.split())assert options.hasOption(&#x27;f&#x27;)assert options.f == &#x27;two&#x27;assert !options.hasOption(&#x27;t&#x27;)assert options.t == 35options = cli.parse(&#x27;-t 45&#x27;.split())assert !options.hasOption(&#x27;from&#x27;)assert options.from == &#x27;one&#x27;assert options.hasOption(&#x27;to&#x27;)assert options.to == 45\n\ninterface WithDefaultValueI &#123;    @Option(shortName=&#x27;f&#x27;, defaultValue=&#x27;one&#x27;) String from()    @Option(shortName=&#x27;t&#x27;, defaultValue=&#x27;35&#x27;) int to()&#125;def cli = new CliBuilder()def options = cli.parseFromSpec(WithDefaultValueI, &#x27;-f two&#x27;.split())assert options.from() == &#x27;two&#x27;assert options.to() == 35options = cli.parseFromSpec(WithDefaultValueI, &#x27;-t 45&#x27;.split())assert options.from() == &#x27;one&#x27;assert options.to() == 45\n\nUse with TypeCheckedThe dynamic api style of using CliBuilder is inherently dynamic but you have a few options should you want to make use of ++Groovy’s static type checking capabilities++.\ninterface TypeCheckedI&#123;    @Option String name()    @Option int age()    @Unparsed List remaining()&#125;@TypeCheckedvoid testTypeCheckedInterface() &#123;    def argz = &quot;--name John --age 21 and some more&quot;.split()    def cli = new CliBuilder()    def options = cli.parseFromSpec(TypeCheckedI, argz)    String n = options.name()    int a = options.age()    assert n == &#x27;John&#x27; &amp;&amp; a == 21    assert options.remaining() == [&#x27;and&#x27;, &#x27;some&#x27;, &#x27;more&#x27;]&#125;def cli = new CliBuilder()TypedOption&lt;Integer&gt; age = cli.a(longOpt: &#x27;age&#x27;, type: Integer, &#x27;some age option&#x27;)def args = &#x27;--age 21&#x27;.split()def options = cli.parse(args)int a = options[age]assert a == 21\n\nimport groovy.cli.TypedOptionimport groovy.transform.TypeChecked@TypeCheckedvoid testTypeChecked() &#123;    def cli = new CliBuilder()    TypedOption&lt;String&gt; name = cli.option(String, opt: &#x27;n&#x27;, longOpt: &#x27;name&#x27;, &#x27;name option&#x27;)    TypedOption&lt;Integer&gt; age = cli.option(Integer, longOpt: &#x27;age&#x27;, &#x27;age option&#x27;)    def argz = &quot;--name John --age 21 and some more&quot;.split()    def options = cli.parse(argz)    String n = options[name]    int a = options[age]    assert n == &#x27;John&#x27; &amp;&amp; a == 21    assert options.arguments() == [&#x27;and&#x27;, &#x27;some&#x27;, &#x27;more&#x27;]&#125;\n","categories":["Groovy User Guides - Domain-Specific Languages"],"tags":["User Guides","Groovy","Domain-Specific Languages"]},{"title":"Groovy Builders","url":"/groovy/user-guides/domain-specific-languages/groovy-builders/","content":"\n\n\nGroovy Builders\nDOMBuilder\nNodeBuilder\nJsonBuilder\nStreamingJsonBuilder\n\n\n\n\n\nGroovy BuildersDOMBuilderA builder for parsing HTML, XHTML and XML into a W3C DOM tree.\nString recordsXML = &#x27;&#x27;&#x27;    &lt;records&gt;      &lt;car name=&#x27;HSV Maloo&#x27; make=&#x27;Holden&#x27; year=&#x27;2006&#x27;&gt;        &lt;country&gt;Australia&lt;/country&gt;        &lt;record type=&#x27;speed&#x27;&gt;Production Pickup Truck with speed of 271kph&lt;/record&gt;      &lt;/car&gt;      &lt;car name=&#x27;P50&#x27; make=&#x27;Peel&#x27; year=&#x27;1962&#x27;&gt;        &lt;country&gt;Isle of Man&lt;/country&gt;        &lt;record type=&#x27;size&#x27;&gt;Smallest Street-Legal Car at 99cm wide and 59 kg in weight&lt;/record&gt;      &lt;/car&gt;      &lt;car name=&#x27;Royale&#x27; make=&#x27;Bugatti&#x27; year=&#x27;1931&#x27;&gt;        &lt;country&gt;France&lt;/country&gt;        &lt;record type=&#x27;price&#x27;&gt;Most Valuable Car at $15 million&lt;/record&gt;      &lt;/car&gt;    &lt;/records&gt;&#x27;&#x27;&#x27;def reader = new StringReader(recordsXML)def doc = groovy.xml.DOMBuilder.parse(reader)def records = doc.documentElementuse(groovy.xml.dom.DOMCategory) &#123;    assert records.car.size() == 3&#125;\n\nNodeBuilderNodeBuilder is used for creating nested trees of Node objects for handling arbitrary data.\ndef nodeBuilder = new NodeBuilder()def userlist = nodeBuilder.userlist &#123;    user(id: &#x27;1&#x27;, firstname: &#x27;John&#x27;, lastname: &#x27;Smith&#x27;) &#123;        address(type: &#x27;home&#x27;, street: &#x27;1 Main St.&#x27;, city: &#x27;Springfield&#x27;, state: &#x27;MA&#x27;, zip: &#x27;12345&#x27;)        address(type: &#x27;work&#x27;, street: &#x27;2 South St.&#x27;, city: &#x27;Boston&#x27;, state: &#x27;MA&#x27;, zip: &#x27;98765&#x27;)    &#125;    user(id: &#x27;2&#x27;, firstname: &#x27;Alice&#x27;, lastname: &#x27;Doe&#x27;)&#125;assert userlist.user.@firstname.join(&#x27;, &#x27;) == &#x27;John, Alice&#x27;assert userlist.user.find &#123; it.@lastname == &#x27;Smith&#x27; &#125;.address.size() == 2\n\nJsonBuilderGroovy’s JsonBuilder makes it easy to create Json.\nJsonBuilder builder = new JsonBuilder()builder.records &#123;  car &#123;        name &#x27;HSV Maloo&#x27;        make &#x27;Holden&#x27;        year 2006        country &#x27;Australia&#x27;        record &#123;            type &#x27;speed&#x27;            description &#x27;production pickup truck with speed of 271kph&#x27;        &#125;  &#125;&#125;String json = JsonOutput.prettyPrint(builder.toString())\n\nUsing JsonUnit to check that the builder produced the expected result:\nJsonAssert.assertJsonEquals(json, carRecords)\n\nIf you need to customize the generated output you can pass a JsonGenerator instance when creating a JsonBuilder:\nimport groovy.json.*def generator = new JsonGenerator.Options()        .excludeNulls()        .excludeFieldsByName(&#x27;make&#x27;, &#x27;country&#x27;, &#x27;record&#x27;)        .excludeFieldsByType(Number)        .addConverter(URL) &#123; url -&gt; &quot;http://groovy-lang.org&quot; &#125;        .build()JsonBuilder builder = new JsonBuilder(generator)builder.records &#123;  car &#123;        name &#x27;HSV Maloo&#x27;        make &#x27;Holden&#x27;        year 2006        country &#x27;Australia&#x27;        homepage new URL(&#x27;http://example.org&#x27;)        record &#123;            type &#x27;speed&#x27;            description &#x27;production pickup truck with speed of 271kph&#x27;        &#125;  &#125;&#125;assert builder.toString() == &#x27;&#123;&quot;records&quot;:&#123;&quot;car&quot;:&#123;&quot;name&quot;:&quot;HSV Maloo&quot;,&quot;homepage&quot;:&quot;http://groovy-lang.org&quot;&#125;&#125;&#125;&#x27;\n\nStreamingJsonBuilderStreamingJsonBuilder directly streams to a writer without any intermediate memory data structure. If you do not need to modify the structure and want a more memory-efficient approach, use StreamingJsonBuilder.\nStringWriter writer = new StringWriter()StreamingJsonBuilder builder = new StreamingJsonBuilder(writer)builder.records &#123;    car &#123;        name &#x27;HSV Maloo&#x27;        make &#x27;Holden&#x27;        year 2006        country &#x27;Australia&#x27;        record &#123;            type &#x27;speed&#x27;            description &#x27;production pickup truck with speed of 271kph&#x27;        &#125;    &#125;&#125;String json = JsonOutput.prettyPrint(writer.toString())JsonAssert.assertJsonEquals(json, carRecords)\n\ndef generator = new JsonGenerator.Options()        .excludeNulls()        .excludeFieldsByName(&#x27;make&#x27;, &#x27;country&#x27;, &#x27;record&#x27;)        .excludeFieldsByType(Number)        .addConverter(URL) &#123; url -&gt; &quot;http://groovy-lang.org&quot; &#125;        .build()StringWriter writer = new StringWriter()StreamingJsonBuilder builder = new StreamingJsonBuilder(writer, generator)builder.records &#123;    car &#123;        name &#x27;HSV Maloo&#x27;        make &#x27;Holden&#x27;        year 2006        country &#x27;Australia&#x27;        homepage new URL(&#x27;http://example.org&#x27;)        record &#123;            type &#x27;speed&#x27;            description &#x27;production pickup truck with speed of 271kph&#x27;        &#125;    &#125;&#125;assert writer.toString() == &#x27;&#123;&quot;records&quot;:&#123;&quot;car&quot;:&#123;&quot;name&quot;:&quot;HSV Maloo&quot;,&quot;homepage&quot;:&quot;http://groovy-lang.org&quot;&#125;&#125;&#125;&#x27;\n","categories":["Groovy User Guides - Domain-Specific Languages"],"tags":["User Guides","Groovy","Domain-Specific Languages"]},{"title":"Groovy Command chains","url":"/groovy/user-guides/domain-specific-languages/groovy-command-chains/","content":"Groovy Command chainsAllowing us to chain such parentheses-free method calls, requiring neither parenthese around arguments, nor dots between the chained calls\n允许我们将没有括号的方法链接起来，不需要括号包裹入参，不需要使用点号\nThis also works with multiple arguments, closure arguments, and even named arguments\n还可以和多参数方法，Closure 参数方法，甚至命名参数方法一起工作\n// equivalent to: turn(left).then(right)turn left then right// equivalent to: take(2.pills).of(chloroquinine).after(6.hours)take 2.pills of chloroquinine after 6.hours// equivalent to: paint(wall).with(red, green).and(yellow)paint wall with red, green and yellow// with named parameters too// equivalent to: check(that: margarita).tastes(good)check that: margarita tastes good// with closures as parameters// equivalent to: given(&#123;&#125;).when(&#123;&#125;).then(&#123;&#125;)given &#123; &#125; when &#123; &#125; then &#123; &#125;\n\nIt is also possible to use methods in the chain which take no arguments, but in that case, the parentheses are needed\n还可以在链式命令中使用没有入参的方法，但是这个无入参的方法的括号不能省略\n// equivalent to: select(all).unique().from(names)select all unique() from names\n\nIf your command chain contains an odd number of elements, the chain will be composed of method&#x2F;arguments, and will finish by a final property access\n如果你的 command chain 包含奇数个元素，command chain 可以组合方法&#x2F;参数，然后使用一个属性访问作为结束\n// equivalent to: take(3).cookies// and also this: take(3).getCookies()take 3 cookies\n\nshow = &#123; println it &#125;square_root = &#123; Math.sqrt(it)&#125;def please(action) &#123;    [        the: &#123; what -&gt;            [                of: &#123; n-&gt;                    action(what(n))                &#125;            ]        &#125;    ]&#125;// equivalent to: please(show).the(square_root).of(100)please show the square_root of 100\n\n\nplease show : 等价于 please(action)，action 为一个 Closure， 返回一个 Map\n这个 Map 的 key 为 the ，value 为一个 Closure\n这个 Closure 接受一个参数 what ，返回一个 Map\n这个 Map 的 key 为 of ，value 为一个 Closure，接收一个参数 n\naction(what(n))\n\n@Grab(&#x27;com.google.guava:guava:r09&#x27;)import com.google.common.base.*def result = Splitter.on(&#x27;,&#x27;)                        .trimResults(CharMatcher.is(&#x27;_&#x27; as char))                        .split(&quot;_a ,_b_ ,c__&quot;)                        .iterator()                        .toList()// 先定义一个帮助类def split(string) &#123;    [on: &#123; sep -&gt;        [trimming: &#123; trimChar -&gt;            Splitter.on(sep)                    .trimResults(CharMatcher.is(trimChar as char))                    .split(string)                    .iterator()                    .toList()        &#125;]    &#125;]&#125;result = split &quot;_a ,_b_ ,c__&quot; on &#x27;,&#x27; trimming &#x27;_\\&#x27;\n","categories":["Groovy User Guides - Domain-Specific Languages"],"tags":["User Guides","Groovy","Domain-Specific Languages"]},{"title":"Groovy @DelegatesTo","url":"/groovy/user-guides/domain-specific-languages/groovy-delegatesto/","content":"Groovy @DelegatesTo如果要实现如下 DSL 功能：\nemail &#123;    from &#x27;dsl-guru@mycompany.com&#x27;    to &#x27;john.doe@waitaminute.com&#x27;    subject &#x27;The pope has resigned!&#x27;    body &#123;        p &#x27;Really, the pope has resigned!&#x27;    &#125;&#125;\n\nclass EmailSpec &#123;    void from(String from)          &#123; println &quot;From: $from&quot; &#125;    void to(String... to)           &#123; println &quot;To: $to&quot; &#125;    void subject(String subject)    &#123; println &quot;Subject: $subject&quot; &#125;    void body(Closure body) &#123;        def bodySpec = new BodySpec()        def code = body.rehydrate(bodySpec, this, this)        code.resolveStrategy = Closure.DELEGATE_ONLY        code()    &#125;&#125;def email(@DelegatesTo(strategy = Closure.DELEGATE_ONLY, value = EmailSpec) Closure cl) &#123;    def email = new EmailSpec()    def code = cl.rehydrate(email, this, this)    code.resolveStrategy = Closure.DELEGATE_ONLY    code()&#125;@TypeCheckedvoid doEmail() &#123;    email &#123;        from &#x27;dsl-guru@mycompany.com&#x27;        to &#x27;john.doe@waitaminute.com&#x27;        subject &#x27;The pope has resigned!&#x27;        body &#123;            p &#x27;Really, the pope has resigned!&#x27;        &#125;    &#125;&#125;\n","categories":["Groovy User Guides - Domain-Specific Languages"],"tags":["User Guides","Groovy","Domain-Specific Languages"]},{"title":"Groovy FileTreeBuilder","url":"/groovy/user-guides/domain-specific-languages/groovy-filetreebuilder/","content":"Groovy FileTreeBuildersrc/ |--- main |     |--- groovy |            |--- Foo.groovy |--- test       |--- groovy              |--- FooTest.groovy\n\n生成如上的目录结构\ntmpDir = File.createTempDir()def fileTreeBuilder = new FileTreeBuilder(tmpDir)fileTreeBuilder.dir(&#x27;src&#x27;) &#123;    dir(&#x27;main&#x27;) &#123;        dir(&#x27;groovy&#x27;) &#123;            file(&#x27;Foo.groovy&#x27;, &#x27;println &quot;Hello&quot;&#x27;)        &#125;    &#125;    dir(&#x27;test&#x27;) &#123;        dir(&#x27;groovy&#x27;) &#123;            file(&#x27;FooTest.groovy&#x27;, &#x27;class FooTest extends groovy.test.GroovyTestCase &#123;&#125;&#x27;)        &#125;    &#125;&#125;\n\nFileTreeBuilder also supports a shorthand syntax:\ntmpDir = File.createTempDir()def fileTreeBuilder = new FileTreeBuilder(tmpDir)fileTreeBuilder.src &#123;    main &#123;        groovy &#123;            &#x27;Foo.groovy&#x27;(&#x27;println &quot;Hello&quot;&#x27;)        &#125;    &#125;    test &#123;        groovy &#123;            &#x27;FooTest.groovy&#x27;(&#x27;class FooTest extends groovy.test.GroovyTestCase &#123;&#125;&#x27;)        &#125;    &#125;&#125;\n","categories":["Groovy User Guides - Domain-Specific Languages"],"tags":["User Guides","Groovy","Domain-Specific Languages"]},{"title":"Groovy ObjectGraphBuilder","url":"/groovy/user-guides/domain-specific-languages/groovy-objectgraphbuilder/","content":"Groovy ObjectGraphBuilderIt is in particular useful for creating test data.\npackage com.acmeclass Company &#123;    String name    Address address    List employees = []&#125;class Address &#123;    String line1    String line2    int zip    String state&#125;class Employee &#123;    String name    int employeeId    Address address    Company company&#125;\n\nThen using ObjectGraphBuilder building a Company with three employees is as easy as:\ndef builder = new ObjectGraphBuilder()builder.classLoader = this.class.classLoaderbuilder.classNameResolver = &quot;com.acme&quot;def acme = builder.company(name: &#x27;ACME&#x27;) &#123;    3.times &#123;        employee(id: it.toString(), name: &quot;Drone $it&quot;) &#123;            address(line1: &quot;Post street&quot;)        &#125;    &#125;&#125;assert acme != nullassert acme instanceof Companyassert acme.name == &#x27;ACME&#x27;assert cme.employees.size() == 3def employee = acme.employees[0]assert employee instanceof Employeeassert employee.name == &#x27;Drone 0&#x27;assert emppoyee.address instanceof Address\n\nBuild a class which is immutable:\n@Immutableclass Person &#123;    String name    int age&#125;builder.newInstanceResolver = &#123; Class klazz, Map attributes -&gt;    if (klazz.getConstructor(Map)) &#123;        def o = klazz.newInstance(attributes)        attributes.clear()        return o    &#125;    klazz.newInstance()&#125;def person = builder.person(name:&#x27;Jon&#x27;, age:17)\n","categories":["Groovy User Guides - Domain-Specific Languages"],"tags":["User Guides","Groovy","Domain-Specific Languages"]},{"title":"Groovy Operator overloading","url":"/groovy/user-guides/domain-specific-languages/groovy-operator-overloading/","content":"Groovy Operator overloading\n\n\nOperator\nMethod\n\n\n\na + b\na.plus(b)\n\n\na - b\na.minus(b)\n\n\na * b\na.multiply(b)\n\n\na ** b\na.power(b)\n\n\na &#x2F; b\na.div(b)\n\n\na % b\na.mod(b)\n\n\na\nb\n\n\na &amp; b\na.and(b)\n\n\na ^ b\na.xor(b)\n\n\na++ or\n++a a.next()\n\n\na– or\n–a a.previous()\n\n\na[b]\na.getAt(b)\n\n\na[b] &#x3D; c\na.putAt(b, c)\n\n\na &lt;&lt; b\na.leftShift(b)\n\n\na &gt;&gt; b\na.rightShift(b)\n\n\na &gt;&gt;&gt; b\na.rightShiftUnsigned(b)\n\n\nswitch(a) { case(b) : }\nb.isCase(a)\n\n\nif(a)\na.asBoolean()\n\n\n~a\na.bitwiseNegate()\n\n\n-a\na.negative()\n\n\n+a\na.positive()\n\n\na as b\na.asType(b)\n\n\na &#x3D;&#x3D; b\na.equals(b)\n\n\na !&#x3D; b\n! a.equals(b)\n\n\na &lt;&#x3D;&gt; b\na.compareTo(b)\n\n\na &gt; b\na.compareTo(b) &gt; 0\n\n\na &gt;&#x3D; b\na.compareTo(b) &gt;&#x3D; 0\n\n\na &lt; b\na.compareTo(b) &lt; 0\n\n\na &lt;&#x3D; b\na.compareTo(b) &lt;&#x3D; 0\n\n\n","categories":["Groovy User Guides - Domain-Specific Languages"],"tags":["User Guides","Groovy","Domain-Specific Languages"]},{"title":"Groovy Data and objects","url":"/groovy/user-guides/groovy-development-kit/groovy-data-and-objects/","content":"Groovy Data and objectsYou could serialize data into a file and deserialize it using this code:\nboolean b = trueString message = &#x27;Hello from Groovy&#x27;// Serialize data into a filefile.withDataOutputStream &#123; out -&gt;    out.writeBoolean(b)    out.writeUTF(message)&#125;// Then read it backfile.withDataInputStream &#123; input -&gt;    assert input.readBoolean()  == b    assert input.readUTF()      == message&#125;\n\nAnd similarity, if the data you want to serialize implements the Serializable interface, you can proceed with an object output stream:\nPerson p = new Person(name: &#x27;Bob&#x27;, age: 38&#x27;)// Serialize data into a filefile.withObjectOutputStream &#123; out -&gt;    out.writeObject(p)&#125;// Then read it backfile.withObjectInputStream &#123; input -&gt;     def p2 = input.readObject()    assert p2.name == p.name    assert p2.age  == p.age&#125;\n","categories":["Groovy User Guides - Groovy Development Kit"],"tags":["User Guides","Groovy","Groovy Development Kit"]},{"title":"Groovy Executing External Processes","url":"/groovy/user-guides/groovy-development-kit/groovy-executing-external-processes/","content":"Groovy Executing External ProcessesGroovy provides a simple way to execute command line processes\nSimple write the commond line as a string ane call the execute() method\ndef process = &quot;ls -l&quot;.execute()println &quot;Found text $&#123;process.text&#125;&quot;\n\nThe execute() method returns a java.lang.Process instance which will subsequently(随后) allow the in&#x2F;out&#x2F;err streams to be processed and the exit value from the process to be inspected(检查) etc\ndef process = &quot;ls -l&quot;.execute()process.in.eachLine &#123; line -&gt;    println line&#125;\n\nIt is worth noting that in corresponds to an input stream to the standard output of the command.\nout will refer to a stream where you can send data to the process (its standard input).\nAlso, because this functionality currently makes use of java.lang.Process undercover, the deficiencies(缺陷) of that class must be taken into consideration.\nIn particular, the javadoc for this class says:\n\nBecause some native platforms only provide limited buffer size for standard input and out streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, and even deadlock\n\nBecause of this, Groovy provides some additional helper methods which make stream handling for precess easier.\nHere is how to gobble(狼吞虎咽) all of the output (including the error stream output) from your process:\ndef p = &quot;rm -f foo.tmp&quot;.execute([], tmpDir)p.consumeProcessOutput()p.waitFor()\n\nThera are also variations of consumeProcessOutput that make use of StringBuffer, InputStream, OutputStream etc…\nIn addition, these is a pipTo command (mapped to | to allow overloading) which lets the output stream of one process be fed into the input stream of another process:\n// Pipes in actionproc1 = &#x27;ls&#x27;.execute()proc2 = &#x27;tr -d o&#x27;.execute()proc3 = &#x27;tr -d e&#x27;.execute()proc4 = &#x27;tr -d i&#x27;.execute()proc1 | proc2 | proc3 | proc4proc4.waitFor()if (proc4.exitValue()) &#123;    println proc4.err.text&#125; else &#123;    println proc4.text&#125;\n\n// Consuming errorsdef sout = new StringBuilder()def serr = new StringBuilder()proc2 = &#x27;tr -d o&#x27;.execute()proc3 = &#x27;tr -d e&#x27;.execute()proc4 = &#x27;tr -d i&#x27;.execute()proc4.consumeProcessOutput(sout, serr)proc2 | proc3 | proc4[proc2, proc3].each &#123; it.consumeProcessErrorStream(serr) &#125;proc2.withWriter &#123; writer -&gt;    writer &lt;&lt; &#x27;testfile.groovy&#x27;&#125;proc4.waitForOrKill(1000)println &quot;Standard output: $sout&quot;println &quot;Standard error: $serr&quot;\n","categories":["Groovy User Guides - Groovy Development Kit"],"tags":["User Guides","Groovy","Groovy Development Kit"]},{"title":"Groovy Iterating on a list","url":"/groovy/user-guides/groovy-development-kit/groovy-iterating-on-a-list/","content":"Groovy Iterating on a list通常用 each 和 eachWithIndex 方法\n[1, 2, 3].each &#123;    println &quot;Item: $it&quot;&#125;[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;].eachWithIndex &#123; it, i -&gt;    println &quot;$i: $it&quot;&#125;\n\nMapping, is done in Groovy thanks to the collect method:\nassert [1, 2, 3].collect &#123; it * 2 &#125; == [2, 4, 6]// shortcut syntax instead of collectassert [1, 2, 3]*.multiply(2) == [1, 2, 3].collect &#123; it.multiply(2) &#125;// it is possible to give `collect` the list which collects the elementsdef list = [0]assert [1, 2, 3].collect(list) &#123; it * 2 &#125; == [0, 2, 4, 6]assert list == [0, 2, 4, 6]\n","categories":["Groovy User Guides - Groovy Development Kit"],"tags":["User Guides","Groovy","Groovy Development Kit"]},{"title":"Groovy List literals","url":"/groovy/user-guides/groovy-development-kit/groovy-list-literals/","content":"Groovy List literalsassert [1, 2, 3, 4, 5][-1] == 5         // use negative indices to count from the endassert [1, 2, 3, 4, 5][-2] == 4         // use negative indices to count from the endassert [1, 2, 3, 4, 5].getAt(-2) == 4   // getAt() available with negative indextry &#123;    [1, 2, 3, 4, 5].get(-2)             // but negative index not allowed with get()&#125; catch (e) &#123;    assert e instanceof IndexOutOfBoundsException&#125;\n","categories":["Groovy User Guides - Groovy Development Kit"],"tags":["User Guides","Groovy","Groovy Development Kit"]},{"title":"Groovy Ranges","url":"/groovy/user-guides/groovy-development-kit/groovy-ranges/","content":"Groovy Ranges使用 .. 定义的 Range 包含左右两端的值\n使用 ..&lt; 定义的 Range 不包含右端的值\ndef range = 5..8assert range.size() == 4assert range.get(2) == 7assert range[2] == 7assert range instanceof java.util.Listassert range.contains(5)assert range.contains(8)range = 5..&lt;8assert range.size() == 3assert range.get(2) == 7assert range[2] == 7assert range instanceof java.util.Listassert range.contains(5)assert !range.contains(8)// get the end points of the range without using indexesrange = 1..10assert range.from == 1assert range.to == 10range = 1..&lt;10assert range.from == 1assert range.to == 9\n\nRange 的实现非常高效，创建了一个轻量级的 Java 对象，只包含起始值和结束值\nRange 相当于实现了 java.lang.Comparable 接口的 Java 对象，能够进行比较操作\nRange 还实现了 next() 和 previous() 方法去返回下一个&#x2F;上一个元素\n可以从 String 中创建 Range:\ndef range = &#x27;a&#x27;..&#x27;d&#x27;assert range.size() == 4assert range.get(2) == &#x27;c&#x27;assert range[2] == &#x27;c&#x27;assert range instanceof java.util.Listassert range.contains(&#x27;a&#x27;)assert !range.contains(&#x27;e&#x27;)\n\n可以在经典 for 上迭代访问 Range:\nfor (i in 1..10) &#123;    println &quot;Hello $&#123;i&#125;&quot;&#125;\n\n也可以使用 Range 上的 each() 方法进行迭代访问：\n(1..10).each &#123; i -&gt; println &quot;Hello $&#123;i&#125;&quot; &#125;\n\nRange 也可用于 switch 表达式:\nswitch(years) &#123;    case 1..10  : interestRate = 0.076; break;    case 11..25 : interestRate = 0.052; break;    default     : interestRate = 0.037;&#125;\n","categories":["Groovy User Guides - Groovy Development Kit"],"tags":["User Guides","Groovy","Groovy Development Kit"]},{"title":"Groovy Reading files","url":"/groovy/user-guides/groovy-development-kit/groovy-reading-files/","content":"Groovy Reading filesnew File(baseDir, &#x27;haiku.txt&#x27;).eachLine &#123; line -&gt;     println line&#125;\n\nnew File(baseDir, &#x27;haiku.txt&#x27;).eachLine &#123; line, nb -&gt;    println &quot;Line $nb: $line&quot;&#125;\n\nIf for whatever reason an exception is thrown in the eachLine body, the method makes sure that the resource is properly closed.\nThis is true for all I&#x2F;O resource methods that Groovy adds.\nFor example in some cases you will prefer to use a Reader, but still benefit from the automic resource management from Groovy.\nIn the next example, the reader will be closed even if the exception occurs:\ndef count = 0, MAXSIZE = 3new File(baseDir, &quot;haiku.txt&quot;).withReader &#123; reader -&gt;    while (reader.readLine()) &#123;        if (++count &gt; MAXSIZE) &#123;            throw new RuntimeException(&#x27;Haiku should only have 3 verses&#x27;)        &#125;    &#125;&#125;\n\ndef list = new File(baseDir, &#x27;haiku.txt&#x27;).collect &#123;it&#125;\n\ndef array = new File(baseDir, &#x27;haiku.txt&#x27;) as String[]\n\nbyte[] contents = file.bytes\n\nUsing input&#x2F;output streams:\ndef is = new File(baseDir, &#x27;haiku.txt&#x27;).withInputStream &#123; stream -&gt;    // do something&#125;\n\nIn Groovy it is in general a better idea to use the withInputStream idiom that will take care of that for you\n","categories":["Groovy User Guides - Groovy Development Kit"],"tags":["User Guides","Groovy","Groovy Development Kit"]},{"title":"Groovy Traversing file trees","url":"/groovy/user-guides/groovy-development-kit/groovy-traversing-file-trees/","content":"Groovy Traversing file trees在文件树中搜索指定的文件进行处理\nYou can perform something on all files of a directory\ndir.eachFile &#123; file -&gt;    println file.name&#125;dir.eachFileMatch(~/.*\\.txt/) &#123; file -&gt;    println file.name&#125;\n\nOften you will have to deal with a deeper hierarchy of files, in which case you use eachFileRecurse:\ndir.eachFileRecurse &#123; file -&gt;    println file.name&#125;dir.eachFileRecurse(FileType.FILES) &#123; file -&gt;    println file.name&#125;\n\nFor more complex traversal techniques you can use the traverse method, which requires you to set a special flag indicating what to do with the traversal:\ndir.traverse &#123; file -&gt;     if (file.directory &amp;&amp; file.name == &#x27;bin&#x27;) &#123;        FileVisitResult.TERMINATE   // 1    &#125; else &#123;        pringln file.name        FileVisitResult.CONTINUE    // 2    &#125;&#125;\n\n1 : if the current file is a directory and its name is bin, stop the traversal\n2 : otherwise print the file name and continue\n","categories":["Groovy User Guides - Groovy Development Kit"],"tags":["User Guides","Groovy","Groovy Development Kit"]},{"title":"Groovy Working with legacy Date/Calendar types","url":"/groovy/user-guides/groovy-development-kit/groovy-working-with-legacy-date-calendar-types/","content":"Groovy Working with legacy Date&#x2F;Calendar typesgroovy-dateutil 模块提供了许多扩展和 Java 经典的 Date&#x2F;Calendar 一起工作\n你可以通过使用 Calendar 提供的字段常量值来访问 Date&#x2F;Calendar 中的属性：\nimport static java.util.Calendar.*def cal = instancecal[YEAR] = 2000cal[MONTH] = JANUARYcal[DAY_OF_MONTH] = 1assert cal[DAY_OF_WEEK] == SATURDAY\n\n在 Date 和 Calendar 之间 Groovy 提供了算术计算和迭代：\ndef utc = TimeZone.getTimeZone(&#x27;UTC&#x27;)Date date = Date.parse(&quot;yyyy-MM-dd HH:mm&quot;, &quot;2010-05-23 09:01&quot;, utc)def prev = date - 1def next = date + 1def diffInDays = next - prevassert diffInDays == 2int count = 0prev.upto(next) &#123; count++ &#125;assert count == 3\n\n可以字符串转换为日期，或者将日期转换为字符串：\nimport static java.util.Calendar.*def newYear = Date.parse(&#x27;yyyy-MM-dd&#x27;, &#x27;2000-01-01&#x27;)def newYearsEve = newYear.copyWith(        year: 1999,        month: DECEMBER,        dayOfMonth: 31)assert newYearsEve[DAY_OF_WEEK] == FRIDAY\n","categories":["Groovy User Guides - Groovy Development Kit"],"tags":["User Guides","Groovy","Groovy Development Kit"]},{"title":"Groovy Writing files","url":"/groovy/user-guides/groovy-development-kit/groovy-writing-files/","content":"Groovy Writing filesnew File(baseDir, &#x27;haiku.txt&#x27;).withWriter(&#x27;utf-8&#x27;) &#123; writer -&gt;    writer.writeLine &#x27;Into the ancient pond&#x27;    writer.writeLine &#x27;A frog jumps&#x27;    writer.writeLine &quot;Water&#x27;s sound!&quot;&#125;\n\nUsing the &lt;&lt; operator would have been enough:\nnew File(baseDir, &#x27;haiku.txt&#x27;) &lt;&lt; &#x27;&#x27;&#x27;Into the ancient pondA frog jumpsWater&#x27;s sound!&#x27;&#x27;&#x27;\n\nDirectly write bytes:\nfile.bytes = [66, 22, 11]\n\nDirectly deal with output streams:\ndef os = new File(baseDir, &#x27;data.bin&#x27;).newOutputStream()// do somethingos.close()\n\nUse the withOutputStream idiom that will handle the exceptions and close the stream in any case:\nnew File(baseDir, &#x27;data.bin&#x27;).withOutputStream &#123; stream -&gt;    // do something&#125;\n","categories":["Groovy User Guides - Groovy Development Kit"],"tags":["User Guides","Groovy","Groovy Development Kit"]},{"title":"Groovy integration mechanisms","url":"/groovy/user-guides/integrating-groovy-in-a-java-application/groovy-integration-mechanisms/","content":"Groovy integration mechanismsEvalgroovy.util.Eval\nimport groovy.utl.Evalassert Eval.me(&#x27;33*3&#x27;) == 99assert Eval.me(&#x27;&quot;foo&quot;.toUpperCase()&#x27;) == &#x27;FOO&#x27;assert Eval.x(4, &#x27;2*x&#x27;) == 8assert Eval.me(&#x27;k&#x27;, 4, &#x27;2*k&#x27;) == 8assert Eval.xy(4, 5, &#x27;x*y&#x27;) == 20assert Eval.xyz(4, 5, 6, &#x27;x*y+z&#x27;) == 26\n\nThere is no caching of the script, and it isn’t meant to evaluate more than one liners\nGroovyShelldef shell = new GroovyShell()def result = shell.evalute &#x27;3*5&#x27;def result2 = shell.evalute(new StringReader(&#x27;3*5&#x27;))assert result == result2def script = shell.parse &#x27;3*5&#x27;assert script instanceof groovy.lang.Scriptassert script.run() == 15\n\nSharing data between a script and the application使用 groovy.lang.Binding\ndef sharedData = new Binding()def shell = new GroovyShell(sharedData)def now = new Date()sharedData.setProperty(&#x27;text&#x27;, &#x27;I am shared data!&#x27;)sharedData.setProperty(&#x27;data&#x27;, now)String result = shell.evaluate(&#x27;&quot;At $date, $text&quot;&#x27;)assert result == &#x27;At $now, I am shared data!&#x27;\n\ndef sharedData = new Binding()def shell = new GroovyShell(sharedData)shell.evaluate(&#x27;foo=123&#x27;)assert sharedData.getProperty(&#x27;foo&#x27;) == 123\n\n// Using def or an explicit type like in the example below would fail because you would then create a local variable:def sharedData = new Binding()def shell = new GroovyShell(sharedData)shell.evaluate(&#x27;int foo=123&#x27;)try &#123;    assert sharedData.getProperty(&#x27;foo&#x27;)&#125; catch (MissingPropertyException e) &#123;    println &quot;foo is defined as a local variable&quot;&#125;\n\ndef shell = new GroovyShell()def b1 = new Binding(x:3)def b2 = new Binding(x:4)def script1 = shell.parse(&#x27;x = 2*x&#x27;)def script2 = shell.parse(&#x27;x = 2*x&#x27;)assert script1 != script2script1.binding = b1script2.binding = b2def t1 = Thread.start &#123; script1.run() &#125;def t2 = Thread.start &#123; script2.run() &#125;[t1, t2]*.join()assert b1.getProperty(&#x27;x&#x27;) == 6assert b2.getProperty(&#x27;x&#x27;) == 8assert b1 != b2\n\nCustom script class通过继承 Script 类来进行自定义\nabstract class MyScript extends Script &#123;    String name    String greet() &#123; &quot;Hello, $name!&quot; &#125;&#125;\n\nimport org.codehaus.groovy.control.CompilerConfigurationdef config = new CompilerConfiguration()config.scriptBaseClass = &#x27;MyScript&#x27;def shell = new GroovyShell(this.class.classLoader, new Binding(), config)def script = shell.parse(&#x27;greet()&#x27;)assert script instanceof MyScriptscript.setName(&#x27;Michel&#x27;)assert script.run() == &#x27;Hello, Michel&#x27;\n","categories":["Groovy User Guides - Integrating Groovy in a Java application"],"tags":["User Guides","Groovy","Integrating Groovy in a Java application"]},{"title":"Groovy Connecting to the database","url":"/groovy/user-guides/interacting-with-a-sql-database/groovy-connecting-to-the-database/","content":"\n\n\nGroovy Connecting to the database\nConnecting to HSQLDB\nConnecting to HSQLDB (withInstance variation)\nConnecting to HSQLDB with a DataSource\nConnecting to HSQLDB with a DataSource using Apache Commons DBCP\nConnecting using @Grab\n\n\n\n\n\nGroovy Connecting to the database需要如下信息来连接数据库：\n\nThe database uniform resource locator; 数据库 URL\nUsername; 用户名\nPassword; 密码\nThe driver class name (which can be derived automatically in some situations); 驱动名称\n\n对于 HSQLDB 来说：\n\n\n\nProperty\nValue\n\n\n\nurl\njdbc:hslqdb:mem:yourdb\n\n\nuser\nyourUsername\n\n\npassword\nyourPassword\n\n\ndriver\norg.hsqldb.jdbcDriver\n\n\nConnecting to HSQLDBgroovy.sql.Sql 类的 newInstance 工厂方法接受这些参数来连接到数据库：\nimport groovy.sql.Sqldef url = &#x27;jdbc:hsqldb:mem:yourDB&#x27;def user = &#x27;sa&#x27;def password = &#x27;&#x27;def driver = &#x27;org.hsqldb.jdbcDriver&#x27;def sql = Sql.newInstance(url, user, password, driver)// use &#x27;sql&#x27; instancesql.close()\n\nConnecting to HSQLDB (withInstance variation)如果你不想手动处理资源（例如调用 close() 方法），可以使用 withInstance 方法：\nSql.withInstance(url, user, password, driver) &#123; sql -&gt;    // use `sql` instance&#125;\n\nConnecting to HSQLDB with a DataSourceimport groovy.sql.Sqlimport org.hsqldb.jdbc.JDBCDataSourcedef dataSource = new JDBCDataSource(    database: &#x27;jdbc:hsqldb:mem:yourDB&#x27;,     user: &#x27;sa&#x27;,     password: &#x27;&#x27;)def sql = new Sql(dataSource)// use then close &#x27;sql&#x27; instance ...\n\nConnecting to HSQLDB with a DataSource using Apache Commons DBCP使用连接池来连接数据库\n@Grab(&#x27;commons-dbcp:commons-dbcp:1.4&#x27;)import groovy.sql.Sqlimport org.apache.commons.dbcp.BasicDataSourcedef ds = new BasicDataSource(    driverClassName: &#x27;org.hsqldb.jdbcDriver&#x27;,    url: &#x27;jdbc:hsqldb:mem:yourDB&#x27;,    username: &#x27;sa&#x27;,    password: &#x27;&#x27;)def sql = new Sql(ds)   // 将 DataSource 传给 Sql\n\nConnecting using @Grab使用 @Grab 获取驱动类\n@Grab(&#x27;org.hsqldb:hsqldb:2.5.1&#x27;)@GrabConfig(systemClassLoader=true)// create, use, and then close sql instance ...\n\nThe @GrabConfig statement is necessary to make sure the system classloader is used.\nThis ensures that the driver classes and system classes like java.sql.DriverManager are in the same classloader.\n","categories":["Groovy User Guides - Interacting with a SQL database"],"tags":["User Guides","Groovy","Interacting with a SQL database"]},{"title":"Groovy Executing SQL","url":"/groovy/user-guides/interacting-with-a-sql-database/groovy-executing-sql/","content":"Groovy Executing SQLCreating tablessql.execute &#x27;&#x27;&#x27;    CREATE TABLE Author (        id          INTEGER GENERATED BY DEFAULT AS IDENTITY,        firstname   VARCHAR(64),        lastname    VARCHAR(64)    )&#x27;&#x27;&#x27;\n","categories":["Groovy User Guides - Interacting with a SQL database"],"tags":["User Guides","Groovy","Interacting with a SQL database"]},{"title":"Groovy Interacting with a SQL database","url":"/groovy/user-guides/interacting-with-a-sql-database/groovy-interacting-with-a-sql-database/","content":"Groovy Interacting with a SQL databaseGroovy 的 groovy-sql 模块比 Java 的 JDBC 提供了更高级别的抽象\nJDBC 提供了低级的，全面的 API\n最常使用的 groovy-sql 类是 groovy.sql.Sql\ngroovy.sql.Sql 将 JDBC 抽象提升了一个级别\n","categories":["Groovy User Guides - Interacting with a SQL database"],"tags":["User Guides","Groovy","Interacting with a SQL database"]},{"title":"Groovy Using DataSets","url":"/groovy/user-guides/interacting-with-a-sql-database/groovy-using-datasets/","content":"Groovy Using DataSetsGroovy 提供了 groovy.sql.DataSet ，这个类增强了 groovy.sql.Sql，可以认为是一个迷你的 ORM 工具\n通过使用 POGO 字段和操作符去访问和查询数据库，而不是 JDBC 级别的 API 和关系型数据库的列名\ngroovy.sql.Sql 写法：\ndef qry = &quot;&quot;&quot;    SELECT * FROM Author    WHERE (firstname &gt; ?)    AND (lastname &lt; ?)    ORDER BY lastname DESC&quot;&quot;&quot;def params = [&#x27;Dierk&#x27;, &#x27;Pragt&#x27;]def result = sql.rows(qry, params)assert result*.firstname == [&#x27;Eric&#x27;, &#x27;Guillaume&#x27;, &#x27;Paul&#x27;]\n\n使用 groovy.sql.DataSet 写法：\ndef authorDS = sql.dataSet(&#x27;Author&#x27;)def result = authorDS.findAll &#123;it.firstname &gt; &#x27;Dierk&#x27;&#125;                        .findAll &#123;it.lastname &lt; &#x27;Pragt&#x27;&#125;                        .sort &#123;it.lastname&#125;                        .reverse()assert result.rows()*.firstname == [&#x27;Eric&#x27;, &#x27;Guillaume&#x27;, &#x27;Paul&#x27;]// Here we have a helper &quot;domain&quot; class:class Author &#123;    String firstname    String lastname&#125;\n\nDatabase access and manipulation involves creating or working with instances of the domain class.\n","categories":["Groovy User Guides - Interacting with a SQL database"],"tags":["User Guides","Groovy","Interacting with a SQL database"]},{"title":"Groovy Metaprogramming","url":"/groovy/user-guides/metaprogramming/groovy-metaprogramming/","content":"Groovy MetaprogrammingGroovy 语言支持两种类型的 metaprogramming: 运行时和编译时\n第一种允许在运行时改变类的模型和行为\n第二种只发生在编译时\n这两种都有好处和坏处\n","categories":["Groovy User Guides - Metaprogramming"],"tags":["User Guides","Groovy","Metaprogramming"]},{"title":"Groovy JsonOutput","url":"/groovy/user-guides/processing-json/groovy-jsonoutput/","content":"Groovy JsonOutputJsonOutput 将 Groovy 对象转换为 JSON 字符串\nJsonOutput 提供了静态的多个重载的 toJson 方法\nimport groovy.json.JsonOutputdef json = JsonOutput.toJson(    [name: &#x27;John Doe&#x27;, age: 42])assert json == &#x27;&#123;&quot;name&quot;:&quot;John Doe&quot;,&quot;age&quot;:42&#125;&#x27;\n\nJsonOutput 不仅支持原始类型，Map，List数据类型，还支持 serialising POGOs，plain-old Groovy 对象：\nclass Person &#123; String name &#125;def json = JsonOutput.toJson([    new Person(name: &#x27;John&#x27;),    new Person(name: &#x27;Max&#x27;)])assert json == &#x27;[&#123;&quot;name&quot;:&quot;John&quot;&#125;,&#123;&quot;name&quot;:&quot;Max&quot;&#125;]&#x27;\n\nCustomizing Output使用 JsonGenerator 来控制序列化输出\nJsonGenerator.Options 创建器用来创建自定义生成器\nclass Person &#123;    String name    String title    int age    String password    Date dob    URL favoriteUrl&#125;Person person = new Person(    name: &#x27;John&#x27;,    title: null,    age: 21,    password: &#x27;secret&#x27;,    dob: Date.parse(&#x27;yyyy-MM-dd&#x27;, &#x27;1984-12-15&#x27;),    favoriteUrl: new URL(&#x27;http://groovy-lang.org/&#x27;))def generator = new JsonGenerator.Options()                                    .excludeNulls()                                    .dateFormat(&#x27;yyyy@MM&#x27;)                                    .excludeFieldByName(&#x27;age&#x27;, &#x27;password&#x27;)                                    .excludeFieldByType(URL)                                    .build()assert generator.toJson(person) == &#x27;&#123;&quot;dob&quot;:&quot;1984@12&quot;,&quot;name&quot;:&quot;John&quot;&#125;&#x27;\n\n一个 Closure 可以用于转换类型：\nclass Person &#123;    String name    URL favoriteUrl&#125;Person person = new Person(name: &#x27;John&#x27;, favoriteUrl: new URL(&#x27;http://groovy-lang.org/json.html#_jsonoutput&#x27;))def generator = new JsonGenerator.Options()                                    .addConverter(URL) &#123; URL u, String key -&gt;                                        if (key == &#x27;favoriteUrl&#x27;) &#123;                                            u.getHost() // 如果 key 名称为 favoriteUrl 时，只返回 host 值                                        &#125; else &#123;                                            u                                        &#125;                                    &#125;                                    .build()assert generator.toJson(person) == &#x27;&#123;&quot;favoriteUrl&quot;:&quot;groovy-lang.org&quot;,&quot;name&quot;:&quot;John&quot;&#125;&#x27;// No key available when generating a JSON Arraydef list = [new URL(&#x27;http://groovy-lang.org/json.html#_jsonoutput&#x27;)]assert generator.toJson(list) == &#x27;[&quot;http://groovy-lang.org/json.html#_jsonoutput&quot;]&#x27;// First parameter to the converter must match the type for which it is registeredshouldFail(IllegalArgumentException) &#123;    new JsonGenerator.Options()        .addConverter(Date) &#123; Calendar cal -&gt; &#125;&#125;\n\nFormatted OutputJsonOutput 中的 prettyPrint 方法进行格式化输出：\ndef json = JsonOutput.toJson([name: &#x27;John Doe&#x27;, age: 42])assert json == &#x27;&#123;&quot;name&quot;:&quot;John Doe&quot;,&quot;age&quot;:42&#125;&#x27;assert JsonOutput.prettyPrint(json) == &#x27;&#x27;&#x27;&#123;    &quot;name&quot;: &quot;John Doe&quot;,    &quot;age&quot;: 42&#125;&#x27;&#x27;&#x27;\n\nBuilders可以通过 JsonBuilder 和 StreamingJsonBuilder 来在 Groovy 中创建 JSON\n","categories":["Groovy User Guides - Processing JSON"],"tags":["User Guides","Groovy","Processing JSON"]},{"title":"Groovy JsonSlurper","url":"/groovy/user-guides/processing-json/groovy-jsonslurper/","content":"Groovy JsonSlurperJsonSlurper 用于将 JSON 字符串转换为 Groovy 数据结构，如 Map，List，Integer，Double，Boolean，String\nJsonSlurper 有许多重载的 parse 方法和一些特殊的方法，如 parseText，parseFile\nparseText 方法解析一个 JSON String ，将其转换为一个 List 或者一个 Map\nimport groovy.json.JsonSlurperdef jsonSlurper = new JsonSlurper()def object = jsonSlurper.parseText(&#x27;&#123;&quot;name&quot;:&quot;John Doe&quot;&#125; /* some comment */&#x27;)assert object instanceof Mapassert object.name == &#x27;John Doe&#x27;\n\nJsonSlurper parses the given JSON as defined by the ECMA-404 JSON Interchange Standard plus support for JavaScript comments and dates.\nJsonSlurper 还支持注释和日期类型\nimport groovy.json.JsonSlurper()def jsonSlurper = new JsonSlurper()def object = jsonSlurper.parseText(    &#x27;&#123;&quot;myList&quot;: [4, 8, 15, 16, 23, 42]&#125;&#x27;)assert object instanceof Mapassert object.myList instanceof Listassert object.myList = [4, 8, 15, 16, 23, 42]\n\nJSON 标准支持这些原始数据类型：\n\nstring\nnumber\nobject\ntrue\nfalse\nnull\n\nJsonSlurper 将这些 JSON 类型转换为对应的 Groovy 类型\nimport groovy.json.JsonSlurperdef jsonSlurper = new JsonSlurper()def object = jsonSlurper.parseText &#x27;&#x27;&#x27;&#123;    &quot;simple&quot;: 123,    &quot;fraction&quot;: 123.66    &quot;exponential&quot;: 123e12&#125;&#x27;&#x27;&#x27;assert object instanceof Mapassert object.simple.class == Integerassert object.fraction.class == BigDecimal      // 浮点数默认为 BigDecimalassert object.exponential.class == BigDecimal   // 浮点数默认为 BigDecimal\n\nJSON 数据类型和对应的 Groovy 数据类型：\n\n\n\nJSON\nGroovy\n\n\n\nstring\njava.lang.String\n\n\nnumber\njava.lang.BigDecimal or java.lang.Integer\n\n\nobject\njava.util.LinkedHashMap\n\n\narray\njava.util.ArrayList\n\n\ntrue\ntrue\n\n\nfalse\nfalse\n\n\nnull\nnull\n\n\ndate\njava.util.Date based on the yyyy-MM-dd&#39;T&#39;HH:mm:ssZ date format\n\n\nParser Variants解析器变种\n\nJsonParserCharArray\nJsonFastParser : JsonParserCharArray 的特殊变种。速度更快。尽量晚创建对象。用于 JSON buffers 低于 2MB 的情况\nJsonParserLax : JsonParserCharArray 的特殊变种。和 JsonFastParser 性能相当。支持注释，没有单引号字符串\nJsonParserUsingCharacterSource : 用于解析超大文件。超过 2MB 的文件。\n\nJsonSlurper 的默认实现是 JsonParserCharArray\nJsonParserType 枚举包含了所有的解析器：\n\n\n\nImplementation\nConstant\n\n\n\nJsonParserCharArray\nJsonParserType#CHAR_BUFFER\n\n\nJsonFastParser\nJsonParserType#INDEX_OVERLAY\n\n\nJsonParserLax\nJsonParserType#LAX\n\n\nJsonParserUsingCharacterSource\nJsonParserType#CHARACTER_SOURCE\n\n\n指定要解析器实现：\nimport groovy.gson.JsonSlurperimport groovy.gson.JsonParserTypedef jsonSlurper = new JsonSlurper(type: JsonParserType.INDEX_OVERLAY)def object = jsonSlurper.parseText &#x27;&#x27;&#x27;    &#123; &quot;myList&quot;: [4, 8, 15, 16, 23, 42] &#125;&#x27;&#x27;&#x27;assert object instanceof Mapassert object.myList instanceof Listassert object.myList == [4, 8, 15, 16, 23, 42]\n","categories":["Groovy User Guides - Processing JSON"],"tags":["User Guides","Groovy","Processing JSON"]},{"title":"Groovy Functional Tests with Geb","url":"/groovy/user-guides/testing-guide/groovy-functional-tests-with-geb/","content":"Groovy Functional Tests with GebGeb is a functional web testing and scraper library that integrates with JUnit and Spock.\nGeb 是一个与 JUnit 和 Spock 集成的 web 功能测试和获取的库。\nIt is based upon the ++Selenium++ web drivers and, like Spock, provides a Groovy DSL to write functional tests for web applications.\nGeb has great features that make it a good fit for a functional testing library:\n\nDOM access via a JQuery-like $ function\nimplements the page pattern\nsupport for modularization of certain web components (e.g. menu-bars, etc.) with modules\nintegration with Javascript via the JS variable\n\nA Geb Script尽管 Geb 可以单独在 Groovy 脚本中使用，但是在许多场景下 Geb 是和其他测试框架结合使用\nGeb 有许多基础类可以用在 JUnit 3&#x2F;4，TestNG or Spock 中\nThe base classes are part of additional Geb modules that need to be added as a dependency.\nFor example, the following @Grab dependencies can be used to run Geb with the Selenium Firefox driver in JUnit4 tests. The module that is needed for JUnit 3&#x2F;4 support is geb-junit4:\n@Grab(&#x27;org.gebish:geb-core:0.9.2&#x27;)@Grab(&#x27;org.gebish:geb-junit4:0.9.2&#x27;)@Grab(&#x27;org.seleniumhq.selenium:selenium-firefox-driver:2.26.0&#x27;)@Grab(&#x27;org.seleniumhq.selenium:selenium-support:2.26.0&#x27;)\n\nThe central class in Geb is the geb.Browser class.\nAs its name implies it is used to browse pages and access DOM elements:\nimport geb.Browserimport org.openqa.selenium.firefox.FirefoxDriverdef browser = new Browser(                      // 1    driver: new FirefoxDriver(),    baseUrl: &#x27;http://myhost:8080/myapp&#x27;)browser.drive &#123;    go &quot;/login&#x27;                                 // 2    $(&quot;#username&quot;).text = &#x27;John&#x27;                // 3    $(&quot;#password&quot;).text = &#x27;Doe&#x27;    $(&quot;#loginButton&quot;).click()    assert title == &quot;My Application - Dashboard&quot;&#125;\n\n1 : A new Browser instance is created. In the case it uses the Selenium FirefoxDriver and sets the baseUrl\n2 : go is used to navigate to an URL or relative URI\n3 : $ together with CSS selectors is used to access the username and password DOM fields\nThe Browser class comes with a drive method that delegates all method&#x2F;property calls to the current browser instance.\nThe Browser configuration must not be done inline, it can also be externalized in a GebConfig.groovy configuration file for example.\nIn practice, the usage of the Browser class is mostly hidden by Geb test base classes.\nThey delegate all missing properties and method calls to the current browser instance that exists in the background:\nclass SearchTests extends geb.junit4.GebTest &#123;    @Test    void executeSeach() &#123;        go &#x27;http://somehost/mayapp/search&#x27;                              // 1        $(&#x27;#searchField&#x27;).text = &#x27;John Doe&#x27;                             // 2        $(&#x27;#searchButton&#x27;).click()                                      // 3        assert $(&#x27;.searchResult a&#x27;).first().text() == &#x27;Mr. John Doe&#x27;    // 4    &#125;&#125;\n\n1 : Browser#go takes a relative or absolute link and calls the page\n2 : Browser#$ is used to access DOM content. Any CSS selectors supported by the underlying Selenium drivers are allowed\n3 : click is used to click a button\n4 : $ is used to get the first link out of the searchResult block\nThe example above shows a simple Geb web test with the JUnit 4 base class geb.junit4.GebTest.\nNote that in this case the Browser configuration is externalized.\nGebTest delegates methods like go and $ to the underlying browser instance\n","categories":["Groovy User Guides - Testing Guide"],"tags":["User Guides","Groovy","Testing Guide"]},{"title":"Groovy Testing with Spock","url":"/groovy/user-guides/testing-guide/groovy-testing-with-spock/","content":"Groovy Testing with SpockSpecificationsclass StackSpec extends Specification &#123;    def &quot;adding an element leads to size increase&quot;() &#123;  // 1        setup: &quot;a new stack instance is created&quot;        // 2            def stack = new Stack()                when:                                           // 3            stack.push 42                then:                                           // 4            stack.size() == 1    &#125;&#125;\n\n1 : Feature method, is by convention named with a String literal\n2 : Setup block, here is where any setup work for this feature needs to be done\n3 : When block describes a stimulus, a certain action under target by this feature specification\n4 : Then block any expressions that can be used to validate the result of the code that was triggered by the when block\nSpock feature specifications are defined as methods inside a spock.lang.Specification class\nThey describe the feature by using a String literal instead of a method name\nA feature method holds multiple blocks, in our example we used setup, when and then\nThe setup block is special in that it is optional and allows to configure local variables visible inside the feature method\nThe when block defines the stimulus and is a companion of the then block which describes the response to the stimulus\n","categories":["Groovy User Guides - Testing Guide"],"tags":["User Guides","Groovy","Testing Guide"]},{"title":"Groovy GStringTemplateEngine","url":"/groovy/user-guides/template-engines/groovy-gstringtemplateengine/","content":"Groovy GStringTemplateEnginetest.template:\nDear &quot;$firstname $lastname&quot;,So nice to meet you in &lt;% out &lt;&lt; (city == &quot;New York&quot; ? &quot;\\\\&quot;The Big Apple\\\\&quot;&quot; : city) %&gt;.See you in $&#123;month&#125;,$&#123;signed&#125;\n\nwe used out instead of print to support the streaming nature of GStringTemplateEngine.\nBecause we have the template in a separate file, there is no need to escape the backslashes.\ndef f = new File(&#x27;test.template&#x27;)def engine = new groovy.text.GStringTemplateEngine()def template = engine.createTemplate(f)                        .make(binding)println template.toString()\n\noutput:\nDear &quot;Sam Pullara&quot;,So nice to meet you in &quot;The Big Apple&quot;.See you in December,Groovy-Dev\n","categories":["Groovy User Guides - Template engines"],"tags":["User Guides","Groovy","Template engines"]},{"title":"Groovy SimpleTemplateEngine","url":"/groovy/user-guides/template-engines/groovy-simpletemplateengine/","content":"Groovy SimpleTemplateEngineSimpleTemplateEngine that allows you to use JSP-like scriptlets, script, and EL expressions in your template in order to generate parametrized text.\ndef text = &#x27;Dear $firstname $lastname, \\nSo nice to meet you in &lt;% print city %&gt;.\\nSee you in $&#123;month&#125;,\\n$&#123;signed&#125;&#x27;def binding = [    &#x27;firstname&#x27;:&#x27;Sam&#x27;,    &#x27;lastname&#x27;:&#x27;Pullara&#x27;,    &#x27;city&#x27;:&#x27;San Francison&#x27;,    &#x27;month&#x27;:&#x27;December&#x27;,    &#x27;signed&#x27;:&#x27;Groovy-dev&#x27;]def engine = new groovy.text.SimpleTemplateEngine()def template = engine.createTemplate(text).make(binding)def result = &#x27;Dear &quot;Sam Pullara&quot;,\\nSo nice to meet you in San Francisco.\\nSee you in December,\\nGroovy-Dev&#x27;assert result == template.toString()\n\n先创建 Engine 实例，再调用 Engine 实例上的 createTemplate() 方法，传入模版，最后调用 make() 方法生成结果\nAdvanced Usage Note转义问题，要使用 \\ 来进行转义\n&lt;% print city == &quot;New York&quot; ? &quot;\\\\&quot;The Big Apple\\\\&quot;&quot; : city %&gt;\n\n换行：\n\\\\n\n\n输出斜杠：\n\\\\\\\\\n","categories":["Groovy User Guides - Template engines"],"tags":["User Guides","Groovy","Template engines"]},{"title":"Groovy StreamingTemplateEngine","url":"/groovy/user-guides/template-engines/groovy-streamingtemplateengine/","content":"Groovy StreamingTemplateEngineSpecifically this template engine can handle strings larger than 64k.\nIt uses JSP style &lt;% %&gt; script and &lt;%&#x3D; %&gt; expression syntax or GString style expressions.\nThe variable ‘out’ is bound to the writer that the template is being written to.\ndef text = &#x27;&#x27;&#x27;\\Dear &lt;% out.print firstname %&gt; $&#123;lastname&#125;,We &lt;% if (accepted) out.print &#x27;are pleased&#x27; else out.print &#x27;regret&#x27; %&gt; \\to inform you that your paper entitled&#x27;$title&#x27; was $&#123; accepted ? &#x27;accepted&#x27; : &#x27;rejected&#x27;&#125;.The conference committee.&#x27;&#x27;&#x27;def template = new groovy.text.StreamingTemplateEngine().createTemplate(text)def binding = [    firstname   : &quot;Grace&quot;,    lastname    : &quot;Hopper&quot;,    accepted    : true,    title       : &#x27;Groovy for COBOL programmers&#x27;]String response = template.make(binding)assert response == &#x27;&#x27;&#x27;Dear Grace Hopper,We are pleased to inform you that your paper entitled&#x27;Groovy for COBOL programmers&#x27; was accepted.The conference committee.&#x27;&#x27;&#x27;\n","categories":["Groovy User Guides - Template engines"],"tags":["User Guides","Groovy","Template engines"]},{"title":"Groovy Template framework","url":"/groovy/user-guides/template-engines/groovy-template-framework/","content":"Groovy Template frameworkThe template framework in Groovy consists of TemplateEngine abstract base class that the engines must implement\nAnd a Template interface that the resulting templates they generate must implement\nGroovy 提供了这些模版引擎:\n\nSimpleTemplateEngine - for basic templates\nStreamingTemplateEngine - functionally equivalent to SimpleTemplateEngine, but can handle strings larger than 64k\nGStringTemplateEngine - stores the template as writeable closures (useful for streaming scenarios)\nXmlTemplateEngine - works well when the template and output are valid XML\nMarkupTemplateEngine - a very complete, optimized, template engine\n\n","categories":["Groovy User Guides - Template engines"],"tags":["User Guides","Groovy","Template engines"]},{"title":"Groovy XmlTemplateEngine","url":"/groovy/user-guides/template-engines/groovy-xmltemplateengine/","content":"Groovy XmlTemplateEngineTemplates may use the normal $&#123;expression&#125; and $variable notations to insert an arbitrary expression into the template.\nIn addition, support is also provided for special tags: &lt;gsp:scriptlet&gt; (for inserting code fragments) and &lt;gsp:expression&gt; (for code fragments which produce output).\nComments and processing instructions will be removed as part of processing and special XML characters such as &lt;, &gt;, &quot; and &#39; will be escaped using the respective XML notation.\nThe output will also be indented using standard XML pretty printing.\nThe xmlns namespace definition for gsp: tags will be removed but other namespace definitions will be preserved\ndef binding = [firstname: &#x27;Jochen&#x27;, lastname: &#x27;Theodorou&#x27;, nickname: &#x27;blackdrag&#x27;, salutation: &#x27;Dear&#x27;]def engine = new groovy.text.XmlTemplateEngine()def text = &#x27;&#x27;&#x27;\\    &lt;document xmlns:gsp=&#x27;http://groovy.codehaus.org/2005/gsp&#x27; xmlns:foo=&#x27;baz&#x27; type=&#x27;letter&#x27;&gt;        &lt;gsp:scriptlet&gt;def greeting = &quot;$&#123;salutation&#125;est&quot;&lt;/gsp:scriptlet&gt;        &lt;gsp:expression&gt;greeting&lt;/gsp:expression&gt;        &lt;foo:to&gt;$firstname &quot;$nickname&quot; $lastname&lt;/foo:to&gt;        How are you today?    &lt;/document&gt;&#x27;&#x27;&#x27;def template = engine.createTemplate(text).make(binding)println template.toString()\n\noutput:\n&lt;document type=&#x27;letter&#x27;&gt;  Dearest  &lt;foo:to xmlns:foo=&#x27;baz&#x27;&gt;    Jochen &amp;quot;blackdrag&amp;quot; Theodorou  &lt;/foo:to&gt;  How are you today?&lt;/document&gt;\n","categories":["Groovy User Guides - Template engines"],"tags":["User Guides","Groovy","Template engines"]},{"title":"Configure logging drivers","url":"/docker/run-your-app-in-production/configure-containers/logging/configure-logging-drivers/","content":"Docker 默认使用 json-file 日志驱动\njson-file 默认不进行日志转储\n\nDocker keeps the json-file logging driver (without log-rotation) as a default to remain backward compatibility with older versions of Docker, and for situations where Docker is used as runtime for Kubernetes\n\n可以使用 local 日志驱动, 它默认进行日志转储\nConfigure the default logging driver在 /etc/docker/daemon.json 配置文件中配置 Docker daemon 使用的配置日志驱动\n配置 json-file:\n&#123;    &quot;log-driver&quot;: &quot;json-file&quot;,    &quot;log-opts&quot;: &#123;        &quot;max-size&quot;: &quot;10m&quot;,        &quot;max-file&quot;: &quot;3&quot;,        &quot;labels&quot;: &quot;production_status&quot;,        &quot;env&quot;: &quot;os,customer&quot;    &#125;&#125;\n\n设置默认日志驱动为 local:\n&#123;    &quot;log-driver&quot;: &quot;local&quot;&#125;\n\n修改配置之后需要重新启动 Docker daemon, 否则只有新创建的的容器会受影响, 已存在的容器不会使用到新的日志配置\n查看当前使用的日志驱动: $ docker info --format &#39;&#123;&#123;.LoggingDriver&#125;&#125;&#39;\nConfigure the logging driver for a container创建容器或运行容器时可以使用 --log-driver 标志来指定要使用的日志驱动\n可以使用多个 --log-opt &lt;NAME&gt;=&lt;VALUE&gt; 来指定日志配置\nExample - 使用 none 作为日志驱动:\n$ docker run -ti --log-driver none alpine ash\n\n查看当前运行的容器使用的日志驱动:\n$ docker inspect -f &#x27;&#123;&#123;.HostConfig.LogConfig.Type&#125;&#125;&#x27; &lt;CONTAINER&gt;\n\nConfigure the delivery mode of log messages from container to log driverDocker 提供了两种模式来从容器中传输信息到日志驱动中:\n\ndirect - 默认模式, 阻塞从容器到日志驱动的传输\nnon-blocking - 将日志信息保存在每个容器的中间 ring buffer 中, 以供日志驱动使用\n\nnon-blocking 模式防止应用因为日志背压而阻塞\n警告: 当 buffer 满了且有新的信息入队, 内存中最旧的信息将会被丢弃. 丢弃信息通常比阻止应用程序日志写入进程更加推荐\n使用 mode 日志选项控制使用 blocking (默认) 还是 non-blocking 消息传递\nmax-buffer-size 日志选项控制 ring buffer 的大小, 默认为 1M\nExample:\n$ docker run -it --log-opt mode=non-blocking --log-opt max-buffer-size=4m alpine ping 127.0.0.1\n\nUse environment variables or labels with logging drivers一些日志驱动添加容器的 --env|-e 或 --label 标志的值到容器日志中\nExample:\n$ docker run -dit --label production_status=testing -e os=ubuntu alpine sh\n\n如果日志驱动支持这个, 它将添加额外字段到日志输出中\nExample - json-file 生成如下日志输出:\n&quot;attrs&quot;: &#123;&quot;production_status&quot;:&quot;testing&quot;,&quot;os&quot;:&quot;ubuntu&quot;&#125;\n\nSupported logging drivers使用 gelf 将日志发送到 Logstash 中\n\n\n\nDriver\nDescription\n\n\n\nnone\n没有可用于容器的日志且 docker logs 不会返回任何输出\n\n\nlocal\n日志以旨在将开销降至最低的定制格式存储\n\n\njson-file\n日志格式化为 JSON. Docker 默认的日志驱动\n\n\nsyslog\n将日志写入到 syslog 设备. syslog 守护进程必须运行在宿主机上\n\n\njournald\n将日志写入到 journald. journald 守护进程必须运行在宿主机上\n\n\ngelf\n将日志写入到 Graylog Extended Log Format (GELF) 端点, 例如 Graylog 或 Logstash\n\n\nfluentd\n将日志写入到 fluentd (forward input). fluentd 守护进程必须运行在宿主机上\n\n\nawslogs\n将日志写入到 Amazon CloudWatch Logs\n\n\nsplunk\n使用 HTTP Event Collector 将日志写入到 splunk\n\n\netwlogs\n将日志作为 Event Tracing for Windows (ETW) events 进行写入. 只在 Windows 平台生效\n\n\ngcplogs\n将日志写入到 Google Cloud Platform (GCP) Logging\n\n\nlogentries\n将日志写入到 Rapid7 Logentries\n\n\n如果使用的是 Docker Engine 19.03 或更旧的版本, docker logs 命令只会作用于 local,json-file,journald 日志驱动\nDocker 20.10 及之后提供了 “dual logging”, “dual logging” 使用一个本地 buffer, 这个 buffer 使得可以在任何日志驱动下使用 docker logs\n查看 reading logs when using remote logging drivers 获取更多细节\n参考Configure logging drivers\n","categories":["Docker - Run your app in production - Configure containers - Logging"],"tags":["Docker","Notes"]},{"title":"Elasticsearch Character filters reference","url":"/elasticsearch/elasticsearch-guide/text-analysis/character-filters-reference/elasticsearch-character-filters-reference/","content":"Elasticsearch Character filters reference字符过滤器用来预处理字符序列, 在字符序列被传递给分词器之前\n一个字符过滤器接收原始的字符序列, 然后可以添加字符到字符序列, 删除字符序列中的字符, 改变字符序列中的字符\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch HTML strip character filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/character-filters-reference/elasticsearch-html-strip-character-filter/","content":"Elasticsearch HTML strip character filter将 HTML 中的符号进行转义\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Mapping characters filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/character-filters-reference/elasticsearch-mapping-characters-filter/","content":"Elasticsearch Mapping characters filter将指定的字符转换为配置的字符\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Pattern replace character filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/character-filters-reference/elasticsearch-pattern-replace-character-filter/","content":"Elasticsearch Pattern replace character filter通过正则表达式进行匹配与替换指定字符\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Apostrophe token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-apostrophe-token-filter/","content":"Elasticsearch Apostrophe token filterapostrophe : 省略符号，撇号；呼语，顿呼\n去掉 apostrophe 后面的字符, 也会删除 apostrophe 本身\nGET /_analyze&#123;  &quot;tokenizer&quot; : &quot;standard&quot;,  &quot;filter&quot; : [&quot;apostrophe&quot;],  &quot;text&quot; : &quot;Istanbul&#x27;a veya Istanbul&#x27;dan&quot;&#125;\n\n返回:\n[ Istanbul, veya, Istanbul ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch ASCII folding token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-ascii-folding-token-filter/","content":"Elasticsearch ASCII folding token filter将字母, 数字, 符号字符转换为其对应的 ASCII 字符\nGET /_analyze&#123;  &quot;tokenizer&quot; : &quot;standard&quot;,  &quot;filter&quot; : [&quot;asciifolding&quot;],  &quot;text&quot; : &quot;açaí à la carte&quot;&#125;\n\n返回:\n[ acai, a, la, carte ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch CJK bigram token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-cjk-bigram-token-filter/","content":"Elasticsearch CJK bigram token filter对 Chinese, Japanese, Korean 进行 N-Gram 处理\nGET /_analyze&#123;  &quot;tokenizer&quot; : &quot;standard&quot;,  &quot;filter&quot; : [&quot;cjk_bigram&quot;],  &quot;text&quot; : &quot;東京都は、日本の首都であり&quot;&#125;\n\n返回:\n[ 東京, 京都, 都は, 日本, 本の, の首, 首都, 都で, であ, あり ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch CJK width token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-cjk-width-token-filter/","content":"Elasticsearch CJK width token filter作用于中文, 日文, 韩文字符\n转换全长的 ASCII 的字符为对应的普通的 ASCII 字符\n转换半长的片假名字符变体为对应的字符\nGET /_analyze&#123;  &quot;tokenizer&quot; : &quot;standard&quot;,  &quot;filter&quot; : [&quot;cjk_width&quot;],  &quot;text&quot; : &quot;ｼｰｻｲﾄﾞﾗｲﾅｰ&quot;&#125;\n\n返回:\nシーサイドライナー\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Classic token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-classic-token-filter/","content":"Elasticsearch Classic token filter为 classic 分词器生成的单词进行可选的后置处理\n这个过滤器删除英文中单词结尾的 &#39;s, 删除首字母的点\nGET /_analyze&#123;  &quot;tokenizer&quot; : &quot;classic&quot;,  &quot;filter&quot; : [&quot;classic&quot;],  &quot;text&quot; : &quot;The 2 Q.U.I.C.K. Brown-Foxes jumped over the lazy dog&#x27;s bone.&quot;&#125;\n\n返回:\n[ The, 2, QUICK, Brown, Foxes, jumped, over, the, lazy, dog, bone ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Common grams token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-common-grams-token-filter/","content":"Elasticsearch Common grams token filter使用提供的指定的单词来进行 N-Gram 操作\nGET /_analyze&#123;  &quot;tokenizer&quot; : &quot;whitespace&quot;,  &quot;filter&quot; : [    &#123;      &quot;type&quot;: &quot;common_grams&quot;,      &quot;common_words&quot;: [&quot;is&quot;, &quot;the&quot;]    &#125;  ],  &quot;text&quot; : &quot;the quick fox is brown&quot;&#125;\n\n返回:\n[ the, the_quick, quick, fox, fox_is, is, is_brown, brown ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Conditional token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-conditional-token-filter/","content":"Elasticsearch Conditional token filter使用脚本定义的条件来决定是否使用配置的过滤器\nGET /_analyze&#123;    &quot;tokenizer&quot;: &quot;standard&quot;,    &quot;filter&quot;: [        &#123;            &quot;type&quot;: &quot;condition&quot;,                                // 声明当前是条件过滤器            &quot;filter&quot;: [ &quot;lowercase&quot; ],                          // 配置要使用的过滤器            &quot;script&quot;: &#123;                &quot;source&quot;: &quot;token.getTerm().length() &lt; 5&quot;        // 分词长度小于 5 , 就进行小写化            &#125;        &#125;    ],    &quot;text&quot;: &quot;THE QUICK BROWN FOX&quot;&#125;\n\n返回:\n[ the, QUICK, BROWN, fox ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Decimal digit token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-decimal-digit-token-filter/","content":"Elasticsearch Decimal digit token filter将 Unicode 中的数字转换为常用的 0-9\nGET /_analyze&#123;  &quot;tokenizer&quot; : &quot;whitespace&quot;,  &quot;filter&quot; : [&quot;decimal_digit&quot;],  &quot;text&quot; : &quot;१-one two-२ ३&quot;&#125;\n\n返回:\n[ 1-one, two-2, 3]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Delimited payload token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-delimited-payload-token-filter/","content":"Elasticsearch Delimited payload token filter使用特定的分隔符进行分词处理\nGET _analyze&#123;  &quot;tokenizer&quot;: &quot;whitespace&quot;,  &quot;filter&quot;: [&quot;delimited_payload&quot;],  &quot;text&quot;: &quot;the|0 brown|10 fox|5 is|0 quick|10&quot;&#125;\n\n返回:\n[ the, brown, fox, is, quick ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Dictionary decompounder token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-dictionary-decompounder-token-filter/","content":"Elasticsearch Dictionary decompounder token filter使用指定的单词列表和蛮力方法在复合词中查找子单词。如果找到，这些子词将包含在分词输出中\nGET _analyze&#123;  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;: [    &#123;      &quot;type&quot;: &quot;dictionary_decompounder&quot;,      &quot;word_list&quot;: [&quot;Donau&quot;, &quot;dampf&quot;, &quot;meer&quot;, &quot;schiff&quot;]    &#125;  ],  &quot;text&quot;: &quot;Donaudampfschiff&quot;&#125;\n\n输出:\n[ Donaudampfschiff, Donau, dampf, schiff ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Edge n-gram token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-edge-n-gram-token-filter/","content":"Elasticsearch Edge n-gram token filter在一个分词上进行 N-Gram 操作, 但是是从单词的最左边字符开始, 而不是滑动窗口\n通过 min_gram 和 max_gram 来控制生成的结果的最大长度和最小长度\nGET _analyze&#123;  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;: [    &#123; &quot;type&quot;: &quot;edge_ngram&quot;,      &quot;min_gram&quot;: 1,      &quot;max_gram&quot;: 2    &#125;  ],  &quot;text&quot;: &quot;the quick brown fox jumps&quot;&#125;\n\n返回:\n[ t, th, q, qu, b, br, f, fo, j, ju ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Elision token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-elision-token-filter/","content":"Elasticsearch Elision token filter删除单词开头的元音\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Fingerprint token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-fingerprint-token-filter/","content":"Elasticsearch Fingerprint token filter从一个单词序列中排序并删除重复的单词\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Flattern graph token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-flattern-graph-token-filter/","content":"Elasticsearch Flattern graph token filterflattern_graph 使用的是这个过滤器\nGET /_analyze&#123;  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;: [    &#123;      &quot;type&quot;: &quot;synonym_graph&quot;,      &quot;synonyms&quot;: [ &quot;dns, domain name system&quot; ]    &#125;  ],  &quot;text&quot;: &quot;domain name system is fragile&quot;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Hunspell token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-hunspell-token-filter/","content":"Elasticsearch Hunspell token filter词干提取过滤器\nHunspell 是一个拼写检查器和形态分析器, 专为具有丰富形态和复杂的字复合和字符编码的语言而设计\n\nProvides dictionary stemming based on a provided Hunspell dictionary\n\n基于提供的 Hunspell 字典提供字典词干分析\n\nThe hunspell filter requires configuration of one or more language-specific Hunspell dictionaries\n\nhunspell 过滤器需要配置一个或多个特定于语言的 hunspell 字典\nGET /_analyze&#123;  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;: [    &#123;      &quot;type&quot;: &quot;hunspell&quot;,      &quot;locale&quot;: &quot;en_US&quot;    &#125;  ],  &quot;text&quot;: &quot;the foxes jumping quickly&quot;&#125;\n\n返回:\n[ the, fox, jump, quick ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Hyphenation decompounder token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-hyphenation-decompounder-token-filter/","content":"Elasticsearch Hyphenation decompounder token filter\nUses XML-based hyphenation patterns to find potential subwords in compound words\n\n使用基于 xml 的连字符模式在复合词中查找潜在的子单词\n\nThese subwords are then checked against the specified word list\n\n然后根据指定的单词列表检查这些子单词\n\nSubwords not in the list are excluded from the token output\n\n不在列表中的子单词将从分词输出中排除\nGET _analyze&#123;  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;: [    &#123;      &quot;type&quot;: &quot;hyphenation_decompounder&quot;,      &quot;hyphenation_patterns_path&quot;: &quot;analysis/hyphenation_patterns.xml&quot;,      &quot;word_list&quot;: [&quot;Kaffee&quot;, &quot;zucker&quot;, &quot;tasse&quot;]    &#125;  ],  &quot;text&quot;: &quot;Kaffeetasse&quot;&#125;\n\n返回:\n[ Kaffeetasse, Kaffee, tasse ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Keep types token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-keep-types-token-filter/","content":"Elasticsearch Keep types token filter根据指定类型来保持或删除分词\n分词类型由分词器在转换文本为分词时设置\n有一些过滤器也可以提供分词类型\nGET _analyze&#123;    &quot;tokenizer&quot;: &quot;standard&quot;,    &quot;filter&quot;: [        &#123;            &quot;type&quot;: &quot;keep_types&quot;,            &quot;types&quot;: [ &quot;&lt;NUM&gt;&quot; ]        &#125;    ],    &quot;text&quot;: &quot;1 quick fox 2 lazy dogs&quot;&#125;\n\n返回:\n[ 1, 2 ]\n\n排除例子:\nGET _analyze&#123;  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;: [    &#123;      &quot;type&quot;: &quot;keep_types&quot;,      &quot;types&quot;: [ &quot;&lt;NUM&gt;&quot; ],      &quot;mode&quot;: &quot;exclude&quot;    &#125;  ],  &quot;text&quot;: &quot;1 quick fox 2 lazy dogs&quot;&#125;\n\n返回:\n[ quick, fox, lazy, dogs ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Keep words token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-keep-words-token-filter/","content":"Elasticsearch Keep words token filter只有在指定列表中的分词才会被保留\nGET _analyze&#123;  &quot;tokenizer&quot;: &quot;whitespace&quot;,  &quot;filter&quot;: [    &#123;      &quot;type&quot;: &quot;keep&quot;,      &quot;keep_words&quot;: [ &quot;dog&quot;, &quot;elephant&quot;, &quot;fox&quot; ]    &#125;  ],  &quot;text&quot;: &quot;the quick fox jumps over the lazy dog&quot;&#125;\n\n返回:\n[ fox, dog ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Keyword marker token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-keyword-marker-token-filter/","content":"Elasticsearch Keyword marker token filter\nMarks specified tokens as keywords, which are not stemmed.\n\n将指定的分词标记为不被进行词根转换的关键字\n使用前:\nGET /_analyze&#123;  &quot;tokenizer&quot;: &quot;whitespace&quot;,  &quot;filter&quot;: [ &quot;stemmer&quot; ],  &quot;text&quot;: &quot;fox running and jumping&quot;&#125;[ fox, run, and, jump ]\n\n使用后:\nGET /_analyze&#123;  &quot;tokenizer&quot;: &quot;whitespace&quot;,  &quot;filter&quot;: [    &#123;      &quot;type&quot;: &quot;keyword_marker&quot;,      &quot;keywords&quot;: [ &quot;jumping&quot; ]    &#125;,    &quot;stemmer&quot;  ],  &quot;text&quot;: &quot;fox running and jumping&quot;&#125;[ fox, run, and, jumping ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Keyword repeat token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-keyword-repeat-token-filter/","content":"Elasticsearch Keyword repeat token filter\nOutputs a keyword version of each token in a stream. These keyword tokens are not stemmed.\n\n为一个序列中每个分词输出一个关键字版本. 这些关键字分词不会被抽取词根\n\nThe keyword_repeat filter assigns keyword tokens a keyword attribute of true.\n\nkeyword_repeat 过滤器为关键词分词赋予一个为 true 的关键词属性\n\nStemmer token filters, such as stemmer or porter_stem, skip tokens with a keyword attribute of true.\n\n词根抽取分词过滤器, 例如 stemmer 或者 porter_stem , 跳过处理一个关键词属性为 true 的分词\n\nYou can use the keyword_repeat filter with a stemmer token filter to output a stemmed and unstemmed version of each token in a stream.\n\n你可以搭配 keyword_repeat过滤器和 分词词根抽取过滤器 从序列中输出每个分词的抽取词根的版本和未抽取词根的版本\nkey_repeat 过滤器必须在任何词根抽取过滤器前进行配置\n词根抽取不是在所有的分词上生效的, 这意味着序列可能在相同的位置包含重复的分词, 即使在进行词根抽取后\n为了删除这些重复的分词, 在词根抽取过滤器后添加 remove_duplicates 过滤器\nGET /_analyze&#123;    &quot;tokenizer&quot;: &quot;whitespace&quot;,    &quot;filter&quot;: [        &quot;keyword_repeat&quot;    ],    &quot;text&quot;: &quot;fox running and jumping&quot;,    &quot;explain&quot;: true,    &quot;attributes&quot;: &quot;keyword&quot;&#125;\n\n输出:\n&#123;  &quot;detail&quot;: &#123;    &quot;custom_analyzer&quot;: true,    &quot;charfilters&quot;: [],    &quot;tokenizer&quot;: ...,    &quot;tokenfilters&quot;: [      &#123;        &quot;name&quot;: &quot;keyword_repeat&quot;,        &quot;tokens&quot;: [          &#123;            &quot;token&quot;: &quot;fox&quot;,            &quot;start_offset&quot;: 0,            &quot;end_offset&quot;: 3,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 0,            &quot;keyword&quot;: true          &#125;,          &#123;            &quot;token&quot;: &quot;fox&quot;,            &quot;start_offset&quot;: 0,            &quot;end_offset&quot;: 3,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 0,            &quot;keyword&quot;: false          &#125;,          &#123;            &quot;token&quot;: &quot;running&quot;,            &quot;start_offset&quot;: 4,            &quot;end_offset&quot;: 11,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 1,            &quot;keyword&quot;: true          &#125;,          &#123;            &quot;token&quot;: &quot;running&quot;,            &quot;start_offset&quot;: 4,            &quot;end_offset&quot;: 11,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 1,            &quot;keyword&quot;: false          &#125;,          &#123;            &quot;token&quot;: &quot;and&quot;,            &quot;start_offset&quot;: 12,            &quot;end_offset&quot;: 15,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 2,            &quot;keyword&quot;: true          &#125;,          &#123;            &quot;token&quot;: &quot;and&quot;,            &quot;start_offset&quot;: 12,            &quot;end_offset&quot;: 15,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 2,            &quot;keyword&quot;: false          &#125;,          &#123;            &quot;token&quot;: &quot;jumping&quot;,            &quot;start_offset&quot;: 16,            &quot;end_offset&quot;: 23,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 3,            &quot;keyword&quot;: true          &#125;,          &#123;            &quot;token&quot;: &quot;jumping&quot;,            &quot;start_offset&quot;: 16,            &quot;end_offset&quot;: 23,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 3,            &quot;keyword&quot;: false          &#125;        ]      &#125;    ]  &#125;&#125;\n\n可以看到, 每个分词的每个版本都有一个 true 关键字属性\n为了抽取非关键词分词的词根, 在 keyword_repeat 过滤器后面添加 stemmer 过滤器:\nGET /_analyze&#123;    &quot;tokenizer&quot;: &quot;whitespace&quot;,    &quot;filter&quot;: [        &quot;keyword_repeat&quot;,        &quot;stemmer&quot;    ],    &quot;text&quot;: &quot;fox running and jumping&quot;,    &quot;explain&quot;: true,    &quot;attributes&quot;: &quot;keyword&quot;&#125;\n\n返回值:\n&#123;  &quot;detail&quot;: &#123;    &quot;custom_analyzer&quot;: true,    &quot;charfilters&quot;: [],    &quot;tokenizer&quot;: ...,    &quot;tokenfilters&quot;: [      &#123;        &quot;name&quot;: &quot;keyword_repeat&quot;,        &quot;tokens&quot;: ...      &#125;,      &#123;        &quot;name&quot;: &quot;stemmer&quot;,        &quot;tokens&quot;: [          &#123;            &quot;token&quot;: &quot;fox&quot;,            &quot;start_offset&quot;: 0,            &quot;end_offset&quot;: 3,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 0,            &quot;keyword&quot;: true          &#125;,          &#123;            &quot;token&quot;: &quot;fox&quot;,            &quot;start_offset&quot;: 0,            &quot;end_offset&quot;: 3,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 0,            &quot;keyword&quot;: false          &#125;,          &#123;            &quot;token&quot;: &quot;running&quot;,            &quot;start_offset&quot;: 4,            &quot;end_offset&quot;: 11,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 1,            &quot;keyword&quot;: true          &#125;,          &#123;            &quot;token&quot;: &quot;run&quot;,            &quot;start_offset&quot;: 4,            &quot;end_offset&quot;: 11,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 1,            &quot;keyword&quot;: false          &#125;,          &#123;            &quot;token&quot;: &quot;and&quot;,            &quot;start_offset&quot;: 12,            &quot;end_offset&quot;: 15,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 2,            &quot;keyword&quot;: true          &#125;,          &#123;            &quot;token&quot;: &quot;and&quot;,            &quot;start_offset&quot;: 12,            &quot;end_offset&quot;: 15,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 2,            &quot;keyword&quot;: false          &#125;,          &#123;            &quot;token&quot;: &quot;jumping&quot;,            &quot;start_offset&quot;: 16,            &quot;end_offset&quot;: 23,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 3,            &quot;keyword&quot;: true          &#125;,          &#123;            &quot;token&quot;: &quot;jump&quot;,            &quot;start_offset&quot;: 16,            &quot;end_offset&quot;: 23,            &quot;type&quot;: &quot;word&quot;,            &quot;position&quot;: 3,            &quot;keyword&quot;: false          &#125;        ]      &#125;    ]  &#125;&#125;\n\n为了删除重复的分词, 添加 remove_duplicates 过滤器到 stemmer 之后:\nGET /_analyze&#123;    &quot;tokenizer&quot;: &quot;whitespace&quot;,    &quot;filter&quot;: [        &quot;keyword_repeat&quot;,        &quot;stemmer&quot;,        &quot;remove_duplicates&quot;    ],    &quot;text&quot;: &quot;fox running and jumping&quot;,    &quot;explain&quot;: true,    &quot;attributes&quot;: &quot;keyword&quot;&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Limit token count token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-limit-token-count-token-filter/","content":"Elasticsearch Limit token count token filter用来限制输出的分词数量\nGET _analyze&#123;  &quot;tokenizer&quot;: &quot;standard&quot;,    &quot;filter&quot;: [    &#123;      &quot;type&quot;: &quot;limit&quot;,      &quot;max_token_count&quot;: 2    &#125;  ],  &quot;text&quot;: &quot;quick fox jumps over lazy dog&quot;&#125;\n\n输出:\n[ quick, fox ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Lowercase token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-lowercase-token-filter/","content":"Elasticsearch Lowercase token filter将分词文本转换为小写\nGET _analyze&#123;  &quot;tokenizer&quot; : &quot;standard&quot;,  &quot;filter&quot; : [&quot;lowercase&quot;],  &quot;text&quot; : &quot;THE Quick FoX JUMPs&quot;&#125;\n\n返回:\n[ the, quick, fox, jumps ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch MinHash token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-minhash-token-filter/","content":"Elasticsearch MinHash token filter用来提供一个分词序列的摘要( signature )\n可以用来估计一个文档的相似度\n可以使用 min_hash 分词过滤器来进行相似度搜索\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Multiplexer token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-multiplexer-token-filter/","content":"Elasticsearch Multiplexer token filtermultiplexer 会获取同一个位置上的多个分词, 每个版本的分词都已经经过一个不同的过滤器了\n相同位置的相同分词将会被移除\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Length token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-length-token-filter/","content":"Elasticsearch Length token filter根据配置的长度参数来删除分词\nGET _analyze&#123;  &quot;tokenizer&quot;: &quot;whitespace&quot;,  &quot;filter&quot;: [    &#123;      &quot;type&quot;: &quot;length&quot;,      &quot;min&quot;: 0,      &quot;max&quot;: 4    &#125;  ],  &quot;text&quot;: &quot;the quick brown fox jumps over the lazy dog&quot;&#125;\n\n返回:\n[ the, fox, over, the, lazy, dog ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch KStem token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-kstem-token-filter/","content":"Elasticsearch KStem token filter也是一种词根转换过滤器\nGET /_analyze&#123;  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;filter&quot;: [ &quot;kstem&quot; ],  &quot;text&quot;: &quot;the foxes jumping quickly&quot;&#125;\n\n返回:\n[ the, fox, jump, quick ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch N-gram token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-n-gram-token-filter/","content":"Elasticsearch N-gram token filter在分词上执行指定长度的 n-grams 处理\nfox -&gt; [ f, fo, o, ox, x ]\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Pattern capture token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-pattern-capture-token-filter/","content":"Elasticsearch Pattern capture token filter使用正则表达式来获取文本中符合条件的单词, 而不是使用正则表达式来进行分词\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Pattern replace token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-pattern-replace-token-filter/","content":"Elasticsearch Pattern replace token filter将符合正则表达式的文本替换成指定的文本\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Porter stem token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-porter-stem-token-filter/","content":"Elasticsearch Porter stem token filter\nProvides algorithmic stemming for the English language, based on the Porter stemming algorithm.\n\n为英文提供词根计算, 基于 Porter stemming 算法\nGET /_analyze&#123;    &quot;tokenizer&quot;: &quot;standard&quot;,    &quot;filter&quot;: [ &quot;porter_stem&quot; ],    &quot;text&quot;: &quot;the foxes jumping quickly&quot;&#125;\n\n返回:\n[ the, fox, jump, quickli ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Predicate script token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-predicate-script-token-filter/","content":"Elasticsearch Predicate script token filter使用指定的脚本来过滤分词\nGET /_analyze&#123;    &quot;tokenizer&quot;: &quot;whitespace&quot;,    &quot;filter&quot;: [        &#123;            &quot;type&quot;: &quot;predicate_token_filter&quot;,            &quot;script&quot;: &#123;                &quot;source&quot;: &quot;&quot;&quot;                    token.term.length() &gt; 3                &quot;&quot;&quot;            &#125;        &#125;    ],    &quot;text&quot;: &quot;the fox jumps the lazy dog&quot;&#125;\n\n返回:\n[ jumps, lazy ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Remove duplicates token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-remove-duplicates-token-filter/","content":"Elasticsearch Remove duplicates token filter删除同一个位置上的重复分词\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Reverse token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-reverse-token-filter/","content":"Elasticsearch Reverse token filter将分词进行反转操作, cat -&gt; tac\n在进行基于后缀的查找时很有用, 例如查询 -ion 结尾的分词或者通过后缀名查找文件\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Shingle token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-shingle-token-filter/","content":"Elasticsearch Shingle token filter对分词进行笛卡尔积的组合\nthe lazy dog -&gt; [ the, lazy, dog ] - shingle filter -&gt; [ the, the lazy, lazy, lazy dog, dog ]\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Snowball token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-snowball-token-filter/","content":"Elasticsearch Snowball token filter使用指定的语言进行词根转换\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Stemmer override token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-stemmer-override-token-filter/","content":"Elasticsearch Stemmer override token filter使用自定义的词根转换规则来覆盖后续的词根转换\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Stemmer token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-stemmer-token-filter/","content":"Elasticsearch Stemmer token filter进行词根转换, 可以指定不同的语言\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Stop token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-stop-token-filter/","content":"Elasticsearch Stop token filter删除一个分词序列中的停用词\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Synonym graph token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-synonym-graph-token-filter/","content":"Elasticsearch Synonym graph token filter进行同义词转换, 包含多单词转换\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Synonym token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-synonym-token-filter/","content":"Elasticsearch Synonym token filter使用指定的同义词配置进行同义词转换\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Trim token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-trim-token-filter/","content":"Elasticsearch Trim token filter删除分词前后的空格\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Truncate token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-truncate-token-filter/","content":"Elasticsearch Truncate token filter对分词进行指定长度的截断, jumping fox -&gt; jump fox\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Unique token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-unique-token-filter/","content":"Elasticsearch Unique token filter删除字符序列中相同的字符\n如果 only_on_same_position 参数设置为 true , 那么只有相同 position 上的相同分词才会被删除, 这时 unique 过滤器的行为和 remove_duplicates 过滤器的行为完全一样\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Uppercase token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-uppercase-token-filter/","content":"Elasticsearch Uppercase token filter将文本转换为大写\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Word delimiter graph token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-word-delimiter-graph-token-filter/","content":"Elasticsearch Word delimiter graph token filter使用指定分隔符来分隔文本, 推荐使用这个过滤器\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Word delimiter token filter","url":"/elasticsearch/elasticsearch-guide/text-analysis/token-filter-reference/elasticsearch-word-delimiter-token-filter/","content":"Elasticsearch Word delimiter token filter使用指定的分隔符来分隔字符\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Token filter reference"],"tags":["User Guides","Elasticsearch","Text analysis","Token filter reference"]},{"title":"Elasticsearch Character group tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-character-group-tokenizer/","content":"Elasticsearch Character group tokenizer当char_group 分词器遇到字符是在预定义的集合中时, 其将文本分解成单词\nchar_group 主要用于需要简单的自定义分词的情况，且 pattern tokenizer 的使用开销不可接受的情况\nPOST _analyze&#123;    &quot;tokenizer&quot;: &#123;        &quot;type&quot;: &quot;char_group&quot;,        &quot;tokenizer_on_chars&quot;: [            &quot;whitespace&quot;,            &quot;-&quot;,            &quot;\\n&quot;        ]    &#125;,    &quot;text&quot;: &quot;The QUICK brown-fox&quot;&#125;\n\n返回:\n&#123;  &quot;tokens&quot;: [    &#123;      &quot;token&quot;: &quot;The&quot;,      &quot;start_offset&quot;: 0,      &quot;end_offset&quot;: 3,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 0    &#125;,    &#123;      &quot;token&quot;: &quot;QUICK&quot;,      &quot;start_offset&quot;: 4,      &quot;end_offset&quot;: 9,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 1    &#125;,    &#123;      &quot;token&quot;: &quot;brown&quot;,      &quot;start_offset&quot;: 10,      &quot;end_offset&quot;: 15,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 2    &#125;,    &#123;      &quot;token&quot;: &quot;fox&quot;,      &quot;start_offset&quot;: 16,      &quot;end_offset&quot;: 19,      &quot;type&quot;: &quot;word&quot;,      &quot;position&quot;: 3    &#125;  ]&#125;\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Classic tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-classic-tokenizer/","content":"Elasticsearch Classic tokenizer主要用于英文\n基于语法的分词器, 在英语下工作良好\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Edge n-gram tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-edge-n-gram-tokenizer/","content":"Elasticsearch Edge n-gram tokenizer每当遇到指定字符列表中的一个字符时, Edge n-gram tokenizer 首先将文本分解单词, 然后生成每个单词的 n 个 gram , 其中 n 个语法的开头固定在单词的开头\nEdge N-Grams are useful for ++search-as-you-type++ queries\n根据输入的字符作为开头进行联想的场景\nWhen you need search-as-you-type for text which has a widely known order, such as movie or song titles, the completion suggester is a much more efficient choice than edge N-grams. Edge N-grams have the advantage when trying to autocomplete words that can appear in any order.\n当你需要对具有广泛顺序的文本(如电影或歌曲标题)进行按类型搜索时, 补全建议器是比 Edge N-Grams 更有效的选择. Edge N-Grams 在尝试自动补全可以以任何顺序出现的单词时有优势\n默认情况edge_ngram 默认情况下生成最小长度为 1 最大长度为 2 的 N-grams\nPOST _analyze&#123;    &quot;tokenizer&quot;: &quot;edge_ngram&quot;,    &quot;text&quot;: &quot;Quick Fox&quot;&#125;\n\n返回:\n[ Q, Qu ]\n\n默认的 gram 长度几乎是没用的, 所以需要在使用 edge_ngram 前进行配置\n配置min_gram默认为 1 , gram 的最小长度\nmax_gram默认为 2 , gram 的最大长度\ntoken_chars需要包括在分词中的字符类\nElasticsearch 会在不属于字符类定义的字符上进行分割\n默认值是 []\n字符类可以是这些:\n\nletter : 字符\ndigit : 数字\nwhitespace : 空格, 回车符\npunctuation : 标点符号\nsymbol : 符号, 例如美元符号\ncustom : 使用 custom_token_chars 属性自定义的字符\n\ncustom_token_chars自定义的需要被看作是分词的一部分的字符\nLimitations of the max_gram parameteredge_ngram 分词器的 max_gram 值限制了分词后的 tokens 的长度\n当 edge_ngram 分词器用于索引时, 意味着搜索长度大于 max_gram 的单词将不会匹配任何已索引的单词, 因为文档入库时, 分词的最大长度是 max_gram\n如果 max_gram 是 3 , 然后搜索 apple , 将不会匹配到索引的单词 app\n可以使用 truncate 来截断搜索的单词的长度来匹配 max_gram 的大小, 但是会导致搜索的精确度下降\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Keyword tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-keyword-tokenizer/","content":"Elasticsearch Keyword tokenizer将接受的文本不做修改地返回\n可以用来和 token filters 配合使用, 来泛化输出, 例如将邮件地址小写化\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Letter tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-letter-tokenizer/","content":"Elasticsearch Letter tokenizer遇到不是字母的字符, 就进行分词\n在欧洲语言下工作良好\n在不是以空格分隔的亚洲语言下工作差劲\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Lowercase tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-lowercase-tokenizer/","content":"Elasticsearch Lowercase tokenizer和 letter tokenizer 一样, 遇到不是字母的字符就进行分词, 然后进行小写化操作\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch N-gram tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-n-gram-tokenizer/","content":"Elasticsearch N-gram tokenizerngram 首先将文本使用指定的字符进行分词\n然后使用指定的最短到最大长度来为每个单词进行字符的拆分组合\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Path hierarchy tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-path-hierarchy-tokenizer/","content":"Elasticsearch Path hierarchy tokenizerpath_hierarchy 分词器接受一个路径值, 返回这个路径的所有层级\nPOST _analyze&#123;  &quot;tokenizer&quot;: &quot;path_hierarchy&quot;,  &quot;text&quot;: &quot;/one/two/three&quot;&#125;\n\n返回:\n[ /one, /one/two, /one/two/three ]\n\nPUT my-index-000001&#123;  &quot;settings&quot;: &#123;    &quot;analysis&quot;: &#123;      &quot;analyzer&quot;: &#123;        &quot;my_analyzer&quot;: &#123;          &quot;tokenizer&quot;: &quot;my_tokenizer&quot;        &#125;      &#125;,      &quot;tokenizer&quot;: &#123;        &quot;my_tokenizer&quot;: &#123;          &quot;type&quot;: &quot;path_hierarchy&quot;,          &quot;delimiter&quot;: &quot;-&quot;,          &quot;replacement&quot;: &quot;/&quot;,          &quot;skip&quot;: 2        &#125;      &#125;    &#125;  &#125;&#125;POST my-index-000001/_analyze&#123;  &quot;analyzer&quot;: &quot;my_analyzer&quot;,  &quot;text&quot;: &quot;one-two-three-four-five&quot;&#125;\n\n返回:\n[ /three, /three/four, /three/four/five ]\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Pattern tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-pattern-tokenizer/","content":"Elasticsearch Pattern tokenizerpattern 使用 Java Regular Expressions 来进行分词, 默认是 \\W+\n可能会导致性能问题\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Simple pattern split tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-simple-pattern-split-tokenizer/","content":"Elasticsearch Simple pattern split tokenizersimple_pattern_split 使用 Lucene regular expressions 进行分词, 比 pattern 速度更快\n默认的 pattern 是空字符串, 使用前必须进行配置\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Simple pattern tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-simple-pattern-tokenizer/","content":"Elasticsearch Simple pattern tokenizersimple_pattern 使用 Lucene regular expressions 进行分词, 比 pattern 速度更快\n默认的 pattern 是空字符串, 使用前必须进行配置\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Standard tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-standard-tokenizer/","content":"Elasticsearch Standard tokenizerstandard 分词器使用 Unicode Text Segmentation algorithm 进行基于语法的分词\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Tokenizer reference","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-tokenizer-reference/","content":"Elasticsearch Tokenizer referenceWord Oriented Tokenizers面向单词的分词器\n\nStandard Tokenizer\nLetter Tokenizer\nLowercase Tokenizer\nWhitespace Tokenizer\nUAX URL Email Tokenizer\nClassic Tokenizer\nThai Tokenizer\n\nPartial Word Tokenizers单词分解分词器\n\nN-Gram Tokenizer\nEdge N-Gram Tokenizer\n\nStructed Text Tokenizers结构化文本分词器\n\nKeyword Tokenizer\nPattern Tokenizer\nSimple Pattern Tokenizer\nChar Group Tokenizer\nSimple Pattern Split Tokenizer\nPath Tokenizer\n\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch UAX URL email tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-uax-url-email-tokenizer/","content":"Elasticsearch UAX URL email tokenizeruax_url_email 分词器和 standard 分词器一样, 不同的点是 uax_url_email 会将 URLs 和 邮件地址 作为单独的分词处理\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Elasticsearch Whitespace tokenizer","url":"/elasticsearch/elasticsearch-guide/text-analysis/tokenizer-reference/elasticsearch-whitespace-tokenizer/","content":"Elasticsearch Whitespace tokenizerwhitespace 分词器使用空格进行分词\n参考link\n","categories":["Elasticsearch - User Guides - Text analysis - Tokenizer reference"],"tags":["User Guides","Elasticsearch","Text analysis","Tokenizer reference"]},{"title":"Groovy Behavior of meta-annotations","url":"/groovy/object-orientation/annotation/meta-annotations/groovy-behavior-of-meta-annotations/","content":"Groovy Behavior of meta-annotationsMeta-annotations 是 Groovy 的特性，不能用于 Java\nGroovy 编译器会将 meta-annotation 包含的 Annotation 放到目标中\nExample: replace @TransactionalService with @Transactional and @Service\ndef annotations = MyTransactionalService.annotations*.annotationType()assert (Service in annotations)assert (Transaction in annotations)\n","categories":["Groovy Object Orientation - Annotation - Meta-annotations"],"tags":["Groovy","Object Orientation","Annotation","Meta-annotations"]},{"title":"Groovy Custom annotation processors","url":"/groovy/object-orientation/annotation/meta-annotations/groovy-custom-annotation-processors/","content":"Groovy Custom annotation processors一个自定义的注解处理器允许你选择怎样去展开一个 meta-annotation\n定义自定义注解处理器：\n\n创建一个 meta-annotation 处理器，继承 AnnotationCollectorTransform\n在 meta-annotation 的定义中声明使用的处理器\n\n@AnnotationCollector(processor = &quot;org.codehaus.groovy.transform.CompileDynamicProcessor&quot;)public @interface CompileDynamic\n\n@CompileStaticclass CompileDynamicProcessor extends AnnotationCollectorTransform &#123;    private static final ClassNode CS_NODE = ClassHelper.make(CompileStatic)    private static final ClassNode TC_NODE = ClassHelper.make(TypeCheckingMode)        List&lt;AnnotationNode&gt; visit(AnnotationNode collector,                                AnnotationNode aliasAnnotationUsage,                                AnnotatedNode aliasAnnotated,                                SourceUnit source) &#123;        def node = new AnnotationNode(CS_NODE)        def enumRef = new PropertyExpression(            new ClassExpression(TC_NODE),            &quot;SKIP&quot;        )        node.addMember(&quot;value&quot;, enumRef)        Collections.singletonList(node)    &#125;&#125;\n","categories":["Groovy Object Orientation - Annotation - Meta-annotations"],"tags":["Groovy","Object Orientation","Annotation","Meta-annotations"]},{"title":"Groovy Declaring meta-annotations","url":"/groovy/object-orientation/annotation/meta-annotations/groovy-declaring-meta-annotations/","content":"Groovy Declaring meta-annotations将多个 Annotation 合成一个 Annotation\n一个 Meta-annotation 是多个 Annotation 的别名\nimport groovy.transform.AnnotationCollector@Service@Transactional@AnnotationCollector@interface TransactionalService &#123;&#125;\n","categories":["Groovy Object Orientation - Annotation - Meta-annotations"],"tags":["Groovy","Object Orientation","Annotation","Meta-annotations"]},{"title":"Groovy Meta-annotation parameters","url":"/groovy/object-orientation/annotation/meta-annotations/groovy-meta-annotation-parameters/","content":"Groovy Meta-annotation parametersThe meta-annotation supports overriding specific values:\n@Timeout(after=3600)@Dangerous(type=&#x27;explosive&#x27;)@Timeout(after=3600)@Dangerous(type=&#x27;explosive&#x27;)@AnnotationCollectorpublic @interface Explosive &#123;&#125;@Explosive(after=0)class Bomb &#123;&#125;\n\n如果两个 Annotation 有相同的参数名称，那默认的处理器将会将这个名称的参数复制到每个有个这个名称参数的 Annotation 中\n如果有两个 Annotation 有相同的参数名称，但是参数类型不同，将会报编译时异常\n","categories":["Groovy Object Orientation - Annotation - Meta-annotations"],"tags":["Groovy","Object Orientation","Annotation","Meta-annotations"]},{"title":"Groovy Optional parentheses","url":"/groovy/object-orientation/semantics/optionality/groovy-optional-parentheses/","content":"Groovy Optional parentheses方法调用时可以省略括号，在方法有至少一个入参且没有歧义的时候\nprintln &#x27;hello world&#x27;def maximum = Math.max 5, 10\n\n当方法没有入参，或者有歧义的时候，不能省略括号\nprintln()println(Max.max(5, 10))\n","categories":["Groovy Object Orientation - Semantics - Optionality"],"tags":["Groovy","Object Orientation","Semantics","Optionality"]},{"title":"Groovy Optional public keyword","url":"/groovy/object-orientation/semantics/optionality/groovy-optional-public-keyword/","content":"Groovy Optional public keywordGroovy 中 Class 和 Method 默认是 public 的，因此 public 可以省略\npublic class Server &#123;    public String toString() &#123; &quot;a String&quot; &#125;&#125;// 等于class Server &#123;    String toString() &#123; &quot;a String&quot; &#125;&#125;\n","categories":["Groovy Object Orientation - Semantics - Optionality"],"tags":["Groovy","Object Orientation","Semantics","Optionality"]},{"title":"Groovy Optional return keyword","url":"/groovy/object-orientation/semantics/optionality/groovy-optional-return-keyword/","content":"Groovy Optional return keywordMethod 或者 Closure 里面的最后一行表达式的计算结果将会作为返回\n意味着 return 关键字可以省略\n","categories":["Groovy Object Orientation - Semantics - Optionality"],"tags":["Groovy","Object Orientation","Semantics","Optionality"]},{"title":"Groovy Optional semicolons","url":"/groovy/object-orientation/semantics/optionality/groovy-optional-semicolons/","content":"Groovy Optional semicolons如果一行只有一个语句，那么结尾的分号可以省略\n","categories":["Groovy Object Orientation - Semantics - Optionality"],"tags":["Groovy","Object Orientation","Semantics","Optionality"]},{"title":"Groovy Class literals vs variables and the as operator","url":"/groovy/object-orientation/semantics/promotion-and-coercion/groovy-class-literals-vs-variables-and-the-as-operator/","content":"Groovy Class literals vs variables and the as operatoras 关键字只能在 Class 字面量的情况下工作，如果是要转换反射而来的 Class ，要使用 asType 方法\nClass clazz = Class.forName(&#x27;Greeter&#x27;)def greeter = &#123; println &#x27;Hello, Groovy!&#x27; &#125; as clazz         // 将会报错\n\nClass clazz = Class.forName(&#x27;Greeter&#x27;)def greeter = &#123; println &#x27;Hello, Groovy!&#x27; &#125;.asType(clazz)    // works well\n","categories":["Groovy Object Orientation - Semantics - Promotion and coercion"],"tags":["Groovy","Object Orientation","Semantics","Promotion and coercion"]},{"title":"Groovy Closure to type coercion","url":"/groovy/object-orientation/semantics/promotion-and-coercion/groovy-closure-to-type-coercion/","content":"Groovy Closure to type coercionAssigning a closure to a SAM typeSAM type 是只有一个抽象方法的类型，包括：\n\n函数式接口\n只有一个抽象方法的抽象类\n\n任何 Closure 可以通过使用 as 操作符来将其转换为 SAM type：\nPredicate filter = &#123; it.contains &#x27;G&#x27; &#125; as Predicateassert filter.accept(&#x27;Groovy&#x27;) == trueGreeter greeter = &#123; &#x27;Groovy&#x27; &#125; as Greetergreeter.greet()\n\n在 Groovy 2.2.0 之后，as 操作符可以省略：\nPredicate filter = &#123; it.contains &#x27;G&#x27; &#125;assert filter.accept(&#x27;Groovy&#x27;) == trueGreeter greeter = &#123; &#x27;Groovy&#x27; &#125;greeter.greet()\n\n还可以使用 方法指针，使用 .&amp; 操作符：\nboolean doFilter(String s) &#123; s.contains(&#x27;G&#x27;) &#125;Predicate filter = this.&amp;doFilterassert filter.accept(&#x27;Groovy&#x27;) == trueGreeter greeter = GroovySystem.&amp;getVersiongreeter.greet()\n\nCalling a method accepting a SAM type with a Closure在接受 SAM type 作为入参的方法中使用 Closure：\npublic &lt;T&gt; List&lt;T&gt; filter(List&lt;T&gt; source, Predicate&lt;T&gt; predicate) &#123;    source.findAll &#123; predicate.accept(it) &#125;&#125;\n\n使用 as 关键字：\nassert filter([&#x27;Java&#x27;, &#x27;Groovy&#x27;], &#123; it.contains(&#x27;G&#x27;) &#125; as Predicate) == [&#x27;Groovy&#x27;]\n\n在 Groovy 2.2.0 之后，可以省略 as 关键字：\nassert filter([&#x27;Java&#x27;, &#x27;Groovy&#x27;]) &#123; it.contains(&#x27;G&#x27;) &#125; == [&#x27;Groovy&#x27;]\n\nClosure to arbitrary type coercioninterface FooBar &#123;    int foo()    void bar()&#125;def impl = &#123; println &#x27;ok&#x27;; 123 &#125; as FooBarassert impl.foo() == 123impl.bar()// 打印结果okok\n\n除了 SAM type，还可以将一个 Closure 转换为任何类型，特别是接口\ndef impl = &#123; println &#39;ok&#39;; 123 &#125; as FooBar 将会生成一个类，这个类中所有方法都使用 Closure 作为实现\n还可以将一个 Closure 转换为任何 Class\nclass FooBar &#123;    int foo() &#123; 1 &#125;    void bar() &#123; println &#x27;bar&#x27; &#125;&#125;def impl = &#123; println &#x27;ok&#x27;; 123 &#125; as FooBarassert impl.foo()impl.bar()// 打印结果okok\n","categories":["Groovy Object Orientation - Semantics - Promotion and coercion"],"tags":["Groovy","Object Orientation","Semantics","Promotion and coercion"]},{"title":"Groovy Custom type coercion","url":"/groovy/object-orientation/semantics/promotion-and-coercion/groovy-custom-type-coercion/","content":"Groovy Custom type coercion可以在类中实现 asType 方法自定义类型转换的逻辑\n自定义类型转换通过 as 关键字来调用，并且 as 关键字不能省略\nclass Polar &#123;    double r    double phi        /**     * 定义 asType 方法来实现自定义的类型转换*/    def asType(Class target) &#123;        if (target == Cartesian) &#123;            return new Cartesian(x: r * cos(phi), y: r * sin(phi))        &#125;    &#125;&#125;class Cartesian &#123;    double x    double y&#125;def sigma = 1E-16def polar = new Polar(r: 1.0, phi: PI / 2)def cartesian = polar as Cartesian      // 使用 as 关键字来进行类型转换，将会调用 Polar 上的 asType() 方法assert abs(cartesian.x - sigma) &lt; sigma\n\n可以在 Polar 类的外面实现 asType() 方法，这在不能直接修改源码的情况下很有用：\nPolar.metaClass.asType = &#123; Class target -&gt;    if (Cartesian == target) &#123;        return new Cartesian(x: r * cos(phi), y: r * sin(phi))    &#125;&#125;\n","categories":["Groovy Object Orientation - Semantics - Promotion and coercion"],"tags":["Groovy","Object Orientation","Semantics","Promotion and coercion"]},{"title":"Groovy Map to type coercion","url":"/groovy/object-orientation/semantics/promotion-and-coercion/groovy-map-to-type-coercion/","content":"Groovy Map to type coercionGroovy 允许你将一个 Map 转换成一个接口或者类\nMap 的 key 作为方法的名称\nMap 的 value 作为方法的实现\ndef mapmap = [        i      : 10,        hasNext: &#123; println map; map.i &gt; 0 &#125;,        next   : &#123; println map; map.i-- &#125;]def iter = map as Iteratorprintln mapif (iter.hasNext()) &#123;    println iter.next()&#125;\n\n输出：\n[i:10, hasNext:Test$_run_closure1@702ed190, next:Test$_run_closure2@173b9122][i:10, hasNext:Test$_run_closure1@702ed190, next:Test$_run_closure2@173b9122][i:10, hasNext:Test$_run_closure1@702ed190, next:Test$_run_closure2@173b9122]10\n\n只需要实现实际需要被调用的方法，如果一个被调用的方法不存在于 Map 中，那么一个 MissingMethodException 或 UnsupportedOperationException 异常将会抛出，取决于入参：\ninterface X &#123;    void f()    void g(int n)    void h(String s, int n)&#125;def x = [f: &#123; println &quot;f called&quot; &#125;] as Xx.f()       // 方法存在x.g()       // 抛出 MissingMethodExceptionx.g(5)      // 抛出 UnsupportedOperationException\n\nThe type of the exception depends on the call itself:\n\nMissingMethodException if the arguments of the call do not match those from the interface&#x2F;class\nUnsupportedOperatoinException if the arguments of the call match one of the overloaded methods of the interface&#x2F;class\n\n","categories":["Groovy Object Orientation - Semantics - Promotion and coercion"],"tags":["Groovy","Object Orientation","Semantics","Promotion and coercion"]},{"title":"Groovy String to enum coercion","url":"/groovy/object-orientation/semantics/promotion-and-coercion/groovy-string-to-enum-coercion/","content":"Groovy String to enum coercionenum State &#123;    up,    down&#125;State st = &#x27;up&#x27;         // 不需要明确使用 as 关键字assert st == State.up\n\ndef val = &#x27;up&#x27;State st = &quot;$&#123;val&#125;&quot;     // 使用 GString 的插值assert st == State.up\n\nState switchState(State st) &#123;    switch(st) &#123;        case &#x27;up&#x27;:            return State.down   // 返回明确的枚举        case &#x27;down&#x27;:            return &#x27;up&#x27;         // 返回隐式转换的枚举    &#125;&#125;\n\n// 在方法调用中使用字符串转枚举时，必须明确使用 as 关键字assert switchState(&#x27;up&#x27; as State) == State.downassert switchState(State.down)    == State.up\n","categories":["Groovy Object Orientation - Semantics - Promotion and coercion"],"tags":["Groovy","Object Orientation","Semantics","Promotion and coercion"]},{"title":"Groovy Conditional structures","url":"/groovy/object-orientation/semantics/statements/groovy-conditional-structures/","content":"Groovy Conditional structuresGroovy switch statement can handle any kind of switch value and different kinds of matching can be performed\ndef x = 4def result = &quot;&quot;switch (x) &#123;    case &#x27;foo&#x27;:        result = &#x27;found foo&#x27;    case &#x27;bar&#x27;:        result += &#x27;bar&#x27;    case [4, 5, 6, &#x27;inList&#x27;]:   // 查找目标是否在 List 中        result = &#x27;list&#x27;        break    case 12..30:                // 查找目标是否在 Range 中        result = &#x27;range&#x27;        break    case Integer:        result = &#x27;integer&#x27;        break    case Number:        result = &#x27;number&#x27;        break    case ~/fo*/:                    // toString() representation of x matches the pattern ?        result = &#x27;foo regex&#x27;        break    case &#123; it &lt; 0 &#125;:        result = &#x27;negative&#x27;        break    default:        result = &#x27;default&#x27;&#125;assert result == &#x27;list&#x27;\n\nSwitch supports the following kinds of comparisons:\n\n直接比较类型; Class case values match if the switch value is an instance of the class\n正则表达式和toString()方法进行匹配; Regular expression case values match if the toString() representation of the switch value matches the regex\n可以判断值是否在集合中; Collection case values match if the switch value is contained in the collection. This also includes ranges(since they are Lists)\nClosure case values match if the calling the closure returns a result which is true according to the Groovy truth\nif none of the above are used then the case value matches if the case value equals the switch case\n\n当使用 Closure 作为 case value 时，默认的 it 参数就是代表 switch value\n","categories":["Groovy Object Orientation - Semantics - Statements"],"tags":["Groovy","Object Orientation","Semantics","Statements"]},{"title":"Groovy Labeled statements","url":"/groovy/object-orientation/semantics/statements/groovy-labeled-statements/","content":"Groovy Labeled statementsAny statement can be associated with a label\nLabels do not impact the semantics of the code\nLabels can be used to make the code easier to read like in the following example:\ngiven:    def x = 1    def y = 2when:    def z = x+ythen:    assert z == 3\n\n在默认情况下 Lable 对代码来说没有语义作用，但是 Lable 属于 AST (抽象语法树)，所以在 AST 转换的时候是可以使用这些 Label 信息的，使得结果是不同的语义\nSpock Framework 就是使用这样的操作来使得测试更加简单\n","categories":["Groovy Object Orientation - Semantics - Statements"],"tags":["Groovy","Object Orientation","Semantics","Statements"]},{"title":"Groovy Looping structures","url":"/groovy/object-orientation/semantics/statements/groovy-looping-structures/","content":"Groovy Looping structuresMulti-assignment in combination with for loopdef baNums = []for (def (String u, int v) = [&#x27;bar&#x27;, 42]; v &lt; 45; u++, v++) &#123;    baNums &lt;&lt; &quot;$u $v&quot;&#125;assert baNums == [&#x27;bar 42&#x27;, &#x27;bas 43&#x27;, &#x27;bat 44&#x27;]\n\nfor in loop// iterate over a mapdef map = [&#x27;abc&#x27;: 1, &#x27;def&#x27;: 2, &#x27;xyz&#x27;: 3]x = 0for (e in map) &#123;    x += e.value&#125;assert x == 6// iterate over values in a mapx = 0for (e in map.values()) &#123;    x += v&#125;assert x == 6// iterate over the characters in a stringdef text = &#x27;abc&#x27;def list = []for (c in text) &#123;    list.add(c)&#125;assert list == [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]// iterate over the characters in a stringdef text = &#x27;abc&#x27;def list = []for (c : text) &#123;    list.add(c)&#125;assert list == [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]\n","categories":["Groovy Object Orientation - Semantics - Statements"],"tags":["Groovy","Object Orientation","Semantics","Statements"]},{"title":"Groovy Multiple assignment","url":"/groovy/object-orientation/semantics/statements/groovy-multiple-assignment/","content":"Groovy Multiple assignmentdef (a, b, c) = [10, 20, &#x27;foo&#x27;]assert a == 10 &amp;&amp; b == 20 &amp;&amp; c == &#x27;foo&#x27;\n\ndef (int i, String j) == [10, &#x27;foo&#x27;]assert i == 10 &amp;&amp; j == &#x27;foo&#x27;\n\ndef nums = [1, 3, 5]def a, b, c(a, b, c) = numsassert a == 1 &amp;&amp; b == 3 &amp;&amp; c == 5\n\ndef (_, month, year) = &quot;18th June 2009&quot;.split()assert &quot;In $month of $year&quot; == &#x27;In June of 2009&#x27;\n","categories":["Groovy Object Orientation - Semantics - Statements"],"tags":["Groovy","Object Orientation","Semantics","Statements"]},{"title":"Groovy Object destructuring with multiple assignment","url":"/groovy/object-orientation/semantics/statements/groovy-object-destructuring-with-multiple-assignment/","content":"Groovy Object destructuring with multiple assignmentWe can combine multiple assignments and the subscript operator(getAt()&#x2F;putAt()) mehtods to implement object destructuring\n@Immutableclass Coordinates &#123;    double latitude    double longitude        double getAt(int idx) &#123;        if (idx == 0) latitude        else if (idx == 1) longitude        else throw new Exception(&quot;Wrong coordinate index, use 0 or 1&quot;)    &#125;&#125;def coordinates = new Coordinates(latitude: 43.33, longitude: 3.67)def (la, lo) = coordinatesassert la   == 43.33assert log  == 3.67\n","categories":["Groovy Object Orientation - Semantics - Statements"],"tags":["Groovy","Object Orientation","Semantics","Statements"]},{"title":"Groovy Power assertion","url":"/groovy/object-orientation/semantics/statements/groovy-power-assertion/","content":"Groovy Power assertionA power assertion is decomposed into 3 parts:\nassert [left expression] == [right expression] : (optional message)\n","categories":["Groovy Object Orientation - Semantics - Statements"],"tags":["Groovy","Object Orientation","Semantics","Statements"]},{"title":"Groovy Semantics Statements Overflow and Underflow","url":"/groovy/object-orientation/semantics/statements/groovy-semantics-statements-overflow-and-underflow/","content":"Groovy Semantics Statements Overflow and Underflow如果左边的变量过多，则多出来的变量为 null\ndef (a, b, c) = [1, 2]assert a == 1 &amp;&amp; b == 2 &amp;&amp; c == null\n\n如果右边的赋值过多，则多出来的值被忽略\ndef (a, b) = [1, 2, 3]assert a == 1 &amp;&amp; b == 2\n","categories":["Groovy Object Orientation - Semantics - Statements"],"tags":["Groovy","Object Orientation","Semantics","Statements"]},{"title":"Groovy The Groovy Truth","url":"/groovy/object-orientation/semantics/the-groovy-truth/groovy-the-groovy-truth/","content":"Groovy The Groovy TruthGroovy 通过以下规则来决定一个表达式是 true 还是 false\nCollections and Arrays非空集合 和 非空数组 ，判断为 true\nassert [1, 2, 3]assert ![]\n\nMatchers如果 Matcher 有至少一个匹配，判断为 true\nassert (&#x27;a&#x27; =~ /a/)assert !(&#x27;a&#x27; =~ /b/)\n\nIterators and EnumerationsIetrators 和 Enumerations 还有元素的时候，判读为 true\nassert [0].iterator()assert ![].iterator()Vector v = [0] as VectorEnumeration enumeration = v.elements()assert enumerationenumeration.nextElement()   // 注意看这里assert !enumeration\n\nMaps非空的 Maps ，判断为 true\nassert [one: 1]assert ![:]\n\nStrings非空的字符串，判断为 true\nassert &#x27;a&#x27;assert !&#x27;&#x27;def nonEmpty = &#x27;a&#x27;assert &quot;$nonEmpty&quot;def empty = &#x27;&#x27;assert !&quot;$empty&quot;\n\nNumbers非 0 的数字，判断为 true\nassert 1assert 3.5assert !0\n\nObject References非 null 的对象引用，判断为 true\nassert new Object()assert !null\n\nCustomizing the truth with asBoolean() methods通过自定义 asBoolean() 方法来让 Groovy 计算你的对象是 true 还是 false\nclass Color &#123;    String name        Boolean asBoolean() &#123;        this.name == &#x27;green&#x27; ? true : false    &#125;&#125;assert new Color(name: &#x27;green&#x27;)assert !new Color(name: &#x27;red&#x27;)\n","categories":["Groovy Object Orientation - Semantics - The Groovy Truth"],"tags":["Groovy","Object Orientation","Semantics","The Groovy Truth"]},{"title":"Groovy List and map constructors","url":"/groovy/object-orientation/semantics/typing/groovy-list-and-map-constructors/","content":"Groovy List and map constructors在下面的情况中，一个 List字面量A 或者一个 Map字面量A 可以被赋值给 类型T 的变量：\n\nthe assignment is a variable declaration and A is a list literal and T has a constructor whose parameters match the types of the elements in the list literal\nthe assignment is a variable declaration and A is a map literal and T has a no-arg constructor and a property for each of the map keys\n\n@groovy.transform.TupleConstructorclass Person &#123;    String firstName    String lastName&#125;Person classic = new Person(&quot;Ada&quot;, &quot;Lovelace&quot;)\n\n可以使用 list constructor :\nPerson list = [&#x27;Ada&#x27;, &#x27;Lovelace&#x27;]\n\n或者 map constructor :\nPerson map = [firstName: &#x27;Ada&#x27;, lastName: &#x27;Lovelace&#x27;]\n\n在 map constructor 中，会额外检查 map 中的 keys 是否和属性的名字一致：\nimport groovy.transform.TupleConstructor@TupleConstructorclass Person &#123;    String firstName    String lastName&#125;Person p = [firstName: &#x27;lin&#x27;, lastName: &#x27;weiyu&#x27;, age: 18]assert p.firstName == &#x27;lin&#x27;\n\n将会报错：Caught: org.codehaus.groovy.runtime.typehandling.GroovyCastException: Cannot cast object &#39;&#123;firstName=lin, lastName=weiyu, age=18&#125;&#39; with class &#39;java.util.LinkedHashMap&#39; to class &#39;Person&#39; due to: org.codehaus.groovy.runtime.metaclass.MissingPropertyExceptionNoStack: No such property: age for class: Person\nmap 中的 key 的数量不可以多于要转换的对象的属性\n","categories":["Groovy Object Orientation - Semantics - Typing"],"tags":["Groovy","Object Orientation","Semantics","Typing"]},{"title":"Groovy Method resolution","url":"/groovy/object-orientation/semantics/typing/groovy-method-resolution/","content":"Groovy Method resolutionIn type checked mode, methods are resolved at compile time\nResolution works by name and arguments\nThe return type is irrelevant(无关) to method selection\nTypes of arguments are matched against the type of the parameters following those rules:\nT : 是方法参数的类型\nA : 是入参的类型\no : 是入参对象\nT equals Aint sum(int x, int y) &#123; x+y &#125;assert sum(3, 4) == 7\n\nT is a String and A is a GStringString format(String str) &#123; &quot;Result: $str&quot; &#125;assert format(&quot;$&#123;4+3&#125;&quot;) == &quot;Result: 7&quot;\n\no is null and T is not a primitive typeString format(int value) &#123; &quot;Result: $value&quot; &#125;assert format(7) == &quot;Result: 7&quot;format(null)    // fails\n\nT is an array and A is an array and the component type of A is assignable to the component type of TString format(String[] values) &#123;    &quot;Result: $&#123;values.join(&#x27; &#x27;)&#125;&quot;&#125;assert format([&#x27;a&#x27;, &#x27;b&#x27;] as String[]) == &quot;Result: a b&quot;format([1, 2] as int[])     // fails\n\nT is a superclass of AString format(AbstractList list) &#123;    list.join(&#x27;,&#x27;)&#125;format(new ArrayList()      // passesString format(LinkedList list) &#123;    list.join(&#x27;,&#x27;)&#125;format(new ArrayList()      // fails\n\nT is an interface implements by AString format(List list) &#123;    list.join(&#x27;,&#x27;)&#125;format(new ArrayList())     // passesString format(RandomAccess list) &#123;    &#x27;foo&#x27;&#125;format(new LinkedList())    // fails\n\nT or A are primitive type and their boxed types are assignableint sum(int x, int y) &#123; x+y &#125;assert sum(3, new Integer(4))               == 7assert sum(new Integer(3), 4)               == 7assert sum(new Integer(3), new Integer(4))  == 7\n\nT extends groovy.lang.Closure and A is a SAM-type (single abstract method type)interface SAMType &#123;    int doSomething()&#125;int twice(SAMType sam) &#123; 2*sam.doSomething() &#125;assert twice &#123; 123 &#125; == 246abstract class AbstractSAM &#123;    int calc() &#123; 2*value &#125;    abstract int value()&#125;int eightTimes(AbstractSAM sam) &#123; 4*sam.calc() &#125;assert eightTimes &#123; 123 &#125; == 984\n\nT and A derive from java.lang.Number and conform to the same rules as assignment of numbersT and A derive from java.lang.Number and conform to the same rules as assignment of numbers\n","categories":["Groovy Object Orientation - Semantics - Typing"],"tags":["Groovy","Object Orientation","Semantics","Typing"]},{"title":"Groovy Optional Typing","url":"/groovy/object-orientation/semantics/typing/groovy-optional-typing/","content":"Groovy Optional Typing变量的类型可以不指定，使用 def 来代替变量的类型\n方法的返回值类型 和 方法入参的类型 都可以使用 def 来代替：\ndef concat(def a, def b) &#123;    a + b&#125;\n\n变量的类型，方法的返回值类型，方法的入参 还可以省略 def 关键字声明\nname = &#x27;lin&#x27;assert name == &#x27;lin&#x27;\n\n如果 方法的返回值类型 和 方法入参的类型 都省略，那么方法必须使用明确的修饰符，不然就变成了方法的调用：\nprivate concat(a, b) &#123;  // `concat(a, b)` 是方法调用    a + b&#125;assert concat(&#x27;foo&#x27;, &#x27;bar&#x27;) == &#x27;foobar&#x27;assert concat(1, 2) == 3\n\ndef concat(a, b) &#123; a + b &#125;assert concat(&#x27;lin&#x27;, &#x27;weiyu&#x27;) == &#x27;linweiyu&#x27;\n","categories":["Groovy Object Orientation - Semantics - Typing"],"tags":["Groovy","Object Orientation","Semantics","Typing"]},{"title":"Groovy Static type checking","url":"/groovy/object-orientation/semantics/typing/groovy-static-type-checking/","content":"Groovy Static type checking默认情况下，Groovy 在编译时进行最小限度的类型检查\n由于 Groovy 是一个动态语言，许多静态编译器会做的检查在编译时都不会进行\n可以通过在运行时元编程（runtime metaprogramming）添加一个方法来改变一个类或实例的运行时的行为\nclass Person &#123;                                                              String firstName    String lastName&#125;def p = new Person(firstName: &#x27;Raymond&#x27;, lastName: &#x27;Devos&#x27;)             assert p.formattedName == &#x27;Raymond Devos&#x27;       // 3\n\n上诉代码在 Groovy 中，在编译时不会失败；在正确编码的情况下，运行时也不会失败\n事实上，为了让 3 在运行时正确运行，一个可能的做法是依赖运行时元编程，只要添加以下代码到 Person 类的声明后面：\nPerson.metaClass.getFormattedname() = &#123; &quot;$delegate.firstName $delegate.lastName&quot; &#125;\n\n这意味着，在 Groovy 中你不能通过一个对象的声明类型来做任何的假定\n即使你知道这个假定，你也不能明确在编译时哪个方法会被调用，或者哪个属性会被获取\n你可以明确告诉编译器你要转换为类型检查模式，这可以通过使用注解 @groovy.transform.TypeChecked 来修饰类或方法来实现\n当类型检查启动时，编译器会做更多的工作：\n\n类型推断开启，举例来说，意味着即使你使用 def 声明一个本地变量，类型检查器将会从赋值中推断变量的类型\n方法调用会在编译时进行解析，意味着如果一个方法在类中没有定义，那么编译器将会抛出一个异常\n总的来说，所有在静态语言中会出现的编译时异常都会出现：方法没有找到，属性没有找到，方法调用中不匹配的类型，类型精度异常\n\n","categories":["Groovy Object Orientation - Semantics - Typing"],"tags":["Groovy","Object Orientation","Semantics","Typing"]},{"title":"Groovy The @TypeChecked annotation","url":"/groovy/object-orientation/semantics/typing/groovy-the-typechecked-annotation/","content":"Groovy The @TypeChecked annotationActivating type checking at compile timegroovy.transform.TypeChecked 注解开启类型检查，它可以放在 Class 上：\n@groovy.transform.TypeCheckedclass Calculator &#123;    int sum(int x, int y) &#123; x + y &#125;&#125;\n\n被注解的 Class 中所有的方法，属性，字段，内部类都被进行类型检查\n或者放在一个 Method 上：\nclass Calculator &#123;    @groovy.transform.TypeChecked    int sum(int x , int y) &#123; x + y &#125;&#125;\n\n被注解的 Method 中，只有方法和潜在的 Closures 或者 匿名内部类会被进行类型检查\nSkipping sections类型检查都范围可以被限制，如果一个 Class 是类型检查的，你可以指示类型检查器跳过一个使用了 @TypeChecked(TypeCheckingMode.SKIP) 的方法：\nimport groovy.transform.TypeCheckedimport groovy.transform.TypeCheckingMode@TypeCheckedclass GreetingService &#123;    String greeting() &#123;        doGreet()    &#125;        @TypeChecked(TypeCheckingMode.SKIP)    private String doGreet() &#123;        def b = new SentenceBuilder()        b.hello.my.name.is.John         // the type checker doesn&#x27;t complain about missing properties here        b    &#125;&#125;def s = new GreetingService()assert s.greeting() == &#x27;Hello my name is John&#x27;\n","categories":["Groovy Object Orientation - Semantics - Typing"],"tags":["Groovy","Object Orientation","Semantics","Typing"]},{"title":"Groovy Type checking assignments","url":"/groovy/object-orientation/semantics/typing/groovy-type-checking-assignments/","content":"Groovy Type checking assignments在下面的情况中，一个 类型A 的 对象o 可以被分配给一个 类型T 的 变量：\n声明在接下来的代码例子中，= 左边代表 类型T，= 右边代表 类型A\n类型T 是被赋值的 变量 的类型\n类型T 等于 类型ADate now = new Date()\n\n类型T 是 String,boolean,Boolean,ClassString s = new Date()               // 隐式调用 toString() 方法Boolean boxed = &#x27;some string&#x27;       // Groovy truthboolean prim = &#x27;some string&#x27;        // Groovy truthClass clazz = &#x27;java.lang.String&#x27;    // class coercion\n\n对象o 是 null 且 类型T 不是原始类型String s = null     // passesint i = null        // fails\n\nT is an array and A is an array and the component type of A is assignable to the component type of Tint[] i = new int[4]    // passesint[] i = new String[4] // fails\n\nT is an array and A is a list and the component type of A is assignable to the component type of Tint[] i = [1, 2, 3]                 // passesint[] i = [1, 2, 3, new Date()]     // fails\n\n类型T 是 类型A 的子类AbstractList list = new ArrayList()     // passesLinkedList list = new ArrayList()       // fails\n\n类型T 是 类型A 实现了的接口类型List list = new ArrayList()             // passesRandomAccess list = new LinkedList()    // fails\n\n类型T 和 类型A 都是原始类型且它们的包装类型都是可赋值的int i = 0Integer bi = 1int x = new Integer(123)double d = new Float(5F)\n\n类型T 继承了 groovy.lang.Closure 且 类型A 是 SAM-type (single abstract method type)Runnable r = &#123; println &#x27;Hello&#x27; &#125;interface SAMType &#123;    int doSomething()&#125;SAMType sam = &#123; 123 &#125;assert sam.doSomething() == 123abstract class AbstractSAM &#123;    int calc() &#123; 2 * value() &#125;    abstract int value()&#125;AbstractSAM c = &#123; 123 &#125;assert c.calc() == 246\n\n类型T 和 类型A 是 java.lang.Number 的子类需要满足不同数值类型之间的转换规则\n","categories":["Groovy Object Orientation - Semantics - Typing"],"tags":["Groovy","Object Orientation","Semantics","Typing"]},{"title":"Groovy ConfigSlurper","url":"/groovy/user-guides/groovy-development-kit/handy-utilities/groovy-configslurper/","content":"Groovy ConfigSlurperConfigSlurper 是一个读取定义在 Groovy 脚本文件中的配置的工具\nConfigSlurper 允许使用 . 访问\nConfigSlurper 允许使用 Closure 范围定义配置和任意类型\nBut in addition, it allows for Closure scoped configuration values and arbitraty object types.\ndef config = new ConfigSlurper().parse(&#x27;&#x27;&#x27;    app.date = new Date()    app.age = 42            // 1    app &#123;        name = &quot;Test$&#123;42&#125;&quot;  // 2    &#125;&#x27;&#x27;&#x27;)assert config.app.date instanceof Dateassert config.app.age == 42assert config.app.name == &#x27;Test42&#x27;\n\n1 : Usage of the dot notation\n2 : usage of Closure scopes as an alternative to the dot notation\nparse 方法可以用来获取一个 groovy.util.ConfigObject 实例\nConfigObject 是一个特别的 java.util.Map 实现\nConfigObject 不仅返回配置值而且 ConfigObject 不会为 null\nConfigObject config = new ConfigSlurper().parse(&#x27;&#x27;&#x27;    shit.name = &#x27;lin&#x27;    shit.age = 33    shit &#123;        length = &quot;$&#123;28&#125;cm&quot;    &#125;        app.&quot;person.age&quot; = 42               // 当配置名称有 `.` 的时候，使用单引号或者双引号将这个名字扩起来&#x27;&#x27;&#x27;)assert config instanceof java.util.Map  // ConfigObject 是一个 java.util.Map 的实例assert config.shit.name == &#x27;lin&#x27;        // 通过 `.` 方式定义的值assert config.shit.length == &#x27;28cm&#x27;     // 通过 Closure 域方式定义的值assert config.app.age != null           // 没有定义的值不会为 nullassert config.app.&quot;person.age&quot; == 42    // 当配置名称有 `.` 的时候，使用单引号或者双引号将这个名字扩起来\n\n\ndef config = new ConfigSlurper(&#x27;development&#x27;).parse(&#x27;&#x27;&#x27;    environments &#123;        development &#123;            app.port = 8080        &#125;                test &#123;            app.port = 8082        &#125;                production &#123;            app.port = 80        &#125;    &#125;&#x27;&#x27;&#x27;)assert config.app.port = 8080\n\nIn addition, ConfigSlurper comes with support for environments.\nThe environments method can be used to hand over a Closure instance that itself may consist of a several sections.\nLet’s say we wanted to create a particular configuration value for the development environment.\nWhen creating the ConfigSlurper instance we can use the ConfigSlurper(String) constructor to specify the target environment.\nThe ConfigSlurper environments aren’t restricted(限制) to any particular environment names.\nIt solely  depends on the ConfigSlurper client code what value are supported and interpreted accordingly.\n\nThe environments method is built-in but the registerConditionalBlock method can be used to register other method names in addition to the environments name.\ndef slurper = new ConfigSlurper()slurper.registerConditionalBlock(&#x27;myProject&#x27;, &#x27;developers&#x27;) // 1def config = slurper.parse(&#x27;&#x27;&#x27;    sendMail = true        myProject &#123;        developers &#123;            sendMail = false        &#125;    &#125;&#x27;&#x27;&#x27;)assert !config.sendMail\n\npublic void registerConditionalBlock(String blockName, String blockValue)\n\n1 : Once the new block is registered ConfigSlurper can parse it\n\nFor Java integration purposes the toProperties method can be used to convert the ConfigObject to a java.util.Properties object that might be stored to a *.properties text file.\nBe aware though that the configuration values are converted to String instances during adding them to newly created Properties instance.\ndef config = new ConfigSlurper().parse(&#x27;&#x27;&#x27;    app.date = new Date()    app.age = 42    app &#123;        name = &quot;Test$&#123;42&#125;&quot;    &#125;&#x27;&#x27;&#x27;)def properties = config.toProperties()assert properties.&quot;app.date&quot; instanceof Stringassert properties.&quot;app.age&quot; == &#x27;42&#x27;assert properties.&quot;app.name&quot; == &#x27;Test42&#x27;\n","categories":["Groovy User Guides - Groovy Development Kit - Handy utilities"],"tags":["User Guides","Groovy","Groovy Development Kit","Handy utilities"]},{"title":"Groovy Expando","url":"/groovy/user-guides/groovy-development-kit/handy-utilities/groovy-expando/","content":"Groovy ExpandoExpando 类用于创建动态的可扩展对象\nDespite its name it does not use the ExpandoMetaClass underneath.\nEach Expando object represents a standalone, dynamically-crafted instance that can be extended with properties (or methods) at runtime.\ndef expando = new Expando()expando.name = &#x27;lin&#x27;assert expando.name == &#x27;lin&#x27;\n\nA special case occurs when a dynamic property registers a Closure code block.\nOnce being registered it can be invoked as it would be done with a method call.\ndef expando = new Expando()expando.toString = &#123; -&gt; &#x27;John&#x27; &#125;expando.say = &#123; String s -&gt; &quot;John says: $&#123;s&#125;&quot; &#125;assert expando as String == &#x27;John&#x27;assert expando.say(&#x27;fuck&#x27;) == &#x27;John says: fuck&#x27;\n","categories":["Groovy User Guides - Groovy Development Kit - Handy utilities"],"tags":["User Guides","Groovy","Groovy Development Kit","Handy utilities"]},{"title":"Groovy Observable list, map and set","url":"/groovy/user-guides/groovy-development-kit/handy-utilities/groovy-observable-list-map-and-set/","content":"Groovy Observable list, map and setGroovy 提供了可监测的 List，Map，Set\n当这些集合的元素被添加，删除或者改变的时候会触发 java.beans.PropertyChangeEvent 事件\nPropertyChangeEvent 并不仅仅代表了一个具体事件的发生，它还保存了属性的名称，属性的旧值&#x2F;新值\n根据发生的事件的类型，可监测集合还会触发更具体的 PropertyChangeEvent\n例如，添加一个元素到一个可监测 List 时，将会触发 ObservableList.ElementAddedEvent 事件\nimport java.beans.PropertyChangeListenerdef event                                                   // 1def listener = &#123;    if (it instanceof ObservableList.ElementAddedEvent) &#123;   // 2        event = it    &#125;&#125; as PropertyChangeListenerdef observable = [1, 2, 3] as ObservableList                // 3observable.addPropertyChangeListener(listener)              // 4observable.add 42                                           // 5assert event instanceof ObservableList.ElementAddedEventdef elementAddedEvent = event as ObservableList.ElementAddedEventassert elementAddedEvent.changeType == ObservableList.ChangeType.ADDEDassert elementAddedEvent.index == 3assert elementAddedEvent.oldValue == nullassert elementAddedEvent.newValue == 42\n\n1 : Declares a PropertyChangeEventListener that is capturing the fired events\n2 : ObservableList.ElementEvent and its descendant(后代) types are relevant for this listener\n3 : Creates an ObservableList from the given list\n4 : Registers the listener\n5 : Triggers an ObservableList.ElementAddedEvent event\n要注意的是，添加一个元素实际上会导致两个事件触发，一个是 ObservableList.ElementAddedEvent，另一个是 通知监听器属性(property) size 变化 的PropertyChangeEvent\n还有一个有趣的事件是 ObservableList.ElementClearedEvent，无论何时当多个元素被删除时，例如调用 clear() 方法，这个事件会持有从 List 中删除的元素们\ndef eventdef listener = &#123;    if (it instanceof ObservableList.Element) &#123;        event = it    &#125;&#125; as PropertyChangeListenerdef observable = [1, 2, 3] as ObservableListobservable.addPropertyChangeListener(listener)observable.clear()assert event instanceof ObservableList.ElementsClearedEventdef elementClearedEvent = event as ObservableList.ElementClearedEventassert elementClearedEvent.values = [1, 2, 3]assert observable.size() == 0\n","categories":["Groovy User Guides - Groovy Development Kit - Handy utilities"],"tags":["User Guides","Groovy","Groovy Development Kit","Handy utilities"]},{"title":"Groovy Adding or removing elements","url":"/groovy/user-guides/groovy-development-kit/manipulating-lists/groovy-adding-or-removing-elements/","content":"Groovy Adding or removing elements使用 [] 去声明一个空 List ，使用 &lt;&lt; 增加一个元素到 List 中\nIt is however important that the + operator on a list is not mutating(可变的). Compared to &lt;&lt;, it will create a new list\n&lt;&lt; 一般不要用于添加集合类型\ndef list = []assert list.emptylist &lt;&lt; 5assert list.size() == 1list &lt;&lt; 7 &lt;&lt; &#x27;i&#x27; &lt;&lt; 11assert list == [5, 7, &#x27;i&#x27;, 11]list &lt;&lt; [&#x27;m&#x27;, &#x27;o&#x27;]assert list == [5, 7, &#x27;i&#x27;, 11, [&#x27;m&#x27;, &#x27;o&#x27;]]// first item in chain of &lt;&lt; is target listassert ([1, 2] &lt;&lt; 3 &lt;&lt; [4, 5] &lt;&lt; 6) == [1, 2, 3, [4, 5], 6]// using leftShift is equivalent to using &lt;&lt;assert ([1, 2, 3] &lt;&lt; 4) == ([1,2,3].leftShift(4))\n\nAdd to a list in many ways:\nassert [1, 2] + 3 + [4, 5] + 6 == [1, 2, 3, 4, 5, 6]// equivalent to calling the `plus` methodassert [1, 2].plus(3).plus([4, 5]),plus(6) == [1, 2, 3, 4, 5, 6]def a = [1,2,3]a += 4  // create a new list and assigns it to `a`a += [5,6]assert a == [1,2,3,4,5,6]assert [1, *[222,333], 456] == [1, 222, 333, 456]assert [*[1,2,3]] == [1,2,3]assert [1, [2, 3, [4, 5], 6], 7, [8, 9]].flatten() == [1, 2, 3, 4, 5, 6, 7, 8, 9]def list = [1, 2]list.add(3)list.addAll([5, 4])assert list == [1, 2, 3, 5, 4]list = [1, 2]list.add(1, 3)              // add 3 just before index 1assert list == [1, 3, 2]list.addAll(2, [5, 4])      // add [5, 4] just before index 2assert list == [1, 3, 5, 4, 2]list = [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;z&#x27;, &#x27;e&#x27;, &#x27;u&#x27;, &#x27;v&#x27;, &#x27;g&#x27;]list[8] = &#x27;x&#x27;               // the [] operator is growing the list as needed// nulls inserted if requiredassert list == [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;z&#x27;, &#x27;e&#x27;, &#x27;u&#x27;, &#x27;v&#x27;, &#x27;g&#x27;, null, &#x27;x&#x27;]\n\nThe GDK also contains methods allowing you to easily remove elements from a list by value:\nassert [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;b&#x27;,&#x27;b&#x27;] - &#x27;c&#x27; == [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;b&#x27;,&#x27;b&#x27;]assert [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;b&#x27;,&#x27;b&#x27;] - &#x27;b&#x27; == [&#x27;a&#x27;, &#x27;c&#x27;]assert [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;b&#x27;,&#x27;b&#x27;] - [&#x27;b&#x27;, &#x27;c&#x27;] == [&#x27;a&#x27;]def list = [1,2,3,4,3,2,1]list -= 3   // creates a new list by removing `3` from the original oneassert list == [1,2,4,2,1]assert (list -= [2, 4]) == [1, 1]\n\n在 reomve 方法中传入索引位置删除元素：\ndef list [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;,&#x27;e&#x27;,&#x27;f&#x27;,&#x27;b&#x27;,&#x27;b&#x27;,&#x27;a&#x27;]assert list.remove(2) == &#x27;c&#x27;    // remove the third element, and return itassert list == [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;d&#x27;,&#x27;e&#x27;,&#x27;f&#x27;,&#x27;b&#x27;,&#x27;b&#x27;,&#x27;a&#x27;]def list = [3, 2, 1, 0]list.remove(0)                  // 删除了位置0上的元素assert list == [2, 1, 0]list.removeElement(0)           // 删除了元素0assert list == [2, 1]\n\nIn case you want to remove the first element having the same value in a list, instead of removing all elements, you can call the remove method passing the value:\ndef list = [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;b&#x27;,&#x27;b&#x27;]assert list.remove(&#x27;c&#x27;)     // remove &#x27;c&#x27;, and return true because element removedassert list.remove(&#x27;b&#x27;)     // remove first &#x27;b&#x27;, and return true because element removedassert !list.remove(&#x27;z&#x27;)    // return false because no elements removedassert list == [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;b&#x27;]\n\nAs you can see, there two remove methods available.\nOne that takes an integer and removes an element by its index\nAnd another that will remove the first element that matches the passed value.\nSo what should we do when wo have a list of integers?\nIn this case, you may wish to use removeAt to remove an element by its index, and removeElement to remove the first element that matches a value:\ndef list = [1,2,3,4,5,6,2,2,1]assert list.remove(2) == 3          // this removes the element at index 2, and returns itassert list == [1,2,4,5,6,2,2,1]assert list.removeElement(2)        // remove first 2 and return trueassert list == [1,4,5,6,2,2,1]assert ! list.removeElement(8)      // return false because 8 is not in the listassert list == [1,4,5,6,2,2,1]assert list.removeAt(1) == 4        // remove element at index 1, and return it\n\nAdditionally, removing all the elments in a list can be done by calling the clear method:\ndef list = [&#x27;a&#x27;, 2, &#x27;c&#x27;, 5]list.clear()assert list.empty\n","categories":["Groovy User Guides - Groovy Development Kit - Manipulating lists"],"tags":["User Guides","Groovy","Groovy Development Kit","Manipulating lists"]},{"title":"Groovy Duplicating elements","url":"/groovy/user-guides/groovy-development-kit/manipulating-lists/groovy-duplicating-elements/","content":"Groovy Duplicating elementsThe GDK also takes advantage of operator overloading to provide methods allowing duplication of element of a list:\nassert [1, 2, 3] * 3 = [1, 2, 3, 1, 2, 3, 1, 2, 3]assert [1, 2, 3].multiply(2) = [1, 2, 3, 1, 2, 3]assert Collections.nCopies(3, &#x27;b&#x27;) == [&#x27;b&#x27;, &#x27;b&#x27;, &#x27;b&#x27;]// nCopies from the JDK has different semantics than multiply for listsassert Collections.nCopies(2, [1, 2]) == [[1, 2], [1, 2]] // not [1, 2, 1, 2]\n","categories":["Groovy User Guides - Groovy Development Kit - Manipulating lists"],"tags":["User Guides","Groovy","Groovy Development Kit","Manipulating lists"]},{"title":"Groovy Manipulating lists","url":"/groovy/user-guides/groovy-development-kit/manipulating-lists/groovy-manipulating-lists/","content":"Groovy Manipulating listsFiltering and searching\n\n\nName\nMeaning\nExample\n\n\n\nfind\nfind 1st element matching criteria\n[1,2,3].find &#123;it&gt;1&#125; == 2\n\n\nfindAll\nfind all elements matching criteria\n[1,2,3].findAll &#123;it&gt;1&#125; == [2, 3]\n\n\nfindIndexOf\nfind index of 1st element matching criteria; 找到第一个匹配的元素的位置\nassert [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;].findIndexOf &#123;it in [&#39;c&#39;, &#39;e&#39;, &#39;g&#39;]&#125; == 2\n\n\nindexOf\n返回匹配的元素的位置; return -1 means value not in list\nassert [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;c&#39;].indexOf(&#39;c&#39;) == 2, assert [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;c&#39;].indexOf(&#39;z&#39;) == -1\n\n\nlastIndexOf\nindex returned; 返回匹配的元素里面最后一个元素的位置\nassert [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;c&#39;].lastIndexOf(&#39;c&#39;) == 4\n\n\nevery\nreturns true if all elements match the predicate\nassert [1,2,3].every &#123;it&lt;3&#125;\n\n\nany\nreturns true if any element matches the predicate\nassert [1,2,3].any &#123;it&gt;2&#125;\n\n\nsum\nsum anything with a plus() method\nassert [1,2,3,4,5,6].sum() == 21\n\n\njoin\nString joining\nassert [1,2,3].join(&#39;-&#39;) == &#39;1-2-3&#39;\n\n\ninject\nreduce operation\nassert [1,2,3].inject(&#39;counting: &#39;) &#123;str, item -&gt; str + item&#125; == &#39;counting: 123&#39;\n\n\nassert [1, 2, 3].find &#123; it &gt; 1 &#125; == 2           // find 1st element matching criteriaassert [1, 2, 3].findAll &#123; it &gt; 1 &#125; == [2, 3]   // find all elements matching critieriaassert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;].findIndexOf &#123;      // find index of 1st element matching criteria    it in [&#x27;c&#x27;, &#x27;e&#x27;, &#x27;g&#x27;]&#125; == 2assert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;c&#x27;].indexOf(&#x27;c&#x27;) == 2  // index returnedassert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;c&#x27;].indexOf(&#x27;z&#x27;) == -1 // index -1 means value not in listassert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;c&#x27;].lastIndexOf(&#x27;c&#x27;) == 4assert [1, 2, 3].every &#123; it &lt; 5 &#125;               // returns true if all elements match the predicateassert ![1, 2, 3].every &#123; it &lt; 3 &#125;assert [1, 2, 3].any &#123; it &gt; 2 &#125;                 // returns true if any element matches the predicateassert ![1, 2, 3].any &#123; it &gt; 3 &#125;assert [1, 2, 3, 4, 5, 6].sum() == 21                // sum anything with a plus() methodassert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;].sum &#123;    it == &#x27;a&#x27; ? 1 : it == &#x27;b&#x27; ? 2 : it == &#x27;c&#x27; ? 3 : it == &#x27;d&#x27; ? 4 : it == &#x27;e&#x27; ? 5 : 0    // custom value to use in sum&#125; == 15assert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;].sum &#123; ((char) it) - ((char) &#x27;a&#x27;) &#125; == 10assert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;].sum() == &#x27;abcde&#x27;assert [[&#x27;a&#x27;, &#x27;b&#x27;], [&#x27;c&#x27;, &#x27;d&#x27;]].sum() == [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;]// an initial value can be providedassert [].sum(1000) == 1000assert [1, 2, 3].sum(1000) == 1006assert [1, 2, 3].join(&#x27;-&#x27;) == &#x27;1-2-3&#x27;           // String joiningassert [1, 2, 3].inject(&#x27;counting: &#x27;) &#123;    str, item -&gt; str + item                     // reduce operation&#125; == &#x27;counting: 123&#x27;assert [1, 2, 3].inject(0) &#123; count, item -&gt;    count + item&#125; == 6\n\nGroovy code for finding the maximum and minimum in a collection:\ndef list = [9, 4, 2, 10, 5]assert list.max() == 10assert list.min() == 2// we can also compare single characters, as anything comparableassert [&#x27;x&#x27;, &#x27;y&#x27;, &#x27;a&#x27;, &#x27;&#x27;z].min() == &#x27;a&#x27;// we can use a closure to specify the sorting behaviourdef list2 = [&#x27;abc&#x27;, &#x27;z&#x27;, &#x27;xyzuvw&#x27;, &#x27;Hello&#x27;, &#x27;321&#x27;]assert list2.max &#123;it.size()&#125; == &#x27;xyzuvw&#x27;assert list2.min &#123;it.size()&#125; == &#x27;z&#x27;\n\nIn addition to closures, you can use a Comparator to define the comparison criteria:\nComparator mc = &#123; a, b -&gt;    a == b ? 0 : (a &lt; b ? -1 : 1)&#125;def list = [7, 4, 9, -6, -1, 11, 2, 3, -9, 5, -13]assert list.max(mc) == 1assert list.min(mc) == -13Comparator mc2 = &#123; a, b -&gt;    a == b ? 0 : (Math.abs(a) &lt; Math.abs(b)) ? -1 : 1&#125;assert list.max(mc2) == -13assert list.min(mc2) == -1assert list.max &#123;a, b -&gt; a.equals(b) ? 0 : Math.abs(a) &lt; Math.abs(b) ? -1 : 1&#125; == -13assert list.min &#123;a, b -&gt; a.equals(b) ? 0 : Math.abs(a) &lt; Math.abs(b) ? -1 : 1&#125; == -1\n","categories":["Groovy User Guides - Groovy Development Kit - Manipulating lists"],"tags":["User Guides","Groovy","Groovy Development Kit","Manipulating lists"]},{"title":"Groovy Set operations","url":"/groovy/user-guides/groovy-development-kit/manipulating-lists/groovy-set-operations/","content":"Groovy Set operationsassert &#x27;a&#x27; in [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;]             // returns true if an element belongs to the listassert [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;].contains(&#x27;a&#x27;)      // equivalent to the `contains` method in Javaassert [1,3,4].containsAll([1,4])       // `containsAll` will check that all elements are foundassert [1,2,3,3,3,3,4,5].count(3) == 4  // count the number of elements which have some valueassert [1,2,3,3,3,3,4,5].count &#123;    it%2==0                             // count the number of elements which match the predicate&#125; == 2assert [1,2,4,6,8,10,12].intersect([1,3,6,9,12]) == [1,6,12]assert [1,2,3].disjoint( [4,6,9] )assert ![1,2,3].disjoint( [2,4,6] )\n\nintersect : 取交集\ndisjoint : 是否 不相交\n","categories":["Groovy User Guides - Groovy Development Kit - Manipulating lists"],"tags":["User Guides","Groovy","Groovy Development Kit","Manipulating lists"]},{"title":"Groovy Sorting","url":"/groovy/user-guides/groovy-development-kit/manipulating-lists/groovy-sorting/","content":"Groovy Sortingassert [6, 3, 9, 2, 7, 1, 5].sort() == [1, 2, 3, 5, 6, 7, 9]def list = [&#x27;abc&#x27;, &#x27;z&#x27;, &#x27;xyzuvw&#x27;, &#x27;Hello&#x27;, &#x27;321&#x27;]assert list.sort &#123;    it.size()&#125; == [&#x27;z&#x27;, &#x27;abc&#x27;, &#x27;321&#x27;, &#x27;Hello&#x27;, &#x27;xyzuvw&#x27;]def list2 = [7, 4, -6, -1, 11, 2, 3, -9, 5, -13]assert list2.sort &#123; a, b -&gt; a == b ? 0 : Math.abs(a) &lt; Math.abs(b) ? -1 : 1 &#125; ==        [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]Comparator mc = &#123; a, b -&gt; a == b ? 0 : Math.abs(a) &lt; Math.abs(b) ? -1 : 1 &#125;// JDK 8+ only// list2.sort(mc)// assert list2 == [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]def list3 = [6, -3, 9, 2, -7, 1, 5]Collections.sort(list3)assert list3 == [-7, -3, 1, 2, 5, 6, 9]Collections.sort(list3, mc)assert list3 == [1, 2, -3, 5, 6, -7, 9]\n","categories":["Groovy User Guides - Groovy Development Kit - Manipulating lists"],"tags":["User Guides","Groovy","Groovy Development Kit","Manipulating lists"]},{"title":"Groovy Iterating on maps","url":"/groovy/user-guides/groovy-development-kit/maps/groovy-iterating-on-maps/","content":"Groovy Iterating on mapsMap 是有序的，所以对 Map 进行迭代访问也是有序的\ndef map = [        Bob  : 42,        Alice: 54,        Max  : 33]// 使用 Map.Entrymap.each &#123; entry -&gt; println &quot;Name: $entry.key Age: $entry.value&quot; &#125;// 使用 Map.Entry 和 indexmap.eachWithIndex &#123; Map.Entry&lt;String, Integer&gt; entry,                    int index    -&gt;    println &quot;$index - Name: $entry.key Age: $entry.value&quot;&#125;// 直接使用 key 和 valuemap.each &#123; key, value -&gt; println &quot;Name: $key Age: $value&quot; &#125;// 使用 key 和 value 和 indexmap.eachWithIndex &#123; key,                    value,                    index    -&gt;    println &quot;$index Name: $key Age: $value&quot;&#125;\n","categories":["Groovy User Guides - Groovy Development Kit - Maps"],"tags":["User Guides","Groovy","Groovy Development Kit","Maps"]},{"title":"Groovy Map literals","url":"/groovy/user-guides/groovy-development-kit/maps/groovy-map-literals/","content":"Groovy Map literals通过使用 [:] 来创建 Map 字面量\ndef map = [name: &#x27;Gromit&#x27;, likes: &#x27;cheeese&#x27;, id: 1234]assert map.get(&#x27;name&#x27;)  == &#x27;Gromit&#x27;assert map.get(&#x27;id&#x27;)    == 1234assert map[&#x27;name&#x27;]      == &#x27;Gromit&#x27;assert map[&#x27;id&#x27;]        == 1234assert map instanceof   java.util.Mapdef emptyMap = [:]assert emptyMap.size()      == 0emptyMap.put(&quot;foo&quot;, 5)assert emptyMap.size()      == 1assert emptyMap.get(&quot;foo&quot;)  == 5\n\nMap 的 字符串类型 Key ，[a: 1] 默认等于 [&#39;a&#39;: 1]。即字符串类型的 Key 可以不使用 单引号或者双引号\n如果你定义了一个名称为 a 的变量，你想使用变量 a 中的值作为 Key 的名称。此时只需要使用 () 将变量 a 包起来就行：\ndef a = &#x27;Bob&#x27;def ages = [a : 43]assert ages[&#x27;Bob&#x27;]  == null // `Bob` is not foundassert ages[&#x27;a&#x27;]    == 43   // because `a` is a literalages = [(a): 43]            // now we escape `a` by using parenthesisassert ages[&#x27;Bob&#x27;]  == 43\n\n可以克隆一个 Map ：\ndef map = [    simple: 123,    complex: [a: 1, b: 2]]def map2 = map.clone()assert map2.get(&#x27;simple&#x27;)           == map.get(&#x27;simple&#x27;)assert map2.get(&#x27;complex&#x27;)          == map.get(&#x27;complex&#x27;)map2.get(&#x27;complex&#x27;).put(&#x27;c&#x27;, 3)assert map.get(&#x27;complex&#x27;).get(&#x27;c&#x27;)  == 3    // 复制出来的 map2 是原始 Map 的浅拷贝\n","categories":["Groovy User Guides - Groovy Development Kit - Maps"],"tags":["User Guides","Groovy","Groovy Development Kit","Maps"]},{"title":"Groovy Map property notation","url":"/groovy/user-guides/groovy-development-kit/maps/groovy-map-property-notation/","content":"Groovy Map property notationMaps 也可以像 beans 一样，通过属性表示法（property notation）去获取&#x2F;设置 map 里面的元素，只要 Maps 中的 Keys 都是 Groovy 有效的字符串\ndef map = [name: &#x27;Gromit&#x27;, likes: &#x27;cheese&#x27;, id: 1234]assert map.name     == &#x27;Gromit&#x27;     // can be used instead of map.get(&#x27;name&#x27;)assert map.id       == 1234def emptyMap = [:]assert emptyMap.size()  == 0emptyMap.foo = 5assert emptyMap.size()  == 1assert emptyMap.foo     == 5\n\ndef map = [age: 18]assert map.class == nullassert map.getClass() == LinkedHashMap\n\nmap.class 将会在 Map 中查找 Key 为 &#39;class&#39; 的值，由于以上例子中，map 没有 Key 为 &#39;class&#39; 的 Entry ，所以返回了 null\n如果想获取 Map 的 Class ，要调用 getClass() 方法\ndef map = [        1      : &#x27;a&#x27;,        (true) : &#x27;b&#x27;,        (false): &#x27;c&#x27;,        (null) : &#x27;d&#x27;,        &#x27;null&#x27; : &#x27;e&#x27;]assert map.containsKey(1)assert map.true         == null // map 中没有值为字符串 &#x27;true&#x27; 的 keyassert map.false        == null // map 中没有值为字符串 &#x27;false&#x27; 的 keyassert map.get(true)    == &#x27;b&#x27;  // map 中有值为 true 的 keyassert map.get(false)   == &#x27;c&#x27;  // map 中有值为 false 的 keyassert map.null         == &#x27;e&#x27;  // map 中有值为字符串 &#x27;null&#x27; 的 key\n","categories":["Groovy User Guides - Groovy Development Kit - Maps"],"tags":["User Guides","Groovy","Groovy Development Kit","Maps"]},{"title":"Groovy GPath support","url":"/groovy/user-guides/groovy-development-kit/syntax-enhancements-for-collections/groovy-gpath-support/","content":"Groovy GPath support得益于 List 和 Map 的属性表示法，Groovy 提供了便捷访问内嵌集合的语法糖：\ndef listOfMaps = [        [&#x27;a&#x27;: 11, &#x27;b&#x27;: 12],        [&#x27;a&#x27;: 21, &#x27;b&#x27;: 22]]assert listOfMaps.a == [11, 21]     // GPath notationassert listOfMaps*.a == [11, 21]    // spread dot notationlistOfMaps = [        [&#x27;a&#x27;: 11, &#x27;b&#x27;: 12],        [&#x27;a&#x27;: 21, &#x27;b&#x27;: 22],        null]assert listOfMaps*.a == [11, 21, null]  // caters(迎合) for null valuesassert listOfMaps*.a == listOfMaps.collect &#123; it?.a &#125;assert listOfMaps.a == [11, 21]         //  只会收集 non-null 的值\n","categories":["Groovy User Guides - Groovy Development Kit - Syntax enhancements for collections"],"tags":["User Guides","Groovy","Groovy Development Kit","Syntax enhancements for collections"]},{"title":"Groovy Slicing with the subscript operator","url":"/groovy/user-guides/groovy-development-kit/syntax-enhancements-for-collections/groovy-slicing-with-the-subscript-operator/","content":"Groovy Slicing with the subscript operator可以在 List, Array, Map 中使用下标操作符\nString 也可以使用下标操作符\n// 字符串的下标操作符def text = &#x27;nice cheese gromit!&#x27;def x = text[2]assert x == &#x27;c&#x27;assert x instanceof String// 字符串的下标操作符def sub = text[5..10]assert sub == &#x27;cheese&#x27;// List 的下标操作符def list = [10, 11, 12, 13]def answer = list[2, 3]assert answer == [12, 13]// 使用 Range 去提取集合的一部分list = (100..200)sub = list[1, 3, 20..25, 33]assert sub == [101, 103, 120, 121, 122, 123, 124, 125, 133]// 使用下标操作符去更新一个已存在的集合list = [&#x27;a&#x27;, &#x27;x&#x27;, &#x27;x&#x27;, &#x27;d&#x27;]list[1..2] = [&#x27;b&#x27;, &#x27;c&#x27;]assert list == [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;]// 支持负数的下标，使用负数的下标可以更容易地从尾部开始提取集合元素text = &quot;nice cheese gromit!&quot;x = text[-1]assert x == &#x27;!&#x27;// 使用负数的下标从尾部开始进行范围访问def name = text[-7..-2]assert name == &#x27;gromit&#x27;// 还可以使用反向的 Range// Eventually, if you use a backwards range(the starting index is greater than the end index), then the answer is reversedtext = &quot;nice cheese gromit!&quot;name = text[3..1]assert name == &#x27;eci&#x27;\n","categories":["Groovy User Guides - Groovy Development Kit - Syntax enhancements for collections"],"tags":["User Guides","Groovy","Groovy Development Kit","Syntax enhancements for collections"]},{"title":"Groovy Spread operator","url":"/groovy/user-guides/groovy-development-kit/syntax-enhancements-for-collections/groovy-spread-operator/","content":"Groovy Spread operatorThe Spread operator 用于将一个集合内联到另一个集合\n这是一个避免调用 putAll() 方法的语法糖\ndef l1 = [        &#x27;a&#x27;: 100,        &#x27;b&#x27;: 200]def l2 = [        &#x27;z&#x27;: 900,        *  : l1,    // 注意看这里        &#x27;a&#x27;: 300]assert l2 == [&#x27;a&#x27;: 300, &#x27;b&#x27;: 200, &#x27;z&#x27;: 900]def f = &#123; [1: &#x27;u&#x27;, 2: &#x27;v&#x27;, 3: &#x27;w&#x27;] &#125;def l3 = [        * : f(),    // 注意看这里        10: &#x27;zz&#x27;]assert l3 == [1: &#x27;u&#x27;, 2: &#x27;v&#x27;, 3: &#x27;w&#x27;, 10: &#x27;zz&#x27;]// spread map notation in function argumentsf = &#123; map -&gt; map.c &#125;assert f(*: [&#x27;a&#x27;: 10, &#x27;b&#x27;: 20, &#x27;c&#x27;: 30], &#x27;e&#x27;: 50) == 30// using spread map notation with mixed unnamed and named argumentsf = &#123; m, i, j, k -&gt; [m, i, j, k] &#125;assert f(        &#x27;e&#x27;: 100,        *[4, 5],        *: [&#x27;a&#x27;: 10, &#x27;b&#x27;: 20, &#x27;c&#x27;: 30],        6) == [[&quot;e&quot;: 100, &quot;b&quot;: 20, &quot;c&quot;: 30, &quot;a&quot;: 10], 4, 5, 6]\n","categories":["Groovy User Guides - Groovy Development Kit - Syntax enhancements for collections"],"tags":["User Guides","Groovy","Groovy Development Kit","Syntax enhancements for collections"]},{"title":"Groovy The star-dot *. operator","url":"/groovy/user-guides/groovy-development-kit/syntax-enhancements-for-collections/groovy-the-star-dot-operator/","content":"Groovy The star-dot *. operator*. 可以在集合的每个元素上面调用一个方法或者访问一个属性\nThe “star-dot” operator is a shortcut operator allowing you to call a method or a property on all elements of a collection:\nassert [1, 3, 5] == [&#x27;a&#x27;, &#x27;few&#x27;, &#x27;words&#x27;]*.size()class Person &#123;    String name    Integer age&#125;def persons = [    new Person(name: &#x27;Hugo&#x27;, age: 17),    new Person(name: &#x27;Sandra&#x27;, age: 19)]assert [17, 19] == persons*.age\n","categories":["Groovy User Guides - Groovy Development Kit - Syntax enhancements for collections"],"tags":["User Guides","Groovy","Groovy Development Kit","Syntax enhancements for collections"]},{"title":"Groovy Converting between legacy and JSR 310 types","url":"/groovy/user-guides/groovy-development-kit/working-with-date-and-time-types/groovy-converting-between-legacy-and-jsr-310-types/","content":"Groovy Converting between legacy and JSR 310 typesGroovy 提供了一些方法来在 JSR 310 和 历史类型之间进行转换\n大部分 JSR 310 类型通过 toDate() 和 toCalendar() 方法转换成最靠近的 java.util.Date 和 java.util.Calendar 值\nZoneId 和 ZoneOffset 通过 toTimeZone() 方法转换为 java.util.TimeZone\nimport java.time.*// LocalDate to java.util.Datedef valentines = LocalDate.of(2018, Month.FEBRUARY, 14)assert valentines.toDate().format(&#x27;MMMM dd, yyyy&#x27;) == &#x27;二月 14, 2018&#x27;// LocalTime to java.util.Datedef noon = LocalTime.of(12, 0, 0)assert noon.toDate().format(&#x27;HH:mm:ss&#x27;) == &#x27;12:00:00&#x27;// ZoneId to java.util.TimeZonedef newYork = ZoneId.of(&#x27;America/New_York&#x27;)assert newYork.toTimeZone() == TimeZone.getTimeZone(&#x27;America/New_York&#x27;)// ZonedDateTime to java.util.Calendardef valAtNoonInNY = ZonedDateTime.of(valentines, noon, newYork)assert valAtNoonInNY.toCalendar().getTimeZone().toZoneId() == newYork\n\n转换为历史类型注意事项\n\n纳秒值转换为毫秒值时进行截断。值为 999,999,999 的 ChronoUnit.NANOS ，截断成值为 999 的毫秒值\n将本地化的LocalDate,LocalTime,LocalDateTime转化为Date和Calendar时，时区就会时系统的默认值\n当转换时间类型的LocalTime,OffsetTime为Date或Calendar时，年月日默认为当前时间\n当转换日期类型的LocalDate为Date或Calendar时，时分秒全部默认为0\n当转换OffsetDateTime为Calendar时，only the ++hours++ and ++minutes++ of the ZoneOffset convey into the corresponding TimeZone. Fortunately, Zone Offsets with non-zero seconds are rare.\n\nGroovy 提供了许多方法将 Date 和 Calendar 转换为 JSR 310 types：\nimport java.time.*def legacy = Date.parse(&#x27;yyyy-MM-dd HH:mm:ss.SSS&#x27;, &#x27;2010-04-03 10:30:58.999&#x27;)assert legacy.toLocalDate() == LocalDate.of(2010, 4, 3)assert legacy.toLocalTime() == LocalTime.of(10, 30, 58, 999_000_000)assert legacy.toOffsetTime().hour == 10assert legacy.toYear() == Year.of(2010)assert legacy.toMonth() == Month.APRILassert legacy.toDayOfWeek() == DayOfWeek.SATURDAYassert legacy.toMonthDay() == MonthDay.of(Month.APRIL, 3)assert legacy.toYearMonth() == YearMonth.of(2010, Month.APRIL)assert legacy.toLocalDateTime().year == 2010assert legacy.toOffsetDateTime().dayOfMonth == 3assert legacy.toZonedDateTime().zone == ZoneId.systemDefault()\n","categories":["Groovy User Guides - Groovy Development Kit - Working with Date and Time types"],"tags":["User Guides","Groovy","Groovy Development Kit","Working with Date and Time types"]},{"title":"Groovy Formatting and parsing","url":"/groovy/user-guides/groovy-development-kit/working-with-date-and-time-types/groovy-formatting-and-parsing/","content":"Groovy Formatting and parsingGroovy 为 JSR 310 types 添加了额外的方法来将日期格式化为字符串，将字符串解析为日期:\n\n\n\nMethod\n\n\n\ngetDateString()\n\n\ngetDateTimeString()\n\n\ngetTimeString()\n\n\nformat(FormatStyle style)\n\n\nformat(String pattern)\n\n\nGroovy 添加了一个 static parse 方法到许多 JSR 310 types 中来将字符串解析(parse)为日期\nstatic parse 接收两个参数，被解析字符串和模版：\nimport java.time.*def date = LocalDate.parse(&#x27;2021-10-16&#x27;, &#x27;yyyy-MM-dd&#x27;)assert date == LocalDate.of(2021, Month.OCTOBER, 16)def time = LocalTime.parse(&#x27;4:45&#x27;, &#x27;H:mm&#x27;)assert time == LocalTime.of(4, 45, 0)def offsetTime = OffsetTime.parse(&#x27;09:47:51-1234&#x27;, &#x27;HH:mm:ssZ&#x27;)assert offsetTime == OffsetTime.of(9, 47, 51, 0, ZoneOffset.ofHoursMinutes(-12, -34))def dateTime = ZonedDateTime.parse(&#x27;2017/07/11 9:47PM Pacific Standard Time&#x27;, &#x27;yyyy/MM/dd h:mma zzzz&#x27;)assert dateTime == ZonedDateTime.of(        LocalDate.of(2017, 7, 11),        LocalTime.of(21, 47, 0),        ZoneId.of(&#x27;America/Los_Angeles&#x27;))\n","categories":["Groovy User Guides - Groovy Development Kit - Working with Date and Time types"],"tags":["User Guides","Groovy","Groovy Development Kit","Working with Date and Time types"]},{"title":"Groovy Fetching metadata","url":"/groovy/user-guides/interacting-with-a-sql-database/advanced-sql-operations/groovy-fetching-metadata/","content":"Groovy Fetching metadataUsing row metadatasql.eachRow(&quot;SELECT * FROM Author WHERE firstname = &#x27;Dierk&#x27;&quot;) &#123; row -&gt;    def md = row.getMetaData()    assert md.getTableName(1) == &#x27;AUTHOR&#x27;    assert (1..md.columnCount).collect &#123;md.getColumnName(it)&#125; == [&#x27;ID&#x27;, &#x27;FIRSTNAME&#x27;, &#x27;LASTNAME&#x27;]    assert (1..md.columnCount).collect &#123;md.getColumnTypeName(it)&#125; == [&#x27;INTEGER&#x27;, &#x27;VARCHAR&#x27;, &#x27;VARCHAR&#x27;]&#125;\n\nAlso using row metadatasql.eachRow(&quot;SELECT firstname AS first FROM Author WHERE firstname = &#x27;Dierk&#x27;&quot;) &#123; row -&gt;    def md = row.getMetaData()    assert md.getColumnName(1) == &#x27;FIRSTNAME&#x27;    assert md.getColumnLabel(1) == &#x27;FIRST&#x27;&#125;\n\nUsing row and metadata closures对于每一行都会调用一次 metaClosure 和 rowClosure\ndef metaClosure = &#123; meta -&gt; assert meta.getColumnName(1) == &#x27;FIRSTNAME&#x27; &#125;def rowClosure = &#123; row -&gt; assert row.FIRSTNAME == &#x27;Dierk&#x27; &#125;sql.eachRow(    &quot;SELECT firstname FROM Author WHERE firstname = &#x27;Dierk&#x27;&quot;,    metaClosure,    rowClosure)\n\nUsing connection metadatadef md = sql.connection.metaDataassert md.driverName == &#x27;HSQL Database Engine Driver&#x27;assert md.databaseProductVersion == &#x27;2.5.1&#x27;assert [&#x27;JDBCMajorVersion&#x27;, &#x27;JDBCMinorVersion&#x27;].collect &#123;md[it]&#125; == [4,2]assert md.stringFunctions.tokenize(&#x27;,&#x27;).contains(&#x27;CONCAT&#x27;)def rs = md.getTables(null, null, &#x27;AUTH%&#x27;, null)assert rs.next()assert rs.getString(&#x27;TABLE_NAME&#x27;) == &#x27;AUTHOR&#x27;\n","categories":["Groovy User Guides - Interacting with a SQL database - Advanced SQL operations"],"tags":["User Guides","Groovy","Interacting with a SQL database","Advanced SQL operations"]},{"title":"Groovy Named and named-ordinal parameters","url":"/groovy/user-guides/interacting-with-a-sql-database/advanced-sql-operations/groovy-named-and-named-ordinal-parameters/","content":"Groovy Named and named-ordinal parametersnamed-ordinal : 命名序数\nNamed parameters (colon form)colon : 冒号\n:参数名 的形式\nsql.execute &quot;INSERT INTO Author (firstname, lastname) VALUES (:first, :last)&quot;,            first: &#x27;Dierk&#x27;,            last: &#x27;Koenig&#x27;\n\nNamed parameters (question mark form)?.参数名 的形式\nsql.execute &quot;INSERT INTO Author (firstname, lastname) VALUES (?.first, ?.last)&quot;,            first: &#x27;Dierk&#x27;,            last: &#x27;Koenig&#x27;\n\nNamed-ordinal parameters?1.参数名,?2.参数名 的形式\nIf the information you need to supply is ++spread across multiple maps or domain objects++ you can use the ++question mark form++ with an additional ordinal index\nclass Rockstar &#123; String first, last &#125;def pogo = new Rockstar(first: &#x27;Paul&#x27;, last: &#x27;McCartney&#x27;)def map = [lion: &#x27;King&#x27;]sql.execute &quot;INSERT INTO Author (firstname, lastname) VALUES (?1.first, ?2.lion)&quot;,            pogo,            map\n\n?1.first : 1 代表第一个参数 pogo\n?2.lion  : 2 代表第二个参数 map\n","categories":["Groovy User Guides - Interacting with a SQL database - Advanced SQL operations"],"tags":["User Guides","Groovy","Interacting with a SQL database","Advanced SQL operations"]},{"title":"Groovy Performing pagination","url":"/groovy/user-guides/interacting-with-a-sql-database/advanced-sql-operations/groovy-performing-pagination/","content":"Groovy Performing paginationRetrieving pages of datadef qry = &#x27;SELECT * FROM Author&#x27;assert sql.rows(qry, 1, 3)*.firstname == [&#x27;Dierk&#x27;, &#x27;Paul&#x27;, &#x27;Guillaume&#x27;]assert sql.rows(qry, 4, 3)*.firstname == [&#x27;Hamlet&#x27;, &#x27;Cedric&#x27;, &#x27;Erik&#x27;]assert sql.rows(qry, 7, 3)*.firstname == [&#x27;Jon&#x27;]\n","categories":["Groovy User Guides - Interacting with a SQL database - Advanced SQL operations"],"tags":["User Guides","Groovy","Interacting with a SQL database","Advanced SQL operations"]},{"title":"Groovy Using batches","url":"/groovy/user-guides/interacting-with-a-sql-database/advanced-sql-operations/groovy-using-batches/","content":"Groovy Using batchesBatching SQL statements使用 withBatch 方法\nsql.withBatch(3) &#123; stmt -&gt;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Dierk&#x27;, &#x27;Koenig&#x27;)&quot;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Paul&#x27;, &#x27;King&#x27;)&quot;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Guillaume&#x27;, &#x27;Laforge&#x27;)&quot;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Hamlet&#x27;, &#x27;D&#x27;&#x27;Arcy&#x27;)&quot;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Cedric&#x27;, &#x27;Champeau&#x27;)&quot;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Erik&#x27;, &#x27;Pragt&#x27;)&quot;    stmt.addBatch &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Jon&#x27;, &#x27;Skeet&#x27;)&quot;&#125;\n\nLogging additional SQL informationimport java.util.logging.*// add fine loggingLogger.getLogger(&#x27;groovy.sql&#x27;).level = Level.FINE// also adjust logging.properties file in JRE_HOME/lib to hava: java.util.logging.ConsoleHandler.level = FINE\n\nSQL logging output with batching enableFINE: Successfully executed batch with 3 command(s)Apr 19, 2015 8:38:42 PM groovy.sql.BatchingStatementWrapper processResultFINE: Successfully executed batch with 3 command(s)Apr 19, 2015 8:38:42 PM groovy.sql.BatchingStatementWrapper processResultFINE: Successfully executed batch with 1 command(s)Apr 19, 2015 8:38:42 PM groovy.sql.Sql getStatement\n\nBatching prepared statementsdef qry = &#x27;INSERT INTO Author (firstname, lastname) VALUES (?, ?)&#x27;sql.withBatch(3, qry) &#123;    ps.addBatch(&#x27;Dierk&#x27;, &#x27;Koenig&#x27;)    ps.addBatch(&#x27;Paul&#x27;, &#x27;King&#x27;)    ps.addBatch(&#x27;Guillaume&#x27;, &#x27;Laforge&#x27;)    ps.addBatch(&#x27;Hamlet&#x27;, &quot;D&#x27;Arcy&quot;)    ps.addBatch(&#x27;Cedric&#x27;, &#x27;Champeau&#x27;)    ps.addBatch(&#x27;Erik&#x27;, &#x27;Pragt&#x27;)    ps.addBatch(&#x27;Jon&#x27;, &#x27;Skeet&#x27;)&#125;\n","categories":["Groovy User Guides - Interacting with a SQL database - Advanced SQL operations"],"tags":["User Guides","Groovy","Interacting with a SQL database","Advanced SQL operations"]},{"title":"Groovy Working with transactions","url":"/groovy/user-guides/interacting-with-a-sql-database/advanced-sql-operations/groovy-working-with-transactions/","content":"Groovy Working with transactions使用 withTransactions 方法，传入一个 Closure ，在 Closure 中的逻辑就是事务控制的：\nA successful transactionassert sql.firstRow(&#x27;SELECT COUNT(*) as num FROM Author&#x27;).num == 0sql.withTransaction &#123;    sql.execute &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Dierk&#x27;, &#x27;Koenig&#x27;)&quot;    sql.execute &quot;INSERT INTO Author (firstname, lastname) VALUES (&#x27;Jon&#x27;, &#x27;Skeet&#x27;)&quot;&#125;assert sql.firstRow(&#x27;SELECT COUNT(*) as num FROM Author&#x27;).num == 2\n\nA failed transaction will cause a rollbackdef maxFirstnameLengthdef metaClosure = &#123; meta -&gt;    maxFirstnameLength = meta.getPrecision(1)&#125;def rowClosure = &#123;&#125;def rowCountBefore = sql.firstRow(&#x27;SELECT COUNT(*) as num FROM Author&#x27;).numtry &#123;    sql.withTransaction &#123;        sql.execute &quot;INSERT INTO Author (firstname) VALUES (&#x27;Dierk&#x27;)&quot;        sql.eachRow &quot;SELECT firstname FROM Author WHERE firstname = &#x27;Dierk&#x27;&quot;,                    metaClosure,                    rowClosure        sql.execute &quot;INSERT INTO Author (firstname) VALUES (?)&quot;,                    &#x27;X&#x27; * (maxFirstnameLength + 1)    &#125;&#125; catch (ignore) &#123; println ignore.message &#125;def rowCountAfter = sql.firstRow(&#x27;SELECT COUNT(*) as num FROM Author&#x27;).numassert rowCountBefore == rowCountAfter\n","categories":["Groovy User Guides - Interacting with a SQL database - Advanced SQL operations"],"tags":["User Guides","Groovy","Interacting with a SQL database","Advanced SQL operations"]},{"title":"Groovy Creating and Inserting data","url":"/groovy/user-guides/interacting-with-a-sql-database/basic-crud-operations/groovy-creating-and-inserting-data/","content":"Groovy Creating and Inserting dataInserting a rowsql.execute &quot;&quot;&quot;    INSERT INTO Author (firstname, lastname) VALUES (&#x27;Dierk&#x27;, &#x27;Koenig&#x27;)&quot;&quot;&quot;\n\n可以用 executeInsert 代替 execute，这个方法将会返回一个包含所有生成的 key 的 List\nInserting a row using executeInsert with placeholders and parametersexecute 和 executeInsert 方法都可以在 SQL 语句中使用占位符 ?，然后传入 List 作为参数，在这种情况下，PreparedStatement 将会被使用来避免 SQL 注入问题\ndef insertSql = &#x27;INSERT INTO Author (firstname, lastname) VALUES (?, ?)&#x27;def params = [&#x27;John&#x27;, &#x27;Skeet&#x27;]def keys = sql.executeInsert insertSql, paramsassert keys[0] == [1]\n\nInserting a row using executeInsert with a GString and specifying key namesexecute 和 executeInsert 方法都允许你使用 GString ，SQL 语句中的所有 ‘$’ 都被认为是占位符\nexecuteInsert allows you to supply a list of key column names, when multiple key are returned and you are only interested in some of them\ndef first = &#x27;Guillaume&#x27;def last = &#x27;Laforge&#x27;def myKeyNames = [&#x27;ID&#x27;] // 定义想要返回的列def myKeys = sql.executeInsert &quot;&quot;&quot;    INSERT INTO Author (firstname, lastname)    VALUES ($&#123;first&#125;, $&#123;last&#125;)&quot;&quot;&quot;, myKeyNamesassert myKeys[0] == [ID: 2]\n","categories":["Groovy User Guides - Interacting with a SQL database - Basic CRUD operations"],"tags":["User Guides","Groovy","Interacting with a SQL database","Basic CRUD operations"]},{"title":"Groovy Deleting rows","url":"/groovy/user-guides/interacting-with-a-sql-database/basic-crud-operations/groovy-deleting-rows/","content":"Groovy Deleting rows使用 execute 执行删除操作\nassert sql.firstRow(&#x27;SELECT COUNT(*) as num FROM Author&#x27;).num == 3sql.execute &quot;DELETE FROM Author WHERE lastname = &#x27;Skeet&#x27;&quot;assert sql.firstRow(&#x27;SELECT COUNT(*) as num FROM Author&#x27;).num == 2\n","categories":["Groovy User Guides - Interacting with a SQL database - Basic CRUD operations"],"tags":["User Guides","Groovy","Interacting with a SQL database","Basic CRUD operations"]},{"title":"Groovy Reading rows","url":"/groovy/user-guides/interacting-with-a-sql-database/basic-crud-operations/groovy-reading-rows/","content":"Groovy Reading rows使用如下方法来从数据库中读取行：\n\nquery\neachRow\nfirstRow\nrows\n\nReading data using query如果你想通过 JDBC API 提供的 ResultSet 来迭代，那就使用 query 方法\ndef expected = [ &#x27;Dierk Koenig&#x27;, &#x27;Jon Skeet&#x27;, &#x27;Guillaume Laforge&#x27; ]def rowNum = 0sql.query(&#x27;SELECT firstname, lastname FROM Author&#x27;) &#123; resultSet -&gt;    while (resultSet.next()) &#123;        def first = resultSet.getString(1)        def last = resultSet.getString(&#x27;lastname&#x27;)        assert expected[rowNum++] == &quot;$first $last&quot;    &#125;&#125;\n\nReading data using eachRow如果你想要使用 Groovy 提供的友好的 map-like 的稍微高级别的抽象，那就使用 eachRow 方法\nrowNum = 0sql.eachRow(&#x27;SELECT firstname, lastname FROM Author&#x27;) &#123; row -&gt;    def first = row[0]  // Groovy list-like notations    def last = row.lastname // Groovy map-like notations    assert expected[rowNum++] == &quot;$first $last&quot;&#125;\n\nReading data using firstRowdef first = sql.firstRow(&#x27;SELECT lastname, firstname FROM Author&#x27;)assert first.values().sort().join(&#x27;,&#x27;) == &#x27;Dierk,Koenig&#x27;\n\nReading data using rows如果你想处理一个 map-like 数据结构的 List，那就使用 rows 方法\nList authors = sql.rows(&#x27;SELECT firstname, lastname FROM Author&#x27;)assert authors.size() == 3assert authors.collect &#123; &quot;$it.FIRSTNAME $&#123;it[-1]&#125;&quot; &#125; == expected\n\n可以看到，map-like 抽象的 Key 是大小写不敏感的，’FIRSTNAME’ 等价于 firstname\n反向索引 it[-1] 也是支持的\nReading scalar values读取标记数据；读取取了别名的列值\nassert sql.firstRow(&#x27;SELECT COUNT(*) AS num FROM Author&#x27;).num == 3\n","categories":["Groovy User Guides - Interacting with a SQL database - Basic CRUD operations"],"tags":["User Guides","Groovy","Interacting with a SQL database","Basic CRUD operations"]},{"title":"Groovy Updating rows","url":"/groovy/user-guides/interacting-with-a-sql-database/basic-crud-operations/groovy-updating-rows/","content":"Groovy Updating rowsUpdating a rowsql.execute &quot;INSERT INTO Author (lastname) VALUES (&#x27;Thorvaldsson&#x27;)&quot;sql.execute &quot;UPDATE Author SET firstname = &#x27;Erik&#x27; WHERE lastname = &#x27;Thorvaldsson&#x27;&quot;\n\nUsing executeUpdateexecuteUpdate 方法返回被更新的记录的数量\ndef updateSql = &quot;UPDATE Author SET lastname=&#x27;Pragt&#x27; where lastname=&#x27;Thorvaldsson&#x27;&quot;def updateCount = sql.executeUpdate updateSqlassert updateCount == 1def row = sql.firstRow &quot;SELECT * FROM Author where firstname = &#x27;Erik&#x27;&quot;assert &quot;$&#123;row.firstname&#125; $&#123;row.lastname&#125;&quot; == &#x27;Erik Pragt&#x27;\n","categories":["Groovy User Guides - Interacting with a SQL database - Basic CRUD operations"],"tags":["User Guides","Groovy","Interacting with a SQL database","Basic CRUD operations"]},{"title":"Groovy Compile-time metaprogramming","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/groovy-compile-time-metaprogramming/","content":"Groovy Compile-time metaprogrammingCompile-time metaprogramming in Groovy allows code generation at compile-time.\nThose transformations are altering the Abstract Syntax Tree (AST) of a program, which is why in Groovy we call it AST transformations.\n这些转换会修改程序的 AST ，这在 Groovy 中称为 AST 转换\nAST transformations allow you to hook into the compilation process, modify the AST and continue the compilation process to generate regular bytecode.\nAST 转换允许你介入编译过程，修改 AST 然后继续编译过程去生成常规字节码\nCompared to runtime metaprogramming, this has the advantage of making the changes visible in the class file itself (that is to say, in the bytecode).\n与运行时元编程相比，编译时元编程的优势是使得修改结果可以在类文件中可见（字节码中）\nMaking it visible in the bytecode is important for example if you want the transformations to be part of the class contract (implementing interfaces, extending abstract classes, …​) or even if you need your class to be callable from Java (or other JVM languages).\n让修改在字节码中可见非常重要，例如如果你想让转换结果成为类合约的一部分（实现接口，继承抽象类），或者你想让你的类在 Java&#x2F;其他 JVM 语言中被调用\nFor example, an AST transformation can add methods to a class.\n举例来说，一个 AST 转换可以添加一个方法到一个类里面\nIf you do it with runtime metaprogramming, the new method would only be visible from Groovy.\n如果你使用运行时元编程来实现，新的方法只能在 Groovy 中可见\nIf you do the same using compile-time metaprogramming, the method would be visible from Java too.\n如果你使用编译时元编程来实现，新的方法在 Java 中也可见\nLast but not least, performance would likely be better with compile-time metaprogramming (because no initialization phase is required).\n最后，编译时元编程的性能会更加好，因为不需要初始化阶段\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming"]},{"title":"Groovy Categories","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/groovy-categories/","content":"Groovy Categories\nThere are situations where it is useful if a class not under control had additional methods.\n\n有些情况下，给不受控制的类添加额外方法是非常有用的\n\nCategories are implemented with so-called category classes. A category class is special in that it needs to meet certain pre-defined rules for defining extension methods.\n\nCategory 使用被称为 category 类来实现。一个 category 类的特殊之处在于它需要满足某些预定义的规则来定义扩展方法。\nThere are a few categories that are included in the system for adding functionality to classes that make them more usable within the Groovy environment:\n\ngroovy.time.TimeCategory\ngroovy.servlet.ServletCategory\ngroovy.xml.dom.DOMCategory\n\n\nCategory classes aren’t enabled by default.\nTo use the methods defined in a category class it is necessary to apply the second use method that is provided by the GDK and available from inside the every Groovy object instance:\nuse(TimeCategory) &#123;    println 1.minute.from.now       // 1    println 10.hours.age        def someDate = new Date()       // 2    println someDate - 3.months&#125;\n\n1 : TimeCategory adds methods to Integer\n2 : TimeCategory adds methods to Date\nuse 方法接受 category 类作为第一个参数，一个 Closure 作为第二个参数\n在 Closure 里面，调用 category 方法是可以的\n在上面的例子中可以看到，即使是 JDK 的 java.lang.Integer 和 java.util.Date 类都可以使用用户定义的方法进行增强\n\n我们可以在 groovy.time.TimeCategory 类中可以看到所有的扩展方法都是 static 修饰的\nIn fact, this is one of the requirements that must be met by category classes for its methods to be successfully added to a class inside the use code block\npublic class TimeCategory &#123;    public static Date plus(final Date date, final BaseDuration duration) &#123;        return duration.plus(date);    &#125;    public static Date minus(final Date date, final BaseDuration duration) &#123;        final Calendar cal = Calendar.getInstance();        cal.setTime(date);        cal.add(Calendar.YEAR, -duration.getYears());        cal.add(Calendar.MONTH, -duration.getMonths());        cal.add(Calendar.DAY_OF_YEAR, -duration.getDays());        cal.add(Calendar.HOUR_OF_DAY, -duration.getHours());        cal.add(Calendar.MINUTE, -duration.getMinutes());        cal.add(Calendar.SECOND, -duration.getSeconds());        cal.add(Calendar.MILLISECOND, -duration.getMillis());        return cal.getTime();    &#125;    // ...\n\n简单来说就是，category 中的扩展方法必须是 static 的\n\nAnother requirement is the first argument of the static method must define the type the method is attached to once beging activated.\nThe other arguments are the normal arguments the method will take as parameters.\ncategory 中的 static 修饰的扩展方法的第一个参数必须是要被增强的类，第二个参数是这个增强方法要使用的普通参数\nBecause of the parameter and static method convention, category method definitions may be a bit less intuitive than normal method definitions.\nAs an alternative Groovy comes with a @Category annotation that transforms annotated classes into category classes at compile-time\n因为 category method 的参数定义和 static 要求，category method 的定义会比普通方法的定义有一点不够直观\nGroovy 提供了一个 @Category 注解来将普通类在编译时转换为 Category 类\nclass Distance &#123;    def number    String toString() &#123; &quot;$&#123;number&#125;m&quot; &#125;&#125;@Category(Number)class NumberCategory &#123;    Distance getMeters() &#123;        new Distance(number: this)          // `this` 代表被增强的类的实例，在这个例子中是 Number 类的实例    &#125;&#125;use (NumberCategory) &#123;    assert 42.meters.toString() == &#x27;42m&#x27;    // `42.meters` 使用了 property notation 调用了 `getMeters()` 方法，这个方法返回了 Distance 实例，然后调用 Distance 实例上的 `toString()` 方法&#125;\n\nApplying the @Category annotation has the advantage of being able to use ++instance methods++ without the target type as a first parameter.\nThe target type class is given as an argument to the annotation instead\nclass Person &#123;    String name&#125;@Category(Person.class)class EatShitCategory &#123;    void eat() &#123;        println &quot;$name eat shit&quot;    &#125;&#125;use(EatShitCategory) &#123;    def p = new Person(name: &#x27;林威羽&#x27;)    p.eat()&#125;\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming"]},{"title":"Groovy getAttribute setAttribute","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/groovy-getattribute-setattribute/","content":"Groovy getAttribute setAttribute这个功能和 MetaClass 有关\n在默认情况下，你可以不需要调用 getter&#x2F;setter 方法来访问字段：\nclass SomeGroovyClass &#123;        def field1 = &#x27;ha&#x27;    def field2 = &#x27;ho&#x27;        def getField1() &#123;        return &#x27;getHa&#x27;    &#125;    &#125;def someGroovyClass = new SomeGroovyClass()assert someGroovyClass.metaClass.getAttribute(someGroovyClass, &#x27;field1&#x27;) == &#x27;ha&#x27;assert someGroovyClass.metaClass.getAttribute(someGroovyClass, &#x27;field2&#x27;) == &#x27;ho&#x27;assert someGroovyClass.field1 == &#x27;getHa&#x27;\n\nclass POGO &#123;    private String field            String property1        void setProperty1(String property1) &#123;        this.property1 = property1    &#125;&#125;def pogo = new POGO()pogo.metaClass.setAttribute(pogo, &#x27;field&#x27;, &#x27;ha&#x27;)pogo.metaClass.setAttribute(pogo, &#x27;property1&#x27;, &#x27;ho&#x27;)assert pogo.field == &#x27;ha&#x27;assert pogo.property1 == &#x27;ho&#x27;\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming"]},{"title":"Groovy GroovyInterceptable","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/groovy-groovyinterceptable/","content":"Groovy GroovyInterceptableThe groovy.lang.GroovyInterceptable interface is marker interface that extends GroovyObject and is used to notify the Groovy runtime that all methods should be intercepted through the method dispatcher mechanism of the Groovy runtime\nclass Interception implements GroovyInterceptable &#123;    def definedMethod() &#123;&#125;    def invokeMethod(String name, Object args) &#123; &#x27;invokedMethod&#x27; &#125;&#125;\n\nclass InterceptableTest extends GroovyTestCase &#123;    def interception = new Interception()        assert interception.definedMethod() == &#x27;invokedMethod&#x27;    assert interception.someMethod() == &#x27;invokedMethod&#x27;&#125;\n\n\nWe cannot use default groovy methods like println because these methods are injected into all Groovy objects so they will be intercepted too.\n\nIf we want to intercept all method calls but do not want to implement the GroovyInterceptable interface we can implement invokeMethod() on an object’s MetaClass. This approach works for both POGOs ans POJOs.\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming"]},{"title":"Groovy GroovyObject interface","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/groovy-groovyobject-interface/","content":"Groovy GroovyObject interface在 Groovy 中 groovy.lang.GroovyObject 是主要的接口，像 Object 在 Java 中一样。\nGroovyObject 在 groovy.lang.GroovyObjectSupport 中有默认的实现，它的责任是传递调用给 groovy.lang.MetaClass 对象\nGroovyObject 的源码看起来是这样的：\npackage groovy.lang;public interface GroovyObject &#123;        Object invokeMethod(String name, Object args);        Object getProperty(String propertyName);        void setProperty(String propertyName, Object newValue);        MetaClass getMetaClass();        void setMetaClass(MetaClass metaClass);    &#125;\n\ninvokeMethod这个方法的主要目的是和 GroovyInterceptable 接口，或者一个对象中会拦截所有方法调用的 MetaClass，去结合。\n这个方法还会在一个方法不存在于 Groovy 对象时被调用\noverridden invokeMethod() 方法的例子：\nclass SomeGroovyClass &#123;        def invokeMethod(String name, Object args) &#123;        return &quot;called invokeMethod $name $args&quot;    &#125;        def test() &#123;        return &#x27;method exists&#x27;    &#125;    &#125;def someGroovyClass = new SomeGroovyClass()assert someGroovyClass.test() == &#x27;method exists&#x27;assert someGroovyClass.someMethod == &#x27;called invokeMethod someMethod []&#x27;\n\n但是，使用 invokeMethod 去拦截不存在的方法是不好的\n如果目的仅仅是在方法分派（method dispatch）失败时拦截方法调用，那就使用 methodMissing\nget&#x2F;setProperty所有读访问属性可以通过在当前对象重写 getProperty() 方法来进行拦截：\nclass SomeGroovyClass &#123;        def property1 = &#x27;ha&#x27;        def field2 = &#x27;ho&#x27;        def field4 = &#x27;hu&#x27;        def getField1() &#123; return &#x27;getHa&#x27; &#125;        def getProperty(String name) &#123;        if (name != &#x27;field3&#x27;) &#123;            return metaClass.getProperty(this, name)    // 1        &#125; else &#123;            return &#x27;field3&#x27;        &#125;    &#125;    &#125;def someGroovyClass = new SomeGroovyClass()assert someGroovyClass.field1 == &#x27;getHa&#x27;assert someGroovyClass.field2 == &#x27;ho&#x27;assert someGroovyClass.field3 == &#x27;field3&#x27;assert someGroovyClass.field4 == &#x27;hu&#x27;\n\n1 : Forwards the request to the getter for all properties except field3\n可以通过重写 setProperty() 方法，可以拦截写访问属性：\nclass POGO &#123;        String property        void setProperty(String name, Object value) &#123;        this.@&quot;$name&quot; = &#x27;overridden&#x27;    &#125;    &#125;def pogo = new POGO()pogo.property = &#x27;a&#x27;assert pogo.property == &#x27;overridden&#x27;\n\nget&#x2F;setMetaClass你可以获取一个对象的 metaClass 或者设置你自己的 MetaClass 实现来改变默认的拦截机制\n例如，你可以实现你自己的 MetaClass 然后将其赋值给一个对象来改变它的拦截机制：\n// getMetaclasssomeObject.metaClass// setMetaClasssomeObject.metaClass = new OwnMetaClassImplementation()\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming"]},{"title":"Groovy methodMissing","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/groovy-methodMissing/","content":"Groovy methodMissing方法分派（method dispatch）失败找不到可以执行的方法时，methodMissing 方法才会被调用\nclass Foo &#123;    def methodMissing(String name,                      def args) &#123;        return &quot;this is me&quot;    &#125;&#125;assert new Foo().someUnknownMethod(42L) == &#x27;this is me&#x27;\n\n典型的，methodMissing 方法被用于缓存方法执行结果：\nclass GORM &#123;   def dynamicMethods = [...] // an array of dynamic methods that use regex   def methodMissing(String name, args) &#123;       def method = dynamicMethods.find &#123; it.match(name) &#125;       if(method) &#123;          GORM.metaClass.&quot;$name&quot; = &#123; Object[] varArgs -&gt;             method.invoke(delegate, name, varArgs)          &#125;          return method.invoke(delegate,name, args)       &#125;       else throw new MissingMethodException(name, delegate, args)   &#125;&#125;\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming"]},{"title":"Groovy propertyMissing","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/groovy-propertymissing/","content":"Groovy propertyMissingpropertyMissing 方法接受一个 String 类型的参数（代表属性名称）\nclass Foo &#123;    def propertyMissing(String name) &#123; name.toUpperCase() &#125;&#125;assert new Foo().linweiyu == &#x27;LINWEIYU&#x27;\n\n只有在 Groovy 运行时，属性没有 getter 方法时 propertyMissing(String) 方法才会被调用\n通过 propertyMissing(String, Object) 方法来进行 setter 操作\nclass Foo &#123;    def storage = [:]    def propertyMissing(String name, value) &#123; storage[name] = value &#125; // setter    def propertyMissing(String name) &#123; storage[name] &#125;&#125;def f = new Foo()f.foo = &#x27;bar&#x27;assert f.foo == &#x27;bar&#x27;\n\n使用 propertyMissing 方法来在运行时动态注册一个新的属性是提高全局查找性能的最好实践\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming"]},{"title":"Groovy Runtime metaprogramming","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/groovy-runtime-metaprogramming/","content":"Groovy Runtime metaprogramming通过 runtime metaprogramming 我们可以延迟拦截（intercept），inject（注入）和合成（synthesize）类和接口的方法的决策\nMOP : Groovy’s metaobject protocol\n在 Groovy 中我们使用三种对象: POJO, POGO和Groovy Interceptors\n为了不同的目的，Groovy 允许在所有类型的对象上面进行 metaprogramming\n\nPOJO : 一个典型的 Java 对象，它的类可以使用 Java 进行重写，或者使用 JVM 上面其他的语言\nPOGO : 一个 Groovy 对象，它的类使用 Groovy 语言进行编写。它默认继承了 java.lang.Object，默认实现了 groovy.lang.GroovyObject 接口\nGroovy Interceptor : 一个实现了 groovy.lang.GroovyInterceptable 接口的 Groovy 对象，拥有方法拦截能力\n\n每一次方法调用，Groovy 会检查一个对象是 POJO 还是 POGO。\n如果是 POJO ，Groovy 从 groovy.lang.MetaClassRegistry 获取它的 MetaClass ，然后将方法调用委托给 MetaClass\n如果是 POGO ，Groovy 会执行更多的操作，例如判断类是否实现了 GroovyInterceptable，方法是否在 MetaClass 中等等\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming"]},{"title":"Groovy static methodMissing","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/groovy-static-methodMissing/","content":"Groovy static methodMissingclass Foo &#123;    // 在类级别声明    static def $static_methodMissing(String name,                                     Object args) &#123;        return &quot;Missing static method name is $name&quot;    &#125;&#125;assert Foo.bar() == &quot;Missing static method name is bar&quot;// 使用 ExpandoMetaClassFoo.metaClass.static.shit = &#123; &#x27;fuck&#x27; &#125;assert Foo.shit() == &#x27;fuck&#x27;\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming"]},{"title":"Groovy static propertyMissing","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/groovy-static-propertymissing/","content":"Groovy static propertyMissingclass Foo &#123;    static def $static_propertyMissing(String name) &#123;        return &quot;Missing static property name is $name&quot;    &#125;&#125;assert Foo.shit == &quot;Missing static property name is shit&quot;\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming"]},{"title":"Groovy DOMToGroovy","url":"/groovy/user-guides/processing-xml/creating-xml/groovy-domtogroovy/","content":"Groovy DOMToGroovySuppose we have an existing XML document and we want to automate generation of the markup without having to type it all in?\nWe just need to use org.codehaus.groovy.tools.xml.DOMToGroovy\nBuilding MarkupBuilder from DOMToGroovydef songs = &quot;&quot;&quot;    &lt;songs&gt;      &lt;song&gt;        &lt;title&gt;Here I go&lt;/title&gt;        &lt;band&gt;Whitesnake&lt;/band&gt;      &lt;/song&gt;    &lt;/songs&gt;&quot;&quot;&quot;def builder =        javax.xml.parsers.DocumentBuilderFactory.newInstance().newDocumentBuilder()def inputStream = new ByteArrayInputStream(songs.bytes)def document = builder.parse(inputStream)def output = new StringWriter()def converter = new DomToGroovy(new PrintWriter(output)) converter.print(document) String xmlRecovered =        new GroovyShell()                .evaluate(&quot;&quot;&quot;           def writer = new StringWriter()           def builder = new groovy.xml.MarkupBuilder(writer)           builder.$&#123;output&#125;           return writer.toString()        &quot;&quot;&quot;) assert new XmlSlurper().parseText(xmlRecovered).song.title.text() == &#x27;Here I go&#x27;\n","categories":["Groovy User Guides - Processing XML - Creating XML"],"tags":["User Guides","Groovy","Processing XML","Creating XML"]},{"title":"Groovy MarkupBuilder","url":"/groovy/user-guides/processing-xml/creating-xml/groovy-markupbuilder/","content":"Groovy MarkupBuilderCreating Xml with MarkupBuilder使用 MarkupBuilder 创建 XML\ndef writer = new StringWriter()def xml = new MarkupBuilder(writer)xml.records() &#123;    car(name: &#x27;HSY Maloo&#x27;, make: &#x27;Holden&#x27;, year: 2006) &#123;        country(&#x27;Australia&#x27;)        record(type: &#x27;speed&#x27;, &#x27;Production Pickup Truck with speed of 271kph&#x27;)    &#125;    car(name: &#x27;Royale&#x27;, make: &#x27;Bugatti&#x27;, year: 1931) &#123;        country(&#x27;France&#x27;)        record(type: &#x27;price&#x27;, &#x27;Most Valuable Car at $15 million&#x27;)    &#125;&#125;def records = new XmlSlurper.parseText(writer.toString())assert records.car.first().name.text() == &#x27;HSY Maloo&#x27;assert records.car.last().name.text() == &#x27;Royale&#x27;\n\n生成的 XML ：\n&lt;records&gt;  &lt;car name=&#x27;HSY Maloo&#x27; make=&#x27;Holden&#x27; year=&#x27;2006&#x27;&gt;    &lt;country&gt;Australia&lt;/country&gt;    &lt;record type=&#x27;speed&#x27;&gt;Production Pickup Truck with speed of 271kph&lt;/record&gt;  &lt;/car&gt;  &lt;car name=&#x27;Royale&#x27; make=&#x27;Bugatti&#x27; year=&#x27;1931&#x27;&gt;    &lt;country&gt;France&lt;/country&gt;    &lt;record type=&#x27;price&#x27;&gt;Most Valuable Car at $15 million&lt;/record&gt;  &lt;/car&gt;&lt;/records&gt;\n\nCreating XML elements创建 XML 元素\ndef xmlString = &quot;&lt;movie&gt;the godfather&lt;/movie&gt;&quot;def xmlWriter = new StringWriter()def xmlMarkup = new MarkupBuilder(xmlWriter)xmlMarkup.movie(&quot;the godfather&quot;)        // 1assert xmlString == xmlWriter.toString()\n\n1 : The xmlMarkup.movie(&quot;the godfather&quot;) call will create a XML node with a tag called movie and with content the godfather\nCreating XML elements with attributes创建有属性的 XML 元素\ndef xmlString = &quot;&lt;movie id=&#x27;2&#x27;&gt;the godfather&lt;/movie&gt;&quot;def xmlWriter = new StringWriter()def xmlMarkup = new MarkupBuilder(xmlWriter)xmlMarkup.movie(id: 2, &quot;the godfather&quot;)assert xmlString == xmlWriter.toString()\n\nCreating XML nested element创建嵌套元素\ndef xmlWriter = new StringWriter()def xmlMarkup = new MarkupBuilder(xmlWriter)xmlMarkup.movie(id: 2) &#123;     name(&quot;the godfather&quot;)&#125;def movie = new XmlSlurper().parseText(xmlWriter.toString())assert movie.@id == 2assert movie.name.text() == &#x27;the godfather&#x27;\n\n输出：\n&lt;movie id=&#x27;2&#x27;&gt;  &lt;name&gt;the godfather&lt;/name&gt;&lt;/movie&gt;\n\nNamespace aware创建有命名空间的 XML\ndef xmlWriter = new StringWriter()def xmlMarkup = new MarkupBuilder(xmlWriter)xmlMarkup        .&#x27;x:movies&#x27;(&#x27;xmlns:x&#x27;: &#x27;http://www.groovy-lang.org&#x27;) &#123;     &#x27;x:movie&#x27;(id: 1, &#x27;the godfather&#x27;)    &#x27;x:movie&#x27;(id: 2, &#x27;ronin&#x27;)&#125;def movies =        new XmlSlurper()                 .parseText(xmlWriter.toString())                .declareNamespace(x: &#x27;http://www.groovy-lang.org&#x27;)assert movies.&#x27;x:movie&#x27;.last().@id == 2assert movies.&#x27;x:movie&#x27;.last().text() == &#x27;ronin&#x27;\n\n输出：\n&lt;x:movies xmlns:x=&#x27;http://www.groovy-lang.org&#x27;&gt;  &lt;x:movie id=&#x27;1&#x27;&gt;the godfather&lt;/x:movie&gt;  &lt;x:movie id=&#x27;2&#x27;&gt;ronin&lt;/x:movie&gt;&lt;/x:movies&gt;\n\nMix codedef xmlWriter = new StringWriter()def xmlMarkup = new MarkupBuilder(xmlWriter)xmlMarkup        .&#x27;x:movies&#x27;(&#x27;xmlns:x&#x27;: &#x27;http://www.groovy-lang.org&#x27;) &#123;    (1..3).each &#123; n -&gt;         &#x27;x:movie&#x27;(id: n, &quot;the godfather $n&quot;)        if (n % 2 == 0) &#123;             &#x27;x:movie&#x27;(id: n, &quot;the godfather $n (Extended)&quot;)        &#125;    &#125;&#125;def movies =        new XmlSlurper()                .parseText(xmlWriter.toString())                .declareNamespace(x: &#x27;http://www.groovy-lang.org&#x27;)assert movies.&#x27;x:movie&#x27;.size() == 4assert movies.&#x27;x:movie&#x27;*.text().every &#123; name -&gt; name.startsWith(&#x27;the&#x27;) &#125;\n\n输出：\n&lt;x:movies xmlns:x=&#x27;http://www.groovy-lang.org&#x27;&gt;  &lt;x:movie id=&#x27;1&#x27;&gt;the godfather 1&lt;/x:movie&gt;  &lt;x:movie id=&#x27;2&#x27;&gt;the godfather 2&lt;/x:movie&gt;  &lt;x:movie id=&#x27;2&#x27;&gt;the godfather 2 (Extended)&lt;/x:movie&gt;  &lt;x:movie id=&#x27;3&#x27;&gt;the godfather 3&lt;/x:movie&gt;&lt;/x:movies&gt;\n\nMix code2def xmlWriter = new StringWriter()def xmlMarkup = new MarkupBuilder(xmlWriter)Closure&lt;MarkupBuilder&gt; buildMovieList = &#123; MarkupBuilder builder -&gt;    (1..3).each &#123; n -&gt;        builder.&#x27;x:movie&#x27;(id: n, &quot;the godfather $n&quot;)        if (n % 2 == 0) &#123;            builder.&#x27;x:movie&#x27;(id: n, &quot;the godfather $n (Extended)&quot;)        &#125;    &#125;    return builder&#125;xmlMarkup.&#x27;x:movies&#x27;(&#x27;xmlns:x&#x27;: &#x27;http://www.groovy-lang.org&#x27;) &#123;    buildMovieList(xmlMarkup) &#125;def movies =        new XmlSlurper()                .parseText(xmlWriter.toString())                .declareNamespace(x: &#x27;http://www.groovy-lang.org&#x27;)assert movies.&#x27;x:movie&#x27;.size() == 4assert movies.&#x27;x:movie&#x27;*.text().every &#123; name -&gt; name.startsWith(&#x27;the&#x27;) &#125;\n\n输出：\n&lt;x:movies xmlns:x=&#x27;http://www.groovy-lang.org&#x27;&gt;  &lt;x:movie id=&#x27;1&#x27;&gt;the godfather 1&lt;/x:movie&gt;  &lt;x:movie id=&#x27;2&#x27;&gt;the godfather 2&lt;/x:movie&gt;  &lt;x:movie id=&#x27;2&#x27;&gt;the godfather 2 (Extended)&lt;/x:movie&gt;  &lt;x:movie id=&#x27;3&#x27;&gt;the godfather 3&lt;/x:movie&gt;&lt;/x:movies&gt;\n","categories":["Groovy User Guides - Processing XML - Creating XML"],"tags":["User Guides","Groovy","Processing XML","Creating XML"]},{"title":"Groovy MarkupBuilderHelper","url":"/groovy/user-guides/processing-xml/creating-xml/groovy-markupbuilderhelper/","content":"Groovy MarkupBuilderHelperThis helper normally can be accessed from within an instance of class groovy.xml.MarkupBuilder or an instance of groovy.xml.StreamingMarkupBuilder.\nThis helper could be handy in situations when you may want to:\n\nProduce a comment in the output\nProduce an XML processing instruction in the output\nProduce an XML declaration in the output\nPrint data in the body of the current tag, escaping XML entities\nPrint data in the body of the current tag\n\nIn both MarkupBuilder and StreamingMarkupBuilder this helper is accessed by the property mkp\nUsing MarkupBuilder’s ‘mkp’def xmlWriter = new StringWriter()def xmlMarkup = new MarkupBuilder(xmlWriter).rules &#123;    mkp.comment(&#x27;THIS IS THE MAIN RULE&#x27;)    // 1    rule(sentence: mkp.yield(&#x27;3 &gt; n&#x27;))      // 2 &#125;assert xmlWriter.toString().contains(&#x27;3 &amp;gt; n&#x27;)assert xmlWriter.toString().contains(&#x27;&lt;!-- THIS IS THE MAIN RULE --&gt;&#x27;)\n\n1 : 使用 mkp 生成注释2 : 使用 mkp 生成转义的值\n输出：\n&lt;rules&gt;&lt;!-- THIS IS THE MAIN RULE --&gt;3 &amp;gt; n  &lt;rule sentence=&#x27;&#x27; /&gt;&lt;/rules&gt;\n\nUsing StreamingMarkupBuilder’s ‘mkp’use of mkp property accessible from within the bind method scope when using StreamingMarkupBuilder\ndef xml = new StreamingMarkupBuilder().bind &#123;    records &#123;        car(name: mkp.yield(&#x27;3 &lt; 5&#x27;))         car(name: mkp.yieldUnescaped(&#x27;1 &lt; 3&#x27;))     &#125;&#125;assert xml.toString().contains(&#x27;3 &amp;lt; 5&#x27;)assert xml.toString().contains(&#x27;1 &lt; 3&#x27;)\n\n输出：\n&lt;records&gt;3 &amp;lt; 5&lt;car name=&#x27;3 &amp;lt; 5&#x27;/&gt;1 &lt; 3&lt;car name=&#x27;groovy.xml.streamingmarkupsupport.StreamingMarkupWriter@6826c41e&#x27;/&gt;&lt;/records&gt;\n","categories":["Groovy User Guides - Processing XML - Creating XML"],"tags":["User Guides","Groovy","Processing XML","Creating XML"]},{"title":"Groovy StreamingMarkupBuilder","url":"/groovy/user-guides/processing-xml/creating-xml/groovy-streamingmarkupbuilder/","content":"Groovy StreamingMarkupBuildergroovy.xml.StreamingMarkupBuilder uses a groovy.xml.streamingmarkupsupport.StreamingMarkupWriter to handle output\nUsing StreamingMarkupBuilderdef xml = new StreamingMarkupBuilder().bind &#123;               // 1    records &#123;        car(name: &#x27;HSV Maloo&#x27;, make: &#x27;Holden&#x27;, year: 2006) &#123;             country(&#x27;Australia&#x27;)            record(type: &#x27;speed&#x27;, &#x27;Production Pickup Truck with speed of 271kph&#x27;)        &#125;        car(name: &#x27;P50&#x27;, make: &#x27;Peel&#x27;, year: 1962) &#123;            country(&#x27;Isle of Man&#x27;)            record(type: &#x27;size&#x27;, &#x27;Smallest Street-Legal Car at 99cm wide and 59 kg in weight&#x27;)        &#125;        car(name: &#x27;Royale&#x27;, make: &#x27;Bugatti&#x27;, year: 1931) &#123;            country(&#x27;France&#x27;)            record(type: &#x27;price&#x27;, &#x27;Most Valuable Car at $15 million&#x27;)        &#125;    &#125;&#125;def records = new XmlSlurper().parseText(xml.toString()) assert records.car.size() == 3assert records.car.find &#123; it.@name == &#x27;P50&#x27; &#125;.country.text() == &#x27;Isle of Man&#x27;\n\n1 : StreamingMarkupBuilder.bind 返回一个 Writable 实例\n","categories":["Groovy User Guides - Processing XML - Creating XML"],"tags":["User Guides","Groovy","Processing XML","Creating XML"]},{"title":"Groovy Flexible navigation with children (), depthFirst (*) and breadthFirst","url":"/groovy/user-guides/processing-xml/gpath/groovy-flexible-navigation-with-children-depthfirst-and-breadthfirst/","content":"Groovy Flexible navigation with children (*), depthFirst (**) and breadthFirst* : children()\n** : depthFirst()\nUsing *Only iterators over the direct children of the node\nstatic final String books = &#x27;&#x27;&#x27;    &lt;response version-api=&quot;2.0&quot;&gt;        &lt;value&gt;            &lt;books&gt;                &lt;book available=&quot;20&quot; id=&quot;1&quot;&gt;                    &lt;title&gt;Don Quixote&lt;/title&gt;                    &lt;author id=&quot;1&quot;&gt;Miguel de Cervantes&lt;/author&gt;                &lt;/book&gt;                &lt;book available=&quot;14&quot; id=&quot;2&quot;&gt;                    &lt;title&gt;Catcher in the Rye&lt;/title&gt;                   &lt;author id=&quot;2&quot;&gt;JD Salinger&lt;/author&gt;               &lt;/book&gt;               &lt;book available=&quot;13&quot; id=&quot;3&quot;&gt;                   &lt;title&gt;Alice in Wonderland&lt;/title&gt;                   &lt;author id=&quot;3&quot;&gt;Lewis Carroll&lt;/author&gt;               &lt;/book&gt;               &lt;book available=&quot;5&quot; id=&quot;4&quot;&gt;                   &lt;title&gt;Don Quixote&lt;/title&gt;                   &lt;author id=&quot;4&quot;&gt;Miguel de Cervantes&lt;/author&gt;               &lt;/book&gt;           &lt;/books&gt;       &lt;/value&gt;    &lt;/response&gt;&#x27;&#x27;&#x27;def response = new XmlSlurper().parseText(books)// .&#x27;*&#x27; could be replaced by .children()def catcherInTheRye = response.value.books.&#x27;*&#x27;.find &#123; node -&gt;    // node.@id == 2 could be expressed as node[&#x27;@id&#x27;] == 2    node.name() == &#x27;book&#x27; %% node.@id == &#x27;2&#x27;&#125;assert catcherInTheRye.title.text() == &#x27;Catcher in the Rye&#x27;\n\n只在 books 节点下的进行搜索\nIt only stops at ++one level++ instead of continuing to the inner levels\nUsing **深度优先搜索；递归搜索\nstatic final String books = &#x27;&#x27;&#x27;    &lt;response version-api=&quot;2.0&quot;&gt;        &lt;value&gt;            &lt;books&gt;                &lt;book available=&quot;20&quot; id=&quot;1&quot;&gt;                    &lt;title&gt;Don Quixote&lt;/title&gt;                    &lt;author id=&quot;1&quot;&gt;Miguel de Cervantes&lt;/author&gt;                &lt;/book&gt;                &lt;book available=&quot;14&quot; id=&quot;2&quot;&gt;                    &lt;title&gt;Catcher in the Rye&lt;/title&gt;                   &lt;author id=&quot;2&quot;&gt;JD Salinger&lt;/author&gt;               &lt;/book&gt;               &lt;book available=&quot;13&quot; id=&quot;3&quot;&gt;                   &lt;title&gt;Alice in Wonderland&lt;/title&gt;                   &lt;author id=&quot;3&quot;&gt;Lewis Carroll&lt;/author&gt;               &lt;/book&gt;               &lt;book available=&quot;5&quot; id=&quot;4&quot;&gt;                   &lt;title&gt;Don Quixote&lt;/title&gt;                   &lt;author id=&quot;4&quot;&gt;Miguel de Cervantes&lt;/author&gt;               &lt;/book&gt;           &lt;/books&gt;       &lt;/value&gt;    &lt;/response&gt;&#x27;&#x27;&#x27;def response = new XmlSlurper().parseText()// .&#x27;**&#x27; could be replaced by .depthFirst()def bookId = response.&#x27;**&#x27;.find &#123; book -&gt;    book.author.text() == &#x27;Lewis Carroll&#x27;&#125;.@idassert bookId == 3\n\n** is the same as looking for something everywhere in the tree from this point down\n** goes as far down the tree as it can while navigating down the tree from a given node\ndepthFirst() vs. breadthFirst深度优先 vs 广度优先\ndef response = new XmlSlurper().parseText(books)def nodeName = &#123; node -&gt; node.name() &#125;def withId2or3 = &#123; node -&gt; node.@id in [2, 3]&#125;assert [&#x27;book&#x27;, &#x27;author&#x27;, &#x27;book&#x27;, &#x27;author&#x27;] == response.value.books.depthFirst().findAll(withId2or3).collect(nodeName)assert [&#x27;book&#x27;, &#x27;book&#x27;, &#x27;author&#x27;, &#x27;author&#x27;] == response.value.books.breadthFirst().findAll(withId2or3).collect(nodeName)\n\nhelpersdef response = new XmlSlurper().parseText(books)def titles = response.value.books.book.findAll &#123; book -&gt;    /* You can use toInteger() over the GPathResult object */    book.@id.toInteger() &gt; 2&#125;*.titleassert titles.size() == 2\n","categories":["Groovy User Guides - Processing XML - GPath"],"tags":["User Guides","Groovy","Processing XML","GPath"]},{"title":"Groovy GPath","url":"/groovy/user-guides/processing-xml/gpath/groovy-gpath/","content":"Groovy GPath在 Groovy 查询 XML 最常用的方式是使用 GPath\n在 XMl ，你可以这种访问 Attribute ：\n\na[&quot;@href&quot;] : the href attribute of all the a elements\na.&#39;@href&#39;  : an alternative way of expressing this\na.@href    : an alternative way of expressing this when using XmlSlurper\n\n","categories":["Groovy User Guides - Processing XML - GPath"],"tags":["User Guides","Groovy","Processing XML","GPath"]},{"title":"Groovy Simply traversing the tree","url":"/groovy/user-guides/processing-xml/gpath/groovy-simply-traversing-the-tree/","content":"Groovy Simply traversing the treestatic final String books = &#x27;&#x27;&#x27;    &lt;response version-api=&quot;2.0&quot;&gt;        &lt;value&gt;            &lt;books&gt;                &lt;book available=&quot;20&quot; id=&quot;1&quot;&gt;                    &lt;title&gt;Don Quixote&lt;/title&gt;                    &lt;author id=&quot;1&quot;&gt;Miguel de Cervantes&lt;/author&gt;                &lt;/book&gt;                &lt;book available=&quot;14&quot; id=&quot;2&quot;&gt;                    &lt;title&gt;Catcher in the Rye&lt;/title&gt;                   &lt;author id=&quot;2&quot;&gt;JD Salinger&lt;/author&gt;               &lt;/book&gt;               &lt;book available=&quot;13&quot; id=&quot;3&quot;&gt;                   &lt;title&gt;Alice in Wonderland&lt;/title&gt;                   &lt;author id=&quot;3&quot;&gt;Lewis Carroll&lt;/author&gt;               &lt;/book&gt;               &lt;book available=&quot;5&quot; id=&quot;4&quot;&gt;                   &lt;title&gt;Don Quixote&lt;/title&gt;                   &lt;author id=&quot;4&quot;&gt;Miguel de Cervantes&lt;/author&gt;               &lt;/book&gt;           &lt;/books&gt;       &lt;/value&gt;    &lt;/response&gt;&#x27;&#x27;&#x27;\n\nGetting node value使用 POJO’s notation\ndef response = new XmlSlurper().parseText(books)def authorResult = response.value.books.book[0].authorassert authorResult.text() == &#x27;Miguel de Cervantes&#x27;\n\nGetting an attribute’s valuedef response = new XmlSlurper().parseText(books)def book = response.value.books.book[0] // Getting the first book mode def bookAuthorId1 = book.@id            // Getting the book&#x27;s id attribute `@id`def bookAuthorId2 = book[&#x27;@id&#x27;]         // Getting the book&#x27;s id attribute with `map notation` `[&#x27;@id&#x27;]`assert bookAuthorId1 == &#x27;1&#x27;             // Getting the value as a Stringassert bookAuthorId1.toInteger() == 1   // Getting the value of the attribute as an `Integer`assert bookAuthorId1 == bookAuthorId2\n\n有两种定位方式获取 Attribute：\n\n直接访问：@nameoftheattribute\nmap 访问: [&#39;@nameoftheattribute&#39;]\n\n","categories":["Groovy User Guides - Processing XML - GPath"],"tags":["User Guides","Groovy","Processing XML","GPath"]},{"title":"Groovy Adding nodes","url":"/groovy/user-guides/processing-xml/manipulating-xml/groovy-adding-nodes/","content":"Groovy Adding nodesdef xml = &quot;&quot;&quot;&lt;response version-api=&quot;2.0&quot;&gt;    &lt;value&gt;        &lt;books&gt;            &lt;book id=&quot;2&quot;&gt;                &lt;title&gt;Don Quixote&lt;/title&gt;                &lt;author id=&quot;1&quot;&gt;Miguel de Cervantes&lt;/author&gt;            &lt;/book&gt;        &lt;/books&gt;    &lt;/value&gt;&lt;/response&gt;&quot;&quot;&quot;\n\nIf you needed to see a node right after creating it then XmlParser should be your choice. 要马上看到结果就用这个\nIf you’re planning to do many changes to the XML and send the result to another process maybe XmlSlurper would be more efficient\n你不能直接使用 XmlSlurper 直接创建一个节点，但是你可以使用 XmlParser 来直接创建节点\n使用 XmlParser 的 createNode() 方法来创建一个新的节点\ndef parser = new XmlParser()def response = parser.parseText(xml)def numberOfResults = parser.createNode(    response,    new QName(&quot;numberOfResults&quot;),    [:])numberOfResults.value = &quot;1&quot;assert response.numberOfResults.text() == &quot;1&quot;\n\nThe createNode() method receives the following parameters:\n\nparent node (could be null)\nThe qualified name for the tag (In this case we only use the local part without any namespace). We’re using an instance of groovy.namespace.QName\nA map with the tag’s attributes (None in this particular case)\n\ndef parser = new XmlParser()def response = parser.parseText(xml)response.appendNode(        new QName(&quot;numberOfResults&quot;),        [:],        &quot;1&quot;)response.numberOfResults.text() == &quot;1&quot;\n\nWhen using XmlSlurper, GPathResult instances don’t have createNode()method.\n","categories":["Groovy User Guides - Processing XML - Manipulating XML"],"tags":["User Guides","Groovy","Processing XML","Manipulating XML"]},{"title":"Groovy Modifying And Removing nodes","url":"/groovy/user-guides/processing-xml/manipulating-xml/groovy-modifying-and-removing-nodes/","content":"Groovy Modifying And Removing nodesdef xml = &quot;&quot;&quot;&lt;response version-api=&quot;2.0&quot;&gt;    &lt;value&gt;        &lt;books&gt;            &lt;book id=&quot;2&quot;&gt;                &lt;title&gt;Don Quixote&lt;/title&gt;                &lt;author id=&quot;1&quot;&gt;Miguel de Cervantes&lt;/author&gt;            &lt;/book&gt;        &lt;/books&gt;    &lt;/value&gt;&lt;/response&gt;&quot;&quot;&quot;\n\ndef response = new XmlParser().parseText(xml)/* Use the same syntax as groovy.xml.MarkupBuilder */response.value.books.book[0].replaceNode &#123;     book(id: &quot;3&quot;) &#123;        title(&quot;To Kill a Mockingbird&quot;)        author(id: &quot;3&quot;, &quot;Harper Lee&quot;)    &#125;&#125;def newNode = response.value.books.book[0]assert newNode.name() == &quot;book&quot;assert newNode.@id == &quot;3&quot;assert newNode.title.text() == &quot;To Kill a Mockingbird&quot;assert newNode.author.text() == &quot;Harper Lee&quot;assert newNode.author.@id.first() == &quot;3&quot;\n\nWhen using replaceNode() the closure we pass as parameter should follow the same rules as if we were using groovy.xml.MarkupBuilder\ndef response = new XmlSlurper().parseText(books)/* Use the same syntax as groovy.xml.MarkupBuilder */response.value.books.book[0].replaceNode &#123;    book(id: &quot;3&quot;) &#123;        title(&quot;To Kill a Mockingbird&quot;)        author(id: &quot;3&quot;, &quot;Harper Lee&quot;)    &#125;&#125;assert response.value.books.book[0].title.text() == &quot;Don Quixote&quot;/* That mkp is a special namespace used to escape away from the normal building mode   of the builder and get access to helper markup methods   &#x27;yield&#x27;, &#x27;pi&#x27;, &#x27;comment&#x27;, &#x27;out&#x27;, &#x27;namespaces&#x27;, &#x27;xmlDeclaration&#x27; and   &#x27;yieldUnescaped&#x27; */def result = new StreamingMarkupBuilder().bind &#123; mkp.yield response &#125;.toString()def changedResponse = new XmlSlurper().parseText(result)assert changedResponse.value.books.book[0].title.text() == &quot;To Kill a Mockingbird&quot;\n\nNotice how using XmlSlurper we have to parse the transformed document again in order to find the created nodes.\nXmlParser:\ndef parser = new XmlParser()def response = parser.parseText(xml)response.@numberOfResults = &quot;1&quot;assert response.@numberOfResults == &quot;1&quot;\n\nXmlSlurper:\ndef response = new XmlSlurper().parseText(books)response.@numberOfResults = &quot;2&quot;assert response.@numberOfResults == &quot;2&quot;\n","categories":["Groovy User Guides - Processing XML - Manipulating XML"],"tags":["User Guides","Groovy","Processing XML","Manipulating XML"]},{"title":"Groovy Printing XML","url":"/groovy/user-guides/processing-xml/manipulating-xml/groovy-printing-xml/","content":"Groovy Printing XMLXmlUtilSometimes is useful to get not only the value of a given node but the node itself (for instance to add this node to another XML).\nFor that you can use groovy.xml.XmlUtil class. It has several static methods to serialize the xml fragment from several type of sources (Node, GPathResult, String…​)\nGetting a node as a stringdef response = new XmlParser().parseText(xml)def nodeToSerialize = response.&#x27;**&#x27;.find &#123; it.name() == &#x27;author&#x27; &#125;def nodeAsText = XmlUtil.serialize(nodeToSerialize)assert nodeAsText ==        XmlUtil.serialize(&#x27;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;author id=&quot;1&quot;&gt;Miguel de Cervantes&lt;/author&gt;&#x27;)\n","categories":["Groovy User Guides - Processing XML - Manipulating XML"],"tags":["User Guides","Groovy","Processing XML","Manipulating XML"]},{"title":"Groovy DOMCategory","url":"/groovy/user-guides/processing-xml/parsing-xml/groovy-domcategory/","content":"Groovy DOMCategory在 Groovy 中还有一种方法解析 XML 文档，使用 groovy.xml.dom.DOMCategory，这个 category 类添加 GPath 风格的操作到 Java 的 DOM 类中\n假设有如下 XML ：\nstatic def CAR_RECORDS = &#x27;&#x27;&#x27;&lt;records&gt;  &lt;car name=&#x27;HSV Maloo&#x27; make=&#x27;Holden&#x27; year=&#x27;2006&#x27;&gt;    &lt;country&gt;Australia&lt;/country&gt;    &lt;record type=&#x27;speed&#x27;&gt;Production Pickup Truck with speed of 271kph&lt;/record&gt;  &lt;/car&gt;  &lt;car name=&#x27;P50&#x27; make=&#x27;Peel&#x27; year=&#x27;1962&#x27;&gt;    &lt;country&gt;Isle of Man&lt;/country&gt;    &lt;record type=&#x27;size&#x27;&gt;Smallest Street-Legal Car at 99cm wide and 59 kg in weight&lt;/record&gt;  &lt;/car&gt;  &lt;car name=&#x27;Royale&#x27; make=&#x27;Bugatti&#x27; year=&#x27;1931&#x27;&gt;    &lt;country&gt;France&lt;/country&gt;    &lt;record type=&#x27;price&#x27;&gt;Most Valuable Car at $15 million&lt;/record&gt;  &lt;/car&gt;&lt;/records&gt;&#x27;&#x27;&#x27;\n\n使用 groovy.xml.DOMBuilder 和 groovy.xml.dom.DOMCategory 来解析这个 XML 文档：\ndef reader = new StringReader(CAR_RECORDS)def doc = DOMBuilder.parse(reader)def records = doc.documentElementuse(DOMCategory) &#123;    assert records.car.size() == 3&#125;\n","categories":["Groovy User Guides - Processing XML - Parsing XML"],"tags":["User Guides","Groovy","Processing XML","Parsing XML"]},{"title":"Groovy XmlParser and XmlSlurper","url":"/groovy/user-guides/processing-xml/parsing-xml/groovy-xmlparser-and-xmlslurper/","content":"Groovy XmlParser and XmlSlurper从字符串或者文件等地方读取 xml 信息，解析成 Groovy 对象\ngroovy.xml.XmlParser\ngroovy.xml.XmlSlurper\nXmlParser 和 XmlSlurper 的相同点：\n\n都是基于 SAX，内存占用都很低\n都可以更新操作 XML\n\nXmlParser 和 XmlSlurper 的不同点：\n\nXmlSlurper 延迟计算结构，如果你更新了 XML ，那么你要再次全部计算 XML tree\nXmlSlurper 解析 XML 返回 GPathResult 实例\nXmlParser 解析 XML 返回 Node 对象\n\n什么时候使用哪个：\n\n如果要将一个已存在的文档转换为另一个文档，使用 XmlSlurper\n如果要同时更新和读取文档，使用 XmlParser\n如果只需要读取文档的一些节点，使用 XmlSlurper，因为它不用在内存中创建一个完整的结构\n\nXmlSlurperdef text = &#x27;&#x27;&#x27;    &lt;list&gt;        &lt;technology&gt;            &lt;name&gt;Groovy&lt;/name&gt;        &lt;/technology&gt;    &lt;/list&gt;&#x27;&#x27;&#x27;def list = new XmlSlurper().parseText(text)assert list instanceof groovy.xml.slurpersupport.GPathResultassert list.technology.name == &#x27;Groovy&#x27;\n\nXmlParserdef text = &#x27;&#x27;&#x27;    &lt;list&gt;        &lt;technology&gt;            &lt;name&gt;Groovy&lt;/name&gt;        &lt;/technology&gt;    &lt;/list&gt;&#x27;&#x27;&#x27;def list = new XmlParser().parseText(text)assert list instanceof groovy.util.Nodeassert list.technology.name.text() == &#x27;Groovy&#x27;\n","categories":["Groovy User Guides - Processing XML - Parsing XML"],"tags":["User Guides","Groovy","Processing XML","Parsing XML"]},{"title":"Groovy Testing GDK Methods","url":"/groovy/user-guides/testing-guide/language-features/groovy-testing-gdk-methods/","content":"Groovy Testing GDK MethodsIterable#combinationsvoid testCombinations() &#123;    def combinations = [[2, 3], [4, 5, 6]].combinations()    assert combinations == [[2, 4], [2, 5], [2, 6], [3, 4], [3, 5], [3, 6]]&#125;\n\nThe method could be used in test case scenarios to generate all possible argument combinations for a specific method call\n用于生成所有可能的参数组合\nIterable#eachCombinationvoid testEachCombination() &#123;    [[2, 3], [4, 5, 6]].eachCombination &#123; println it[0] + it[1]&#125;&#125;\n\nThe method could be used in the testing context to call methods with each of the generated combinations.\n","categories":["Groovy User Guides - Testing Guide - Language Features"],"tags":["User Guides","Groovy","Testing Guide","Language Features"]},{"title":"Groovy Testing Groovy Testing Mocking and Stubbing","url":"/groovy/user-guides/testing-guide/language-features/groovy-testing-groovy-testing-mocking-and-stubbing/","content":"Groovy Testing Groovy Testing Mocking and StubbingMap Coercion使用 Map 或者 Expando\nclass TranslationService &#123;    String convert(String key) &#123;        return &quot;test&quot;    &#125;&#125;def service = [convert: &#123;String key -&gt; &#x27;some text&#x27;&#125;] as TranslationServiceassert &#x27;some text&#x27; == service.convert(&#x27;key.text&#x27;)\n\nas 关键字将 Closure 转换为指定类，覆盖类原本的方法实现\nClosure CoercionGroovy internally create a proxy object descending for the given class.\nGroovy在内部为给定类创建代理对象。\n使用隐式 SAM 转换，可以省略 as 关键字\nabstract class BaseService &#123;    abstract void doSomething()&#125;BaseService service = &#123;-&gt; println &#x27;fuck you&#x27;&#125;service.doSomething()\n\nMockFor and StubForThe Groovy mocking and stubbing classes can be found in the groovy.mock.interceptor package\nMockFor 和 StubFor 不能用来测试静态编译的类，例如使用了 @CompileStatic 修饰的类\nTo stub and&#x2F;or mock these classes you can use Spock or one of the Java mocking libraries\nMockForclass Person &#123;    String first, last&#125;class Family &#123;    Person father, mother    def nameOfMother() &#123;        &quot;$mother.first $mother.last&quot;    &#125;&#125;def mock = new MockFor(Person)  // 1mock.demand.getFirst &#123;&#x27;dummy&#x27;&#125;  // 2mock.demand.getLast  &#123;&#x27;name&#x27;&#125;mock.use &#123;                      // 3    def mary = new Person(first: &#x27;Mary&#x27;, last: &#x27;Smith&#x27;) // 4    def f = new Family(mother: mary)    assert f.nameOfMother() == &#x27;dummy name&#x27;&#125;mock.expect.verify()            // 5\n\n1 : 创建一个新的 MockFor 实例，对 Person 进行 Mock\n2 : demand是期望的意思；对 getFirst 和 getLast 方法进行 Mock(模仿)\n3 : a Closure is passed to use which enables the mocking functionality\n4 : 正常创建 Person，但是它的 getFirst 和 getLast 方法已经被 Mock\n5 : a call to verify checks whether the sequence and number of methods calls is as expected\nStubFordef stub = new StubFor(Person)  // 1stub.demand.with &#123;              // 2    getLast &#123;&#x27;name&#x27;&#125;    getFirst &#123;&#x27;dummy&#x27;&#125;&#125;stub.use &#123;                      // 3    def john = new Person(first: &#x27;John&#x27;, last: &#x27;Smith&#x27;)    def f = new Family(father: john)    assert f.father.first == &#x27;dummy&#x27;    assert f.father.last == &#x27;name&#x27;&#125;stub.expect.verify()            // 4\n\n1 : a new stub is created by a new instance of StubFor\n2 : the with method is used for delegating all calls inside the closure to the StubFor instance\n3 : a Closure is passed to use which enables the stubbing functionality\n4 : a call to verify(optional) checks whether the number of method calls is as expected\nExpando Meta-Class (EMC)ExpandoMetaClass 可以 Mocking 静态方法：\nclass Book &#123;    String title&#125;Book.metaClass.static.create &lt;&lt; &#123; String title -&gt; new Book(title: title)&#125;def b = Book.create(&quot;The Stand&quot;)assert b.title == &#x27;The Stand&#x27;\n\nMocking 实例方法：\ndef b = new Book(title: &#x27;The Stand&#x27;)b.metaClass.getTitle  &#123;-&gt; &#x27;My Title&#x27;&#125;assert b.title == &#x27;My Title&#x27;\n","categories":["Groovy User Guides - Testing Guide - Language Features"],"tags":["User Guides","Groovy","Testing Guide","Language Features"]},{"title":"Groovy Testing Power Assertions","url":"/groovy/user-guides/testing-guide/language-features/groovy-testing-power-assertions/","content":"Groovy Testing Power Assertionsdef x = 1assert x == 2// Output:             //// Assertion failed:// assert x == 2//        | |//        1 false\n\nThe java.lang.AssertionError that is thrown whenever the assertion can not be validated successfully, contains an extended version of the original exception message.\nIn Groovy assertions are enabled by default.\n","categories":["Groovy User Guides - Testing Guide - Language Features"],"tags":["User Guides","Groovy","Testing Guide","Language Features"]},{"title":"Groovy Testing Tool Support","url":"/groovy/user-guides/testing-guide/language-features/groovy-testing-tool-support/","content":"Groovy Testing Tool SupportTest Code CoverageTo get code coverage metrics, the generated byte-code usually needs to be instrumented before the tests are executed.\nOne tool with Groovy support for this task is Cobertura.\n","categories":["Groovy User Guides - Testing Guide - Language Features"],"tags":["User Guides","Groovy","Testing Guide","Language Features"]},{"title":"Groovy JUnit 3","url":"/groovy/user-guides/testing-guide/testing-with-junit/groovy-junit-3/","content":"Groovy JUnit 3Groovy JUnit 3Maybe one of the most prominent Groovy classes supporting JUnit 3 tests is the GroovyTestCase class.\nGroovyTestCase 类可能是支持JUnit3测试的最突出的Groovy类之一。\nBeing derived from junit.framework.TestCase it offers a bunch of additional methods that make testing in Groovy a breeze.\n它从 junit.framework.TestCase 继承而来，提供了一系列额外的方法，使 Groovy 中的测试变得轻而易举。\nAssertion MethodsGroovyTestCase 继承了 junit.framework.TestCase 类，因此拥有大量的 assertion 方法可以使用：\nclass MyTestCase extends GroovyTestCase &#123;    void testAssertions() &#123;        assertTrue(1 == 1)        assertEquals(&quot;test&quot;, &quot;test&quot;)        def x = &quot;42&quot;        assertNotNull &quot;x must not be null&quot;, x        assertNull null        assertSame x, x    &#125;&#125;\n\nGroovyTestCase 添加了一个 assertScript 方法，这个方法判断给定的 Groovy 脚本代码没有异常地成功执行：\nvoid testScriptAssertions() &#123;    assertScript &#x27;&#x27;&#x27;        def x = 1        def y = 2        assert x + y == 3    &#x27;&#x27;&#x27;&#125;\n\nshouldFail MethodsshoudFail 用来检查一个代码块应该执行失败，否则 assertions 失败\nvoid testInvalidIndexAccess1() &#123;    def numbers = [1,2,3,4]    shouldFail &#123;        numbers.get(4)    &#125;&#125;\n\nThe example above uses the basic shouldFail method interface that takes a groovy.lang.Closure as a single argument.\nThe Closure instance holds the code that ++is supported to be breaking++ during run-time\n如果我们想指定 should 方法期待一个指定的异常，我们可以将指定的异常作为第一个参数传入：\nvoid testInvalidIndexAccess2() &#123;    def numbers = [1,2,3,4]    shouldFail IndexOutOfBoundsException, &#123;        numbers.get(4)    &#125;&#125;\n\n如果除了 IndexOutOfBoundsException 之外的异常抛出，那么 should 将会 assert 失败\n更好的做法是使用 shouldFail 方法返回的异常信息：\nvoid testInvalidIndexAccess3() &#123;    def numbers = [1,2,3,4]    def msg = shouldFail IndexOutOfBoundsException, &#123;        numbers.get(4)    &#125;    assert msg.contains(&#x27;Index: 4, Size: 4&#x27;) ||        msg.contains(&#x27;Index 4 out-of-bounds for length 4&#x27;) ||        msg.contains(&#x27;Index 4 out of bounds for length 4&#x27;)&#125;\n\nnotYetImplementedMethodvoid testNotYetImplemented1() &#123;    if (notYetImplemented()) return    assert 1 == 2&#125;\n\n使用 @NotYetImplemented 注解代替这个方法，这个注解允许被注解的方法还没有实现：\n@NotYetImplementedvoid testNotYetImplemented2()) &#123;    assert 1 == 2&#125;\n","categories":["Groovy User Guides - Testing Guide - Testing with JUnit"],"tags":["User Guides","Groovy","Testing Guide","Testing with JUnit"]},{"title":"Groovy JUnit 4","url":"/groovy/user-guides/testing-guide/testing-with-junit/groovy-junit-4/","content":"Groovy JUnit 4Groovy 可以没有障碍地写 JUnit 4 测试用例\ngroovy.test.GroovyAssert 有许多在 JUnit 4 中的静态方法用来代替 GroovyTestCase 中的方法\nimport org.junit.Testimport static groovy.test.GroovyAssert.shouldFailclass JUnit4ExampleTests &#123;    @Test    void indexOutOfBoundsAccess &#123;        def numbers = [1,2,3,4]        shouldFail &#123;            numbers.get(4)        &#125;    &#125;&#125;\n\n和 GroovyTestCase.shouldFail 返回异常信息不同的是，GroovyAssert.shouldFail 直接返回异常：\n@Testvoid shouldFailReturn() &#123;    def e = shouldFail &#123;        throw new RuntimeException(&#x27;foo&#x27;,                                    new RuntimeException(&#x27;bar&#x27;))    &#125;    assert e instanceof RuntimeException    assert e.message == &#x27;foo&#x27;    assert e.cause.message == &#x27;bar&#x27;&#125;\n","categories":["Groovy User Guides - Testing Guide - Testing with JUnit"],"tags":["User Guides","Groovy","Testing Guide","Testing with JUnit"]},{"title":"Groovy JUnit 5","url":"/groovy/user-guides/testing-guide/testing-with-junit/groovy-junit-5/","content":"Groovy JUnit 5Much of the approach and helper classes described under JUnit4 apply when using JUnit5 however JUnit5 uses some slightly different class annotations when writing your tests.\nJUnit4 中描述的许多方法和帮助器类在使用 JUnit5 中也适用，但是 JUnit5 在编写测试时使用了一些稍微不同的类注解。\nclass MyTest &#123;    @Test    void streamSum() &#123;        assertTrue(            Stream.of(1, 2, 3)                    .mapToInt(i -&gt; i)                    .sum() &gt; 5, () -&gt; &quot;Sum should be greater than 5&quot;        )    &#125;    @RepeatedTest(        value = 2,        name = &quot;&#123;displayName&#125;&#123;currentRepetition&#125;/&#123;totalRepetitions&#125;&quot;    )    void streamSumRepeated() &#123;        assert Stream.of(1, 2, 3).mapToInt(i -&gt; i).sum() == 6    &#125;    private boolean isPalindrome(s) &#123; s == s.reverse()&#125;    @ParameterizedTest  // 1    @ValueSource(        strings = [&quot;racecar&quot;, &quot;radar&quot;, &quot;able was I ere I saw elba&quot;]    )    void palindromes(String candidate) &#123;        assert isPalindrome(candidate)    &#125;    @TestFactory    def dynamicTestCollection() &#123;[        dynamicTest(&quot;Add test&quot;) &#123;-&gt; assert 1 + 1 == 2&#125;,        dynamicTest(&quot;Multiply Test&quot;, () -&gt; &#123; assert 2 * 3 == 6 &#125;)    ]&#125;&#125;\n\n1 : This test requires the additional org.junit.jupiter:junit-jupiter-params dependency if not already in your project\n更多的执行信息在 FINE 日志级别中生效：\n@BeforeAllstatic void init() &#123;    def logger = Logger.getLogger(LoggingListener.name)    logger.level = Level.FINE    logger.addHandler(new ConsoleHandler(level: Level.FINE))&#125;\n","categories":["Groovy User Guides - Testing Guide - Testing with JUnit"],"tags":["User Guides","Groovy","Testing Guide","Testing with JUnit"]},{"title":"Groovy The MarkupTemplateEngine","url":"/groovy/user-guides/template-engines/the-markuptemplateengine/groovy-the-markuptemplateengine/","content":"Groovy The MarkupTemplateEngineThis template engine is a template engine primarily aimed at generating XML-like markup (XML, XHTML, HTML5, …​)\nbut that can be used to generate any text based content.\nUnlike traditional template engines, this one relies on a DSL that uses the builder syntax.\nHere is a sample template:\nxmlDeclaration()cars &#123;    cars.each &#123;        car(make: it.make, model: it.model)    &#125;&#125;\n\nIf you feed it with the following model:\nmodel = [cars: [new Car(make: &#x27;Peugeot&#x27;, model: &#x27;508&#x27;), new Car(make: &#x27;Toyota&#x27;, model: &#x27;Prius&#x27;)]]\n\nIt would be rendered as:\n&lt;?xml version=&#x27;1.0&#x27;?&gt;&lt;cars&gt;&lt;car make=&#x27;Peugeot&#x27; model=&#x27;508&#x27;/&gt;&lt;car make=&#x27;Toyota&#x27; model=&#x27;Prius&#x27;/&gt;&lt;/cars&gt;\n\nThe key features of this template engine are:\n\na markup builder like syntax\ntemplates are compiled into bytecode\nfast rendering\noptional type checking of the model\nincludes\ninternationalization support\nfragments&#x2F;layouts\n\n","categories":["Groovy User Guides - Template engines"],"tags":["User Guides","Groovy","Template engines"]},{"title":"Groovy The template format","url":"/groovy/user-guides/template-engines/the-markuptemplateengine/groovy-the-template-format/","content":"Groovy The template formatBasics模版包含了 Groovy 代码\nxmlDeclaration()                                // 1cars &#123;                                          // 2    cars.each &#123;                                 // 3        car(make: it.make, model: it.model)     // 4    &#125;                                           // 5&#125;\n\n1 : renders the XML declaration string\n2 : opens a cars tag\n3 : car is a variable found in the template model, which is a list of Car instances\n4 : for each item, we create a car tag with the attributes from the Car instance\n5 : closes the cars tag\nRendering HTML code like this:\nyieldUnescaped &#x27;&lt;!DOCTYPE html&gt;&#x27;html(lang: &#x27;en&#x27;) &#123;    head &#123;        meta(&#x27;http-equiv&#x27;:&#x27;&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot;&#x27;)        title(&#x27;My page&#x27;)    &#125;    body &#123;        p(&#x27;This is an example of HTML contents&#x27;)    &#125;&#125;\n\noutput:\n&lt;!DOCTYPE html&gt;&lt;html lang=&#x27;en&#x27;&gt;&lt;head&gt;&lt;meta http-equiv=&#x27;&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot;&#x27;/&gt;&lt;title&gt;My page&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;This is an example of HTML contents&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\n\nSupport methodsThe template engine provides several support methods that will help you render contents appropriately:\n\n\n\nMethod\nDescription\nExample\n\n\n\nyield\nRenders contents, but escapes(转义) it before rendering\nyield &#39;Some text with &lt;angle brackets&gt;&#39;\n\n\nyieldUnescaped\nRenders raw contents. The argument is rendered as is, without escaping(不转义)\nyieldUnescaped Some text with &lt;angle brackets&gt;\n\n\nxmlDeclaration\nRenders an XML declaration String. If the encoding is specified in the configuration, it is written in the declaration.\nxmlDeclaration() output &lt;?xml version=&#39;1.0&#39;&gt;\n\n\ncomment\nRenders raw contents inside an XML comment\ncomment &#39;This is &lt;a href=&quot;foo.html&quot;&gt;commented out&lt;/a&gt;&#39; out put &lt;!--This is &lt;a href=&quot;foo.html&quot;&gt;commented out&lt;/a&gt;--&gt;\n\n\nnewLine\nRenders a new line. See also TemplateConfiguration#setAutoNewLine and TemplateConfiguration#setNewLineString\nnewLine()\n\n\npi\nRenders an XML processing instruction\npi(&quot;xml-stylesheet&quot;:[href:&quot;mystyle.css&quot;, type:&quot;text/css&quot;]) output &lt;?xml-stylesheet href=&#39;mystyle.css&#39; type=&#39;text/css&#39;?&gt;\n\n\ntryEscape\nReturns an escaped string for an object, if it is a String (or any type derived from CharSequence). Otherwise returns the object itself.\nyieldUnescaped tryEscape(&#39;Some text with &lt;angle brackets&gt;&#39;) output Some text with &amp;lt;angle brackets&amp;gt;\n\n\nIncludesThe MarkupTemplateEngine supports inclusion of contents from another file. Included contents may be:\n\nanother template\nraw contents\ncontents to be escaped\n\ninclude template: &#x27;other_template.tpl&#x27;\n\ninclude unescaped: &#x27;raw.txt&#x27;\n\ninclude escaped: &#x27;to_be_escaped.txt&#x27;\n\nAlternatively, you can use the following helper methods instead:\n\nincludeGroovy(&lt;name&gt;) to include another template\nincludeEscaped(&lt;name&gt;) to include another file with escaping\nincludeUnescaped(&lt;name&gt;) to include another file without escaping\n\nCalling those methods instead of the include xxx: syntax can be useful if the name of the file to be included is dynamic (stored in a variable for example).\nFiles to be included (independently of their type, template or text) are found on classpath.\nThis is one of the reasons why the MarkupTemplateEngine takes an optional ClassLoader as constructor argument (the other reason being that you can include code referencing other classes in a template).\nIf you don’t want your templates to be on classpath, the MarkupTemplateEngine accepts a convenient constructor that lets you define the directory where templates are to be found.\nFragmentsFragments are nested templates.\nul &#123;    pages.each &#123;        fragment &quot;li(line)&quot;, line:it    &#125;&#125;\n\noutput:\n&lt;ul&gt;&lt;li&gt;Page 1&lt;/li&gt;&lt;li&gt;Page 2&lt;/li&gt;&lt;/ul&gt;\nLayoutsLayouts, unlike fragments, refer to other templates.\nThey can be used to compose templates and share common structures.\nThis is often interesting if you have, for example, a common HTML page setup, and that you only want to replace the body.\nThis can be done easily with a layout. First of all, you need to create a layout template:\nlayout-main.tpl\nhtml &#123;    head &#123;        title(title)    &#125;    body &#123;        bodyContents()    &#125;&#125;\n\nThen what you need is a template that includes the layout:\nlayout &#x27;layout-main.tpl&#x27;,                                       title: &#x27;Layout example&#x27;,                                    bodyContents: contents &#123; p(&#x27;This is the body&#x27;) &#125;  \n","categories":["Groovy User Guides - Template engines - The MarkupTemplateEngine"],"tags":["User Guides","Groovy","Template engines","The MarkupTemplateEngine"]},{"title":"Groovy Closures and type inference @DelegatesTo","url":"/groovy/object-orientation/semantics/typing/closures-and-type-inference/groovy-closures-and-type-inference-delegatesto/","content":"Groovy Closures and type inference @DelegatesToThe @DelegatesTo annotation is used by the type checker to infer the type of the delegate.\nIt allows the API designer to instruct the compiler what is the type of the delegate and the delegation strategy.\n","categories":["Groovy Object Orientation - Semantics - Typing - Closures and type inference"],"tags":["Groovy","Object Orientation","Semantics","Typing","Closures and type inference"]},{"title":"Groovy Closures and type inference Return type inference","url":"/groovy/object-orientation/semantics/typing/closures-and-type-inference/groovy-closures-and-type-inference-return-type-inference/","content":"Groovy Closures and type inference Return type inferenceAs you can see, unlike a method which declares its return type explicitly\nthere’s no need to declare the return type of a closure\nits type is inferred from the body of the closure\n","categories":["Groovy Object Orientation - Semantics - Typing - Closures and type inference"],"tags":["Groovy","Object Orientation","Semantics","Typing","Closures and type inference"]},{"title":"Groovy Dynamic vs static","url":"/groovy/object-orientation/semantics/typing/static-compilation/groovy-dynamic-vs-static/","content":"Groovy Dynamic vs staticGroovy 通过使用 @TypeChecked 注解， 提供了可选的类型检查\n类型检查器在编译时运行，为动态代码执行静态分析\n程序的行为将会完全一样无论类型检查是否开启\n这意味着 @TypeChecked 注解对于一个程序的语义来说是中性的\n即使 @TypeChecked 有必要在源码中提供类型信息使得程序被认为是类型安全的，但是最后程序的语义是完全一样的\nWhile this may sound fine, there is actually one issue with this: type checking of dynamic code, done at compile time, is by definition only correct if no runtime specific behavior occurs\nclass Computer &#123;    int compute(String str) &#123; str.length() &#125;        String compute(int x) &#123; String.valueOf(x) &#125;&#125;@groovy.transform.TypeCheckedvoid test() &#123;    def computer = new Computer()    computer.with &#123;        assert compute(compute(&#x27;foobar&#x27;)) == &#x27;6&#x27;    &#125;&#125;//Computer.metaClass.compute = &#123; String str -&gt; new Date() &#125; // 注释掉这里，将会导致运行异常test()\n\n使用运行时元编程，我们的确改变了 compute(String) 方法的行为\n如果你执行程序，程序将会在运行时失败\n因为这行元编程代码可以添加在任何地方，在任意线程里面，所以类型检查器绝对没有办法静态地确保不会发生这样的事情\n总结来说，类型检查器是脆弱的\n这个例子表明在动态代码上做静态分析是根本上错误的\nThe Groovy language provides an alternative annotation to @TypeChecked which will actually make sure that the methods which are inferred as being called will effectively be called at runtime\nThis annotation turns the Groovy compiler into a static compiler, where all method calls are resolved at compile time and the generated bytecode makes sure that this happens: the annotation is @groovy.transform.ComipleStatic\n","categories":["Groovy Object Orientation - Semantics - Typing - Static compilation"],"tags":["Groovy","Object Orientation","Semantics","Typing","Static compilation"]},{"title":"Groovy Key benefits","url":"/groovy/object-orientation/semantics/typing/static-compilation/groovy-key-benefits/","content":"Groovy Key benefitsThe are several benefits of using @CompileStatic on your code:\n\ntype safety\nimmunity(免疫) to monkey patching\nperformance improvements\n\n性能的提升取决于你执行哪种类型的程序\n如果是 I&#x2F;O 密集型，那动态代码和静态编译代码的性能区别不大\n在 CPU 密集型应用中，由于生成的字节码非常接近 Java 生成的字节码，所以执行性能会大幅度提升\n","categories":["Groovy Object Orientation - Semantics - Typing - Static compilation"],"tags":["Groovy","Object Orientation","Semantics","Typing","Static compilation"]},{"title":"Groovy The @CompileStatic annotation","url":"/groovy/object-orientation/semantics/typing/static-compilation/groovy-the-compilestatic-annotation/","content":"Groovy The @CompileStatic annotation@CompileStatic 注解可以添加到 class 或者 method 上\n没有必要同时使用 @CompileStatic 和 @TypeChecked 注解，因为 @CompileStatic 做了 @TypeChecked 注解做的所有事，此外 CompileStatic 还会触发静态编译\nclass Computer &#123;    int compute(String str) &#123; str.length() &#125;    String compute(int x) &#123; String.valueOf(x) &#125;&#125;@groovy.transform.CompileStaticvoid test() &#123;    def computer = new Computer()    computer.with &#123;        assert compute(compute(&#x27;foobar&#x27;)) == &#x27;6&#x27;    &#125;&#125;Computer.metaClass.compute = &#123; String str -&gt; new Date() &#125;test()\n\n现在将不会有运行时异常\nThe test method became immune(免疫) to monkey patching, because the compute methods which are called in its body are linked at compile time, so even if the metaclass of Computer changes, the program still behaves as expected by the type checker.\n","categories":["Groovy Object Orientation - Semantics - Typing - Static compilation"],"tags":["Groovy","Object Orientation","Semantics","Typing","Static compilation"]},{"title":"Groovy Type inference Advanced type inference","url":"/groovy/object-orientation/semantics/typing/type-inference/groovy-type-inference-advanced-type-inference/","content":"Groovy Type inference Advanced type inferenceclass Top &#123;   void methodFromTop() &#123;&#125;&#125;class Bottom extends Top &#123;   void methodFromBottom() &#123;&#125;&#125;def oif (someCondition) &#123;    o = new Top()                               &#125; else &#123;    o = new Bottom()                            &#125;o.methodFromTop()                               o.methodFromBottom()  // compilation error \n\n在分支结构中，根据 LUB，最终 o 的推断为 Top 类型，所以调用 methodFromBottom 方法将会导致编译时异常\n\nclass Top &#123;   void methodFromTop() &#123;&#125;&#125;class Bottom extends Top &#123;   void methodFromBottom() &#123;&#125;&#125;def o = new Top()                               Thread.start &#123;    o = new Bottom()                            &#125;o.methodFromTop()                               o.methodFromBottom()  // compilation error\n\n因为 Closure 可以在任何时候被调用，所以 Closure 中的共享变量只能根据 LUB 进行类型推断\n在这个例子中，o 推断为 Top 类型\n","categories":["Groovy Object Orientation - Semantics - Typing - Type Inference"],"tags":["Groovy","Object Orientation","Semantics","Typing","Type Inference"]},{"title":"Groovy Type inference Collection literal type inference","url":"/groovy/object-orientation/semantics/typing/type-inference/groovy-type-inference-collection-literal-type-inference/","content":"Groovy Type inference Collection literal type inferenceGroovy 提供了语法支持许多类型字面量\n在 Groovy 中有三种原生集合字面量：\n\nlists, using the [] literal\nmaps, using the [:] literal\nranges, using from..to (inclusive) and from..&lt;to (exclusive)\n\n字面量的推断类型取决于字面量的元素：\n\n\n\nLiteral\nInferred type\n\n\n\ndef list = [&quot;$&#123;foo&#125;&quot;, &quot;$&#123;bar&#125;&quot;]\njava.util.List&lt;GString&gt; be careful, a GString is not a String !\n\n\ndef map = [&quot;$&#123;someKey&#125;&quot;: &#39;someValue&#39;]\njava.util.LinkedHashMap&lt;GString, String&gt; be careful, a GString is not a String\n\n\ndef intRange = (0..10)\ngroovy.lang.IntRange\n\n\n","categories":["Groovy Object Orientation - Semantics - Typing - Type Inference"],"tags":["Groovy","Object Orientation","Semantics","Typing","Type Inference"]},{"title":"Groovy Type inference Flow typing","url":"/groovy/object-orientation/semantics/typing/type-inference/groovy-type-inference-flow-typing/","content":"Groovy Type inference Flow typing编译器可以在代码流中持续推断变量的类型：\n@groovy.transform.TypeCheckedvoid flowTyping() &#123;    def o = &#x27;foo&#x27;    o = o.toUpperCase()    o = 9d    o = Math.sqrt(o)&#125;\n\n编译器可以知道变量变化后的类型，并判断变量调用的方法是否正确\n\n并不是使用 def 声明变量触发了类型推断\nFlow typing 作用于任何类型的任何变量\n使用一个明确的类型声明一个变量仅仅是限制了你能给这个变量赋什么值：\n@groovy.transform.TypeCheckedvoid flowTypingWithExplicitType() &#123;    List list = [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]    list = list*.toUpperCase()  // 2    list = &#x27;foo&#x27;                // 3&#125;\n\n2 : this line passes compilatoin because of flow typing: the type checker knows that list is at this point a List&lt;String&gt;\n3 : but you can’t assign a String to a List so this is a type checking error\n\n即使没有使用范型信息声明一个变量，type checker 也知道元素的类型：\n@groovy.transform.TypeCheckedvoid flowTypingWithExplicitType() &#123;    List list = [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;] // 1    list.add(1)                 // 2&#125;\n\n1 : list 推断为 List&lt;String&gt;\n2 : 添加一个 int 类型到 List&lt;String&gt; 导致编译时异常\n通过明确指定范型来解决这个问题：\n@groovy.transform.TypeCheckedvoid flowTypingWithExplicitType() &#123;    List&lt;? extends Serializable&gt; list = []    list.addAll([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])    list.add(1)&#125;\n\n\n在 Java 中：\npublic Integer compute(String str) &#123;    return str.length();&#125;public String compute(Object o) &#123;    return &quot;Nope&quot;;&#125;Object string = &quot;Some string&quot;;Object result = compute(string);System.out.println(result);\n\n将会输出 Nope\n因为 Java 是在编译时通过方法的声明类型决定了调用 compute(Object) 方法，因为 string 变量的类型声明为 Object 类型\n\n在 Groovy 中：\nint     compute(String string)  &#123; string.length() &#125;String  compute(Object o)       &#123; &quot;Nope&quot; &#125;Object o = &quot;string&quot;def result = compute(o)assert result == 6\n\n在 Groovy 中，方法的调用决定是在运行时进行的，根据变量的类型\n在运行时，变量 o 的类型是 String 类型，因此调用 compute(String) 方法\n这叫做 Groovy 的动态分派\n\n即使使用 @TypeChecked ，方法的调用选择还是基于参数的类型推断（参数的运行时的实际类型），而不是参数的声明类型\n","categories":["Groovy Object Orientation - Semantics - Typing - Type Inference"],"tags":["Groovy","Object Orientation","Semantics","Typing","Type Inference"]},{"title":"Groovy Type inference instanceof inference","url":"/groovy/object-orientation/semantics/typing/type-inference/groovy-type-inference-instanceof-inference/","content":"Groovy Type inference instanceof inferenceclass Greeter &#123;    String greeting() &#123; &#x27;Hello&#x27; &#125;&#125;void doSomething(def o) &#123;    if (o instanceof Greeter) &#123;        println o.greeting()    &#125;&#125;doSomething(new Greeter())\n\ndoSomething 方法可以正常工作，即使 o 没有明确转换为 Greeter 类型\n在 Java 中，必须将 o 强转为 Greeter 类型，才能正常工作\n在 Groovy 中，即使在 doSomething 方法上面添加了 @TypeChecked 开启了类型检查，类型转换也不是必须的\n编译器内嵌了 instanceof 推断，使得 类型转换是可选的\n","categories":["Groovy Object Orientation - Semantics - Typing - Type Inference"],"tags":["Groovy","Object Orientation","Semantics","Typing","Type Inference"]},{"title":"Groovy Type inference Least upper bound","url":"/groovy/object-orientation/semantics/typing/type-inference/groovy-type-inference-least-upper-bound/","content":"Groovy Type inference Least upper boundclass Top &#123;&#125;class Bottom1 extends Top &#123;&#125;class Bottom2 extends Top &#123;&#125;assert leastUpperBound(String, String)          == Stringassert leastUpperBound(ArrayList, LinkedList)   == AbstractListassert leastUpperBound(ArrayList, List)         == Listassert leastUpperBound(List, List)              == Listassert leastUpperBound(Bottom1, Bottom2)        == Topassert leastUpperBound(List, Serializable)      == Object      // 6 \n\n6 : the LUB of two types which having nothing in common is Object\ninterface Foo &#123;&#125;class Top &#123;&#125;class Bottom                extends Top implements Serializable, Foo &#123;&#125;class SerializableFooImpl               implements Serializable, Foo &#123;&#125;\n\nWhat is the least upper bound of Bottom and SerializableFooImpl ?\nThey don’t have a common supper class (apart from Object), but they do share 2 interfaces (Serializable and Foo)\nSo their least upper bound is ++a type which represents the union of two interfaces++ (Serializable and Foo)\nThis type cannot be defined in the source code, yet Groovy knows about it\nIn the context of collection type inference (and generic type inference in general), this becomes handy, because the type of  the components is inferred as the least upper bound\ninterface Greeter   &#123; void greet() &#125;interface Salute    &#123; void salute() &#125;class A implements Greeter, Salute &#123;    void greet()    &#123; println &quot;Hello, I&#x27;m A!&quot; &#125;    void salute()   &#123; println &quot;Bye from A!&quot; &#125;&#125;class B implements Greeter, Salute &#123;    void greet()    &#123; println &quot;Hello, I&#x27;m B!&quot; &#125;    void salute()   &#123; println &quot;Bye from B!&quot; &#125;    void exit()     &#123; println &quot;No way!&quot; &#125;&#125;def list = [new A(), new B()]list.each &#123;    it.greet()    it.salute()    it.exit()       // 9&#125;\n\n9 : yet calling exit() is a compile time error because it doesn’t belong to LUB of A and B (only defined in B)\n","categories":["Groovy Object Orientation - Semantics - Typing - Type Inference"],"tags":["Groovy","Object Orientation","Semantics","Typing","Type Inference"]},{"title":"Groovy Type inference Variables vs fields in type inference","url":"/groovy/object-orientation/semantics/typing/type-inference/groovy-type-inference-variables-vs-fields-in-type-inference/","content":"Groovy Type inference Variables vs fields in type inferenceIt is worth noting that although the compiler performs type inference on local variables, it does not perform any kind of type inference on fields, always falling back to the ++declared type++ of a field.\n","categories":["Groovy Object Orientation - Semantics - Typing - Type Inference"],"tags":["Groovy","Object Orientation","Semantics","Typing","Type Inference"]},{"title":"Groovy Map Adding or removing elements","url":"/groovy/user-guides/groovy-development-kit/maps/manipulating-maps/groovy-map-adding-or-removing-elements/","content":"Groovy Map Adding or removing elements添加元素使用 put 或者 putAll 方法\n删除全部元素使用 clear 方法\n不可以使用 GString 作为 Map 的 key ，因为 GString 的哈希值和相同的 String 的哈希值是不一样的\ndef key = &#x27;some key&#x27;def map = [:]def gstringKey = &quot;$&#123;key.toUpperCase()&#125;&quot;map.put(gstringKey, &#x27;value&#x27;)assert map.get(&#x27;SOME KEY&#x27;) == null\n","categories":["Groovy User Guides - Groovy Development Kit - Maps - Manipulating maps"],"tags":["User Guides","Groovy","Groovy Development Kit","Maps","Manipulating maps"]},{"title":"Groovy Map Filtering and searching","url":"/groovy/user-guides/groovy-development-kit/maps/manipulating-maps/groovy-map-filtering-and-searching/","content":"Groovy Map Filtering and searching\nfind : 查找一个元素；返回 Map.Entry\nfindAll : 查找所有元素；返回 Map\ncollect : Map 操作\nevery : 判断所有元素；返回 Boolean\nany : 判断任一元素；返回 Boolean\n\ndef people = [        1: [name: &#x27;Bob&#x27;, age: 32, gender: &#x27;M&#x27;],        2: [name: &#x27;Johnny&#x27;, age: 36, gender: &#x27;M&#x27;],        3: [name: &#x27;Claire&#x27;, age: 21, gender: &#x27;F&#x27;],        4: [name: &#x27;Amy&#x27;, age: 54, gender: &#x27;F&#x27;]]// find 用来查找满足条件的一个元素// 返回的是 Map.EntryMap.Entry&lt;Integer, LinkedHashMap&lt;String, Serializable&gt;&gt; bob = people.find &#123; it.value.name == &#x27;Bob&#x27; &#125;// findAll 用来查找满足条件的所有元素// 返回的是 MapMap&lt;Integer, LinkedHashMap&lt;String, Serializable&gt;&gt; females = people.findAll &#123; it.value.gender == &#x27;F&#x27; &#125;def ageOfBob = bob.value.ageassert ageOfBob == 32// collect 相当于 Java 中的 Mapdef agesOfFemales = females.collect &#123; it.value.age &#125;assert agesOfFemales == [21, 54]// 在 findAll 中使用 key/value 作为参数def agesOfMales = people.findAll &#123; id, person -&gt; person.gender == &#x27;M&#x27; &#125;.collect &#123; id, person -&gt; person.age &#125;assert agesOfMales == [32, 36]// 使用 every() 方法判断是否所有元素都满足指定的条件// it 的类型是 Map.Entry// 返回的是 Booleanassert people.every &#123; it.value.age &gt; 18 &#125;// 使用 any() 方法判断是否任一元素都满足指定的条件// Closure 的入参使用的是 key/value// 返回的是 Booleanassert people.any &#123; id, person -&gt; person.age == 54 &#125;\n","categories":["Groovy User Guides - Groovy Development Kit - Maps - Manipulating maps"],"tags":["User Guides","Groovy","Groovy Development Kit","Maps","Manipulating maps"]},{"title":"Groovy Map Grouping","url":"/groovy/user-guides/groovy-development-kit/maps/manipulating-maps/groovy-map-grouping/","content":"Groovy Map Grouping可以使用 groupBy 方法将一个 List 转换为 Map\ndef list = [&#x27;a&#x27;, 7, &#x27;b&#x27;, [2, 3]]println list.groupBy &#123; it.class &#125;def list2 = [        [name: &#x27;Clark&#x27;, city: &#x27;London&#x27;],        [name: &#x27;Sharma&#x27;, city: &#x27;London&#x27;],        [name: &#x27;Maradona&#x27;, city: &#x27;LA&#x27;],        [name: &#x27;Zhang&#x27;, city: &#x27;HK&#x27;],        [name: &#x27;Ali&#x27;, city: &#x27;HK&#x27;],        [name: &#x27;Liu&#x27;, city: &#x27;HK&#x27;]]println list2.groupBy &#123; it.city &#125;\n\n输出：\n[    class java.lang.String      :[a, b],    class java.lang.Integer     :[7],    class java.util.ArrayList   :[[2, 3]]][    London  :[[name:Clark, city:London], [name:Sharma, city:London]],    LA      :[[name:Maradona, city:LA]],    HK      :[[name:Zhang, city:HK], [name:Ali, city:HK], [name:Liu, city:HK]]]\n","categories":["Groovy User Guides - Groovy Development Kit - Maps - Manipulating maps"],"tags":["User Guides","Groovy","Groovy Development Kit","Maps","Manipulating maps"]},{"title":"Groovy Map Keys, values and entries","url":"/groovy/user-guides/groovy-development-kit/maps/manipulating-maps/groovy-map-keys-values-and-entries/","content":"Groovy Map Keys, values and entries就是 Java 中的 keySet()，values()，entrySet()\n","categories":["Groovy User Guides - Groovy Development Kit - Maps - Manipulating maps"],"tags":["User Guides","Groovy","Groovy Development Kit","Maps","Manipulating maps"]},{"title":"Groovy Combining date and time values","url":"/groovy/user-guides/groovy-development-kit/working-with-date-and-time-types/interacting-with-date-and-time-values/groovy-combining-date-and-time-values/","content":"Groovy Combining date and time values&lt;&lt; 操作符可以将两个 JSR 310 types 组合成一个聚合类型\n例如，一个 LocalDate 可以 &lt;&lt; 到一个 LocalTime，组合成一个 LocalDateTime 实例\nimport java.time.*MonthDay monthDay = Month.JUNE &lt;&lt; 3                                 // June 3rdLocalDate date = monthDay &lt;&lt; Year.of(2015)                          // 3-Jun-2015LocalDateTime dateTime = date &lt;&lt; LocalTime.NOON                     // 3-Jun-2015 @ 12pmOffsetDateTime offsetDateTime = dateTime &lt;&lt; ZoneOffset.ofHours(-5)  // 3-Jun-2015 @ 12pm UTF-5\n\n&lt;&lt; 操作符是反射的，操作数的顺序无关的：\nimport java.time.Monthimport java.time.Yearimport java.time.YearMonthdef year = Year.of(2000)def month = Month.DECEMBERYearMonth a = year &lt;&lt; monthYearMonth b = month &lt;&lt; yearassert a == b\n","categories":["Groovy User Guides - Groovy Development Kit - Working with Date and Time types - Interacting with date and time values"],"tags":["User Guides","Groovy","Groovy Development Kit","Working with Date and Time types","Interacting with date and time values"]},{"title":"Groovy Creating periods and durations","url":"/groovy/user-guides/groovy-development-kit/working-with-date-and-time-types/interacting-with-date-and-time-values/groovy-creating-periods-and-durations/","content":"Groovy Creating periods and durations&gt;&gt; 操作符在操作数之间产生一个表示 Period 或 Duration 的值\n例如 ChronoLocalDate 和 YearMonth 和 Year，操作符产生一个 Period 实例\nimport java.time.LocalDateimport java.time.Monthimport java.time.Perioddef newYears = LocalDate.of(2018, Month.JANUARY, 1)def aprilFools = LocalDate.of(2018, Month.APRIL, 1)def period = newYears &gt;&gt; aprilFoolsassert period instanceof Periodassert period.months == 3\n\n&gt;&gt; 操作面向时间的 JSR types 时产生一个 Duration 实例\nimport java.time.Durationimport java.time.LocalTimedef duration = LocalTime.NOON &gt;&gt; (LocalTime.NOON + 30)assert duration instanceof Durationassert duration.seconds == 30\n\n如果 &gt;&gt; 左边的值早于右边的值，那么结果是正数的\n如果 &gt;&gt; 左边的值晚于右边的值，那么结果就是负数的\n总结就是，&gt;&gt; 左右的值按照时间的流逝顺序，结果就是正数\nimport java.time.LocalDateimport java.time.Yeardef decade = Year.of(2010) &gt;&gt; Year.of(2000)assert decade.years == -10decade = Year.of(2021) &gt;&gt; Year.of(1992)assert decade.years == -29def age = LocalDate.of(1992, 11, 28) &gt;&gt; LocalDate.now()println age\n","categories":["Groovy User Guides - Groovy Development Kit - Working with Date and Time types - Interacting with date and time values"],"tags":["User Guides","Groovy","Groovy Development Kit","Working with Date and Time types","Interacting with date and time values"]},{"title":"Groovy Property notation","url":"/groovy/user-guides/groovy-development-kit/working-with-date-and-time-types/interacting-with-date-and-time-values/groovy-property-notation/","content":"Groovy Property notationTemporalAccessor 类型，例如：LocalDate, LocalTime, ZonedDateTime，的 getLong(TemporalField) 方法\nTemporalAmount 类型，例如：Period, Duration，的 get(TemporalUnit) 方法\n都可以被 Groovy 的属性访问法(property notation)调用\nimport java.time.DayOfWeekimport java.time.LocalDateimport java.time.Monthimport java.time.Periodimport java.time.temporal.ChronoFieldimport java.time.temporal.ChronoUnitdef date = LocalDate.of(2018, Month.MARCH, 12)assert date[ChronoField.YEAR] == 2018assert date[ChronoField.MONTH_OF_YEAR] == Month.MARCH.valueassert date[ChronoField.DAY_OF_MONTH] == 12assert date[ChronoField.DAY_OF_WEEK] == DayOfWeek.MONDAY.valuedef period = Period.ofYears(2).withMonths(4).withDays(6)assert period[ChronoUnit.YEARS] == 2assert period[ChronoUnit.MONTHS] == 4assert period[ChronoUnit.DAYS] == 6\n","categories":["Groovy User Guides - Groovy Development Kit - Working with Date and Time types - Interacting with date and time values"],"tags":["User Guides","Groovy","Groovy Development Kit","Working with Date and Time types","Interacting with date and time values"]},{"title":"Groovy Ranges, upto, and downto","url":"/groovy/user-guides/groovy-development-kit/working-with-date-and-time-types/interacting-with-date-and-time-values/groovy-ranges-upto-and-downto/","content":"Groovy Ranges, upto, and downtoJSR 310 types 可以和范围操作符一起使用：\nimport java.time.LocalDateimport java.time.Perioddef start = LocalDate.now()def end = start + Period.ofDays(6)(start..end).each &#123; println it.dayOfWeek &#125;\n\nupto() 方法完成和上面的范围操作符一样的功能，upto() 方法从 start(包含) 开始迭代，一直到 end(包含)，每一次迭代都调用一次 Clouse：\ndownto() 方法完成相同的功能，方向和 upto() 方法相反：\nimport java.time.LocalDateimport java.time.Perioddef start = LocalDate.now()def end = start + Period.ofDays(6)(start..end).each &#123; println it.dayOfWeek &#125;start.upto(end) &#123; println it.dayOfWeek &#125;int iterationCount = 0end.downto(start) &#123; println it; iterationCount++ &#125;assert iterationCount == 7\n\nrange 和 upto 和 downto 的迭代单位，和相加相减的单位一样：\n\nLocalDate 通过天数来迭代\nYearMonth 通过月数来迭代\nYear 通过年数来迭代\neverything else 通过秒数来迭代\n\nupto 和 downto 都支持一个额外的 TemporalUnit 参数来指定迭代的单位：\nimport java.time.LocalDateimport java.time.Monthimport java.time.temporal.ChronoUnitdef start = LocalDate.of(2018, Month.MARCH, 1)def end = start.plusDays(1)int iterationCount = 0start.upto(end, ChronoUnit.MONTHS) &#123; next    -&gt;    println next    ++iterationCount&#125;assert iterationCount == 1\n\n从参数start开始进行迭代，每次迭代的单位是一个月，在第二次迭代时，next的日期已经超过了参数end，因此只进行了一次迭代\n","categories":["Groovy User Guides - Groovy Development Kit - Working with Date and Time types - Interacting with date and time values"],"tags":["User Guides","Groovy","Groovy Development Kit","Working with Date and Time types","Interacting with date and time values"]},{"title":"Groovy Addition an subtraction","url":"/groovy/user-guides/groovy-development-kit/working-with-date-and-time-types/manipulating-date-and-time/groovy-addition-an-subtraction/","content":"Groovy Addition an subtractionTemporal 类型有 plus 和 minus 方法来 相加 和 相减 一个 java.time.temporal.TemporalAmount 参数\n由于 Groovy 将 + 和 - 操作符映射为 plus 和 minus 的单参数方法，所以可以使用更自然的语法来表达加和减：\nimport java.time.LocalDateimport java.time.Monthimport java.time.Perioddef aprilFools = LocalDate.of(2018, Month.APRIL, 1)def nextAprilFools = aprilFools + Period.ofYears(1) // 注意看这里assert nextAprilFools.year == 2019def idesOfMarch = aprilFools - Period.ofDays(17)    // 注意看这里assert idesOfMarch.dayOfMonth == 15assert idesOfMarch.month == Month.MARCH\n","categories":["Groovy User Guides - Groovy Development Kit - Working with Date and Time types - Manipulating date and time"],"tags":["User Guides","Groovy","Groovy Development Kit","Working with Date and Time types","Manipulating date and time"]},{"title":"Groovy Incrementing and decrementing","url":"/groovy/user-guides/groovy-development-kit/working-with-date-and-time-types/manipulating-date-and-time/groovy-incrementing-and-decrementing/","content":"Groovy Incrementing and decrementing++ 和 -- 操作符可以用来增加或减少一个单位的日期或时间值\n因为 JSR 310 types 都是不可变的，所以操作符执行的结果将会是一个新的实例\nimport java.time.OffsetTimeimport java.time.Yearimport java.time.ZoneOffsetdef year = Year.of(2000)--year                                  // will create a new instance with the incremented value and reassign it to the referenceassert year.value == 1999def offsetTime = OffsetTime.of(0, 0, 0, 0, ZoneOffset.UTC)offsetTime++assert offsetTime.second == 1           // will create a new instance with the incremented value and reassign it to the reference\n","categories":["Groovy User Guides - Groovy Development Kit - Working with Date and Time types - Manipulating date and time"],"tags":["User Guides","Groovy","Groovy Development Kit","Working with Date and Time types","Manipulating date and time"]},{"title":"Groovy Multiplication and division","url":"/groovy/user-guides/groovy-development-kit/working-with-date-and-time-types/manipulating-date-and-time/groovy-multiplication-and-division/","content":"Groovy Multiplication and division* 操作符可以使用整数来乘以 Period 和 Duration\n/ 操作符可以使用整数来除以 Period 和 Duration\nimport java.time.Durationimport java.time.Perioddef period = Period.ofMonths(1) * 2         // a 1-month period times 2assert period.months == 2def duration = Duration.ofSeconds(10) / 5   // a 10-second duration divided by 5assert duration.seconds == 2\n","categories":["Groovy User Guides - Groovy Development Kit - Working with Date and Time types - Manipulating date and time"],"tags":["User Guides","Groovy","Groovy Development Kit","Working with Date and Time types","Manipulating date and time"]},{"title":"Groovy Negation","url":"/groovy/user-guides/groovy-development-kit/working-with-date-and-time-types/manipulating-date-and-time/groovy-negation/","content":"Groovy NegationDuration 和 Period 类型提供了正数和负数长度的时间\n可以使用 - 进行非操作\nimport java.time.Durationdef duration = Duration.ofSeconds(-15)def negated = -durationassert negated.seconds == 15\n","categories":["Groovy User Guides - Groovy Development Kit - Working with Date and Time types - Manipulating date and time"],"tags":["User Guides","Groovy","Groovy Development Kit","Working with Date and Time types","Manipulating date and time"]},{"title":"Groovy Available AST transformations","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/groovy-available-ast-transformations/","content":"Groovy Available AST transformationsGroovy comes with various AST transformations covering different needs:\n\nreducing boilerplate (code generation) : 减少样板代码\nimplementing design patterns (delegation, …​) : 实现设计模式\nlogging : 日志\ndeclarative concurrency : 声明式并发\ncloning : 克隆\nsafer scripting\ntweaking the compilation\nimplementing Swing patterns\ntesting\nmanaging dependencies\n\nAST transformations 可以分为两种：\n\n全局 AST transformations 的使用时透明的，全局的，当它们在 compile classpath 中可见时\nlocal AST transformations are applied by annotating the source code with markers. Unlike global AST transformations, local AST transformations may support parameters.\n\nGroovy 没有提供全局的 AST transformations\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations"]},{"title":"Groovy Easier cloning and externalizing","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/groovy-easier-cloning-and-externalizing/","content":"Groovy Easier cloning and externalizing@groovy.transform.AutoClone用于实现 java.lang.Cloneable 接口，有多种策略可选，通过 style 参数指定策略\n\n默认使用 AutoCloneStyle.CLONE 策略，这个策略先调用 super.clone() 方法，再调用每个可克隆的属性的 clone() 方法\nAutoCloneStyle.SIMPLE 策略使用一个正确的构造方法调用，将所有属性从源复制到克隆目标\nAutoCloneStyle.COPY_CONSTRUCTOR 策略创建和使用一个复制构造方法\nAutoCloneStyle.SERIALIZATION 策略序列化去克隆对象\n\nimport groovy.transform.AutoClone@AutoCloneclass Book &#123;    String isbn    String title    List&lt;String&gt; authors    Date publiccationDate&#125;\n\n相当于\nclass Book implements Cloneable &#123;    String isbn    String title    List&lt;String&gt; authors    Date publicationDate    public Book clone() throws CloneNotSupportedException &#123;        Book result = super.clone()        result.authors = authors instanceof Cloneable ? (List) authors.clone() : authors        result.publicationDate = publicationDate.clone()        result    &#125;&#125;\n\nString 类型属性不会被明确处理，因为 String 类型是不可变的，而且来自 Object 的 clone() 方法会复制 String 引用\n原始类型的处理也是这样。大部分 java.lang.Number 的子类也是如此\n@groovy.transform.AutoExternalize这个注解用于创建 java.io.Externalizable 类\n这个注解会自动添加 java.io.Externalizable 接口到类中，并生成 writeExternal 和 readExternal 方法\nimport groovy.transform.AutoExternalize@AutoExternalizeclass Book &#123;    String isbn    String title    float price&#125;\n\n将会转换为\nclass Book implements java.io.Externalizable &#123;    String isbn    String title    float price    void writeExternal(ObjectOutput out) throws IOException &#123;        out.writeObject(isbn)        out.writeObject(title)        out.writeFloat(price)    &#125;    public void readExternal(ObjectOut oin) &#123;        isbn = (String) oin.readObject()        title = (String) oin.readObject()        price = oin.readFloat()    &#125;&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations"]},{"title":"Groovy Grape handling","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/groovy-grape-handling/","content":"Groovy Grape handling\n@groovy.lang.Grab\n@groovy.lang.GrabConfig\n@groovy.lang.GrabExclude\n@groovy.lang.GrabResolver\n@groovy.lang.Grapes\n\nGrap is a dependency management engine embedded into Groovy, relying on serveral annotations which are described thoroughly in the section of the guide\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations"]},{"title":"Groovy Developing AST transformations","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/developing-ast-transformations/groovy-developing-ast-transformations/","content":"Groovy Developing AST transformations有全局，和本地 transformations 两种\n开发 AST transformations ，请参考章节 Developing AST transformations\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Developing AST transformations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Developing AST transformations"]},{"title":"Groovy Compatibility with type checking","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/extension-modules/groovy-compatibility-with-type-checking/","content":"Groovy Compatibility with type checkingUnlike categories, extension modules are compatible with type checking: if they are found on classpath, then the type checker is aware of the extension methods and will not complain when you call them\nIt is also compatible with static compilation\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Extension modules"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Extension modules"]},{"title":"Groovy Extending existing classes","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/extension-modules/groovy-extending-existing-classes/","content":"Groovy Extending existing classes一个 extension module 允许你添加新方法到已存在的类中，包含已编译的类，例如 JDK 中的类\n这些被添加的新方法，不想通过 metaclass 或者 使用 category 添加的方法，是全局可用的\n例如，当你这样写：\nStandard extension methoddef file = new File()def contents = file.getText(&#x27;utf-8)\n\ngetText 方法不存在于 File 类，但是 Groovy 知道这个方法因为这个方法定义在一个特殊的类中，ResourceGroovyMethods\nResourceGroovyMethods.javapublic static String getText(File file, String charset)throws IOException &#123;    return IOGroovyMethods.getText(newReader(file, charset))&#125;\n\n在 helper 类中使用了 static 修饰扩展方法\n扩展方法 getText 的第一个参数是 File 类型的，代表要被扩展的类\n扩展方法 getText 的剩余的参数就是扩展方法需要接收的参数\npublic static String getText(File file, String charset) 是定义了一个叫做 getText 的方法，作用在 File 上，接受一个 String 作为参数\n创建一个扩展模块的流程很简单：\n\n编写一个类似上面例子的扩展类\n编写一个模块描述文件\n\n要让扩展模块对 Groovy 可见，要将扩展模块放置到 classpath 中：\n\n直接将 classes 和 module descriptor 声明在 classpath\n将扩展模块打包成可重用的 jar\n\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Extension modules"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Extension modules"]},{"title":"Groovy Extension modules and classpath","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/extension-modules/groovy-extension-modules-and-classpath/","content":"Groovy Extension modules and classpath注意，一个 extension 在编译时，其他代码不能使用它\n这意味着使用一个 extension 时，它在 classpath 上必须是可用的，是已编译的类，在其他代码使用它前已经编译好的\nUsually, this means that you can’t have the test classes in the same source unit as the extension class itself\nSince in general, test sources are separated from normal sources and executed in another step of the build, this is not an issue\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Extension modules"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Extension modules"]},{"title":"Groovy Instance methods","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/extension-modules/groovy-instance-methods/","content":"Groovy Instance methods为了添加一个 instance method 到已存在的类中，你需要创建一个扩展类\n例如你想添加一个 maxRetries 方法到 Integer 中：\n// MaxRetriesExtension.groovyclass MaxRetriesExtension &#123;                                 // 1    static void maxRetries(Integer self, Closure code) &#123;    // 2        assert self &gt;= 0        int retries = self        Throwable e = null        while (retries &gt; 0) &#123;            try &#123;                code.call()                break            &#125; catch (Throwable err) &#123;                e = err                retries--            &#125;        &#125;        if (retries == 0 &amp;&amp; e) &#123;            throw e        &#125;    &#125;&#125;\n\n1 : The extension class\n2 : First argument of the static method corresponds to the receiver of the message, that is to say the extended instance\n在声明扩展类之后，这样使用扩展方法：\nint i = 05.maxRetries &#123;    i++&#125;assert i == 1i = 0try &#123;    5.maxRetries &#123;        i++        throw new RuntimeException(&quot;oops&quot;)    &#125;&#125; catch (RuntimeException) &#123;    assert i == 5&#125;\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Extension modules"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Extension modules"]},{"title":"Groovy Module descriptor","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/extension-modules/groovy-module-descriptor/","content":"Groovy Module descriptor为了让 Groovy 可以加载你的扩展方法，你必须定义你的 extension helper classes\n你必须创建一个名为 org.codehaus.groovy.runtime.ExtensionModule 的文件到 META-INF/groovy 文件夹中：\n// org.codehaus.groovy.runtime.ExtensionModule 文件moduleName = Test module for specificationsmoduleVersion = 1.0-testextensionClasses = support.MaxRetriesExtensionstaticExtensionClasses = support.StaticStringExtension\n\nThe module descriptor requires 4 keys:\n\nmoduleName : the name of your module\nmoduleVersion : the version of your module. Note that version number is only used to check that you don’t load the same module in two different verison\nextensionClasses : the list of extension helper classes for instance methods. You can provide serveral classes, given that they are comma seperated\nstaticExtensionClasses : the list of extension helper classes for static methods. You can provide serveral classes, given that they are comma seperated\n\n注意，没有要求一个 module 要同时定义 static helpers 和 instance helpers\n你可以添加多个 class helper 到一个 module\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Extension modules"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Extension modules"]},{"title":"Groovy Static methods","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/extension-modules/groovy-static-methods/","content":"Groovy Static methods可以添加一个静态方法给一个类\n这个静态方法必须是定义在单独的文件中\n实例方法和静态方法不能定义在同一个类文件中\n// StaticStringExtension.groovyclass StaticStringExtension &#123;    static String greeting(String self) &#123;   // 2        &quot;Hello, world!&quot;    &#125;&#125;\n\n2 : First argument of the static method corresponds to the class beging extended and is unused\n当声明好扩展的静态方法之后，可以直接在 String 类上调用扩展方法：\nassert String.greeting() == &#x27;Hello, world!&#x27;\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Extension modules"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Extension modules"]},{"title":"Groovy Custom metaclasses","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/groovy-custom-metaclasses/","content":"Groovy Custom metaclasses可以通过实现 MetaClass 接口来实现自定义的 metaclass\n通过可以继承 MetaClassImpl,DelegatingMetaClass,ExpandoMetaClass,ProxyMetaClass 来快速实现，否则就需要实现 MetaClass 接口中的所有方法\n在使用一个新的 metaclass 实例之前应该调用 groovy.lang.MetaClass#initialze() 方法，否则 metaclass 可能会也有可能不会按照预期进行工作\nDelegating metaclass如果只需要装饰一个存在的 metaclass ，那么使用 DelegatingMetaClass 是最简单的。使用 super 来调用 DelegatingMetaClass 中的已有的逻辑\nclass Foo &#123;    def bar() &#123; &quot;bar&quot; &#125;&#125;class MyFooMetaClass extends DelegatingMetaClass &#123;    MyFooMetaClass(MetaClass metaClass) &#123;        super(metaClass)    &#125;    MyFooMetaClass(Class theClass) &#123;        super(theClass)    &#125;    Object invokeMethod(Object object, String methodName, Object[] args) &#123;        println &quot;---start---&quot;        def result = super.invokeMethod(            object,            methodName.toLowerCase(),            args        )        println &quot;---end-----&quot;        result.toUpperCase()    &#125;&#125;def mc = new MyFooMetaClass(Foo.metaClass)mc.initialize()Foo.metaClass = mcdef f = new Foo()assert f.BAR() == &quot;BAR&quot;\n\nMagic package可以通过提供类名和包名来在启动时改变一个类的 metaclass\n例如，为了改变 java.lang.Integer 的 metaclass ，在 classpath 中提供一个 groovy.runtime.metaclass.java.lang.IntegerMetaClass 类就行了。\n这非常有用，特别是在使用框架时，可以在代码被框架执行前修改 metaclass\nmagic package 的通常形式是：\ngroovy.runtime.metaclass.[package].[class]MetaClass\n在上面的例子中：\n\n[package] 是 java.lang\n[class] 是 Integer\n\n// file: IntegerMetaClass.groovypackage groovy.runtime.metaclass.java.langclass IntegerMetaClass extends DelegatingMetaClass &#123;    IntegerMetaClass(MetaClass metaClass) &#123;        super(metaClass)    &#125;    IntegerMetaClass(Class theClass) &#123;        super(theClass)    &#125;        Object invokeMethod(Object object, String name, Object[] args) &#123;        if (name =~ /isBiggerThan/) &#123;            def other = name.split(/isBiggerThan/)[1].toInteger()            object &gt; other        &#125; else &#123;            return super.invokeMethod(object,name, args);        &#125;    &#125;&#125;/*By compiling the above file with `groovyc IntegerMetaClass.groovy` a `./groovy/runtime/metaclass/java/lang/IntegerMetaClass.class` will be generated*/// The example below will use the new metaclass:// File testInteger.groovydef i = 10assert i.isBiggerThan5()assert !i.isBiggerThan15()println i.isBiggerThan5()\n\n通过使用 groovy -cp . testInteger.groovy 运行这个脚本，IntegerMetaClass 将会出现在 classpath 上并且 IntegerMetaClass 将会成为 java.lang.Integer 的 metaclass，IntegerMetaClass 将会拦截 isBiggerThan*() 方法的调用\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses"]},{"title":"Groovy Metaclasses","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/groovy-metaclasses/","content":"Groovy MetaclassesMetaclasses play a central role in method resolution.\nFor every method invocation from groovy code, Groovy will find the MetaClass for the given object and delegate the method resolution to the metaclass via MetaClass#invokeMethod which should not be confused with GroovyObject#invokeMethod which happens to be a method that the metaclass may eventually call\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses"]},{"title":"Groovy Per instance metaclass","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/groovy-per-instance-metaclass/","content":"Groovy Per instance metaclass可以单独改变每个对象的 metaclass，所有一个类的多个对象实例有不同的 metaclass 是有可能的\nclass Foo &#123;    def bar() &#123;        &quot;bar&quot;    &#125;&#125;class FooMetaClass extends DelegatingMetaClass &#123;    FooMetaClass(MetaClass metaClass) &#123; super(metaClass) &#125;    Object invokeMethod(Object object, String name, Object[] args) &#123;        super.invokeMethod(object,name,args).toUpperCase()    &#125;&#125;def f1 = new Foo()def f2 = new Foo()f2.metaClass = new FooMetaClass(f2.metaClass)assert f1.bar() == &#x27;bar&#x27;assert f2.bar() == &#x27;BAR&#x27;assert f1.metaClass =~ /MetaClassImpl/assert f2.metaClass =~ /FooMetaClass/assert f1.class.toString() == &#x27;class Foo&#x27;assert f2.class.toString() == &#x27;class Foo&#x27;\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses"]},{"title":"Groovy The default metaclass MetaClassImpl","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/groovy-the-default-metaclass-metaclassimpl/","content":"Groovy The default metaclass MetaClassImpl默认地，一个对象有一个 MetaClassImpl 实例，这个实例实现了默认的方法查找（method lookup）\n这个方法查找包含了查找这个对象中的原始方法，如果不存在原始方法，就会调用 methodMissing ，最终将会调用 GroovyObject#invokeMethod\nclass Foo &#123;&#125;def f = new Foo()assert f.metaClass =~ /MetaClassImpl/\n\nclass Person &#123;    String eat() &#123; &#x27;eat shit&#x27; &#125;    def invokeMethod(String name, def args) &#123;        &#x27;invokeMethod&#x27;    &#125;    def methodMissing(String name, def args) &#123;        &#x27;methodMissing&#x27;    &#125;&#125;def p = new Person()assert p.eat() == &#x27;eat shit&#x27;                // eat() 方法存在，直接调用这个方法assert p.fuck() == &#x27;methodMissing&#x27;          // fuck() 方法不存在，最终调用 methodMissing()\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses"]},{"title":"Groovy Explicit closure parameters","url":"/groovy/object-orientation/semantics/typing/closures-and-type-inference/parameter-type-inference/groovy-explicit-closure-parameters/","content":"Groovy Explicit closure parameters可以通过给类型指定明确类型来使得静态检查正常工作：\ninviteIf(p) &#123; Person it -&gt;    it.age &gt;= 8&#125;\n","categories":["Groovy Object Orientation - Semantics - Typing - Closures and type inference - Parameter type inference"],"tags":["Groovy","Object Orientation","Semantics","Typing","Closures and type inference","Parameter type inference"]},{"title":"Groovy Parameter type inference","url":"/groovy/object-orientation/semantics/typing/closures-and-type-inference/parameter-type-inference/groovy-parameter-type-inference/","content":"Groovy Parameter type inferenceClosure 可以从上下文中推断它的参数类型\n编译器有两种方式去推断参数的类型：\n\n通过隐含的 SAM type coercion\n通过 API metadata\n\nclass Person &#123;    String name    int age&#125;void inviteIf(Person p, Closure&lt;Boolean&gt; predicate) &#123;               if (predicate.call(p)) &#123;        // send invite        // ...    &#125;&#125;@groovy.transform.TypeCheckedvoid failCompilation() &#123;    Person p = new Person(name: &#x27;Gerard&#x27;, age: 55)    inviteIf(p) &#123;                                                       it.age &gt;= 18                                // No such property: age                       &#125;&#125;\n\n在动态模式下，没有代码类型检查，所以 it.age 没有问题，因为在运行时 it 有可能会是 Person\n但是在编译时检查下，没有办法知道 it 的类型\n","categories":["Groovy Object Orientation - Semantics - Typing - Closures and type inference - Parameter type inference"],"tags":["Groovy","Object Orientation","Semantics","Typing","Closures and type inference","Parameter type inference"]},{"title":"Groovy Parameters inferred from single-abstract method types","url":"/groovy/object-orientation/semantics/typing/closures-and-type-inference/parameter-type-inference/groovy-parameters-inferred-from-single-abstract-method-types/","content":"Groovy Parameters inferred from single-abstract method types为了更加优雅，不去明确定义 Closure 入参的类型，第一种方法，也是最简单的一种，就是用 SAM 类型代替 Closure ：\ninterface Predicate&lt;On&gt; &#123; boolean apply(On e) &#125;void inviteIf(Person p, Predicate&lt;Person&gt; predicate) &#123;    if (predicate.apply(p)) &#123;        // do something    &#125;&#125;@groovy.transform.TypeCheckedvoid passesCompilation() &#123;    Person p = new Person(name: &#x27;Gerard&#x27;, age: 55)        invite(p) &#123;        it.age &gt;= 18    &#125;&#125;\n\n在许多情况下，使用 SAM interface 已经足够，特别是考虑到 Java 8 中的函数式接口\n但是 Closure 提供了函数式接口没有的特性，Closure 可以有 delegate，owner，Closure 在被调用之前可以被当作对象来操纵（克隆，序列化，科里化）\nClosure 支持多态\n","categories":["Groovy Object Orientation - Semantics - Typing - Closures and type inference - Parameter type inference"],"tags":["Groovy","Object Orientation","Semantics","Typing","Closures and type inference","Parameter type inference"]},{"title":"Groovy The @ClosureParams annotation","url":"/groovy/object-orientation/semantics/typing/closures-and-type-inference/parameter-type-inference/groovy-the-closureparams-annotation/","content":"Groovy The @ClosureParams annotation@ClosureParams 的目标是补充完整类型信息\nThis annotation is primarily aimed at framework and API developers who want extend the capabilities of the type checker by providing type inference metadata\nimport groovy.transform.stc.ClosureParamsimport groovy.transform.stc.FirstParamvoid inviteIf(Person p,               @ClosureParams(FirstParam) Closure&lt;Boolean&gt; predicate            ) &#123;    if (predicate.call(p)) &#123;        // send invite    &#125;&#125;inviteIf(p) &#123;    it.age &gt;= 8&#125;\n\n@ClosureParams 注解至少接受一个参数，这个参数叫做 type hint\n一个 type hint 是一个类，这个类的责任是在编译时为 Closure 提供完整类型信息\n在这个例子中，type hint 使用了 groovy.transform.stc.FirstParam，这个东西指示类型检查器这个 Closure 将会接受一个参数，这个参数的类型 是 ++这个方法的第一个参数的类型++\n在这个例子中，方法第一个参数的类型是 Person ，因此指示类型检查器，告诉它 Closure 的第一个入参的类型是 Person\nPredefined type hints\nFirstParam\nSecondParam\nThirdParam\n\nThe first (resp. second, third) parameter type of the method\n\n\nFirstParam.FirstGenericType\nSecondParam.FirstGenericType\nThirdParam.FirstGenericType\n\nThe first generic type of the first (resp. second, third) parameter of the method\nVariants for SecondGenericType and ThirdGenericType exist for all FirstParam, SecondParam and ThirdParam type hints\n\n\nSimpleType\n\nA type hint for which the type of closure parameters comes from the options string.\nimport groovy.transform.stc.SimpleTypepublic void doSomething(    @ClosureParams(value = SimpleType, options = [&#x27;java.lang.String&#x27;, &#x27;int&#x27;]) Closure c) &#123;    c(&#x27;foo&#x27;, 3)&#125;\n\nThis type hint supports a single signature and each of the parameter is specified as a value of the options array using a fully-qualified type name or a primitive type\n\n\nMapEntryOrKeyValue\n\nA dedicated type hint for closures that either work on a Map.Entry single parameter, or two parameters corresponding to the key and the value\nimport groovy.transform.stc.MapEntryOrKeyValuepublic &lt;K,V&gt; void doSomething(    @ClosureParams(MapEntryOrKeyValue) Closure c) &#123;    // ...&#125;doSomething([a: &#x27;A&#x27;]) &#123; k, v -&gt;    assert k.toUpperCase() == v.toUpperCase()&#125;doSomething([abc: 3]) &#123; entry -&gt;    assert entry.key.length() == e.value&#125;\n\nThis type hint requires that the first argument is a Map type, and infers the closure parameter types from the map actual key&#x2F;value types\n\n\nFromAbstractTypeMethods\n\nInfers closure parameter types from the abstract method of some type\nA signature is inferred for each abstract method\nimport groovy.transform.stc.FromAbstractTypeMethodsabstract class Foo &#123;    abstract void firstSignature(int x, int y)    abstract void secondSignature(String str)&#125;void doSomething(    @ClosureParams(value = FromAbstractTypeMethods, options = [&#x27;Foo&#x27;]) Closure cl) &#123;    // ...&#125;doSomething &#123; a, b -&gt; a + b &#125;doSomething &#123; s -&gt; s.toUpperCase() &#125;\n\nIf there are multiple signatures like in the example above, the type checker will only be able to infer the types of the arguments if the arity(数量) of each method is different.\nIn the example above, firstSignature takes 2 arguments and secondSignature takes 1 argument, so the type checker can infer the argument types based on the number of arguments.\n\n\nFromString\n\nInfers the closure parameter types from the options argument.\nThe options argument consists of an array of comma-separated non-primitive types.\nEach element of the array corresponds to a single signature, and each comma in an element separate parameters of the signature.\nIn short, this is the most generic type hint, and each string of the options map is parsed as if it was a signature literal.\nWhile being very powerful, this type hint must be avoided if you can because it increases the compilation times due to the necessity of parsing the type signatures.\nimport groovy.transform.stc.FromStringvoid doSomething(    @ClosureParams(value=FromString, options=[&quot;String&quot;]) Closure cl) &#123;    // ...&#125;doSomething &#123; s -&gt; s.toUpperCase() &#125;    // A single signature for a closure accepting a String\n\nimport groovy.transform.stc.FromStringvoid doSomething(    @ClosureParams(value=FromString, options=[&quot;String&quot;,&quot;String,Integer&quot;]) Closure cl) &#123;    // ...&#125;doSomething &#123; s -&gt; s.toUpperCase() &#125;doSomething &#123; s,i -&gt; s.toUpperCase()*i &#125;\n\nA polymorphic closure, accepting either a T or a pair T,T:\nimport groovy.transform.stc.FromStringpublic &lt;T&gt; void doSomething(    T e,    @ClosureParams(value=FromString, options=[&quot;T&quot;,&quot;T,T&quot;]) Closure cl) &#123;    // ...&#125;doSomething(&#x27;foo&#x27;) &#123; s -&gt; s.toUpperCase() &#125;doSomething(&#x27;foo&#x27;) &#123; s1,s2 -&gt; assert s1.toUpperCase() == s2.toUpperCase() &#125;\n\n总结In short, the lack of the @ClosureParams annotation on a method accepting a Closure will not fail compilation.\nIf present (and it can be present in Java sources as well as Groovy sources), then the type checker has more information and can perform additional type inference.\nThis makes this feature particularly interesting for framework developers.\nA third optional argument is named conflictResolutionStrategy.\nIt can reference a class (extending from ClosureSignatureConflictResolver) that can perform additional resolution of parameter types if more than one are found after initial inference calculations are complete.\nGroovy comes with the a default type resolver which does nothing, and another which selects the first signature if multiple are found.\nThe resolver is only invoked if more than one signature is found and is by design a post processor.\nAny statements which need injected typing information must pass one of the parameter signatures determined through type hints.\nThe resolver then picks among the returned candidate signatures.\n","categories":["Groovy Object Orientation - Semantics - Typing - Closures and type inference - Parameter type inference"],"tags":["Groovy","Object Orientation","Semantics","Typing","Closures and type inference","Parameter type inference"]},{"title":"Groovy @groovy.lang.Singleton","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/class-design-annotations/groovy-groovy-lang-Singleton/","content":"Groovy @groovy.lang.Singleton实现单例模式\nThe singleton instance is defined eagerly by default, using class initialization, or lazily, in which case the field is initialized using double checked locking\n@Singletonclass GreetingService &#123;    String greeting(String name) &#123; &quot;Hello, $name!&quot; &#125;&#125;assert GreetingService.instance.greeting(&#x27;Bob&#x27;) == &#x27;Hello, Bob&#x27;\n\nBy default, the singleton is created eagerly when the class is initialized and available through the instance property.\nIt is possible to change the name of the singleton using the property parameter:\n@Singleton(property = &#x27;theOne&#x27;)class GreetingService &#123;    String greeting(String name) &#123; &quot;Hello, $name!&quot; &#125;&#125;assert GreetingService.theOne.greeting(&#x27;Bob&#x27;) == &#x27;Hello, Bob&#x27;\n\nAnd it is also possible to make initialization lazy using the lazy parameter:\nclass Collaborator &#123;    public static boolean init = false&#125;@Singleton(lazy = true, strict = false)class GreetingService &#123;    static void init() &#123;&#125;    GreetingService() &#123;        Collaborator.init = true    &#125;    String greeting(String name) &#123; &quot;Hello, $name!&quot; &#125;&#125;GreetingService.init()      // make sure class is initializedassert Collaborator.init == falseGreetingService.instanceassert Collaborator.init == trueassert GreetingService.instance.greeting(&#x27;Bob&#x27;) == &#x27;Hello, Bob!&#x27;\n\nSet the strict parameter to false, which allows us to define our own constructor.\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Class design annotations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Class design annotations"]},{"title":"Groovy @groovy.lang.Delegate","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/class-design-annotations/groovy-groovy-lang-delegate/","content":"Groovy @groovy.lang.Delegate实现 delegation 设计模式\nclass Event &#123;    @Delegate Date when    String title&#125;def ev = new Event(    title: &#x27;Groovy keynote&#x27;,    when: Date.parse(&#x27;yyyy/MM/dd&#x27;, &#x27;2013/09/10&#x27;))def now = new Date()assert ev.before(now)   // Even 将 befoer() 方法的调用委托给 when 上的 before() 方法\n\n还可以将注解用于方法上，在这种情况下，这个方法被看作是 delegate 的 getter 或者工厂方法\nclass Test &#123;    private int robinCount = 0    private List&lt;List&gt; items = [[0], [1], [2]]    @Delegate    List getRoundRobinList() &#123;        items[robinCount++ % items.size()]    &#125;    void checkItems(List&lt;List&gt; testValue) &#123;        assert items == testValue    &#125;&#125;def t = ne Test()t &lt;&lt; &#x27;fee&#x27;  // 将 leftShift() 方法的调用委托给了 getRoundRobinList() 方法的返回值t &lt;&lt; &#x27;fi&#x27;t &lt;&lt; &#x27;fo&#x27;t &lt;&lt; &#x27;fum&#x27;t.checkItems([[0, &#x27;fee&#x27;, &#x27;fum&#x27;], [1, &#x27;fi&#x27;], [2, &#x27;fo&#x27;]])\n\n@Delegate 的行为可以通过参数来调整，具体请查看 API\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Class design annotations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Class design annotations"]},{"title":"Groovy @groovy.transform.BaseScript","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/class-design-annotations/groovy-groovy-transform-BaseScript/","content":"Groovy @groovy.transform.BaseScript为 Script 指定自定义 script class，而不是使用默认的 groovy.lang.Script\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Class design annotations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Class design annotations"]},{"title":"Groovy @groovy.transform.Immutable","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/class-design-annotations/groovy-groovy-transform-immutable/","content":"Groovy @groovy.transform.Immutable@Immutable 注解组合了如下注解：\n\n@ToString\n@EqualsAndHashCode\n@TupleConstructor\n@MapConstructor\n@ImmutableBase\n@ImmutableOptions\n@PropertyOptions\n@KnownImmutable\n\n@Immutable 注解用来简化不可变类的创建\nimport groovy.transform.Immutable@Immutableclass Point &#123;    int x    int y&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Class design annotations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Class design annotations"]},{"title":"Groovy @groovy.transform.ImmutableBase","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/class-design-annotations/groovy-groovy-transform-immutablebase/","content":"Groovy @groovy.transform.ImmutableBase使用这个注解生成的类自动变成 final\n每个属性都会进行检查，类中也会进行各种检查\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Class design annotations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Class design annotations"]},{"title":"Groovy @groovy.transform.ImmutableOptions","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/class-design-annotations/groovy-groovy-transform-immutableoptions/","content":"Groovy @groovy.transform.ImmutableOptionsGroovy’s immutability support relies on a predefined list of known immutable classes (like java.net.URI or java.lang.String)\n, and fails if you use a type which is not in that list\n, you are allowed to add to the list of known immutable types thanks to the following annotation attributes of the @ImmutableOptions annotation\nAttribute: knownImmutableClassesDefault value : Empty list\nDescription : A list of classes which are deemed immutable\nimport groovy.transform.Immutableimport groovy.transform.TupleConstructor@TupleConstructorfinal class Point &#123;    final int x    final int y    public String toString() &#123;        &quot;($x, $y)&quot;    &#125;&#125;@Immutable(knownImmutableClasses = [Point])class Triangle &#123;    Point a, b, c&#125;\n\nAttribute: knownImmutablesDefault value : Empty list\nDescription : A list of property names which are deemed immutable\nimport groovy.transform.Immutableimport groovy.transform.TupleConstructor@TupleConstructorfinal class Point &#123;    final int x    final int y    public String toString() &#123;        &quot;($x, $y)&quot;    &#125;&#125;@Immutable(knownImmutables=[&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;])class Triangle &#123;    Point a, b, c&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Class design annotations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Class design annotations"]},{"title":"Groovy @groovy.transform.KnownImmutable","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/class-design-annotations/groovy-groovy-transform-knownimmutable/","content":"Groovy @groovy.transform.KnownImmutableThe @KnownImmutable annotation isn’t actually one that triggers any AST transformations\nIt is simply a marker annotation\nYou can annotate your classes with the annotation (including Java classes) and they will be recognized as acceptable types for members within an immutable class\nThis saves you having to explicitly use the knownImmutables or knownImmutableClasses annotation attributes from @ImmutableOptions\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Class design annotations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Class design annotations"]},{"title":"Groovy @groovy.transform.Memoized","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/class-design-annotations/groovy-groovy-transform-memoized/","content":"Groovy @groovy.transform.Memoized在方法上使用 @Memoized 可以实现将方法的返回值缓存\n@Memoizedlong longComputation(int seed) &#123;    // slow computation    Thread.sleep(100*seed)    System.nanoTime()&#125;def x = longComputation(1)  // returns after 100 millisecondsdef y = longComputation(1)  // returns immediatlydef z = longComputation(2) // returns after 200 millisecondsassert x == yassert x != z\n\n缓存的大小可以通过两个可选参数进行配置：\n\nprotectedCacheSize : 多少数量的结果保证不会被垃圾回收器回收\nmaxCacheSize : 会被保存在内存中的最大数量\n\n默认情况下，缓存的数量没有限制，没有缓存结果会被保证不被垃圾收集器回收\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Class design annotations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Class design annotations"]},{"title":"Groovy @groovy.transform.PropertyOptions","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/class-design-annotations/groovy-groovy-transform-propertyoptions/","content":"Groovy @groovy.transform.PropertyOptions这个注解用于定义自定义属性处理器\n这个注解会被 Groovy 编译器忽略\n这个注解一般是和 @TupleConstructor,@MapConstructor,@ImmutableBase 一起使用\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Class design annotations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Class design annotations"]},{"title":"Groovy @groovy.transform.TailRecursive","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/class-design-annotations/groovy-groovy-transform-tailrecursive/","content":"Groovy @groovy.transform.TailRecursive尾递归转换，自动将一个方法最后的递归调用转换为一个等价的迭代版本\n尾递归调用避免了递归调用过多导致的栈溢出\nimport groovy.transform.CompileStaticimport groovy.transform.TailRecursive@CompileStaticclass Factorial &#123;    @TailRecursive    static BigInteger factorial(        BigInteger i,        BigInteger product = 1    ) &#123;        if (i == 1) &#123;            return product        &#125;        return factorial(i-1, product*i)    &#125;&#125;assert Factorial.factorial(1) == 1assert Factorial.factorial(3) == 6assert Factorial.factorial(5) == 120assert Factorial.factorial(50000).toString().size() == 213237 // Big number and no Stack Overflow\n\n当前（3.0.9），只能在 self-recursive 方法调用中生效，例如：a single recursive call to the exact same method again.\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Class design annotations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Class design annotations"]},{"title":"Groovy @groovy.transform.VisibilityOptions","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/class-design-annotations/groovy-groovy-transform-visibilityoptions/","content":"Groovy @groovy.transform.VisibilityOptionsThis annotation allows you to specify a custom visibility for a construct generated by another transformation.\nIt is ignored by the main Groovy compiler but is referenced by other transformations like @TupleConstructor,@MapConstructor,@NamedVariant\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Class design annotations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Class design annotations"]},{"title":"Groovy Code generation transformations @TupleConstructor","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/code-generation-transformations/groovy-code-generation-transformations-tupleConstructor/","content":"Groovy Code generation transformations @TupleConstructor@TupleConstructor 注解的目标是通过生成构造方法来减少样板代码\nA tuple constructor is created having a parameter for each property (and possibly each field)\nEach parameter has a default value (using the initial value of the property if present or otherwise Java’s default value according to the properties type).\n构造方法的每一个参数都有一个默认值\nImplementation Detailsimport groovy.transform.TupleConstructor@TupleConstructorclass Person &#123;    String firstName    String lastName&#125;// traditional map-style constructordef p1 = new Person(firstName: &#x27;lin&#x27;, secondName: &#x27;weiyu&#x27;)// generated tuple constructordef p2 = new Person(&#x27;Jack&#x27;, &#x27;Nicholson&#x27;)// generated tuple constructor with default value for second propertydef p3 = new Person(&#x27;Jack&#x27;)\n\ntraditional map-style constructor传统的 map-style 的构造方法适用于不是 final 的 property\n因为在 map-style 中 Groovy 会调用无参构造方法，然后调用对应的 property 的 setter 方法\n如果第一个属性&#x2F;字段是 LinkedHashMap 类型，或者只有一个属性&#x2F;字段，这个属性&#x2F;字段的类型是 Map,AbstractMap,HashMap，那么 map-style 命名参数将不会生效\ngenerated tuple constructorThe other constructors are generated by taking the properties in the order they are defined.\n这个构造方法使用属性的定义顺序来生成\nGroovy will generate as many constructors as there are properties (or fields, depending on the options).\n如果有许多属性，Groovy 会生成许多构造方法\nimport groovy.transform.TupleConstructor@TupleConstructorclass Person &#123;    String  name    Integer age    Long    length&#125;\n\n生成：\n@Generatedpublic Person(String name, Integer age, Long length) &#123;    CallSite[] var4 = $getCallSiteArray();    super();    MetaClass var5 = this.$getStaticMetaClass();    this.metaClass = var5;    this.name = name;    this.age = age;    this.length = length;&#125;@Generatedpublic Person(String name, Integer age) &#123;    CallSite[] var3 = $getCallSiteArray();    this((String)name, (Integer)age, (Long)null);&#125;@Generatedpublic Person(String name) &#123;    CallSite[] var2 = $getCallSiteArray();    this((String)name, (Integer)null, (Long)null);&#125;@Generatedpublic Person() &#123;    CallSite[] var1 = $getCallSiteArray();    this((String)null, (Integer)null, (Long)null);&#125;\n\nSetting the defaults attributeSetting the defaults attribute (see the available configuration options table) to false, disables the normal default values behavior which means:\n设置默认是 attribute 为 false ，关闭默认值行为意味着：\n\n有且只有一个构造方法会被创建\n使用初始值会导致异常\nMap-style 命名参数失效\n\nThis attribute is normally only used in situations where another Java framework is expecting exactly one constructor, e.g. injection frameworks or JUnit parameterized runners.\n这个 attribute 一般只有在另外的 Java 框架要求只有一个参数构造方法的时候使用\nImmutability support如果 @PropertyOptions 注解和 @TupleConstructor 一起使用，那么生成的构造方法可以包含自定义属性处理逻辑\nCustomization options@TupleConstructor 可以接收很多参数，具体参考 API\n将 defaults 属性设置为 false 与将 force 属性设置为 true 将会允许使用多个 tuple constructors 去为不同的使用场景定义不同的配置：\n@ToString(includeSuperProperties=true, ignoreNulls=true, includeNames=true, includeFields=true)@TupleConstructor(force=true, defaults=false)@TupleConstructor(force=true, defaults=false, includeFields=true)@TupleConstructor(force=true, defaults=false, includeSuperProperties=true)class Book extends Named &#123;  Integer published  private Boolean fiction  Book() &#123;&#125;&#125;\n\nToString(includeSuperProperties=true, ignoreNulls=true, includeNames=true, includeFields=true)@TupleConstructor(force=true, defaults=false, includes=&#x27;name,year&#x27;)@TupleConstructor(force=true, defaults=false, includes=&#x27;year,fiction&#x27;)@TupleConstructor(force=true, defaults=false, includes=&#x27;name,fiction&#x27;)class Book &#123;    String name    Integer year    Boolean fiction&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Code generation transformations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Code generation transformations"]},{"title":"Groovy Code generation transformations","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/code-generation-transformations/groovy-code-generation-transformations/","content":"\n\n\nGroovy Code generation transformations\n@groovy.transform.ToString\n@groovy.transform.EqualsAndHashCode\n@groovy.transform.MapConstructor\n@groovy.transform.Canonical\n@groovy.transform.InheritConstructors\n@groovy.lang.Category\n@groovy.transform.IndexedProperty\n@groovy.lang.Lazy\n@groovy.lang.Newify\n@groovy.transform.Sortable\n@groovy.transform.builder.Builder\n@groovy.transform.AutoImplement\n@groovy.transform.NullCheck\n\n\n\n\n\nGroovy Code generation transformations@groovy.transform.ToString生成可读的 toString 方法\ndef p = new Person(firstName: &#x27;Jack&#x27;, lastName: &#x27;Nicholson&#x27;)assert p.toString() == &#x27;Person(Jack, Nicholson)&#x27;\n\n@ToString 注解有许多可选的参数，具体请看 API\n@groovy.transform.EqualsAndHashCode生成 equals 和 hashCode 方法\n生成的 hashcode 根据 《Effective Java》中的最佳实践来生成\n@EqualsAndHashCode 注解有许多可选的参数，具体请看 API\n@groovy.transform.MapConstructor生成一个 map 构造方法\nimport groovy.transform.*@ToString@MapConstructorclass Person &#123;    String firstName    String lastName&#125;def p1 = new Person(firstName: &#x27;Jack&#x27;, lastName: &#x27;Nicholson&#x27;)assert p1.toString() == &#x27;Person(Jack, Nicholson)&#x27;\n\n将会生成一个类似这样的构造方法：\npublic Person(Map args) &#123;    if (args.containsKey(&#x27;firstName&#x27;)) &#123;        this.firstName = args.get(&#x27;firstName&#x27;)    &#125;    if (args.containsKey(&#x27;lastName&#x27;)) &#123;        this.lastName = args.get(&#x27;lastName&#x27;)    &#125;&#125;\n\n如果不使用 @MapConstructor 就不会生成入参为 Map 的构造方法\n@groovy.transform.CanonicalCanonical : 规范，典范的\n@Canonical 注解组合了 @ToString,@EqualsAndHashCode,@TupleConstructor\n@groovy.transform.InheritConstructors生成符合父类构造方法的构造方法\n在继承异常类时非常有用\nimport groovy.transform.InheritConstructors@InheritConstructorsclass CustomException extends Exception &#123;&#125;// all those are generated constructorsnew CustomException()new CustomException(&quot;A custom message&quot;)new CustomException(&quot;A custom message&quot;, new RuntimeException())new CustomException(new RuntimeException())\n\n@groovy.lang.Category简化 Groovy categories 的创建\n以前的 Groovy category 是这样写的：\nclass TripleCategory &#123;    public static Integer triple(Integer self) &#123;        3 * self    &#125;&#125;use (TripleCategory) &#123;    assert 9 == 3.triple()&#125;\n\n@Category 注解可以让你编写一样的逻辑使用 instance-style class 而不是 static class style\nThis removes the need for having the first argument of each method beging the receiver\n去掉了每个方法第一个参数必须是目标类的需要:\n@Category(Integer)class TripleCategory &#123;    public Integer triple() &#123; 3*this &#125;&#125;use (TripleCategory) &#123;    assert 9 == 3.triple()&#125;\n\n在方法中被混合的目标类可以使用 this 代替。值得注意的是在 category 类中使用实例字段会导致潜在的危险，因为 categories 是无状态的\n@groovy.transform.IndexedProperty为列表&#x2F;数组类型的属性生成索引式访问的 getter&#x2F;setter 方法\n这在使用 Java 中的类时非常有用，因为 Groovy 支持使用 GPath 去访问属性，Java 不支持\nclass SomeBean &#123;    @IndexedProperty String[] someArray = new String[2]    @IndexedProperty List someList = []&#125;def bean = new SomeBean()bean.setSomeArray(0, &#x27;value&#x27;)bean.setSomeList(0, 123)assert bean.someArray[0] == &#x27;value&#x27;assert bean.someList == [123]\n\n@groovy.lang.Lazy@Lazy 注解实现了字段的延迟初始化\nclass SomeBean &#123;    @Lazy LinkedList myField&#125;// 生成如下代码List $myFieldList getMyField() &#123;    if ($myField != null) &#123; return $myField &#125;    else &#123;        $myField = new LinkedList()        return $myField    &#125;&#125;\n\nThe default value which is used to initialize the field is the default constructor of the declaration type.\n It is possible to define a default value by using a closure on the right hand side of the property assignment, as in the following example:\nclass SomeBean &#123;    @Lazy LinkedList myField = &#123; [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;] &#125;()&#125;// 生成如下代码List $myFieldList getMyField() &#123;    if ($myField!=null) &#123; return $myField &#125;    else &#123;        $myField = &#123; [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;] &#125;()        return $myField    &#125;&#125;\n\n如果字段声明为 volatile 的，那么初始化就会是线程同步的，使用 double-checked locking 模式\n使用 soft=true 参数，字段将会使用 SoftReference 包装，提供一个简单的缓存机制，当垃圾回收器回收这个引用之后，初始化将会在字段下次被访问的时候进行\n@groovy.lang.Newify@Newify 注解提供创建对象的替代语法\n使用 Python 风格：\n@Newify([Tree, Leaf])class TreeBuilder &#123;    Tree tree = Tree(Leaf(&#x27;A&#x27;), Leaf(&#x27;B&#x27;), Tree(Leaf(&#x27;C&#x27;)))&#125;\n\n使用 Ruby 风格：\n@Newify([Tree, Leaf])class TreeBuilder &#123;    Tree tree = Tree.new(Leaf.new(&#x27;A&#x27;), Leaf.new(&#x27;B&#x27;), Tree.new(Leaf.new(&#x27;C&#x27;)))&#125;\n\n@groovy.transform.SortableThe @Sortable AST transformation is used to help write classes that are Comparable and easily sorted typically by numerous properties.\nimport groovy.transform.Sortable@Sortableclass Person &#123;    String first    String last    Integer born&#125;\n\nThe generated class has the following properties:\n\nit implements the Comparable interface\nit contains a compareTo method with an implementation based on the natural ordering of the first, last and born properties\nit has three methods returning comparators: comparatorByFirst,comparatorByLast,comparatorByBorn\n\nThe Person class can be used wherever a Comparable is expected and the generated comparators wherever a Comparator is expected as shown by these examples:\ndef people = [    new Person(first: &#x27;Johnny&#x27;, last: &#x27;Depp&#x27;, born: 1963),    new Person(first: &#x27;Keira&#x27;, last: &#x27;Knightley&#x27;, born: 1985),    new Person(first: &#x27;Geoffrey&#x27;, last: &#x27;Rush&#x27;, born: 1951),    new Person(first: &#x27;Orlando&#x27;, last: &#x27;Bloom&#x27;, born: 1977)]assert people[0] &gt; people[2]assert people.sort()*.last == [&#x27;Rush&#x27;, &#x27;Depp&#x27;, &#x27;Knightley&#x27;, &#x27;Bloom&#x27;]assert people.sort(false, Person.comparatorByFirst())*.first == [&#x27;Geoffrey&#x27;, &#x27;Johnny&#x27;, &#x27;Keira&#x27;, &#x27;Orlando&#x27;]assert people.sort(false, Person.comparatorByLast())*.last == [&#x27;Bloom&#x27;, &#x27;Depp&#x27;, &#x27;Knightley&#x27;, &#x27;Rush&#x27;]assert people.sort(false, Person.comparatorByBorn())*.last == [&#x27;Rush&#x27;, &#x27;Depp&#x27;, &#x27;Bloom&#x27;, &#x27;Knightley&#x27;]\n\nNormally, all properties are used in the generated compareTo method in th e priority order in which they are defined.\nYou can include or exclude certain properties from the generated compareTo method by giving a list of property names in the includes or excludes annotation attributes\nIf using includes, the order of the property names given determine the priority of the properties when comparing:\n@Sortable(includes = &#x27;first, born&#x27;)class Person &#123;    String last    int born    String first&#125;\n\nIt will have two comparator methods comparatorByFirst and comparatorByBorn and the generated compareTo method\n@groovy.transform.builder.Builder用于生成可以使用 fluent api 调用来生成对象的代码\n有多种策略可以使用：\n// SimpleStrategyimport groovy.transform.builder.*@Builder(builderStrategy = SimpleStrategy)class Person &#123;    String first    String last    Integer born&#125;def p1 = new Person().setFirst(&#x27;Johnny&#x27;).setLast(&#x27;Depp&#x27;).setBorn(1963)assert &quot;$p1.first $p1.last&quot; == &#x27;Johnny Depp&#x27;\n\n指定方法前缀：\n// SimpleStrategyimport groovy.transform.builder.*@Builder(builderStrategy = SimpleStrategy, prefix = &quot;&quot;)class Person &#123;    String first    String last    Integer born&#125;def p1 = new Person().first(&#x27;Johnny&#x27;).last(&#x27;Depp&#x27;).born(1963)assert &quot;$p1.first $p1.last&quot; == &#x27;Johnny Depp&#x27;\n\n// SimpleStrategydef p3 = new Person().with &#123;    fisrt = &#x27;Geoffrey&#x27;    last = &#x27;Rush&#x27;    born = 1951&#125;\n\n// ExternalStrategy, 可以为已存在的类添加 builder 方法class Person &#123;String first; String last; int born;&#125;import groovy.transform.builder.*@Builder(builderStrategy = ExternalStrategy, forClass = Person)class PersonBuilder &#123;&#125;def p = PersonBuilder.first(&#x27;Johnny&#x27;).last(&#x27;Depp&#x27;).born(1963)assert &quot;$p1.first $p1.last&quot; == &#x27;Johnny Depp&#x27;\n\n// ExternalStrategy, 可以为已存在的类添加 builder 方法import groovy.transform.builder.*@Builder(builderStrategy = ExternalStrategy, forClass = javax.swing.DefaultButtonModel)class ButtonModelBuilder &#123;&#125;def model = new ButtonModelBuilder().enabled(true).pressed(true).armed(true).rollover(true).selected(true).build()assert model.isArmed()assert model.isPressed()assert model.isEnabled()assert model.isSelected()assert model.isRollover()\n\n// DefaultStrategyimport groovy.transform.builder.*@Builderclass Person &#123;String firstName;String lastName;int age;&#125;def person = Person.builder().firstName(&quot;Robert&quot;).lastName(&quot;Lewandowski&quot;).age(21).build()assert person.firstName == &quot;Robert&quot;assert person.lastName == &quot;Lewandowski&quot;assert person.age == 21\n\n// DefaultStrategy 使用指定方法作为 builderimport groovy.transform.builder.*import groovy.transform.*@ToString@Builderclass Person &#123;  String first; String last; int born  Person()&#123;&#125;  @Builder(builderClassName=&#x27;MovieBuilder&#x27;, builderMethodName=&#x27;byRoleBuilder&#x27;)  Person(String roleName) &#123;     if (roleName == &#x27;Jack Sparrow&#x27;) &#123;         this.first = &#x27;Johnny&#x27;; this.last = &#x27;Depp&#x27;; this.born = 1963     &#125;  &#125;  @Builder(builderClassName=&#x27;NameBuilder&#x27;, builderMethodName=&#x27;nameBuilder&#x27;, prefix=&#x27;having&#x27;, buildMethodName=&#x27;fullName&#x27;)  static String join(String first, String last) &#123;      first + &#x27; &#x27; + last  &#125;  @Builder(builderClassName=&#x27;SplitBuilder&#x27;, builderMethodName=&#x27;splitBuilder&#x27;)  static Person split(String name, int year) &#123;      def parts = name.split(&#x27; &#x27;)      new Person(first: parts[0], last: parts[1], born: year)  &#125;&#125;assert Person.splitBuilder().name(&quot;Johnny Depp&quot;).year(1963).build().toString() == &#x27;Person(Johnny, Depp, 1963)&#x27;assert Person.byRoleBuilder().roleName(&quot;Jack Sparrow&quot;).build().toString() == &#x27;Person(Johnny, Depp, 1963)&#x27;assert Person.nameBuilder().havingFirst(&#x27;Johnny&#x27;).havingLast(&#x27;Depp&#x27;).fullName() == &#x27;Johnny Depp&#x27;assert Person.builder().first(&quot;Johnny&quot;).last(&#x27;Depp&#x27;).born(1963).build().toString() == &#x27;Person(Johnny, Depp, 1963)&#x27;\n\n// InitializerStrategyimport groovy.transform.builder.*import groovy.transform.*@ToString@Builder(builderStrategy=InitializerStrategy)class Person &#123;    String firstName    String lastName    int age&#125;\n\nYour class will be locked down to have a single public constructor taking a “fully set” initializer.\nIt will also have a factory method to create the initializer.\nThese are used as follows:\n@CompileStaticdef fisrtLastAge() &#123;    assert new Person(        Person.createInitializer().firstName(&#x27;John&#x27;).lastName(&#x27;Smith&#x27;).age(21)    ).toString() == &#x27;Person(John, Smith, 21)&#x27;&#125;\n\nAny attempt to use the initializer which doesn’t involve setting all the properties (though order is not important) will result in a compilation error.\nIf you don’t need this level of strictness, you don’t need to use @CompilStatic\n@groovy.transform.AutoImplement为 继承&#x2F;实现的 还未提供实现的 抽象方法 提供假的实现\nimport groovy.transform.AutoImplement@AutoImplementclass MyNames extend AbstractList&lt;String&gt; implements Closeable &#123;&#125;asert new MyNames().size() == 0\n\n// 指定会抛出的异常@AutoImplement(exception=IOException)class MyWriter extends Writer &#123;&#125;import static groovy.test.GroovyAssert.shouldFailshouldFail(IOException) &#123;    new MyWriter().flush()&#125;\n\n// 指定会抛出的异常@AutoImplement(    exception = UnsupportedOperationException,    message = &#x27;Not supported by MyIterator&#x27;)class MyIterator implements Iterator&lt;String&gt; &#123;&#125;def ex = shouldFail(UnsupportedOperationException) &#123;    new MyIterator.hasNext()&#125;assert ex.message == &#x27;Not supported by MyIterator&#x27;\n\n// 使用用户指定的代码逻辑@AutoImplement(    code = &#123;        throw new UnsupportedOperationException(&#x27;Should never be called but was called on &#x27; + new Date())    &#125;)class EmptyIterator implements Iterator&lt;String&gt; &#123;    boolean hasNext() &#123; false &#125;&#125;def ex = shouldFail(UnsupportedOperationException) &#123;     new EmptyIterator().next()&#125;assert ex.message.startsWith(&#x27;Should never be called but was called on &#x27;)\n\n@groovy.transform.NullCheck@NullCheck 用于在方法或者构造方法中添加 null 检查\n可以单独用于方法上，也可以用于类上，这样类中所有的方法都会添加\n@NullCheckString longerOf(String first, String second) &#123;    first.size() &gt;= second.size() ? first : second&#125;assert longerOf(&#x27;cat&#x27;, &#x27;canary&#x27;) == &#x27;canary&#x27;def ex = shouldFail(IllegalArgumentException) &#123;    longerOf(&#x27;cat&#x27;, null)&#125;assert ex.message == &#x27;second cannot be null&#x27;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Code generation transformations"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Code generation transformations"]},{"title":"Groovy Compiler directives Others","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/compiler-directives/groovy-compiler-directives-others/","content":"\n\n\nGroovy Compiler directives Others\n@groovy.transform.AnnotationCollector\n@groovy.transform.TypeChecked\n@groovy.transform.CompileStatic\n@groovy.transform.CompileDynamic\n@groovy.lang.DelegatesTo\n@groovy.transform.SelfType\n\n\n\n\n\nGroovy Compiler directives Others@groovy.transform.AnnotationCollectorAllows the creation of meta-annotations\n@groovy.transform.TypeCheckedActivates compile-time type checking on your Groovy code\n@groovy.transform.CompileStaticActivates static compilation on your Groovy code\n@groovy.transform.CompileDynamicDisables static compilation on parts of your Groovy code\n@groovy.lang.DelegatesToIt is aimed at documenting code and helping the compiler in case you are using type checking or static compilation\n@groovy.transform.SelfType@SelfType is not an AST transformation but rather a marker interface used with traits\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Compiler directives"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Compiler directives"]},{"title":"Groovy Compiler directives","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/compiler-directives/groovy-compiler-directives/","content":"Groovy Compiler directivesThis category of AST transformations groups annotations which have a direct impact on the semantics of the code, rather than focusing on code generation.\n这个类别的 AST transformations 直接对代码的语义产生影响，而不是集中在代码生成\nWith that regards, they can be seen as compiler directives that either change the behavior of a program at compile time or runtime.\n在这方面，它们可以被视为是编译器指令，在编译时或运行时更改程序的行为\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Compiler directives"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Compiler directives"]},{"title":"Groovy @groovy.transform.AutoFinal","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/compiler-directives/groovy-groovy-transform-autofinal/","content":"Groovy @groovy.transform.AutoFinal@AutoFinal 指示编译器在这个注解修饰的多个地方自动插入 final 修饰符\n如果一个方法（或者构造方法）使用了 @AutoFinal 注解，那么这个方法（或者构造方法）的入参将会被标记为 final\n如果一个类使用了 @AutoFinal 注解，同样的操作将会作用于类中所有声明的方法和构造方法\nIt is often considered bad practice to reassign parameters of a method or constructor with its body.\nBy adding the final modifier to all parameter declarations you can avoid this practice entirely.\nThe @AutoFinal annotation aims to maximise compiler&#x2F;IDE feedback while retaining succinct code with minimum boilerplate noise.\nimport groovy.transform.AutoFinal@AutoFinalclass Person &#123;    private String first, last    Person(String first, String last) &#123;        this.first = first        this.last = last    &#125;    String fullName(String separator) &#123;        &quot;$first$separator$last&quot;    &#125;    String greeting(String salutation) &#123;        &quot;$salutation, $first&quot;    &#125;&#125;\n\nclass Calc &#123;    @AutoFinal    int add(int a, int b) &#123; a + b &#125;    int mult(int a, int b) &#123; a * b &#125;&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Compiler directives"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Compiler directives"]},{"title":"Groovy @groovy.transform.Field","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/compiler-directives/groovy-groovy-transform-field/","content":"Groovy @groovy.transform.Field只在脚本中有用\n将脚本中的局部变量提升为生成的脚本类中的字段\ndef xString line() &#123;    &quot;=&quot;*x&#125;x=3assert &quot;===&quot; == line()x=5assert &quot;=====&quot; == line()\n\nclass MyScript extends Script &#123;    String line() &#123;        &quot;=&quot;*x    &#125;    public def run() &#123;        def x        x=3        assert &quot;===&quot; == line()        x=5        assert &quot;=====&quot; == line()    &#125;&#125;\n\n在第一个代码片段中，变量 x 是定义在 run() 方法中的局部变量，对 line() 方法不可见\n@Field def xString line() &#123;    &quot;=&quot;*x&#125;x=3assert &quot;===&quot; == line()x=5assert &quot;=====&quot; == line()\n\nclass MyScript extends Script &#123;    def x    String line() &#123;        &quot;=&quot;*x    &#125;    public def run() &#123;        x=3        assert &quot;===&quot; == line()        x=5        assert &quot;=====&quot; == line()    &#125;&#125;\n\n使用 @Field 修饰变量 x ，在生成的脚本类中，x 成为脚本类的字段\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Compiler directives"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Compiler directives"]},{"title":"Groovy @groovy.transform.PackageScope","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/compiler-directives/groovy-groovy-transform-packagescope/","content":"Groovy @groovy.transform.PackageScopeclass Person &#123;    String name // this is a property&#125;\n\n默认情况下，不使用修饰符修饰字段，这个字段是一个属性(private field+getter&#x2F;setter)\n如果要创建一个 package private 的字段，使用 @PackageScope 注解\nclass Person &#123;    @PackageScope String name // not a property anymore&#125;\n\n@PackageScope 注解可以用于 classes, methods 和 constructors\nIn addition, by specifying a list of PackageScopeTarget values as the annotation attribute at the class level,\nall members within that class that don’t have an explicit modifier and match the provided PackageScopeTarget will remain package protected.\nimport static groovy.transform.PackageScopeTarget.FIELDS@PackageScope(FIELDS)class Person &#123;    String name     // not a property, package protected    Date dob        // not a property, package protected    private int age // explicit modifier, so won&#x27;t be touched&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Compiler directives"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Compiler directives"]},{"title":"Groovy Declarative concurrency","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/declarative-concurrency/groovy-declarative-concurrency/","content":"Groovy Declarative concurrencyGroovy 提供一些注解使用声明式来简化通用线程同步模式\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Declarative concurrency"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Declarative concurrency"]},{"title":"Groovy @groovy.transform.Synchronized","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/declarative-concurrency/groovy-groovy-transform-synchronized/","content":"Groovy @groovy.transform.Synchronized@Synchronzied 和关键字 synchronized 一样工作，通过锁住不同对象提供更安全的并发\nimport groovy.transform.Synchronizedimport java.util.concurrent.Executorsimport java.util.concurrent.TimeUnitclass Counter &#123;    int cpt    @Synchronized    int incrementAndGet() &#123;        cpt++    &#125;    int get() &#123;        cpt    &#125;&#125;\n\n相当于\nclass Counter &#123;    int cpt    private final Object $lock = new Object()    int incrementAndGet() &#123;        synchronized($lock) &#123;            cpt++        &#125;    &#125;    int get() &#123;        cpt    &#125;&#125;\n\n默认情况下，@Synchronized 注解创建字段 $lock （或者 $LOCK 在静态方法下）作为锁\n可以自定义字段作为锁\nclass Counter &#123;    int cpt    private final Object Object myLock = new Object()    @Synchronized    int incrementAndGet() &#123;        cpt++    &#125;    int get() &#123;        cpt    &#125;&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Declarative concurrency"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Declarative concurrency"]},{"title":"Groovy @groovy.transform.WithReadLock and @groovy.transform.WithWriteLock","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/declarative-concurrency/groovy-groovy-transform-withreadlock-and-groovy-transform-withwritelock/","content":"Groovy @groovy.transform.WithReadLock and @groovy.transform.WithWriteLock@WithReadLock 和 @WithWriteLock 结合工作，提供 读&#x2F;写 同步，使用 ReentrantReadWriteLock 作为实现\n这两个注解可以添加到 method 或者 static method 上\n这两个注解将会透明地创建一个 final $reentrantLock field（或者 final $REENTRANTLOCK 给 static method），正确的同步代码会被添加到代码中\nimport groovy.transform.WithReadLockimport groovy.transform.WithWriteLockclass Counters &#123;    public final Map&lt;String, Integer&gt; map = [:].withDefault &#123; 0 &#125;    @WithReadLock    int get(String id) &#123; map.get(id) &#125;    @WithWriteLock    void add(String id, int num) &#123;        Thread.sleep(20)        map.put(id, map.get(id) + num)    &#125;&#125;\n\n等同于：\nimport groovy.transform.WithReadLock as WithReadLockimport groovy.transform.WithWriteLock as WithWriteLockpublic class Counters &#123;    private final Map&lt;String, Integer&gt; map        private final java.util.concurrent.locks.ReentrantReadWriteLock $reentrantlock    public int get(java.lang.String id) &#123;        $reentrantlock.readLock().lock()        try &#123;            map.get(id)        &#125; finally &#123;            $reentrantlock.readLock().unlock()        &#125;    &#125;    public void add(java.lang.String id, int num) &#123;        $reentrantlock.writeLock().lock()        try &#123;            java.lang.Thread.sleep(200)            map.put(id, map.get(id) + num)        &#125; finally &#123;            $reentrantlock.writeLock().unlock()        &#125;    &#125;&#125;\n\n使用自定义的锁对象\nimport groovy.transform.WithReadLockimport groovy.transform.WithWriteLockclass Counters &#123;    public final Map&lt;String, Integer&gt; map = [:].withDefault &#123; 0 &#125;    private final ReentrantReadWriteLock customLock = new ReentrantReadWriteLock()    @WithReadLock(&#x27;customLock&#x27;)    int get(String id) &#123; map.get(id) &#125;    @WithWriteLock(&#x27;customLock&#x27;)    void add(String id, int num) &#123;        Thread.sleep(20)        map.put(id, map.get(id) + num)    &#125;&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Declarative concurrency"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Declarative concurrency"]},{"title":"Groovy @groovy.util.logging.Log","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/logging-improvements/groovy-groovy-util-logging-Log/","content":"Groovy @groovy.util.logging.Log依赖 JDK 日志框架\n@groovy.util.logging.Logclass Greeter &#123;    void greet() &#123;        log.info &#x27;Called greeter&#x27;        println &#x27;Hello, world!&#x27;    &#125;&#125;\n\n以上代码相当于：\nimport java.util.logging.Levelimport java.util.logging.Loggerclass Greeter &#123;    private static final Logger log = Logger.getLogger(Greeter.name)    void greet() &#123;        if (log.isLoggable(Level.INFO)) &#123;            log.info &#x27;Called greeter&#x27;        &#125;        println &#x27;Hello, world!&#x27;    &#125;&#125;\n\n输出：\n10月 19, 2021 7:22:18 下午 java_util_logging_Logger$info$0 call信息: fuck youHello, world!\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Logging improvements"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Logging improvements"]},{"title":"Groovy @groovy.util.logging.Log4j","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/logging-improvements/groovy-groovy-util-logging-Log4j/","content":"Groovy @groovy.util.logging.Log4j使用 @Log4j 支持 Apache Log4j 1.x 框架\n@groovy.util.logging.Log4jclass Greeter &#123;    void greet() &#123;        log.info &#x27;fuck you&#x27;        println &#x27;Hello, world!&#x27;    &#125;&#125;\n\n相当于\nimport org.apache.log4j.Loggerclass Greeter &#123;    private static final Logger log = Logger.getLogger(Greeter)    void greet() &#123;        if (log.isInfoEnabled()) &#123;            log.info &#x27;Called greeter&#x27;        &#125;        println &#x27;Hello, world!&#x27;    &#125;&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Logging improvements"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Logging improvements"]},{"title":"Groovy @groovy.util.logging.Log4j2","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/logging-improvements/groovy-groovy-util-logging-Log4j2/","content":"Groovy @groovy.util.logging.Log4j2使用 @Log4j2 支持 Apache Log4j 2.x 框架\n@groovy.util.logging.Log4j2class Greeter &#123;    void greet() &#123;        log.info &#x27;fuck you&#x27;        println &#x27;Hello, world!&#x27;    &#125;&#125;\n\n相当于\nimport org.apache.logging.log4j.LogManagerimport org.apache.logging.log4j.Loggerclass Greeter &#123;    private static final Logger log = LogManager.getLogger(Greeter)    void greet() &#123;        if (log.isInfoEnabled()) &#123;            log.info &#x27;Called greeter&#x27;        &#125;        println &#x27;Hello, world!&#x27;    &#125;&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Logging improvements"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Logging improvements"]},{"title":"Groovy @groovy.util.logging.Commons","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/logging-improvements/groovy-groovy-util-logging-commons/","content":"Groovy @groovy.util.logging.Commons使用 @Commons 注解支持 Apache Commons Logging 框架\nimport groovy.util.logging.Commons@Commonsclass Greeter &#123;    void greet() &#123;        log.info &#x27;fuck you&#x27;        println &#x27;Hello, world!&#x27;    &#125;&#125;def p = new Greeter()p.greet()\n\n相当于\nimport org.apache.commons.logging.LogFactoryimport org.apache.commons.logging.Logclass Greeter &#123;    private static final Log log = LogFactory.getLog(Greeter)    void greet() &#123;        if (log.isInfoEnabled) &#123; // 自动生成的 guard 代码            log.info &#x27;fuck you&#x27;        &#125;        println &#x27;Hello, world!&#x27;    &#125;&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Logging improvements"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Logging improvements"]},{"title":"Groovy @groovy.util.logging.Slf4j","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/logging-improvements/groovy-groovy-util-logging-slf4j/","content":"Groovy @groovy.util.logging.Slf4j使用 @Slf4j 来支持 Simple Logging Facade for Java (SLF4) 框架\n@groovy.util.logging.Slf4jclass Greeter &#123;    void greet() &#123;        log.debug &#x27;fuck you&#x27;        println &#x27;Hello, world!&#x27;    &#125;&#125;\n\n相当于\nimport org.slf4j.LoggerFactoryimprot org.slf4j.Loggerclass Greeter &#123;    private static final Logger log = LoggerFactory.getLogger(Greeter)    void greet() &#123;        if (log.isDebugEnabled()) &#123;            log.debug &#x27;Called greeter&#x27;        &#125;        println &#x27;Hello, world!&#x27;    &#125;&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Logging improvements"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Logging improvements"]},{"title":"Groovy Logging improvements","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/logging-improvements/groovy-logging-improvements/","content":"Groovy Logging improvements所有的转换都是一样的方式工作：\n\n添加一个对应的 static final 日志字段\n将所有 log.level() 调用包装成对应的 log.isLevelEnabled 判断，具体取决于依赖的日志框架\n\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Logging improvements"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Logging improvements"]},{"title":"Groovy @groovy.transform.ConditionalInterrupt","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/safer-scripting/groovy-groovy-transform-conditionalinterrupt/","content":"Groovy @groovy.transform.ConditionalInterrupt通过自定义的条件来中断线程的执行\n@ConditionalInterrupt(&#123;Quotas.disallow(&#x27;user&#x27;)&#125;)class UserCode &#123;    void doSomething() &#123;        int i=0        while (true) &#123;            println &quot;Consuming resources $&#123;++i&#125;&quot;        &#125;    &#125;&#125;\n\nclass Quotas &#123;    static def quotas = [:].withDefault &#123; 10 &#125;    static boolean disallow(String userName) &#123;        println &quot;Checking quota for $userName&quot;        (quotas[userName]--)&lt;0    &#125;&#125;\n\nassert Quotas.quotas[&#x27;user&#x27;] == 10def t = Thread.start &#123;    new UserCode().doSomething()&#125;t.join(5000)assert !t.aliveassert Quotas.quotas[&#x27;user&#x27;] &lt; 0\n\ndef config = new CompilerConfiguration()def checkExpression = new ClosureExpression(        Parameter.EMPTY_ARRAY,        new ExpressionStatement(                new MethodCallExpression(new ClassExpression(ClassHelper.make(Quotas)), &#x27;disallow&#x27;, new ConstantExpression(&#x27;user&#x27;))        ))config.addCompilationCustomizers(        new ASTTransformationCustomizer(value: checkExpression, ConditionalInterrupt))def shell = new GroovyShell(this.class.classLoader,new Binding(),config)def userCode = &quot;&quot;&quot;        int i=0        while (true) &#123;            println &quot;Consuming resources \\\\$&#123;++i&#125;&quot;        &#125;&quot;&quot;&quot;assert Quotas.quotas[&#x27;user&#x27;] == 10def t = Thread.start &#123;    shell.evaluate(userCode)&#125;t.join(5000)assert !t.aliveassert Quotas.quotas[&#x27;user&#x27;] &lt; 0\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Declarative concurrency"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Declarative concurrency"]},{"title":"Groovy @groovy.transform.ThreadInterrupt","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/safer-scripting/groovy-groovy-transform-threadinterrupt/","content":"Groovy @groovy.transform.ThreadInterrupt@ThreadInterrupt 注解简化了在线程中对于 Thread#interrupt 的处理，通过在判断的地方添加线程中断检查：\n\n循环（for, while）\n方法的入口\nClosure 的入口\n\n假设有如下的死循环脚本代码：\nwhile (true) &#123;    i++&#125;\n\n通过使用 @ThreadInterrupt 注解来配置执行脚本的 shell\ndef config = new CompilerConfiguration()config.addCompilationCustomizers(    new ASTTransformationCustomizer(ThreadInterrupt))def binding = new Binding(i:0)def shell = new GroovyShell(binding, config)\n\n这个 shell 被配置为自动使用 @ThreadInterrupt 到所有脚本上，这允许使用 shell 这样来执行代码：\ndef t = Thread.start &#123;    shell.evaluate(userCode)&#125;t.join(1000)    // give at most 1000ms for the script to completeif (t.alive) &#123;    t.interrupt()&#125;\n\n@ThreadInterrupt 注解对用户代码的转换：\nwhile (true) &#123;    // `@ThreadInterrupt` 注解生成的判断代码    if (Thread.currentThread().interrupted) &#123;        throw new InterruptedException(&#x27;The current thread has been interrupted&#x27;)    &#125;    i++&#125;\n\nThe check which is introduced inside the loop guarantees that if the interrupt flag is set on the current thread, an exception will be thrown, interrupting the execution of the thread.\n@ThreadInterrupt 有多个参数可以进行自定义配置\n\n\n\nAttribute\nDefault Value\nDescription\n\n\n\nthrown\njava.lang.InterruptedException\n指定线程中断时抛出的异常类型\n\n\ncheckOnMethodStart\ntrue\n一个中断检查是否要插入到每个方法执行的开始\n\n\napplyToAllClasses\ntrue\n转换是否要作用于一个源码单元上的所有类\n\n\napplyToAllMembers\ntrue\n转换是否要作用于类上面的所有成员\n\n\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Declarative concurrency"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Declarative concurrency"]},{"title":"Groovy @groovy.transform.TimedInterrupt","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/safer-scripting/groovy-groovy-transform-timedinterrupt/","content":"Groovy @groovy.transform.TimedInterrupt@TimedInterrupt 注解在线程运行过长时间时自动抛出一个异常\n@TimedInterrupt 可以指定脚本运行多久，超过时间就结束运行并抛出异常\ndef confg = new CompilerConfiguration()config.addCompilationCustomizers(    new ASTTransformationCustomizer(value: 1, TimedInterrupt))def binding = new Binding(result: 0)def shell = new GroovyShell(this.class.classLoader, binding, config)\n\n@TimedInterrupt(value = 1, unit = TimeUnit.SECONDS)class MyClass &#123;    def fib(int n) &#123;        n&lt;2?n:fib(n-1)+fib(n-2)    &#125;&#125;\n\n@TimedInterrupt 注解支持如下参数\n\n\n\nAttribute\nDefault value\n\n\n\nvalue\nLong.MAX_VALUE\n\n\nunit\nTimeUnit.SECONDS\n\n\nthrown\njava.util.concurrent.TimeoutException\n\n\ncheckOnMethodStart\ntrue\n\n\napplyToAllClasses\ntrue\n\n\napplyToAllMembers\ntrue\n\n\n@TimedInterrupt 现在不支持静态方法\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Declarative concurrency"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Declarative concurrency"]},{"title":"Groovy Safer scripting","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/safer-scripting/groovy-safer-scripting/","content":"Groovy Safer scriptingGroovy provides serveral annotations which are aimed towards safer scripting, generating code which will for example allow you to interrupt execution automatically\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Declarative concurrency"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Declarative concurrency"]},{"title":"Groovy @groovy.beans.Bindable","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/swing-patterns/groovy-groovy-beans-bindable/","content":"Groovy @groovy.beans.Bindable@Bindable is an AST transformation that transforms a regular property into a bound property (according to the JavaBeans specification).\nThe @Bindable annotation can be placed on a property or a class.\nTo convert all properties of a class into bound properties, on can annotate the class like in this example:\nimport groovy.beans.Bindable@Bindableclass Person &#123;    String name    int age&#125;\n\nThis is equivalent to writing this:\nimport java.beans.PropertyChangeListenerimport java.beans.PropertyChangeSupportclass Person &#123;    final private PropertyChangeSupport this$propertyChangeSupport    String name    int age    public void addPropertyChangeListener(PropertyChangeListener listener) &#123;        this$propertyChangeSupport.addPropertyChangeListener(listener)    &#125;    public void addPropertyChangeListener(String name, PropertyChangeListener listener) &#123;        this$propertyChangeSupport.addPropertyChangeListener(name, listener)    &#125;    public void removePropertyChangeListener(PropertyChangeListener listener) &#123;        this$propertyChangeSupport.removePropertyChangeListener(listener)    &#125;    public void removePropertyChangeListener(String name, PropertyChangeListener listener) &#123;        this$propertyChangeSupport.removePropertyChangeListener(name, listener)    &#125;    public void firePropertyChange(String name, Object oldValue, Object newValue) &#123;        this$propertyChangeSupport.firePropertyChange(name, oldValue, newValue)    &#125;    public PropertyChangeListener[] getPropertyChangeListeners() &#123;        return this$propertyChangeSupport.getPropertyChangeListeners()    &#125;    public PropertyChangeListener[] getPropertyChangeListeners(String name) &#123;        return this$propertyChangeSupport.getPropertyChangeListeners(name)    &#125;&#125;\n\n@Bindable therefore removes a lot of boilerplate from your class, dramatically increasing readability.\nIf the annotation is put on a single property, only that property is bound:\nimport groovy.beans.Bindableclass Person &#123;    String name    @Bindable int age&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Swing patterns"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Swing patterns"]},{"title":"Groovy @groovy.beans.ListenerList","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/swing-patterns/groovy-groovy-beans-listenerlist/","content":"Groovy @groovy.beans.ListenerListThe @ListenerList AST transformation generates code for adding, removing and getting the list of listeners to a class, just by annotating a collection property:\nimport java.awt.event.ActionListenerimport groovy.beans.ListenerListclass Component &#123;    @ListenerList    List&lt;ActionListener&gt; listeners;&#125;\n\nThe transform will generate the appropriate add&#x2F;remove methods based on the generic type of the list. In addition, it will also create fireXXX methods based on the public methods declared on the class:\nimport java.awt.event.ActionEventimport java.awt.event.ActionListener as ActionListenerimport groovy.beans.ListenerList as ListenerListpublic class Component &#123;    @ListenerList    private List&lt;ActionListener&gt; listeners    public void addActionListener(ActionListener listener) &#123;        if ( listener == null) &#123;            return        &#125;        if ( listeners == null) &#123;            listeners = []        &#125;        listeners.add(listener)    &#125;    public void removeActionListener(ActionListener listener) &#123;        if ( listener == null) &#123;            return        &#125;        if ( listeners == null) &#123;            listeners = []        &#125;        listeners.remove(listener)    &#125;    public ActionListener[] getActionListeners() &#123;        Object __result = []        if ( listeners != null) &#123;            __result.addAll(listeners)        &#125;        return (( __result ) as ActionListener[])    &#125;    public void fireActionPerformed(ActionEvent param0) &#123;        if ( listeners != null) &#123;            ArrayList&lt;ActionListener&gt; __list = new ArrayList&lt;ActionListener&gt;(listeners)            for (def listener : __list ) &#123;                listener.actionPerformed(param0)            &#125;        &#125;    &#125;&#125;\n\n@ListenerList 支持多个参数来自定义 transformation 行为\n\n\n\nAttribute\nDefault value\nDescription\n\n\n\nname\nGeneric type name\nBy default, the suffix which will be appended to add&#x2F;remove&#x2F;…​ methods is the simple class name of the generic type of the list.\n\n\nsynchronize\nfalse\nIf set to true, generated methods will be synchronized\n\n\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Swing patterns"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Swing patterns"]},{"title":"Groovy @groovy.beans.Vetoable","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/swing-patterns/groovy-groovy-beans-vetoable/","content":"Groovy @groovy.beans.VetoableThe @Vetoable annotation works in a similar manner to @Bindable but generates constrained(限制的) property according to the JavaBeans specification, instead of bound properties.\n The annotation can be placed on a class, meaning that all properties will be converted to constrained properties, or on a single property.\nimport groovy.beans.Vetoableimport java.beans.PropertyVetoExceptionimport java.beans.VetoableChangeListener@Vetoableclass Person &#123;    String name    int age&#125;\n\nis equivalent to writing this:\npublic class Person &#123;    private String name    private int age    final private java.beans.VetoableChangeSupport this$vetoableChangeSupport    public void addVetoableChangeListener(VetoableChangeListener listener) &#123;        this$vetoableChangeSupport.addVetoableChangeListener(listener)    &#125;    public void addVetoableChangeListener(String name, VetoableChangeListener listener) &#123;        this$vetoableChangeSupport.addVetoableChangeListener(name, listener)    &#125;    public void removeVetoableChangeListener(VetoableChangeListener listener) &#123;        this$vetoableChangeSupport.removeVetoableChangeListener(listener)    &#125;    public void removeVetoableChangeListener(String name, VetoableChangeListener listener) &#123;        this$vetoableChangeSupport.removeVetoableChangeListener(name, listener)    &#125;    public void fireVetoableChange(String name, Object oldValue, Object newValue) throws PropertyVetoException &#123;        this$vetoableChangeSupport.fireVetoableChange(name, oldValue, newValue)    &#125;    public VetoableChangeListener[] getVetoableChangeListeners() &#123;        return this$vetoableChangeSupport.getVetoableChangeListeners()    &#125;    public VetoableChangeListener[] getVetoableChangeListeners(String name) &#123;        return this$vetoableChangeSupport.getVetoableChangeListeners(name)    &#125;    public void setName(String value) throws PropertyVetoException &#123;        this.fireVetoableChange(&#x27;name&#x27;, name, value)        name = value    &#125;    public void setAge(int value) throws PropertyVetoException &#123;        this.fireVetoableChange(&#x27;age&#x27;, age, value)        age = value    &#125;&#125;\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Swing patterns"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Swing patterns"]},{"title":"Groovy @groovy.test.NotYetImplemented","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/test-assistance/groovy-groovy-test-notyetimplemented/","content":"Groovy @groovy.test.NotYetImplemented@NotYetImplemented is used to invert the result of a JUnit 3&#x2F;4 test case.\nIt is in particular useful if a feature is not yet implemented but the test is.\nIn that case, it is expected that the test fails.\nMarking it with @NotYetImplemented will inverse the result of the test, like in this example:\nimport groovy.test.GroovyTestCaseimport groovy.test.NotYetImplementedclass Maths &#123;    static int fib(int n) &#123;        // todo: implement later    &#125;&#125;class MathsTest extends GroovyTestCase &#123;    @NotYetImplemented    void testFib() &#123;        def dataTable = [                1:1,                2:1,                3:2,                4:3,                5:5,                6:8,                7:13        ]        dataTable.each &#123; i, r -&gt;            assert Maths.fib(i) == r        &#125;    &#125;&#125;\n\nAnother advantage of using this technique is that you can write test cases for bugs before knowing how to fix them.\nIf some time in the future, a modification in the code fixes a bug by side effect, you’ll be notified because a test which was expected to fail passed.\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Test assistance"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Test assistance"]},{"title":"Groovy @groovy.transform.ASTTest","url":"/groovy/user-guides/metaprogramming/compile-time-metaprogramming/available-ast-transformations/test-assistance/groovy-groovy-transform-asttest/","content":"Groovy @groovy.transform.ASTTest@ASTTest is a special AST transformation meant to help debugging other AST transformations or the Groovy compiler itself.\nIt will let the developer “explore” the AST during compilation and perform assertions on the AST rather than on the result of compilation.\nThis means that this AST transformations gives access to the AST before the bytecode is produced.\n@ASTTest can be placed on any annotable node and requires two parameters:\n\nphase : sets at which phase at which @ASTTest will be triggered. The test code will work on the AST tree at the end of this phase.\nvalue : the code which will be executed once the phase is reached, on the annotated node\n\nCompile phase has to be chosen from one of org.codehaus.groovy.control.CompilePhase\nHowever, since it is not possible to annotate a node twice with the same annotation, you will not be able to use @ASTTest on the same node at two distinct compile phases.\nvalue is a closure expression which has access to a special variable node corresponding to the annotated node, and a helper lookup method\nFor example, you can annotate a class node like this:\nimport groovy.transform.ASTTestimport org.codehause.groovy.ast.ClassNode@ASTTest(    phase = CONVERSION,                     // we&#x27;re checking the state of the Abstract Syntax Tree after the CONVERSION phase    value = &#123;        assert node instanceof ClassNode    // node refers to the AST node which is annotated by @ASTTest        assert node.name == &#x27;Person&#x27;        // it can be used to perform assertions at compile time    &#125;)class Person &#123;&#125;\n\nOne interesting feature of @ASTTest is that if an assertion fails, then ++compilation will fail++.\nNow imagine that we want to check the behavior of an AST transformation at compile time.\nWe will take @PackageScope here, and we will want to verify that a property annotated with @PackageScope becomes a package private field.\nFor this, we have to know at which phase the transform runs, which can be found in org.codehaus.groovy.transform.PackageScopeASTTransformation : semantic analysis.\nThen a test can be written like this:\nimport groovy.transform.ASTTestimport groovy.transform.PackageScope@ASTTest(    phase = SEMANTIC_ANALYSIS,     value = &#123;    def nameNode = node.properties.find &#123; it.name == &#x27;name&#x27; &#125;    def ageNode = node.properties.find &#123; it.name == &#x27;age&#x27; &#125;    assert nameNode    assert ageNode == null  // 1    def ageField = node.getDeclaredField &#x27;age&#x27;    assert ageField.modifiers == 0&#125;)class Person &#123;    String name    @PackageScope int age&#125;\n\n1 : shouldn’t be a property anymore\nThe @ASTTest annotation can only be placed wherever the grammar allows it.\nSometimes, you would like to test the contents of an AST node which is not annotable.\nIn this case, @ASTTest provides a convenient lookup method which will search the AST for nodes which are ++labelled++ with a special token:\ndef list = lookup(&#x27;anchor&#x27;) // 1Statement stmt = list[0]    // 2\n\n1 : return the list of AST nodes which label is ‘anchor’\n2 : it is always neccessary to choose which element to process since lookup always returns a list\nImagine, for example, that you want to test the declared type of a for loop variable. Then you can do it like this:\nimport groovy.transform.ASTTestimport groovy.transform.PackageScopeimport org.codehaus.groovy.ast.ClassHelperimport org.codehaus.groovy.ast.expr.DeclarationExpressionimport org.codehaus.groovy.ast.stmt.ForStatementclass Something &#123;    @ASTTest(        phase = SEMANTIC_ANALYSIS,        value = &#123;            def forLoop = lookup(&#x27;anchor&#x27;)[0]            assert forLoop instanceof ForStatement            def decl = forLoop.collectionExpression.expressions[0]            assert decl instanceof DeclarationExpression            assert decl.variableExpression.name == &#x27;i&#x27;            assert decl.variableExpression.originType == ClassHelper.int_TYPE        &#125;    )    void someMethod() &#123;        int x = 1        int y = 10        anchor: for (int i = 0; i &lt; x+y; i++) &#123;            println &quot;$i&quot;        &#125;    &#125;&#125;\n\n@ASTTest also exposes those variables inside the test closure:\n\nnode corresponds to the annotated node, as usual\ncompilationUnit gives access to the current org.codehaus.groovy.control.CompilationUnit\ncompilePhase returns the current compile phase (org.codehaus.groovy.control.CompilePhase)\n\nThe latter is interesting if you don’t specify the phase attribute.\nIn that case, the closure will be executed after each compile phase after (and including) SEMANTIC_ANALYSIS\nThe context of the transformation is kept after each phase, giving you a chance to check what changed between two phases.\nAs an example, here is how you could dump the list of AST transformations registered on a class node:\nimport groovy.transform.ASTTestimport groovy.transform.CompileStaticimport groovy.transform.Immutableimport org.codehaus.groovy.ast.ClassNodeimport org.codehaus.groovy.control.CompilePhase@ASTTest(    value = &#123;        System.err.println &quot;Compile phase: $compilePhase&quot;        ClassNode cn = node        System.err.println &quot;Global AST xforms: $&#123;compilationUnit?.ASTTransformationsContext?.globalTransformNames&#125;&quot;        CompilePhase.values().each &#123;            def transforms = cn.getTransforms(it)            if (transforms) &#123;                System.err.println &quot;Ast xforms for phase $it:&quot;                transforms.each &#123; map -&gt;                    System.err.println(map)                &#125;            &#125;        &#125;    &#125;)@CompileStatic@Immutableclass Foo &#123;&#125;\n\nAnd here is how you can memorize variables for testing between two phases:\nimport groovy.transform.ASTTestimport groovy.transform.ToStringimport org.codehaus.groovy.ast.ClassNodeimport org.codehaus.groovy.control.CompilePhase@ASTTest(    value = &#123;        if (compilePhase == CompilePhase.INSTRUCTION_SELECTION) &#123;   // 1            println &quot;toString() was added at phase: $&#123;added&#125;&quot;            assert added == CompilePhase.CANONICALIZATION   // 2        &#125; else &#123;            if (node.getDeclaredMethods(&#x27;toString&#x27;) &amp;&amp; added == null) &#123; // 3                added = compilePhase    // 4            &#125;        &#125;    &#125;)@ToStringclass Foo &#123;    String name&#125;\n\n1 : if the current compile phase is instruction selection\n2 : then we want to make sure toSting was added at CANONICALIZATION\n3 : otherwise, if toString exists and that the variable from the context, added is null\n4 : then it means that this compile phase is the one where toString was added\n","categories":["Groovy User Guides - Metaprogramming - Compile-time metaprogramming - Available AST transformations - Test assistance"],"tags":["User Guides","Groovy","Metaprogramming","Compile-time metaprogramming","Available AST transformations","Test assistance"]},{"title":"Groovy Borrowing Methods","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/expandometaclass/groovy-borrowing-methods/","content":"Groovy Borrowing Methods通过使用 ExpandoMetaClass 还可以使用 Groovy 的方法指针语法从其他类中借用方法\nclass Person &#123;    String name&#125;class MortgageLender &#123;    def borrowMoney() &#123;        &quot;bug house&quot;    &#125;&#125;def lender = new MortgageLender()Person.metaClass.buyHouse = lender.&amp;borrowMoneydef p = new Person()assert &quot;bug house&quot; == p.buyHouse()\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses - ExpandoMetaClass"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses","ExpandoMetaClass"]},{"title":"Groovy Constructors","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/expandometaclass/groovy-constructors/","content":"Groovy Constructors构造方法可以通过添加一个特殊的 constructor 属性来进行\n&lt;&lt; 和 = 操作符都可以用来赋值一个 Closure 代码\nClosure 的入参将会作为构造方法的入参\nclass Book &#123;    String title&#125;Book.metaClass.constructor &lt;&lt; &#123;String title -&gt; new Book(title: title)&#125;def book = new Book(&#x27;Groovy in Action - 2nd Edition&#x27;)assert boot.title == &#x27;Groovy in Action - 2nd Edition&#x27;\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses - ExpandoMetaClass"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses","ExpandoMetaClass"]},{"title":"Groovy Dynamic Method Names","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/expandometaclass/groovy-dynamic-method-names/","content":"Groovy Dynamic Method Names可以在运行时动态创建方法和属性的名称\nclass Person &#123;    String name = &quot;Fred&quot;&#125;def methodName = &quot;Bob&quot;Person.metaClass.&quot;changeNameTo$&#123;methodName&#125;&quot; = &#123;-&gt;delegate.name = &quot;Bob&quot;&#125;def p = new Person()assert &quot;Fred&quot; == p.namep.changeNameToBob()assert &quot;Bob&quot; == p.name\n\n同样的概念也适用于静态方法和静态属性\nGrails 中的动态编解码概念就是使用动态方法名称实现的：\n// in HTMLCodec Classclass HTMLCodec &#123;    static encode = &#123; theTarget -&gt;         HtmlUtils.htmlEscape(theTaret.toString())    &#125;    static decode = &#123; theTarget -&gt;        HtmlUtils.htmlUnescape(theTarget.toString())    &#125;&#125;\n\n这样使用：\ndef codecs = classes.findAll &#123; it.name.endsWith(&#x27;Codec&#x27;) &#125;codecs.each &#123; codec -&gt;    // 使用动态方法名称    Object.metaClass.&quot;encodeAs$&#123;codec.name-&#x27;Codec&#x27;&#125;&quot; = &#123;        codec.newInstance().encode(delegate)    &#125;    // 使用动态方法名称    Object.metaClass.&quot;decodeFrom$&#123;codec.name-&#x27;Codec&#x27;&#125;&quot; = &#123;        codec.newInstance().decode(delegate)    &#125;&#125;def html = &#x27;&lt;html&gt;&lt;body&gt;hello&lt;/body&gt;&lt;/html&gt;&#x27;assert &#x27;&lt;html&gt;&lt;body&gt;hello&lt;/body&gt;&lt;/html&gt;&#x27; == html.encodeAsHTML\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses - ExpandoMetaClass"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses","ExpandoMetaClass"]},{"title":"Groovy ExpandoMetaClass","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/expandometaclass/groovy-expandometaclass/","content":"Groovy ExpandoMetaClassGroovy 有一个特殊的 MetaClass 叫做 ExpandoMetaClass\n它特殊的地方在于它可以使用 Closure 语法动态地添加&#x2F;修改方法，构造方法，属性，甚至静态方法\n这些修改能力在 Mocking 或者 Stubbing 的场景中非常有用\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses - ExpandoMetaClass"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses","ExpandoMetaClass"]},{"title":"Groovy Extending Interfaces","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/expandometaclass/groovy-extending-interfaces/","content":"Groovy Extending Interfaces通过 ExpandoMetaClass 可以为接口添加方法\n但是必须在应用启动之前调用 ExpandoMetaClass.enableGlobally() 方法来启用：\nList.metaClass.sizeDoubled = &#123;-&gt; delegate.size() * 2&#125;def list = []list &lt;&lt; 1list &lt;&lt; 2assert 4 == list.sizeDoubled()\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses - ExpandoMetaClass"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses","ExpandoMetaClass"]},{"title":"Groovy GroovyObject Methods","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/expandometaclass/groovy-groovyobject-methods/","content":"Groovy GroovyObject MethodsExpandoMetaClass 允许重写 invokeMethod,getProperty,setProperty 方法\n这些方法都可以在 groovy.lang.GroovyObject 类中找到\n重写 invokeMethod 方法的例子：\nclass Stuff &#123;    def invokeMe() &#123;&quot;foo&quot;&#125;&#125;Stuff.metaClass.invokeMethod = &#123; String name, args -&gt;    def metaMethod = Stuff.metaClass.getMetaMethod(name, args)    def result    if (metaMethod) result = metaMethod.invoke(delgate, args)    else &#123;        result = &quot;bar&quot;    &#125;    result&#125;def stf = new Stuff()assert &quot;foo&quot; == stf.invokeMe()assert &quot;bar&quot; == stf.doStuff()\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses - ExpandoMetaClass"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses","ExpandoMetaClass"]},{"title":"Groovy Methods","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/expandometaclass/groovy-methods/","content":"Groovy Methods当使用 metaClass 属性获取到 ExpandoMetaClass 之后，可以使用 &lt;&lt; 或者 = 操作符添加方法\n&lt;&lt; 用于添加一个新方法\n= 用于覆盖已有方法\nThe operators are applied on a non-existent property of metaClass passing an instance of a Closure code block\nclass Book &#123;    String title&#125;// 注意：titleInUpperCase 在 metaClass 是不存在的属性Bool.metaClass.titleInUpperCase &lt;&lt; &#123;-&gt; title.toUpperCase()&#125;def b = new Book(title: &quot;The Stand&quot;)assert &quot;THE STAND&quot; == b.titleInUpperCase()\n\nClosure 的入参作为方法的入参，无入参的方法使用 &#123;-&gt;...&#125; 语法\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses - ExpandoMetaClass"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses","ExpandoMetaClass"]},{"title":"Groovy Overriding Static invokeMethod","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/expandometaclass/groovy-overriding-static-invokemethod/","content":"Groovy Overriding Static invokeMethodExpandoMetaClass 允许重写静态方法，通过使用 &#39;static&#39; 语法：\nclass Stuff &#123;    static invokeMe() &#123; &quot;foo&quot; &#125;&#125;Stuff.metaClass.&#x27;static&#x27;.invokeMethod = &#123; String name, args -&gt;     def metaMethod = Stuff.metaClass.getStaticMethod(name, args)    def result    if (metaMethod) &#123;        result = metaMethod.invokeMethod(delegate, args)    &#125; else &#123;        result = &quot;bar&quot;    &#125;    result&#125;assert &quot;foo&quot; == Stuff.invokeMe()assert &quot;bar&quot; == Stuff.doStuff()\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses - ExpandoMetaClass"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses","ExpandoMetaClass"]},{"title":"Groovy Properties","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/expandometaclass/groovy-properties/","content":"Groovy PropertiesExpandoMetaClass 支持两种方式添加&#x2F;覆盖属性\n通过简单地将一个值赋值给 metaClass 的属性来声明一个可变的属性：\nclass Book &#123;    String title&#125;Book.metaClass.author = &quot;Stephen King&quot;def b = new Book()assert &quot;Stephen King&quot; == b.author\n\n另一种方式是添加 getter&#x2F;setter 实例方法：\nclass Book &#123;    String title&#125;Book.metaClass.getAuthor &lt;&lt; &#123;-&gt;&quot;Stephen King&quot;&#125;def b = new Book()assert &quot;Stephen King&quot; == b.author\n\n上述例子中的 author 属性是只读的，通过添加 setter 方法是可行的，但是属性的值必须存储起来以便后续使用：\nclass Book &#123;    String title&#125;def properties = Collections.synchronizedMap([:])Book.metaClass.setAuthor = &#123;String value-&gt;    properties[System.identityHashCode(delegate) + &quot;author&quot;] = value&#125;Book.metaClass.getAuthor = &#123;String value-&gt;    properties[System.identityHashCode(delegate) + &quot;author&quot;]&#125;\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses - ExpandoMetaClass"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses","ExpandoMetaClass"]},{"title":"Groovy Runtime Discovery","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/expandometaclass/groovy-runtime-discovery/","content":"Groovy Runtime DiscoveryExpandoMetaClass 提供了如下方法：\n\ngetMetaMethod\nhasMetaMethod\ngetMetaProperty\nhasMetaProperty\n\n为什么不直接使用反射？因为 Groovy 的方法有可能是真实存在的方法，也有可能是只在运行时有效的的方法\nThese are sometimes (but not always) represented as MetaMethods\nThe MetaMethods tell you what methods are available at runtime, thus your code can adapt.\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses - ExpandoMetaClass"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses","ExpandoMetaClass"]},{"title":"Groovy Static Methods","url":"/groovy/user-guides/metaprogramming/runtime-metaprogramming/metaclasses/expandometaclass/groovy-static-methods/","content":"Groovy Static Methods在方法名前添加 static 修饰符来添加静态方法：\nclass Book &#123; String title &#125;Book.metaClass.static.create &lt;&lt; &#123; String title -&gt;    new Book(title: title)&#125;def b = Book.create(&#x27;The Stand&#x27;)\n","categories":["Groovy User Guides - Metaprogramming - Runtime metaprogramming - Metaclasses - ExpandoMetaClass"],"tags":["User Guides","Groovy","Metaprogramming","Runtime metaprogramming","Metaclasses","ExpandoMetaClass"]}]